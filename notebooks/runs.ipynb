{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/gabe/Coding/nlpcourseproject\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "PROJECT_ROOT = Path.cwd().parent\n",
    "data_path = PROJECT_ROOT.joinpath('data')\n",
    "print(PROJECT_ROOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(data_path.joinpath('runs.csv'))\n",
    "summary_keys = data_path.joinpath('summary_keys.txt').read_text().splitlines(False)\n",
    "config_keys_to_key = ['name','prompt_task','prompt_name','prompt_id','choices','task_mode','run_name','group']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CommitmentBank[validation]:CTBase has 68 runs\n",
      "CommitmentBank[validation]:CT_ASN has 68 runs\n",
      "CommitmentBank[validation]:CT_INC has 68 runs\n",
      "CommitmentBank[validation]:CT_TNF has 68 runs\n",
      "CommitmentBank[validation]:T0 has 15 runs\n",
      "CommitmentBank[validation]:T0LenNorm has 15 runs\n",
      "CommitmentBank[validation]:T5 has 15 runs\n",
      "CommitmentBank[validation]:T5LenNorm has 15 runs\n",
      "RecognizingTextualEntailment[validation]:CTBase has 68 runs\n",
      "RecognizingTextualEntailment[validation]:T0 has 10 runs\n",
      "RecognizingTextualEntailment[validation]:T0LenNorm has 10 runs\n",
      "RecognizingTextualEntailment[validation]:T5 has 10 runs\n",
      "RecognizingTextualEntailment[validation]:T5LenNorm has 10 runs\n",
      "TheWinogradSchemaChallenge.Fixed[validation]:T0 has 10 runs\n",
      "TheWinogradSchemaChallenge.Fixed[validation]:T0LenNorm has 10 runs\n",
      "TheWinogradSchemaChallenge.Fixed[validation]:T5 has 10 runs\n",
      "TheWinogradSchemaChallenge.Fixed[validation]:T5LenNorm has 10 runs\n",
      "WordsinContext[validation]:CTBase has 68 runs\n",
      "WordsinContext[validation]:T0 has 10 runs\n",
      "WordsinContext[validation]:T0LenNorm has 10 runs\n",
      "WordsinContext[validation]:T5 has 10 runs\n",
      "WordsinContext[validation]:T5LenNorm has 10 runs\n",
      "anli[dev_r1]:CTBase has 68 runs\n",
      "anli[dev_r1]:CT_ASN has 68 runs\n",
      "anli[dev_r1]:CT_INC has 68 runs\n",
      "anli[dev_r1]:CT_TNF has 68 runs\n",
      "anli[dev_r1]:T0 has 15 runs\n",
      "anli[dev_r1]:T0LenNorm has 15 runs\n",
      "anli[dev_r1]:T5 has 15 runs\n",
      "anli[dev_r1]:T5LenNorm has 15 runs\n",
      "anli[dev_r2]:CTBase has 68 runs\n",
      "anli[dev_r2]:CT_ASN has 68 runs\n",
      "anli[dev_r2]:CT_INC has 68 runs\n",
      "anli[dev_r2]:CT_TNF has 68 runs\n",
      "anli[dev_r2]:T0 has 15 runs\n",
      "anli[dev_r2]:T0LenNorm has 15 runs\n",
      "anli[dev_r2]:T5 has 15 runs\n",
      "anli[dev_r2]:T5LenNorm has 15 runs\n",
      "anli[dev_r3]:CTBase has 68 runs\n",
      "anli[dev_r3]:CT_ASN has 68 runs\n",
      "anli[dev_r3]:CT_INC has 68 runs\n",
      "anli[dev_r3]:CT_TNF has 68 runs\n",
      "anli[dev_r3]:T0 has 15 runs\n",
      "anli[dev_r3]:T0LenNorm has 15 runs\n",
      "anli[dev_r3]:T5 has 15 runs\n",
      "anli[dev_r3]:T5LenNorm has 15 runs\n",
      "craigslist_bargains[validation]:CTBase has 68 runs\n"
     ]
    }
   ],
   "source": [
    "group_dicts = {}\n",
    "for group_name,group_df in data.groupby('group'):\n",
    "    group_dfs=[]\n",
    "    for run_name, run_df in group_df.groupby('run_name'):\n",
    "        print(f\"{group_name}:{run_name} has {len(run_df)} runs\")\n",
    "        sliced_df = run_df[['accuracy','f1','f1_choice_1','f1_choice_2','f1_choice_3','f1_choice_4','logits/range_mean',*config_keys_to_key]].copy()\n",
    "        for col in ['accuracy','f1']:\n",
    "            sliced_df[f\"{col}_rank\"]=run_df[col].rank(ascending=False)\n",
    "        for col in ['logits/range_mean']:\n",
    "            sliced_df[f\"{col}_rank\"]=run_df[col].rank(ascending=True)\n",
    "        \n",
    "        group_dfs.append(sliced_df)\n",
    "    group_dicts[group_name]=pd.concat(group_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "      <th>f1_choice_1</th>\n",
       "      <th>f1_choice_2</th>\n",
       "      <th>f1_choice_3</th>\n",
       "      <th>f1_choice_4</th>\n",
       "      <th>logits/range_mean</th>\n",
       "      <th>accuracy_rank</th>\n",
       "      <th>f1_rank</th>\n",
       "      <th>logits/range_mean_rank</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prompt_id</th>\n",
       "      <th>prompt_task</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>145dd841-b971-4550-bc88-305ad3278d58</th>\n",
       "      <th>craigslist_bargains</th>\n",
       "      <td>47.292419</td>\n",
       "      <td>64.215686</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>64.215686</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.301045</td>\n",
       "      <td>68.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>63.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78d1b487-c535-4a0d-ae49-055d321db3fd</th>\n",
       "      <th>craigslist_bargains</th>\n",
       "      <td>49.458484</td>\n",
       "      <td>65.174129</td>\n",
       "      <td>7.894737</td>\n",
       "      <td>65.174129</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.596551</td>\n",
       "      <td>67.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cc2958ca-e826-4fef-96aa-1c4caa188605</th>\n",
       "      <th>BAREBONES</th>\n",
       "      <td>49.819495</td>\n",
       "      <td>65.162907</td>\n",
       "      <td>10.322581</td>\n",
       "      <td>65.162907</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.583414</td>\n",
       "      <td>66.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>67.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27010b55-dd5b-4ee9-9e14-a4b809aa6cdb</th>\n",
       "      <th>craigslist_bargains</th>\n",
       "      <td>50.180505</td>\n",
       "      <td>65.326633</td>\n",
       "      <td>11.538462</td>\n",
       "      <td>65.326633</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.519728</td>\n",
       "      <td>64.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14e73f39-a0d1-44c2-b9a4-4e48f9f1608e</th>\n",
       "      <th>super_glue/wic</th>\n",
       "      <td>50.180505</td>\n",
       "      <td>65.326633</td>\n",
       "      <td>11.538462</td>\n",
       "      <td>65.326633</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.144426</td>\n",
       "      <td>64.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>61.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9b613182-c6ab-4427-9221-3d68f6d62765</th>\n",
       "      <th>anli</th>\n",
       "      <td>72.924188</td>\n",
       "      <td>77.064220</td>\n",
       "      <td>66.960352</td>\n",
       "      <td>77.064220</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.273330</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31fb1471-b3c4-4f99-9134-87239a4ebfe9</th>\n",
       "      <th>BIG-BENCH</th>\n",
       "      <td>73.285199</td>\n",
       "      <td>76.582278</td>\n",
       "      <td>68.907563</td>\n",
       "      <td>76.582278</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.193348</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>091ba88e-d208-4a3a-ada7-d9698aeb5568</th>\n",
       "      <th>math_qa</th>\n",
       "      <td>73.285199</td>\n",
       "      <td>75.496689</td>\n",
       "      <td>70.634921</td>\n",
       "      <td>75.496689</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.897859</td>\n",
       "      <td>3.5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8c4c81cc-ca54-45fc-a69a-4b97a5f2b465</th>\n",
       "      <th>math_qa</th>\n",
       "      <td>74.368231</td>\n",
       "      <td>76.721311</td>\n",
       "      <td>71.485944</td>\n",
       "      <td>76.721311</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.881974</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a1f9951e-2b6b-4530-9636-9cdf4c1658c5</th>\n",
       "      <th>super_glue/copa</th>\n",
       "      <td>75.451264</td>\n",
       "      <td>78.205128</td>\n",
       "      <td>71.900826</td>\n",
       "      <td>78.205128</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.236896</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>68 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                           accuracy  \\\n",
       "prompt_id                            prompt_task                      \n",
       "145dd841-b971-4550-bc88-305ad3278d58 craigslist_bargains  47.292419   \n",
       "78d1b487-c535-4a0d-ae49-055d321db3fd craigslist_bargains  49.458484   \n",
       "cc2958ca-e826-4fef-96aa-1c4caa188605 BAREBONES            49.819495   \n",
       "27010b55-dd5b-4ee9-9e14-a4b809aa6cdb craigslist_bargains  50.180505   \n",
       "14e73f39-a0d1-44c2-b9a4-4e48f9f1608e super_glue/wic       50.180505   \n",
       "...                                                             ...   \n",
       "9b613182-c6ab-4427-9221-3d68f6d62765 anli                 72.924188   \n",
       "31fb1471-b3c4-4f99-9134-87239a4ebfe9 BIG-BENCH            73.285199   \n",
       "091ba88e-d208-4a3a-ada7-d9698aeb5568 math_qa              73.285199   \n",
       "8c4c81cc-ca54-45fc-a69a-4b97a5f2b465 math_qa              74.368231   \n",
       "a1f9951e-2b6b-4530-9636-9cdf4c1658c5 super_glue/copa      75.451264   \n",
       "\n",
       "                                                                 f1  \\\n",
       "prompt_id                            prompt_task                      \n",
       "145dd841-b971-4550-bc88-305ad3278d58 craigslist_bargains  64.215686   \n",
       "78d1b487-c535-4a0d-ae49-055d321db3fd craigslist_bargains  65.174129   \n",
       "cc2958ca-e826-4fef-96aa-1c4caa188605 BAREBONES            65.162907   \n",
       "27010b55-dd5b-4ee9-9e14-a4b809aa6cdb craigslist_bargains  65.326633   \n",
       "14e73f39-a0d1-44c2-b9a4-4e48f9f1608e super_glue/wic       65.326633   \n",
       "...                                                             ...   \n",
       "9b613182-c6ab-4427-9221-3d68f6d62765 anli                 77.064220   \n",
       "31fb1471-b3c4-4f99-9134-87239a4ebfe9 BIG-BENCH            76.582278   \n",
       "091ba88e-d208-4a3a-ada7-d9698aeb5568 math_qa              75.496689   \n",
       "8c4c81cc-ca54-45fc-a69a-4b97a5f2b465 math_qa              76.721311   \n",
       "a1f9951e-2b6b-4530-9636-9cdf4c1658c5 super_glue/copa      78.205128   \n",
       "\n",
       "                                                          f1_choice_1  \\\n",
       "prompt_id                            prompt_task                        \n",
       "145dd841-b971-4550-bc88-305ad3278d58 craigslist_bargains     0.000000   \n",
       "78d1b487-c535-4a0d-ae49-055d321db3fd craigslist_bargains     7.894737   \n",
       "cc2958ca-e826-4fef-96aa-1c4caa188605 BAREBONES              10.322581   \n",
       "27010b55-dd5b-4ee9-9e14-a4b809aa6cdb craigslist_bargains    11.538462   \n",
       "14e73f39-a0d1-44c2-b9a4-4e48f9f1608e super_glue/wic         11.538462   \n",
       "...                                                               ...   \n",
       "9b613182-c6ab-4427-9221-3d68f6d62765 anli                   66.960352   \n",
       "31fb1471-b3c4-4f99-9134-87239a4ebfe9 BIG-BENCH              68.907563   \n",
       "091ba88e-d208-4a3a-ada7-d9698aeb5568 math_qa                70.634921   \n",
       "8c4c81cc-ca54-45fc-a69a-4b97a5f2b465 math_qa                71.485944   \n",
       "a1f9951e-2b6b-4530-9636-9cdf4c1658c5 super_glue/copa        71.900826   \n",
       "\n",
       "                                                          f1_choice_2  \\\n",
       "prompt_id                            prompt_task                        \n",
       "145dd841-b971-4550-bc88-305ad3278d58 craigslist_bargains    64.215686   \n",
       "78d1b487-c535-4a0d-ae49-055d321db3fd craigslist_bargains    65.174129   \n",
       "cc2958ca-e826-4fef-96aa-1c4caa188605 BAREBONES              65.162907   \n",
       "27010b55-dd5b-4ee9-9e14-a4b809aa6cdb craigslist_bargains    65.326633   \n",
       "14e73f39-a0d1-44c2-b9a4-4e48f9f1608e super_glue/wic         65.326633   \n",
       "...                                                               ...   \n",
       "9b613182-c6ab-4427-9221-3d68f6d62765 anli                   77.064220   \n",
       "31fb1471-b3c4-4f99-9134-87239a4ebfe9 BIG-BENCH              76.582278   \n",
       "091ba88e-d208-4a3a-ada7-d9698aeb5568 math_qa                75.496689   \n",
       "8c4c81cc-ca54-45fc-a69a-4b97a5f2b465 math_qa                76.721311   \n",
       "a1f9951e-2b6b-4530-9636-9cdf4c1658c5 super_glue/copa        78.205128   \n",
       "\n",
       "                                                          f1_choice_3  \\\n",
       "prompt_id                            prompt_task                        \n",
       "145dd841-b971-4550-bc88-305ad3278d58 craigslist_bargains          NaN   \n",
       "78d1b487-c535-4a0d-ae49-055d321db3fd craigslist_bargains          NaN   \n",
       "cc2958ca-e826-4fef-96aa-1c4caa188605 BAREBONES                    NaN   \n",
       "27010b55-dd5b-4ee9-9e14-a4b809aa6cdb craigslist_bargains          NaN   \n",
       "14e73f39-a0d1-44c2-b9a4-4e48f9f1608e super_glue/wic               NaN   \n",
       "...                                                               ...   \n",
       "9b613182-c6ab-4427-9221-3d68f6d62765 anli                         NaN   \n",
       "31fb1471-b3c4-4f99-9134-87239a4ebfe9 BIG-BENCH                    NaN   \n",
       "091ba88e-d208-4a3a-ada7-d9698aeb5568 math_qa                      NaN   \n",
       "8c4c81cc-ca54-45fc-a69a-4b97a5f2b465 math_qa                      NaN   \n",
       "a1f9951e-2b6b-4530-9636-9cdf4c1658c5 super_glue/copa              NaN   \n",
       "\n",
       "                                                          f1_choice_4  \\\n",
       "prompt_id                            prompt_task                        \n",
       "145dd841-b971-4550-bc88-305ad3278d58 craigslist_bargains          NaN   \n",
       "78d1b487-c535-4a0d-ae49-055d321db3fd craigslist_bargains          NaN   \n",
       "cc2958ca-e826-4fef-96aa-1c4caa188605 BAREBONES                    NaN   \n",
       "27010b55-dd5b-4ee9-9e14-a4b809aa6cdb craigslist_bargains          NaN   \n",
       "14e73f39-a0d1-44c2-b9a4-4e48f9f1608e super_glue/wic               NaN   \n",
       "...                                                               ...   \n",
       "9b613182-c6ab-4427-9221-3d68f6d62765 anli                         NaN   \n",
       "31fb1471-b3c4-4f99-9134-87239a4ebfe9 BIG-BENCH                    NaN   \n",
       "091ba88e-d208-4a3a-ada7-d9698aeb5568 math_qa                      NaN   \n",
       "8c4c81cc-ca54-45fc-a69a-4b97a5f2b465 math_qa                      NaN   \n",
       "a1f9951e-2b6b-4530-9636-9cdf4c1658c5 super_glue/copa              NaN   \n",
       "\n",
       "                                                          logits/range_mean  \\\n",
       "prompt_id                            prompt_task                              \n",
       "145dd841-b971-4550-bc88-305ad3278d58 craigslist_bargains           2.301045   \n",
       "78d1b487-c535-4a0d-ae49-055d321db3fd craigslist_bargains           1.596551   \n",
       "cc2958ca-e826-4fef-96aa-1c4caa188605 BAREBONES                     2.583414   \n",
       "27010b55-dd5b-4ee9-9e14-a4b809aa6cdb craigslist_bargains           1.519728   \n",
       "14e73f39-a0d1-44c2-b9a4-4e48f9f1608e super_glue/wic                2.144426   \n",
       "...                                                                     ...   \n",
       "9b613182-c6ab-4427-9221-3d68f6d62765 anli                          1.273330   \n",
       "31fb1471-b3c4-4f99-9134-87239a4ebfe9 BIG-BENCH                     1.193348   \n",
       "091ba88e-d208-4a3a-ada7-d9698aeb5568 math_qa                       0.897859   \n",
       "8c4c81cc-ca54-45fc-a69a-4b97a5f2b465 math_qa                       0.881974   \n",
       "a1f9951e-2b6b-4530-9636-9cdf4c1658c5 super_glue/copa               1.236896   \n",
       "\n",
       "                                                          accuracy_rank  \\\n",
       "prompt_id                            prompt_task                          \n",
       "145dd841-b971-4550-bc88-305ad3278d58 craigslist_bargains           68.0   \n",
       "78d1b487-c535-4a0d-ae49-055d321db3fd craigslist_bargains           67.0   \n",
       "cc2958ca-e826-4fef-96aa-1c4caa188605 BAREBONES                     66.0   \n",
       "27010b55-dd5b-4ee9-9e14-a4b809aa6cdb craigslist_bargains           64.0   \n",
       "14e73f39-a0d1-44c2-b9a4-4e48f9f1608e super_glue/wic                64.0   \n",
       "...                                                                 ...   \n",
       "9b613182-c6ab-4427-9221-3d68f6d62765 anli                           5.0   \n",
       "31fb1471-b3c4-4f99-9134-87239a4ebfe9 BIG-BENCH                      3.5   \n",
       "091ba88e-d208-4a3a-ada7-d9698aeb5568 math_qa                        3.5   \n",
       "8c4c81cc-ca54-45fc-a69a-4b97a5f2b465 math_qa                        2.0   \n",
       "a1f9951e-2b6b-4530-9636-9cdf4c1658c5 super_glue/copa                1.0   \n",
       "\n",
       "                                                          f1_rank  \\\n",
       "prompt_id                            prompt_task                    \n",
       "145dd841-b971-4550-bc88-305ad3278d58 craigslist_bargains     64.0   \n",
       "78d1b487-c535-4a0d-ae49-055d321db3fd craigslist_bargains     62.0   \n",
       "cc2958ca-e826-4fef-96aa-1c4caa188605 BAREBONES               63.0   \n",
       "27010b55-dd5b-4ee9-9e14-a4b809aa6cdb craigslist_bargains     60.0   \n",
       "14e73f39-a0d1-44c2-b9a4-4e48f9f1608e super_glue/wic          60.0   \n",
       "...                                                           ...   \n",
       "9b613182-c6ab-4427-9221-3d68f6d62765 anli                     2.0   \n",
       "31fb1471-b3c4-4f99-9134-87239a4ebfe9 BIG-BENCH                4.0   \n",
       "091ba88e-d208-4a3a-ada7-d9698aeb5568 math_qa                  6.0   \n",
       "8c4c81cc-ca54-45fc-a69a-4b97a5f2b465 math_qa                  3.0   \n",
       "a1f9951e-2b6b-4530-9636-9cdf4c1658c5 super_glue/copa          1.0   \n",
       "\n",
       "                                                          logits/range_mean_rank  \n",
       "prompt_id                            prompt_task                                  \n",
       "145dd841-b971-4550-bc88-305ad3278d58 craigslist_bargains                    63.0  \n",
       "78d1b487-c535-4a0d-ae49-055d321db3fd craigslist_bargains                    38.0  \n",
       "cc2958ca-e826-4fef-96aa-1c4caa188605 BAREBONES                              67.0  \n",
       "27010b55-dd5b-4ee9-9e14-a4b809aa6cdb craigslist_bargains                    33.0  \n",
       "14e73f39-a0d1-44c2-b9a4-4e48f9f1608e super_glue/wic                         61.0  \n",
       "...                                                                          ...  \n",
       "9b613182-c6ab-4427-9221-3d68f6d62765 anli                                   16.0  \n",
       "31fb1471-b3c4-4f99-9134-87239a4ebfe9 BIG-BENCH                              10.0  \n",
       "091ba88e-d208-4a3a-ada7-d9698aeb5568 math_qa                                 4.0  \n",
       "8c4c81cc-ca54-45fc-a69a-4b97a5f2b465 math_qa                                 3.0  \n",
       "a1f9951e-2b6b-4530-9636-9cdf4c1658c5 super_glue/copa                        13.0  \n",
       "\n",
       "[68 rows x 10 columns]"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group_name = \"RecognizingTextualEntailment[validation]\"\n",
    "testing_df = group_dicts[group_name][group_dicts[group_name]['run_name'].str.contains('CTBase')]\n",
    "means = testing_df.groupby(['prompt_id','prompt_task']).median().sort_values(by='accuracy')\n",
    "means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "      <th>f1_choice_1</th>\n",
       "      <th>f1_choice_2</th>\n",
       "      <th>f1_choice_3</th>\n",
       "      <th>f1_choice_4</th>\n",
       "      <th>logits/range_mean</th>\n",
       "      <th>accuracy_rank</th>\n",
       "      <th>f1_rank</th>\n",
       "      <th>logits/range_mean_rank</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prompt_id</th>\n",
       "      <th>prompt_task</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>a850110d-f1a3-49b4-949a-d3bfe9f81344</th>\n",
       "      <th>anli</th>\n",
       "      <td>34.30</td>\n",
       "      <td>22.901274</td>\n",
       "      <td>43.003170</td>\n",
       "      <td>14.968815</td>\n",
       "      <td>15.030886</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.618745</td>\n",
       "      <td>8.00</td>\n",
       "      <td>17.5</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3503ead5-4fa5-4f77-95dc-f0c2ed3eecdc</th>\n",
       "      <th>super_glue/wic</th>\n",
       "      <td>33.90</td>\n",
       "      <td>23.534480</td>\n",
       "      <td>11.741081</td>\n",
       "      <td>23.994417</td>\n",
       "      <td>43.730415</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.571782</td>\n",
       "      <td>11.25</td>\n",
       "      <td>15.5</td>\n",
       "      <td>49.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>e5eaa3ee-e537-4d20-9dfa-6084db54f2ef</th>\n",
       "      <th>BAREBONES</th>\n",
       "      <td>34.15</td>\n",
       "      <td>26.538387</td>\n",
       "      <td>7.485425</td>\n",
       "      <td>45.063542</td>\n",
       "      <td>36.659226</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.668127</td>\n",
       "      <td>12.25</td>\n",
       "      <td>23.0</td>\n",
       "      <td>39.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cc2958ca-e826-4fef-96aa-1c4caa188605</th>\n",
       "      <th>BAREBONES</th>\n",
       "      <td>34.70</td>\n",
       "      <td>28.792142</td>\n",
       "      <td>12.178825</td>\n",
       "      <td>35.139164</td>\n",
       "      <td>44.359188</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.241661</td>\n",
       "      <td>13.75</td>\n",
       "      <td>5.5</td>\n",
       "      <td>37.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a1f9951e-2b6b-4530-9636-9cdf4c1658c5</th>\n",
       "      <th>super_glue/copa</th>\n",
       "      <td>34.05</td>\n",
       "      <td>20.737985</td>\n",
       "      <td>49.889050</td>\n",
       "      <td>0.293255</td>\n",
       "      <td>0.886783</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.636816</td>\n",
       "      <td>16.50</td>\n",
       "      <td>46.5</td>\n",
       "      <td>28.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4cfe4126-b9f5-44eb-8a98-973987c5f32e</th>\n",
       "      <th>xsum</th>\n",
       "      <td>31.85</td>\n",
       "      <td>21.442854</td>\n",
       "      <td>8.916424</td>\n",
       "      <td>46.416379</td>\n",
       "      <td>16.633277</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.952448</td>\n",
       "      <td>56.75</td>\n",
       "      <td>32.5</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c97e7bbf-b7f0-4cee-ada5-431ce7d606cc</th>\n",
       "      <th>sem_eval_2010_task_8</th>\n",
       "      <td>32.05</td>\n",
       "      <td>20.863235</td>\n",
       "      <td>16.236908</td>\n",
       "      <td>37.781977</td>\n",
       "      <td>18.463542</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.158229</td>\n",
       "      <td>59.25</td>\n",
       "      <td>21.0</td>\n",
       "      <td>52.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4f08e9d4-bcff-4bc0-9902-87c497625d17</th>\n",
       "      <th>craffel/openai_lambada</th>\n",
       "      <td>32.45</td>\n",
       "      <td>19.753495</td>\n",
       "      <td>7.158244</td>\n",
       "      <td>44.417039</td>\n",
       "      <td>13.909598</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.190070</td>\n",
       "      <td>59.50</td>\n",
       "      <td>41.0</td>\n",
       "      <td>38.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f3f924f3-5327-405b-b0a0-96f30a59136c</th>\n",
       "      <th>BIG-BENCH</th>\n",
       "      <td>32.20</td>\n",
       "      <td>18.593715</td>\n",
       "      <td>6.918624</td>\n",
       "      <td>44.571910</td>\n",
       "      <td>13.106796</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.519800</td>\n",
       "      <td>60.75</td>\n",
       "      <td>46.0</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>774b4349-0524-4a34-881b-b344f8f5c34e</th>\n",
       "      <th>craffel/openai_lambada</th>\n",
       "      <td>32.60</td>\n",
       "      <td>19.375959</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>46.037188</td>\n",
       "      <td>12.947220</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.476201</td>\n",
       "      <td>61.50</td>\n",
       "      <td>46.0</td>\n",
       "      <td>38.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>68 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                             accuracy  \\\n",
       "prompt_id                            prompt_task                        \n",
       "a850110d-f1a3-49b4-949a-d3bfe9f81344 anli                       34.30   \n",
       "3503ead5-4fa5-4f77-95dc-f0c2ed3eecdc super_glue/wic             33.90   \n",
       "e5eaa3ee-e537-4d20-9dfa-6084db54f2ef BAREBONES                  34.15   \n",
       "cc2958ca-e826-4fef-96aa-1c4caa188605 BAREBONES                  34.70   \n",
       "a1f9951e-2b6b-4530-9636-9cdf4c1658c5 super_glue/copa            34.05   \n",
       "...                                                               ...   \n",
       "4cfe4126-b9f5-44eb-8a98-973987c5f32e xsum                       31.85   \n",
       "c97e7bbf-b7f0-4cee-ada5-431ce7d606cc sem_eval_2010_task_8       32.05   \n",
       "4f08e9d4-bcff-4bc0-9902-87c497625d17 craffel/openai_lambada     32.45   \n",
       "f3f924f3-5327-405b-b0a0-96f30a59136c BIG-BENCH                  32.20   \n",
       "774b4349-0524-4a34-881b-b344f8f5c34e craffel/openai_lambada     32.60   \n",
       "\n",
       "                                                                    f1  \\\n",
       "prompt_id                            prompt_task                         \n",
       "a850110d-f1a3-49b4-949a-d3bfe9f81344 anli                    22.901274   \n",
       "3503ead5-4fa5-4f77-95dc-f0c2ed3eecdc super_glue/wic          23.534480   \n",
       "e5eaa3ee-e537-4d20-9dfa-6084db54f2ef BAREBONES               26.538387   \n",
       "cc2958ca-e826-4fef-96aa-1c4caa188605 BAREBONES               28.792142   \n",
       "a1f9951e-2b6b-4530-9636-9cdf4c1658c5 super_glue/copa         20.737985   \n",
       "...                                                                ...   \n",
       "4cfe4126-b9f5-44eb-8a98-973987c5f32e xsum                    21.442854   \n",
       "c97e7bbf-b7f0-4cee-ada5-431ce7d606cc sem_eval_2010_task_8    20.863235   \n",
       "4f08e9d4-bcff-4bc0-9902-87c497625d17 craffel/openai_lambada  19.753495   \n",
       "f3f924f3-5327-405b-b0a0-96f30a59136c BIG-BENCH               18.593715   \n",
       "774b4349-0524-4a34-881b-b344f8f5c34e craffel/openai_lambada  19.375959   \n",
       "\n",
       "                                                             f1_choice_1  \\\n",
       "prompt_id                            prompt_task                           \n",
       "a850110d-f1a3-49b4-949a-d3bfe9f81344 anli                      43.003170   \n",
       "3503ead5-4fa5-4f77-95dc-f0c2ed3eecdc super_glue/wic            11.741081   \n",
       "e5eaa3ee-e537-4d20-9dfa-6084db54f2ef BAREBONES                  7.485425   \n",
       "cc2958ca-e826-4fef-96aa-1c4caa188605 BAREBONES                 12.178825   \n",
       "a1f9951e-2b6b-4530-9636-9cdf4c1658c5 super_glue/copa           49.889050   \n",
       "...                                                                  ...   \n",
       "4cfe4126-b9f5-44eb-8a98-973987c5f32e xsum                       8.916424   \n",
       "c97e7bbf-b7f0-4cee-ada5-431ce7d606cc sem_eval_2010_task_8      16.236908   \n",
       "4f08e9d4-bcff-4bc0-9902-87c497625d17 craffel/openai_lambada     7.158244   \n",
       "f3f924f3-5327-405b-b0a0-96f30a59136c BIG-BENCH                  6.918624   \n",
       "774b4349-0524-4a34-881b-b344f8f5c34e craffel/openai_lambada     0.857143   \n",
       "\n",
       "                                                             f1_choice_2  \\\n",
       "prompt_id                            prompt_task                           \n",
       "a850110d-f1a3-49b4-949a-d3bfe9f81344 anli                      14.968815   \n",
       "3503ead5-4fa5-4f77-95dc-f0c2ed3eecdc super_glue/wic            23.994417   \n",
       "e5eaa3ee-e537-4d20-9dfa-6084db54f2ef BAREBONES                 45.063542   \n",
       "cc2958ca-e826-4fef-96aa-1c4caa188605 BAREBONES                 35.139164   \n",
       "a1f9951e-2b6b-4530-9636-9cdf4c1658c5 super_glue/copa            0.293255   \n",
       "...                                                                  ...   \n",
       "4cfe4126-b9f5-44eb-8a98-973987c5f32e xsum                      46.416379   \n",
       "c97e7bbf-b7f0-4cee-ada5-431ce7d606cc sem_eval_2010_task_8      37.781977   \n",
       "4f08e9d4-bcff-4bc0-9902-87c497625d17 craffel/openai_lambada    44.417039   \n",
       "f3f924f3-5327-405b-b0a0-96f30a59136c BIG-BENCH                 44.571910   \n",
       "774b4349-0524-4a34-881b-b344f8f5c34e craffel/openai_lambada    46.037188   \n",
       "\n",
       "                                                             f1_choice_3  \\\n",
       "prompt_id                            prompt_task                           \n",
       "a850110d-f1a3-49b4-949a-d3bfe9f81344 anli                      15.030886   \n",
       "3503ead5-4fa5-4f77-95dc-f0c2ed3eecdc super_glue/wic            43.730415   \n",
       "e5eaa3ee-e537-4d20-9dfa-6084db54f2ef BAREBONES                 36.659226   \n",
       "cc2958ca-e826-4fef-96aa-1c4caa188605 BAREBONES                 44.359188   \n",
       "a1f9951e-2b6b-4530-9636-9cdf4c1658c5 super_glue/copa            0.886783   \n",
       "...                                                                  ...   \n",
       "4cfe4126-b9f5-44eb-8a98-973987c5f32e xsum                      16.633277   \n",
       "c97e7bbf-b7f0-4cee-ada5-431ce7d606cc sem_eval_2010_task_8      18.463542   \n",
       "4f08e9d4-bcff-4bc0-9902-87c497625d17 craffel/openai_lambada    13.909598   \n",
       "f3f924f3-5327-405b-b0a0-96f30a59136c BIG-BENCH                 13.106796   \n",
       "774b4349-0524-4a34-881b-b344f8f5c34e craffel/openai_lambada    12.947220   \n",
       "\n",
       "                                                             f1_choice_4  \\\n",
       "prompt_id                            prompt_task                           \n",
       "a850110d-f1a3-49b4-949a-d3bfe9f81344 anli                            NaN   \n",
       "3503ead5-4fa5-4f77-95dc-f0c2ed3eecdc super_glue/wic                  NaN   \n",
       "e5eaa3ee-e537-4d20-9dfa-6084db54f2ef BAREBONES                       NaN   \n",
       "cc2958ca-e826-4fef-96aa-1c4caa188605 BAREBONES                       NaN   \n",
       "a1f9951e-2b6b-4530-9636-9cdf4c1658c5 super_glue/copa                 NaN   \n",
       "...                                                                  ...   \n",
       "4cfe4126-b9f5-44eb-8a98-973987c5f32e xsum                            NaN   \n",
       "c97e7bbf-b7f0-4cee-ada5-431ce7d606cc sem_eval_2010_task_8            NaN   \n",
       "4f08e9d4-bcff-4bc0-9902-87c497625d17 craffel/openai_lambada          NaN   \n",
       "f3f924f3-5327-405b-b0a0-96f30a59136c BIG-BENCH                       NaN   \n",
       "774b4349-0524-4a34-881b-b344f8f5c34e craffel/openai_lambada          NaN   \n",
       "\n",
       "                                                             logits/range_mean  \\\n",
       "prompt_id                            prompt_task                                 \n",
       "a850110d-f1a3-49b4-949a-d3bfe9f81344 anli                             3.618745   \n",
       "3503ead5-4fa5-4f77-95dc-f0c2ed3eecdc super_glue/wic                   6.571782   \n",
       "e5eaa3ee-e537-4d20-9dfa-6084db54f2ef BAREBONES                        4.668127   \n",
       "cc2958ca-e826-4fef-96aa-1c4caa188605 BAREBONES                        4.241661   \n",
       "a1f9951e-2b6b-4530-9636-9cdf4c1658c5 super_glue/copa                  2.636816   \n",
       "...                                                                        ...   \n",
       "4cfe4126-b9f5-44eb-8a98-973987c5f32e xsum                             2.952448   \n",
       "c97e7bbf-b7f0-4cee-ada5-431ce7d606cc sem_eval_2010_task_8             6.158229   \n",
       "4f08e9d4-bcff-4bc0-9902-87c497625d17 craffel/openai_lambada           5.190070   \n",
       "f3f924f3-5327-405b-b0a0-96f30a59136c BIG-BENCH                        5.519800   \n",
       "774b4349-0524-4a34-881b-b344f8f5c34e craffel/openai_lambada           4.476201   \n",
       "\n",
       "                                                             accuracy_rank  \\\n",
       "prompt_id                            prompt_task                             \n",
       "a850110d-f1a3-49b4-949a-d3bfe9f81344 anli                             8.00   \n",
       "3503ead5-4fa5-4f77-95dc-f0c2ed3eecdc super_glue/wic                  11.25   \n",
       "e5eaa3ee-e537-4d20-9dfa-6084db54f2ef BAREBONES                       12.25   \n",
       "cc2958ca-e826-4fef-96aa-1c4caa188605 BAREBONES                       13.75   \n",
       "a1f9951e-2b6b-4530-9636-9cdf4c1658c5 super_glue/copa                 16.50   \n",
       "...                                                                    ...   \n",
       "4cfe4126-b9f5-44eb-8a98-973987c5f32e xsum                            56.75   \n",
       "c97e7bbf-b7f0-4cee-ada5-431ce7d606cc sem_eval_2010_task_8            59.25   \n",
       "4f08e9d4-bcff-4bc0-9902-87c497625d17 craffel/openai_lambada          59.50   \n",
       "f3f924f3-5327-405b-b0a0-96f30a59136c BIG-BENCH                       60.75   \n",
       "774b4349-0524-4a34-881b-b344f8f5c34e craffel/openai_lambada          61.50   \n",
       "\n",
       "                                                             f1_rank  \\\n",
       "prompt_id                            prompt_task                       \n",
       "a850110d-f1a3-49b4-949a-d3bfe9f81344 anli                       17.5   \n",
       "3503ead5-4fa5-4f77-95dc-f0c2ed3eecdc super_glue/wic             15.5   \n",
       "e5eaa3ee-e537-4d20-9dfa-6084db54f2ef BAREBONES                  23.0   \n",
       "cc2958ca-e826-4fef-96aa-1c4caa188605 BAREBONES                   5.5   \n",
       "a1f9951e-2b6b-4530-9636-9cdf4c1658c5 super_glue/copa            46.5   \n",
       "...                                                              ...   \n",
       "4cfe4126-b9f5-44eb-8a98-973987c5f32e xsum                       32.5   \n",
       "c97e7bbf-b7f0-4cee-ada5-431ce7d606cc sem_eval_2010_task_8       21.0   \n",
       "4f08e9d4-bcff-4bc0-9902-87c497625d17 craffel/openai_lambada     41.0   \n",
       "f3f924f3-5327-405b-b0a0-96f30a59136c BIG-BENCH                  46.0   \n",
       "774b4349-0524-4a34-881b-b344f8f5c34e craffel/openai_lambada     46.0   \n",
       "\n",
       "                                                             logits/range_mean_rank  \n",
       "prompt_id                            prompt_task                                     \n",
       "a850110d-f1a3-49b4-949a-d3bfe9f81344 anli                                      19.0  \n",
       "3503ead5-4fa5-4f77-95dc-f0c2ed3eecdc super_glue/wic                            49.0  \n",
       "e5eaa3ee-e537-4d20-9dfa-6084db54f2ef BAREBONES                                 39.0  \n",
       "cc2958ca-e826-4fef-96aa-1c4caa188605 BAREBONES                                 37.5  \n",
       "a1f9951e-2b6b-4530-9636-9cdf4c1658c5 super_glue/copa                           28.0  \n",
       "...                                                                             ...  \n",
       "4cfe4126-b9f5-44eb-8a98-973987c5f32e xsum                                      23.0  \n",
       "c97e7bbf-b7f0-4cee-ada5-431ce7d606cc sem_eval_2010_task_8                      52.0  \n",
       "4f08e9d4-bcff-4bc0-9902-87c497625d17 craffel/openai_lambada                    38.5  \n",
       "f3f924f3-5327-405b-b0a0-96f30a59136c BIG-BENCH                                 40.0  \n",
       "774b4349-0524-4a34-881b-b344f8f5c34e craffel/openai_lambada                    38.5  \n",
       "\n",
       "[68 rows x 10 columns]"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'logits/choice_1_rank_mean', 'accuracy', 'f1_choice_2',\n",
       "       'input_len/std', 'input_len/mean', 'logits/diff_1_to_2_std',\n",
       "       'logits/diff_1_to_2_mean', 'logits/choice_2_rank_std', 'f1_choice_1',\n",
       "       'logits/choice_2_rank_mean', 'logits/choice_3_rank_mean',\n",
       "       'logits/diff_2_to_3_std', 'f1_choice_3', 'predictions',\n",
       "       'logits/range_std', 'logits/range_mean', 'logits/diff_2_to_3_mean',\n",
       "       'logits/choice_1_rank_std', 'f1', 'logits/choice_3_rank_std', 'debug',\n",
       "       'force', 'split', 'is_mcq', 'choices', 'num_proc', 'run_name',\n",
       "       'prompt_id', 'task.name', 'task_mode', 'base_model', 'batch_size',\n",
       "       'model_name', 'cuda_device', 'has_choices', 'prompt_name',\n",
       "       'prompt_path', 'prompt_task', 'choice_count', 'group.suffix',\n",
       "       'prompt_count', 'prompt_group', 'prompt_tasks', 'original_task',\n",
       "       'task.category', 'disable_caching', 'prompt_category',\n",
       "       'disable_tracking', 'force_generation', 'choices_in_prompt',\n",
       "       'general_prompts.dir', 'group.override_name', 'length_normalization',\n",
       "       'original_prompt_name', 'task.general_prompts',\n",
       "       'prompt_experiment_mode', 'task.preprocessor.name',\n",
       "       'prompt_filter.name_list', 'prompt_filter.choice_list',\n",
       "       'task.preprocessor.choices', 'evaluation.force_generation',\n",
       "       'prompt_filter.original_task', 'evaluation.lowercase_choices',\n",
       "       'task.preprocessor.choice_str', 'general_prompts.answer_filter',\n",
       "       'evaluation.length_normalization', 'general_prompts.category_filter',\n",
       "       'prompt_filter.choices_in_prompt', 'task.preprocessor.mcq_choice_str',\n",
       "       'evaluation.use_only_correct_choice',\n",
       "       'task.preprocessor.context_template',\n",
       "       'task.preprocessor.premise_template',\n",
       "       'task.preprocessor.question_template',\n",
       "       'task.preprocessor.hypothesis_template',\n",
       "       'task.preprocessor.classification_template', 'name', 'group',\n",
       "       'task.verbose_name', 'task.parent_dataset', 'auc-pr', 'auc-roc',\n",
       "       'f1_choice_4', 'logits/choice_4_rank_std', 'logits/diff_3_to_4_std',\n",
       "       'logits/diff_3_to_4_mean', 'logits/choice_4_rank_mean', 'task.splits',\n",
       "       'task.preprocessor.add_speaker_prefix'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlpcourseproject",
   "language": "python",
   "name": "nlpcourseproject"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
