group_name: GeneralFixedChoice
short_name: GenFC
templates:
  145dd841-b971-4550-bc88-305ad3278d58: !Template
    answer_choices: '{{ choices | join("|||") }}'
    choice_string: null
    id: 145dd841-b971-4550-bc88-305ad3278d58
    jinja: 'The following conversation is a negotiation on craigslist. The first speaker
        is the buyer, and the second speaker is the seller.
        {{ input_sequence }}
        From the sellers point of view, this deal could be considered
        ||| {{ answer_choices[label] }}'
    metadata: !TemplateMetadata
      choices_in_prompt: false
      metrics:
        - Accuracy
      original_task: craigslist_bargains
      is_mcq: False
      task_mode: CLASSIFICATION
    name: good deal for seller no list price implicit
    reference: implicit version of "good deal for seller no list price"
  27010b55-dd5b-4ee9-9e14-a4b809aa6cdb: !Template
    answer_choices: '{{ choices | join("|||") }}'
    choice_string: '"yes", "no", "neither",  or "unknown"'
    id: 27010b55-dd5b-4ee9-9e14-a4b809aa6cdb
    jinja: 'The following conversation is a negotiation on craigslist. The first speaker
       is the buyer, and the second speaker is the seller.
       {{ input_sequence }}
       Was this a good deal for the seller? answer {{ choice_string }}.
       ||| {{ answer_choices[label] }}'
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
        - Accuracy
      original_task: craigslist_bargains
      is_mcq: False
      task_mode: CLASSIFICATION
    name: good deal for seller no list price
    reference: same as "good deal for seller" prompt, but excludes the list price
  78d1b487-c535-4a0d-ae49-055d321db3fd: !Template
    answer_choices: '{{ choices | join("|||") }}'
    choice_string: '"yes", "no", "neither",  or "unknown"'
    id: 78d1b487-c535-4a0d-ae49-055d321db3fd
    jinja: 'The following conversation is a negotiation on craigslist. The first speaker
       is the buyer, and the second speaker is the seller. The listed price was ${{additional_input_1 if additional_input_1 is defined  else "N/A"}}.
       {{ input_sequence }}
       Was this a good deal for the seller? Answer {{ choice_string }}.
       ||| {{ answer_choices[label] }}'
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
        - Accuracy
      original_task: craigslist_bargains
      is_mcq: False
      task_mode: CLASSIFICATION
    name: good deal for seller
    reference: asks the model whether the deal was good for the seller or not (it's
      good if the seller's answer_choices[label] is closer to the final price than the buyer's, or
      there is a tie)
  a1dbb258-2e5c-4160-986b-46fc03546965: !Template
    answer_choices: '{{ choices | join("|||") }}'
    choice_string: 'a) the buyer
      b) the seller
      c) neither - it is a fair compromise
      d) unknown'
    id: a1dbb258-2e5c-4160-986b-46fc03546965
    jinja: 'The following conversation is a negotiation on craigslist. The first speaker
        is the buyer, and the second speaker is the seller. The listed price was ${{additional_input_1 if additional_inputs is defined and (additional_inputs|length) > 0 else "N/A"}}.
        {{ input_sequence }}
        Question: Which party got the better deal? Choose from:
        {{ choice_string }}
        Answer:
        ||| {{answer_choices[label]}}'
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
        - Accuracy
      original_task: craigslist_bargains
      is_mcq: True
      task_mode: MCQ
    name: best deal
    reference: explicitly asks model which party got the best deal
  2283cebf-988e-4bff-96bf-982a09963e49: !Template
    answer_choices: '{{ choices | join("|||") }}'
    choice_string: "N/A"
    id: 2283cebf-988e-4bff-96bf-982a09963e49
    jinja: 'Decide whether the question "{{ question }}" is answerable solely based
        on this passage:
        {{ context }}
        Answer: ||| {{answer_choices[label]}}'
    metadata: !TemplateMetadata
      choices_in_prompt: false
      metrics:
        - Accuracy
      original_task: zest
      is_mcq: false
      task_mode: QA
    name: answerable_or_not
    reference: 'Decide whether this question is answerable. Metric: F1 Score with
        modified precision and recall, please refer to the paper https://arxiv.org/abs/2011.08115'
  6f694e45-1d17-4067-a1f6-7dae89c148db: !Template
    answer_choices: '{{ choices | join("|||") }}'
    choice_string: 'N/A'
    id: 6f694e45-1d17-4067-a1f6-7dae89c148db
    jinja: 'My daughter is asking me a question about {{ domain }}:
        "{{ question }}"
        Here''s what I found on the internet: {{ context }}
        What''s the answer?
        Answer: |||{{answer_choices[label]}}'
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
        - Accuracy
      original_task: zest
      is_mcq: false
      task_mode: QA
    name: ask_question_as_kid
    reference: 'Answer the questions of a curious kid. Metric: F1 Score with modified
        precision and recall, please refer to the paper https://arxiv.org/abs/2011.08115'
  7425232a-9880-428c-9ddc-4070e50e22cc: !Template
    answer_choices: '{{ choices | join("|||") }}'
    choice_string: 'N/A'
    id: 7425232a-9880-428c-9ddc-4070e50e22cc
    jinja: 'Answer the question based on the context. If the question is not answerable
        with the context alone, say "Can''t answer".
        {{ context }}
        {{ question }} ||| {{answer_choices[label]}}'
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
        - Accuracy
      original_task: zest
      is_mcq: false
      task_mode: QA
    name: gpt3_instruct_format
    reference: 'Template format from GPT3 instruct. Metric: F1 Score with modified
        precision and recall, please refer to the paper https://arxiv.org/abs/2011.08115'
  cd563834-49ee-495d-ac46-99f0264e58d5: !Template
    answer_choices: '{{ choices | join("|||") }}'
    choice_string: 'N/A'
    id: cd563834-49ee-495d-ac46-99f0264e58d5
    jinja: 'I am giving my students the following question about {{ domain }}: "{{ question }}".
        What should be their answer based on this context: {{ context }} ||| {{answer_choices[label]}}'
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
        - Accuracy
      original_task: zest
      is_mcq: false
      task_mode: QA
    name: ask_question_as_teacher
    reference: 'I don''t know answer. Metric: F1 Score with modified precision and
        recall, please refer to the paper https://arxiv.org/abs/2011.08115'
  091ba88e-d208-4a3a-ada7-d9698aeb5568: !Template
    answer_choices: '{{ choices | join("|||") }}'
    choice_string: 'N/A'
    id: 091ba88e-d208-4a3a-ada7-d9698aeb5568
    jinja: 'You will receive full credit if you solve the following word problem:
        {{ input_sequence }}
        {{ choice_string }} |||
        {{answer_choices[label]}}'
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
        - Accuracy
      original_task: math_qa
      is_mcq: true
      task_mode: MCQ
    name: choose_correct_variant
    reference: 'Variant of choose_correct. '
  6312d599-8ca4-4bc8-a76f-81f2e36727bd: !Template
    answer_choices: '{{ choices | join("|||") }}'
    choice_string: 'N/A'
    id: 6312d599-8ca4-4bc8-a76f-81f2e36727bd
    jinja: 'Given the following problem:
        {{input_sequence}}
        ===
        and the following options, select the correct option
        {{ choice_string }}|||
        {{answer_choices[label]}}'
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
        - Accuracy
      original_task: math_qa
      is_mcq: true
      task_mode: MCQ
    name: choose_correct_og
    reference: The template asks the model to choose the correct answer.
  8c4c81cc-ca54-45fc-a69a-4b97a5f2b465: !Template
    answer_choices: '{{ choices | join("|||") }}'
    choice_string: 'N/A'
    id: 8c4c81cc-ca54-45fc-a69a-4b97a5f2b465
    jinja: "Solve the problem by choosing the correct answer: \n{{input_sequence}}\n\n{{choice_string}}|||\n\
        {{answer_choices[label]}}"
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
        - Accuracy
      original_task: math_qa
      is_mcq: true
      task_mode: MCQ
    name: pick_the_correct
    reference: The template picks the correct the answer choice
  a313a5f8-53cd-4b76-abb6-fea2ac4e9ef4: !Template
    answer_choices: '{{ choices | join("|||") }}'
    choice_string: 'N/A'
    id: a313a5f8-53cd-4b76-abb6-fea2ac4e9ef4
    jinja: "One of the five choices are correctly answers the math problem. Can you\
        \ choose the right one? \n\n{{ choice_string }}\n\nProblem: {{ input_sequence }}\n|||\n{{answer_choices[label]}}"
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
        - Accuracy
      original_task: math_qa
      is_mcq: true
      task_mode: MCQ
    name: first_choice_then_problem
    reference: First give the list of choices and then describe the problem
  eb89c860-5849-461a-9081-3bd466f5642c: !Template
    answer_choices: '{{ choices | join("|||") }}'
    choice_string: 'N/A'
    id: eb89c860-5849-461a-9081-3bd466f5642c
    jinja: "Solve this advanced GRE problem: \n{{input_sequence}}\n\n{{choice_string}}|||\n{{answer_choices[label]}}"
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
        - Accuracy
      original_task: math_qa
      is_mcq: true
      task_mode: MCQ
    name: gre_problem
    reference: 'Template uses "GRE" as a prefix/template. '
  06719321-62e7-4f6e-8f95-464cd2b5ca5c: !Template
    answer_choices: '{{ choices | join("|||") }}'
    choice_string: '"negative", "neutral", "positive"'
    id: 06719321-62e7-4f6e-8f95-464cd2b5ca5c
    jinja: 'Which word between {{choice_string}}
        would you use to describe the effect of the following news on the related share
        prices?
        {{input_sequence}} |||
        {{answer_choices[label]}}'
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
        - Accuracy
      original_task: financial_phrasebank/sentences_allagree
      is_mcq: false
      task_mode: CLASSIFICATION
    name: share_price_option
    reference: 'Metrics: Accuracy, Precision, Recall, F1 per class'
  0beba048-f949-4034-83b6-a3e0e7363f46: !Template
    answer_choices: '{{ choices | join("|||") }}'
    choice_string: 'N/A'
    id: 0beba048-f949-4034-83b6-a3e0e7363f46
    jinja: 'What is the sentiment of the sentence?
        {{input_sequence}} |||
        {{answer_choices[label]}}'
    metadata: !TemplateMetadata
      choices_in_prompt: false
      metrics:
        - Accuracy
      original_task: financial_phrasebank/sentences_allagree
      is_mcq: false
      task_mode: CLASSIFICATION
    name: sentiment
    reference: 'Metrics: Accuracy, Precision, Recall, F1 per class'
  461efe04-6883-41e8-80f0-e722a75260fe: !Template
    answer_choices: '{{ choices | join("|||") }}'
    choice_string: 'N/A'
    id: 461efe04-6883-41e8-80f0-e722a75260fe
    jinja: 'What does the following argument mean for the complementary industries?
        {{input_sequence}} |||
        {{answer_choices[label]}}'
    metadata: !TemplateMetadata
      choices_in_prompt: false
      metrics:
        - Accuracy
      original_task: financial_phrasebank/sentences_allagree
      is_mcq: false
      task_mode: CLASSIFICATION
    name: complementary_industries
    reference: 'Metrics: Accuracy, Precision, Recall, F1 per class'
  5fa16d31-b513-480d-bd1b-1fa8c182fb76: !Template
    answer_choices: '{{ choices | join("|||") }}'
    choice_string: '"bullish", "neutral", or "bearish"'
    id: 5fa16d31-b513-480d-bd1b-1fa8c182fb76
    jinja: 'Should an investor be {{choice_string}}
        given the following news?
        {{input_sequence}} |||
        {{answer_choices[label]}}'
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
        - Accuracy
      original_task: financial_phrasebank/sentences_allagree
      is_mcq: false
      task_mode: CLASSIFICATION
    name: bullish_neutral_bearish
    reference: 'Metrics: Accuracy, Precision, Recall, F1 per class'
  13c02904-e4e2-4b4f-b115-44b437d22041: !Template
    answer_choices: '{{ choices | join("|||") }}'
    choice_string: 'N/A'
    id: 13c02904-e4e2-4b4f-b115-44b437d22041
    jinja: '{{input_sequence}}
        ===
        Write a summary of the text above : |||
        {{answer_choices[label]}}'
    metadata: !TemplateMetadata
      choices_in_prompt: false
      metrics:
        - Accuracy
      original_task: xsum
      is_mcq: false
      task_mode: CLASSIFICATION
    name: DOC_write_summary_of_above
    reference: ''
  3d388a1e-3361-407b-baa7-61397cc58382: !Template
    answer_choices: '{{ choices | join("|||") }}'
    choice_string: 'N/A'
    id: 3d388a1e-3361-407b-baa7-61397cc58382
    jinja: '{{ input_sequence }}
        How would you rephrase that in a few words? ||| {{answer_choices[label]}}'
    metadata: !TemplateMetadata
      choices_in_prompt: false
      metrics:
        - Accuracy
      original_task: xsum
      is_mcq: false
      task_mode: CLASSIFICATION
    name: DOC_how_would_you_rephrase_few_words
    reference: http://gptprompts.wikidot.com/prompt:summarization
  4cfe4126-b9f5-44eb-8a98-973987c5f32e: !Template
    answer_choices: '{{ choices | join("|||") }}'
    choice_string: 'N/A'
    id: 4cfe4126-b9f5-44eb-8a98-973987c5f32e
    jinja: 'My college roommate asked me what this article means:
       {{input_sequence}}
       So I recapped it in layman''s terms: ||| {{answer_choices[label]}}'
    metadata: !TemplateMetadata
      choices_in_prompt: false
      metrics:
        - Accuracy
      original_task: xsum
      is_mcq: false
      task_mode: CLASSIFICATION
    name: college_roommate_asked_DOC_so_I_recap
    reference: http://gptprompts.wikidot.com/prompt:summarization
  9a3f617f-628f-4fa5-9b74-47d0b166a487: !Template
    answer_choices: '{{ choices | join("|||") }}'
    choice_string: 'N/A'
    id: 9a3f617f-628f-4fa5-9b74-47d0b166a487
    jinja: 'First, please read the article below.
        {{input_sequence}}
        Now, can you write me an extremely short abstract for it?  |||  {{answer_choices[label]}}'
    metadata: !TemplateMetadata
      choices_in_prompt: false
      metrics:
        - Accuracy
      original_task: xsum
      is_mcq: false
      task_mode: CLASSIFICATION
    name: read_below_DOC_write_abstract
    reference: ''
  1ee5ddef-fffb-4b73-a2f7-f600ffac63cb: !Template
    answer_choices: '{{ choices | join("|||") }}'
    choice_string: 'N/A'
    id: 1ee5ddef-fffb-4b73-a2f7-f600ffac63cb
    jinja: '{{input_sequence}}...
        What comes after the ellipses? ||| {{ answer_choices[label] }}'
    metadata: !TemplateMetadata
      choices_in_prompt: false
      metrics:
        - Accuracy
      original_task: craffel/openai_lambada
      is_mcq: false
      task_mode: CLASSIFICATION
    name: ellipses
    reference: ''
  4f08e9d4-bcff-4bc0-9902-87c497625d17: !Template
    answer_choices: '{{ choices | join("|||") }}'
    choice_string: 'N/A'
    id: 4f08e9d4-bcff-4bc0-9902-87c497625d17
    jinja: 'Fill in the blank:
        {{ input_sequence }} ____. ||| {{ answer_choices[label] }}'
    metadata: !TemplateMetadata
      choices_in_prompt: false
      metrics:
        - Accuracy
      original_task: craffel/openai_lambada
      is_mcq: false
      task_mode: CLASSIFICATION
    name: GPT-3 style
    reference: Brown et al.
  774b4349-0524-4a34-881b-b344f8f5c34e: !Template
    answer_choices: '{{ choices | join("|||") }}'
    choice_string: 'N/A'
    id: 774b4349-0524-4a34-881b-b344f8f5c34e
    jinja: 'This story got cut short. What comes next?
       {{ input_sequence }} ||| {{ answer_choices[label] }}'
    metadata: !TemplateMetadata
      choices_in_prompt: false
      metrics:
        - Accuracy
      original_task: craffel/openai_lambada
      is_mcq: false
      task_mode: CLASSIFICATION
    name: what comes next
    reference: ''
  2bca0197-e3d4-4870-bd95-178411e52e09: !Template
    answer_choices: '{{ choices | join("|||") }}'
    choice_string: 'N/A'
    id: 2bca0197-e3d4-4870-bd95-178411e52e09
    jinja: 'Use the reference abstracts to generate related work:
        {{ input_sequence }}  |||
        {{  answer_choices[label]  }}'
    metadata: !TemplateMetadata
      choices_in_prompt: false
      metrics:
        - Accuracy
      original_task: multi_x_science_sum
      is_mcq: false
      task_mode: CLASSIFICATION
    name: ref_relatedwork
    reference: ''
  3bd082cb-4e28-4eb7-9fa2-dd03f1f86219: !Template
    answer_choices: '{{ choices | join("|||") }}'
    choice_string: 'N/A'
    id: 3bd082cb-4e28-4eb7-9fa2-dd03f1f86219
    jinja: 'Given the abstract of a paper, provide some related work for readers to
       learn further
       {{ input_sequence }}  |||
        {{  answer_choices[label]  }}'
    metadata: !TemplateMetadata
      choices_in_prompt: false
      metrics:
        - Accuracy
      original_task: multi_x_science_sum
      is_mcq: false
      task_mode: CLASSIFICATION
    name: abstract_relatedwork
    reference: ''
  af4d550e-54b8-471e-97af-2b2c50a1382e: !Template
    answer_choices: '{{ choices | join("|||") }}'
    choice_string: 'N/A'
    id: af4d550e-54b8-471e-97af-2b2c50a1382e
    jinja: 'Use the related work to guess the abstract:
        {{ input_sequence }}  |||
        {{  answer_choices[label]  }}'
    metadata: !TemplateMetadata
      choices_in_prompt: false
      metrics:
        - Accuracy
      original_task: multi_x_science_sum
      is_mcq: false
      task_mode: CLASSIFICATION
    name: relatedwork_abstract
    reference: ''
  202246b0-3f82-42b9-bc8d-d36997b5f2cb: !Template
    answer_choices: '{{ choices | join("|||") }}'
    choice_string: '{{ choices | join(", ") }}'
    id: 202246b0-3f82-42b9-bc8d-d36997b5f2cb
    jinja: "Given the sentence, {{input_sequence}}\n\nOut of the options {{choice_string}}, \n\nWhat is the semantic relations between the two nominals\
        \ (nouns or noun phrases) e1 and e2 in the sentence: ||| {{ answer_choices[label]\
        \ }}"
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
        - Accuracy
      original_task: sem_eval_2010_task_8
      is_mcq: false
      task_mode: CLASSIFICATION
    name: semantic relations with options
    reference: out of options; macro-averaged F1-score official metric
  5d7123a8-4ed4-42ce-bcfb-4af415962efc: !Template
    answer_choices: '{{ choices | join("|||") }}'
    choice_string: '{{ choices | join(", ") }}'
    id: 5d7123a8-4ed4-42ce-bcfb-4af415962efc
    jinja: 'How semantically related are the two nominals in the sentence, {{input_sequence}}
        Please answer {{choice_string}}:
        ||| {{ answer_choices[label] }}'
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
        - Accuracy
      original_task: sem_eval_2010_task_8
      is_mcq: false
      task_mode: CLASSIFICATION
    name: semantically related nominials with options
    reference: 'please answer; official metric:  macro-averaged F1-score'
  c97e7bbf-b7f0-4cee-ada5-431ce7d606cc: !Template
    answer_choices: '{{ choices | join("|||") }}'
    choice_string: '{{ choices | join(", ") }}'
    id: c97e7bbf-b7f0-4cee-ada5-431ce7d606cc
    jinja: 'Given the sentence, {{ input_sequence }}
        ===
        What is the semantic relations between the two nominals (nouns or noun phrases)
        e1 and e2 in the sentence: ||| {{ answer_choices[label] }}'
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
        - Accuracy
      original_task: sem_eval_2010_task_8
      is_mcq: false
      task_mode: CLASSIFICATION
    name: semantic relations nominials without options
    reference: mention e1,e2 after; macro-averaged F1-score official metric
  1f959d92-dca8-4647-9840-69391dfbd000: !Template
    answer_choices: '{{ choices | join("|||") }}'
    choice_string: 'N/A'
    id: 1f959d92-dca8-4647-9840-69391dfbd000
    jinja: "Fill in the blank in the following sentence using world knowledge:\n\n\
       {{ input_sequence }}\n\nChose from the following\
       \ options:\n\n{{ ', '.join(answer_choices) }} ||| {{ answer_choices[label] }}"
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
        - Accuracy
      original_task: numer_sense
      is_mcq: false
      task_mode: CLASSIFICATION
    name: fill_in_the_blank_with_choices_after
    reference: ''
  4e9da2b8-2502-44a7-a7da-ae62f2d554c9: !Template
    answer_choices: '{{ choices | join("|||") }}'
    choice_string: 'N/A'
    id: 4e9da2b8-2502-44a7-a7da-ae62f2d554c9
    jinja: 'The following sentence needs to be filled with a word which is a number
     word or "no". Using common sense and world knowledge fill in the blanks.
     {{ input_sequence }}
     Which is it?
     |||
     {{ answer_choices[label] }}'
    metadata: !TemplateMetadata
      choices_in_prompt: false
      metrics:
        - Accuracy
      original_task: numer_sense
      is_mcq: false
      task_mode: CLASSIFICATION
    name: fill_in_the_blank_with_instruction
    reference: ''
  5d8e8d21-8059-4373-bbf2-a25cbe1e6960: !Template
    answer_choices: '{{ choices | join("|||") }}'
    choice_string: 'N/A'
    id: 5d8e8d21-8059-4373-bbf2-a25cbe1e6960
    jinja: 'Using common sense reasoning of the world and only the following options,
     how would you fill in the blank?:
     {{ '', ''.join(answer_choices) }}
     {{ input_sequence }}
     |||
     {{answer_choices[label]}}'
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
        - Accuracy
      original_task: numer_sense
      is_mcq: false
      task_mode: CLASSIFICATION
    name: fill_in_the_blank_with_choices_before
    reference: with all the given options
  cacee36c-e2b7-458e-9d51-6fcfd83842b4: !Template
    answer_choices: '{{ choices | join("|||") }}'
    choice_string: 'N/A'
    id: cacee36c-e2b7-458e-9d51-6fcfd83842b4
    jinja: 'Fill in the blanks:
     {{ input_sequence }}
     The correct answer is:
     |||
     {{answer_choices[label]}}'
    metadata: !TemplateMetadata
      choices_in_prompt: false
      metrics:
        - Accuracy
      original_task: numer_sense
      is_mcq: false
      task_mode: CLASSIFICATION
    name: fill_in_the_blank_before_sentence
    reference: replace mask with fill in the blank
  fc76beb7-c258-412f-a623-42fc8d2331b6: !Template
    answer_choices: '{{ choices | join("|||") }}'
    choice_string: 'N/A'
    id: fc76beb7-c258-412f-a623-42fc8d2331b6
    jinja: "{{ input_sequence }}\n\nUsing only the following\
     \ options, what answer would make the most sense in the blank above?\n\n{{ ',\
     \ '.join(answer_choices) }}\n\n||| \n\n{{answer_choices[label]}}"
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
        - Accuracy
      original_task: numer_sense
      is_mcq: false
      task_mode: CLASSIFICATION
    name: fill_in_the_blank_with_instruction_and_choices
    reference: missing word simple
  b7012213-04c4-424d-85fb-39d63d8a0ca2: !Template
    answer_choices: '{{ choices | join("|||") }}'
    choice_string: 'N/A'
    id: b7012213-04c4-424d-85fb-39d63d8a0ca2
    jinja: 'What are the topics in the sentence: {{input_sequence}}
        |||
        {{ answer_choices[label] }}'
    metadata: !TemplateMetadata
      choices_in_prompt: false
      metrics:
        - Accuracy
      original_task: common_gen
      is_mcq: false
      task_mode: CLASSIFICATION
    name: topics from the sentence
    reference: The template generates a random topic from the sentence
  ed215962-8e51-45e7-b025-6e822f877098: !Template
    answer_choices: '{{ choices | join("|||") }}'
    choice_string: 'N/A'
    id: ed215962-8e51-45e7-b025-6e822f877098
    jinja: "We have the sentence: {{input_sequence}}; \nExtract all the key concepts: \n|||\n\
        {{ answer_choices[label] }}"
    metadata: !TemplateMetadata
      choices_in_prompt: false
      metrics:
        - Accuracy
      original_task: common_gen
      is_mcq: false
      task_mode: CLASSIFICATION
    name: sentence to concepts
    reference: Template identifies the concepts from the sentence
  c4ed37ae-d7d7-4197-a725-ef2152fa3b1f: !Template
    answer_choices: '{{ choices | join("|||") }}'
    choice_string: 'N/A'
    id: c4ed37ae-d7d7-4197-a725-ef2152fa3b1f
    jinja: 'Suppose {{premise}} Can we infer that "{{hypothesis}}"? {{ choice_string }}?
        ||| {{ answer_choices[label] }} '
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
        - Accuracy
      original_task: anli
      is_mcq: false
      task_mode: ENTAILMENT
    name: can we infer
    reference: Webson & Pavlick 2021
  ec249357-e672-4e7d-b8b6-d97ed7d090c5: !Template
    answer_choices: '{{ choices | join("|||") }}'
    choice_string: 'N/A'
    id: ec249357-e672-4e7d-b8b6-d97ed7d090c5
    jinja: '{{premise}} Based on that information, is the claim: "{{hypothesis}}"
        {{ choice_string }}? ||| {{ answer_choices[label]
        }}'
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
        - Accuracy
      original_task: anli
      is_mcq: false
      task_mode: ENTAILMENT
    name: claim true/false/inconclusive
    reference: v0.1
  620aa3fc-d5eb-46f5-a1ee-4c754527aa97: !Template
    answer_choices: '{{ choices | join("|||") }}'
    choice_string: 'N/A'
    id: 620aa3fc-d5eb-46f5-a1ee-4c754527aa97
    jinja: '{{premise}}
      Question: {{hypothesis}} {{choice_string}}? ||| {{ answer_choices[label]
      }}'
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
        - Accuracy
      original_task: anli
      is_mcq: false
      task_mode: ENTAILMENT
    name: GPT-3 style
    reference: 'Same as reported in Figure G7 of the GPT-3 paper, except that there
      is no task identifying tokens like "anli R1: ".'
  9b613182-c6ab-4427-9221-3d68f6d62765: !Template
    answer_choices: '{{ choices | join("|||") }}'
    choice_string: 'N/A'
    id: 9b613182-c6ab-4427-9221-3d68f6d62765
    jinja: '{{premise}} Based on the previous passage, is it true that "{{hypothesis}}"?
      {{ choice_string }}? ||| {{ answer_choices[label] }}'
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
        - Accuracy
      original_task: anli
      is_mcq: false
      task_mode: ENTAILMENT
    name: based on the previous passage
    reference: "Adapted from the BoolQ prompts in Schick & Sch\xFCtze 2021."
  a850110d-f1a3-49b4-949a-d3bfe9f81344: !Template
    answer_choices: '{{ choices | join("|||") }}'
    choice_string: 'N/A'
    id: a850110d-f1a3-49b4-949a-d3bfe9f81344
    jinja: '{{premise}} Are we justified in saying that "{{hypothesis}}"? {{ choice_string }}? ||| {{ answer_choices[label] }} '
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
        - Accuracy
      original_task: anli
      is_mcq: false
      task_mode: ENTAILMENT
    name: justified in saying
    reference: Webson & Pavlick 2021
  bab86d5a-4f9c-40db-b619-a7b7d5cae681: !Template
    answer_choices: '{{ choices | join("|||") }}'
    choice_string: 'N/A'
    id: bab86d5a-4f9c-40db-b619-a7b7d5cae681
    jinja: 'Take the following as truth: {{premise}}
      Then the following statement: "{{hypothesis}}" is {{ choice_string }}? ||| {{ answer_choices[label] }}'
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
        - Accuracy
      original_task: anli
      is_mcq: false
      task_mode: ENTAILMENT
    name: take the following as truth
    reference: v0.1
  fb4f8144-37f5-4977-88da-37a5d0bfd0e8: !Template
    answer_choices: '{{ choices | join("|||") }}'
    choice_string: 'N/A'
    id: fb4f8144-37f5-4977-88da-37a5d0bfd0e8
    jinja: 'Given that {{ premise }} Therefore, it must be true that "{{ hypothesis }}"?
      {{ choice_string }}? ||| {{ answer_choices[label] }}'
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
        - Accuracy
      original_task: anli
      is_mcq: false
      task_mode: ENTAILMENT
    name: must be true
    reference: v0.1
  9e078fb4-505b-413c-bb5e-3cd16ddcf5d7: !Template
    answer_choices: '{{ choices | join("|||") }}'
    choice_string: 'N/A'
    id: 9e078fb4-505b-413c-bb5e-3cd16ddcf5d7
    jinja: '"{{premise}} \n\nQuestion: Does this imply that \"{{hypothesis}}\"? {{ choice_string }}? ||| {{answer_choices[label]}}'
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
        - Accuracy
      original_task: anli
      is_mcq: false
      task_mode: ENTAILMENT
    name: does this imply
    reference: v0.1
  2d0d63da-ffcf-4f6e-941a-b8da922be43e: !Template
    answer_choices: '{{ choices | join("|||") }}'
    choice_string: 'N/A'
    id: 2d0d63da-ffcf-4f6e-941a-b8da922be43e
    jinja: 'Given {{premise}} Is it guaranteed true that "{{hypothesis}}"? {{ choice_string }}?
      ||| {{ answer_choices[label] }}'
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
        - Accuracy
      original_task: anli
      is_mcq: false
      task_mode: ENTAILMENT
    name: guaranteed true
    reference: Webson & Pavlick 2021
  0edd8660-f299-4819-a5ac-633c11177228: !Template
    answer_choices: '{{ choices | join("|||") }}'
    choice_string: 'N/A'
    id: 0edd8660-f299-4819-a5ac-633c11177228
    jinja: 'Exercise: choose the most plausible alternative.
        {{ input_sequence }} because...
        {% for choice in answer_choices %}
        - {{ choice }}
        {% endfor %} ||| {{ answer_choices[label] }}'
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
        - Accuracy
      original_task: super_glue/copa
      is_mcq: false
      task_mode: CLASSIFICATION
    name: exercise
    reference: ''
  a1f9951e-2b6b-4530-9636-9cdf4c1658c5: !Template
    answer_choices: '{{ choices | join("|||") }}'
    choice_string: 'N/A'
    id: a1f9951e-2b6b-4530-9636-9cdf4c1658c5
    jinja: 'Pick the more likely continuation to the following sentence:
       {{ input_sequence }} as a result of:
       {% for choice in answer_choices %}
        - {{ choice }}
        {% endfor %} ||| {{ answer_choices[label] }}'
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
        - Accuracy
      original_task: super_glue/copa
      is_mcq: false
      task_mode: CLASSIFICATION
    name: more likely
    reference: ''
  f32348cd-d3cb-4619-87b9-e24f99c78567: !Template
    answer_choices: '{{ choices | join("|||") }}'
    choice_string: 'N/A'
    id: f32348cd-d3cb-4619-87b9-e24f99c78567
    jinja: '{{ input_sequence }} because...
        Choose between:
        {% for choice in answer_choices %}
        - {{ choice }}
        {% endfor %} ||| {% if label != -1 %}{{ answer_choices[label] }}{%endif%}'
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
        - Accuracy
      original_task: super_glue/copa
      is_mcq: false
      task_mode: CLASSIFICATION
    name: choose
    reference: ''
  14e73f39-a0d1-44c2-b9a4-4e48f9f1608e: !Template
    answer_choices: '{{ choices | join("|||") }}'
    choice_string: 'N/A'
    id: 14e73f39-a0d1-44c2-b9a4-4e48f9f1608e
    jinja: 'Does the word "{{domain}}" have the same meaning in these two sentences?
        {{ choice_string }}?
        {{premise}}
        {{hypothesis}}
        ||| {{answer_choices[label]}}'
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
        - Accuracy
      original_task: super_glue/wic
      is_mcq: false
      task_mode: ENTAILMENT
    name: question-context-meaning-with-label
    reference: Generalized question-context format with label
  3503ead5-4fa5-4f77-95dc-f0c2ed3eecdc: !Template
    answer_choices: '{{ choices | join("|||") }}'
    choice_string: 'N/A'
    id: 3503ead5-4fa5-4f77-95dc-f0c2ed3eecdc
    jinja: 'Does the word "{{domain}}" have the same meaning in these two sentences?
      {{premise}}
      {{hypothesis}}
      ||| {{answer_choices[label]}}'
    metadata: !TemplateMetadata
      choices_in_prompt: false
      metrics:
        - Accuracy
      original_task: super_glue/wic
      is_mcq: false
      task_mode: ENTAILMENT
    name: question-context-meaning
    reference: Generalized question-context format
  611d13dc-d414-4b9b-9204-e4f325e859e7: !Template
    answer_choices: '{{ choices | join("|||") }}'
    choice_string: 'N/A'
    id: 611d13dc-d414-4b9b-9204-e4f325e859e7
    jinja: 'Homework
      Decide whether the word "{{domain}}" is used with the same meaning in the two
      following sentences. Answer by yes or no.
      {{premise}}
      {{hypothesis}}
      ||| {{answer_choices[label]}}'
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
        - Accuracy
      original_task: super_glue/wic
      is_mcq: false
      task_mode: ENTAILMENT
    name: grammar_homework
    reference: ''
  725b5ed0-7728-4890-95a4-a74cb7ae1bb4: !Template
    answer_choices: '{{ choices | join("|||") }}'
    choice_string: 'N/A'
    id: 725b5ed0-7728-4890-95a4-a74cb7ae1bb4
    jinja: 'Sentence A: {{premise}}
      Sentence B: {{ hypothesis}}
      "{{ domain }}" has a similar meaning in sentences A and B. {{choice_string}}?
      ||| {{answer_choices[label]}}'
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
        - Accuracy
      original_task: super_glue/wic
      is_mcq: false
      task_mode: ENTAILMENT
    name: affirmation_true_or_false
    reference: ''
  d31ef017-face-4837-a980-ee9fe8fe2b91: !Template
    answer_choices: '{{ choices | join("|||") }}'
    choice_string: 'N/A'
    id: d31ef017-face-4837-a980-ee9fe8fe2b91
    jinja: 'Python code: {{input_sequence}}\n
      {% for choice in answer_choices %}\tchoice: {{ choice.strip() }}\n{% endfor %}
      English language description:
      ||| {{answer_choices[label]}}'
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
        - Accuracy
      original_task: BIG-BENCH
      is_mcq: false
      task_mode: CLASSIFICATION
    name: code line description
    reference: ''
  f91f2647-be17-4985-a106-0c6caa99310a: !Template
    answer_choices: '{{ choices | join("|||") }}'
    choice_string: 'N/A'
    id: f91f2647-be17-4985-a106-0c6caa99310a
    jinja: 'Q: {{ question }}\n
      Clue(s):\n
      {{ context }}\n
      What is the answer?\n
      {% for choice in answer_choices %}\tchoice: {{ choice.strip() }}\n{% endfor %}
      A:
      ||| {{answer_choices[label]}}'
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
        - Accuracy
      original_task: BIG-BENCH
      is_mcq: false
      task_mode: QA
    name: logic grid
    reference: ''
  f3f924f3-5327-405b-b0a0-96f30a59136c: !Template
    answer_choices: '{{ choices | join("|||") }}'
    choice_string: 'N/A'
    id: f3f924f3-5327-405b-b0a0-96f30a59136c
    jinja: 'The following paragraphs each describe a set of five objects arranged in a fixed order. The statements are logically consistent within each paragraph.


      On a shelf, there are five books: {{ input_sequence }}
      ||| {{answer_choices[label]}}'
    metadata: !TemplateMetadata
      choices_in_prompt: false
      metrics:
        - Accuracy
      original_task: BIG-BENCH
      is_mcq: false
      task_mode: CLASSIFICATION
    name: logical deduction
    reference: ''
  31fb1471-b3c4-4f99-9134-87239a4ebfe9: !Template
    answer_choices: '{{ choices | join("|||") }}'
    choice_string: 'N/A'
    id: 31fb1471-b3c4-4f99-9134-87239a4ebfe9
    jinja: "Q: {{ input_sequence }}\n
      {% for choice in answer_choices %}\tchoice: {{ choice.strip() }}\n{% endfor %}
      A:
      ||| {{answer_choices[label]}}"
    metadata: !TemplateMetadata
      choices_in_prompt: True
      metrics:
        - Accuracy
      original_task: BIG-BENCH
      is_mcq: false
      task_mode: CLASSIFICATION
    name: known unknowns
    reference: ''
  9da09aae-5b38-42ca-8082-87d2fa84c41d: !Template
    answer_choices: '{{ choices | join("|||") }}'
    choice_string: 'N/A'
    id: 9da09aae-5b38-42ca-8082-87d2fa84c41d
    jinja: "Let's do some find-the-common-concept problems. In these problems, your goal is to identify the underlying concept or theme that relates the things listed. Make sure to answer carefully.
        What do the following have in common? {{ input_sequence }}
        A:
      ||| {{answer_choices[label]}}"
    metadata: !TemplateMetadata
      choices_in_prompt: True
      metrics:
        - Accuracy
      original_task: BIG-BENCH
      is_mcq: false
      task_mode: CLASSIFICATION
    name: novel concepts
    reference: ''
  88bdb026-e9c9-445b-96ef-0cdb986b7fbd: !Template
    answer_choices: '{{ choices | join("|||") }}'
    choice_string: 'N/A'
    id: 88bdb026-e9c9-445b-96ef-0cdb986b7fbd
    jinja: "{{ input_sequence }}\n {{choice_string}}
      ||| {{answer_choices[label]}}"
    metadata: !TemplateMetadata
      choices_in_prompt: True
      metrics:
        - Accuracy
      original_task: BAREBONES
      is_mcq: false
      task_mode: CLASSIFICATION
    name: classification choices
    reference: ''
  bb648cf3-d9ab-45a8-9bd7-6ba4585c4b9a: !Template
    answer_choices: '{{ choices | join("|||") }}'
    choice_string: 'N/A'
    id: bb648cf3-d9ab-45a8-9bd7-6ba4585c4b9a
    jinja: "{{ premise }}\n{{ hypothesis}}\n{{choice_string}}
      ||| {{answer_choices[label]}}"
    metadata: !TemplateMetadata
      choices_in_prompt: True
      metrics:
        - Accuracy
      original_task: BAREBONES
      is_mcq: false
      task_mode: ENTAILMENT
    name: entailment choices
    reference: ''
  d92fc0d4-5367-41e1-b35d-1058f22a3c1c: !Template
    answer_choices: '{{ choices | join("|||") }}'
    choice_string: 'N/A'
    id: d92fc0d4-5367-41e1-b35d-1058f22a3c1c
    jinja: "{{ context }}\n{{ context }}\n{{choice_string}}
      ||| {{answer_choices[label]}}"
    metadata: !TemplateMetadata
      choices_in_prompt: True
      metrics:
        - Accuracy
      original_task: BAREBONES
      is_mcq: false
      task_mode: QA
    name: qa choices
    reference: ''
  74693ecc-f903-488c-968d-6a2bc8e76611: !Template
    answer_choices: '{{ choices | join("|||") }}'
    choice_string: 'N/A'
    id: 74693ecc-f903-488c-968d-6a2bc8e76611
    jinja: "{{ input_sequence }}
      ||| {{answer_choices[label]}}"
    metadata: !TemplateMetadata
      choices_in_prompt: False
      metrics:
        - Accuracy
      original_task: BAREBONES
      is_mcq: false
      task_mode: CLASSIFICATION
    name: classification no choices
    reference: ''
  cc2958ca-e826-4fef-96aa-1c4caa188605: !Template
    answer_choices: '{{ choices | join("|||") }}'
    choice_string: 'N/A'
    id: cc2958ca-e826-4fef-96aa-1c4caa188605
    jinja: "{{ premise }}\n{{ hypothesis}}
      ||| {{answer_choices[label]}}"
    metadata: !TemplateMetadata
      choices_in_prompt: False
      metrics:
        - Accuracy
      original_task: BAREBONES
      is_mcq: false
      task_mode: ENTAILMENT
    name: entailment no choices
    reference: ''
  97030be6-9843-4fc2-98cf-b47b879b5447: !Template
    answer_choices: '{{ choices | join("|||") }}'
    choice_string: 'N/A'
    id: 97030be6-9843-4fc2-98cf-b47b879b5447
    jinja: "{{ context }}\n{{ context }}
      ||| {{answer_choices[label]}}"
    metadata: !TemplateMetadata
      choices_in_prompt: False
      metrics:
        - Accuracy
      original_task: BAREBONES
      is_mcq: false
      task_mode: QA
    name: qa no choices
    reference: ''

  32a28538-99bc-4c5a-8086-83b885fddb50: !Template
    answer_choices: '{{ choices | join("|||") }}'
    choice_string: 'N/A'
    id: 32a28538-99bc-4c5a-8086-83b885fddb50
    jinja: "{{ input_sequence }}\n {{choice_string}} \nAnswer:
      ||| {{answer_choices[label]}}"
    metadata: !TemplateMetadata
      choices_in_prompt: True
      metrics:
        - Accuracy
      original_task: BAREBONES
      is_mcq: false
      task_mode: CLASSIFICATION
    name: classification choices and answer
    reference: ''
  c225e598-1efe-4cb6-9f7c-a1b7eb5c7803: !Template
    answer_choices: '{{ choices | join("|||") }}'
    choice_string: 'N/A'
    id: c225e598-1efe-4cb6-9f7c-a1b7eb5c7803
    jinja: "{{ premise }}\n{{ hypothesis}}\n{{choice_string}}\nAnswer:
      ||| {{answer_choices[label]}}"
    metadata: !TemplateMetadata
      choices_in_prompt: True
      metrics:
        - Accuracy
      original_task: BAREBONES
      is_mcq: false
      task_mode: ENTAILMENT
    name: entailment choices and answer
    reference: ''
  2e94d035-3c3d-44cf-98cb-3d11bea7c17b: !Template
    answer_choices: '{{ choices | join("|||") }}'
    choice_string: 'N/A'
    id: 2e94d035-3c3d-44cf-98cb-3d11bea7c17b
    jinja: "{{ context }}\n{{ context }}\n{{choice_string}}\nAnswer:
      ||| {{answer_choices[label]}}"
    metadata: !TemplateMetadata
      choices_in_prompt: True
      metrics:
        - Accuracy
      original_task: BAREBONES
      is_mcq: false
      task_mode: QA
    name: qa choices and answer
    reference: ''
  cf005ddf-8cf2-409d-b884-45d22463f463: !Template
    answer_choices: '{{ choices | join("|||") }}'
    choice_string: 'N/A'
    id: cf005ddf-8cf2-409d-b884-45d22463f463
    jinja: "{{ input_sequence }}\nAnswer:
      ||| {{answer_choices[label]}}"
    metadata: !TemplateMetadata
      choices_in_prompt: False
      metrics:
        - Accuracy
      original_task: BAREBONES
      is_mcq: false
      task_mode: CLASSIFICATION
    name: classification no choices and answer
    reference: ''
  e5eaa3ee-e537-4d20-9dfa-6084db54f2ef: !Template
    answer_choices: '{{ choices | join("|||") }}'
    choice_string: 'N/A'
    id: e5eaa3ee-e537-4d20-9dfa-6084db54f2ef
    jinja: "{{ premise }}\n{{ hypothesis}}\nAnswer:
      ||| {{answer_choices[label]}}"
    metadata: !TemplateMetadata
      choices_in_prompt: False
      metrics:
        - Accuracy
      original_task: BAREBONES
      is_mcq: false
      task_mode: ENTAILMENT
    name: entailment no choices and answer
    reference: ''
  f2004e15-9d9a-4ca1-9830-a341e684e97e: !Template
    answer_choices: '{{ choices | join("|||") }}'
    choice_string: 'N/A'
    id: f2004e15-9d9a-4ca1-9830-a341e684e97e
    jinja: "{{ context }}\n{{ context }}
      ||| {{answer_choices[label]}}"
    metadata: !TemplateMetadata
      choices_in_prompt: False
      metrics:
        - Accuracy
      original_task: BAREBONES
      is_mcq: false
      task_mode: QA
    name: qa no choices and answer
    reference: ''

  13bd5099-33fa-4383-a441-33a7d2e1746f: !Template
    answer_choices: '{{ choices | join("|||") }}'
    choice_string: 'N/A'
    id: 13bd5099-33fa-4383-a441-33a7d2e1746f
    jinja: 'Given the problem:

      {{ input_sequence }}

      and the options:

      {% for choice in choice_string.split("\n") %}
      - {{ choice }}
      {% endfor %}

      The correct answer is ||| {{answer_choices[label]}}'
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
        - Accuracy
      original_task: aqua_rat/raw
      is_mcq: true
      task_mode: MCQ
    name: select_the_best_option
    reference: ''
  58a6aa2b-ca26-473d-9bf8-385dd1a743cd: !Template
    answer_choices: '{{ choices | join("|||") }}'
    choice_string: 'N/A'
    id: 58a6aa2b-ca26-473d-9bf8-385dd1a743cd
    jinja: 'You will now be given a question and a set of options. Choose the correct
      option and provide a rationale for the same.
      Question:
      {{ input_sequence }}
      Options:
      {% for choice in choice_string.split("\n") %}
      - {{ choice }}
      {% endfor %}
      |||
      {{answer_choices[label]}}'
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
        - Accuracy
      original_task: aqua_rat/raw
      is_mcq: true
      task_mode: MCQ
    name: generate_rational_and_correct_choice
    reference: ''
  5acfaa48-e1b6-44df-8e92-c58b94bff595: !Template
    answer_choices: '{{ choices | join("|||") }}'
    choice_string: 'N/A'
    id: 5acfaa48-e1b6-44df-8e92-c58b94bff595
    jinja: 'Answer the given question by providing the correct rationale:\n\n{{input_sequence}}\n
    {% for choice in choice_string.split("\n") %}
        {{ choice }}
    {% endfor %}
    ||| {{answer_choices[label]}}'
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
        - Accuracy
      original_task: aqua_rat/raw
      is_mcq: true
      task_mode: MCQ
    name: generate_rationale
    reference: ''
  815acaf5-2e59-4f81-8190-ae75dc237cf1: !Template
    answer_choices: '{{ choices | join("|||") }}'
    choice_string: 'N/A'
    id: 815acaf5-2e59-4f81-8190-ae75dc237cf1
    jinja: '{{input_sequence}}
        The above question was asked in a Math test. Given the following options, can
        you choose the correct one?
        {% for choice in choice_string.split("\n") %}
        - {{ choice }}
        {% endfor %}
        |||
        {{answer_choices[label]}}'
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
        - Accuracy
      original_task: aqua_rat/raw
      is_mcq: true
      task_mode: MCQ
    name: answer_quiz
    reference: ''
  c0403841-68b0-4c08-8c3b-a00a81272d05: !Template
    answer_choices: '{{ choices | join("|||") }}'
    choice_string: 'N/A'
    id: c0403841-68b0-4c08-8c3b-a00a81272d05
    jinja: 'Solve the following question and choose the correct option.

        {{input_sequence}}

        {% for choice in choice_string.split("\n") %}
        - {{ choice }}
        {% endfor %}
        ||| {{answer_choices[label]}}'
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
        - Accuracy
      original_task: aqua_rat/raw
      is_mcq: true
      task_mode: MCQ
    name: Answer questions from options
    reference: ''