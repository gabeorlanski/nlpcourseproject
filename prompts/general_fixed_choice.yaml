group_name: GeneralFixedChoice
short_name: GenFC
templates:
  145dd841-b971-4550-bc88-305ad3278d58: !Template
    answer_choices: '{{ choices | join("|||") }}'
    choice_string: null
    id: 145dd841-b971-4550-bc88-305ad3278d58
    jinja: 'The following conversation is a negotiation on craigslist. The first speaker
        is the buyer, and the second speaker is the seller.
        {{ input_sequence }}
        From the sellers point of view, this deal could be considered
        ||| {{ answer_choices[label] }}'
    metadata: !TemplateMetadata
      choices_in_prompt: false
      metrics:
        - Accuracy
      original_task: craigslist_bargains
      is_mcq: False
      task_mode: CLASSIFICATION
    name: good deal for seller no list price implicit
    reference: implicit version of "good deal for seller no list price"
  27010b55-dd5b-4ee9-9e14-a4b809aa6cdb: !Template
    answer_choices: '{{ choices | join("|||") }}'
    choice_string: '"yes", "no", "neither",  or "unknown"'
    id: 27010b55-dd5b-4ee9-9e14-a4b809aa6cdb
    jinja: 'The following conversation is a negotiation on craigslist. The first speaker
       is the buyer, and the second speaker is the seller.
       {{ input_sequence }}
       Was this a good deal for the seller? answer {{ choice_string }}.
       ||| {{ answer_choices[label] }}'
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
        - Accuracy
      original_task: craigslist_bargains
      is_mcq: False
      task_mode: CLASSIFICATION
    name: good deal for seller no list price
    reference: same as "good deal for seller" prompt, but excludes the list price
  78d1b487-c535-4a0d-ae49-055d321db3fd: !Template
    answer_choices: '{{ choices | join("|||") }}'
    choice_string: '"yes", "no", "neither",  or "unknown"'
    id: 78d1b487-c535-4a0d-ae49-055d321db3fd
    jinja: 'The following conversation is a negotiation on craigslist. The first speaker
       is the buyer, and the second speaker is the seller. The listed price was ${{additional_input_1 if additional_input_1 is defined  else "N/A"}}.
       {{ input_sequence }}
       Was this a good deal for the seller? Answer {{ choice_string }}.
       ||| {{ answer_choices[label] }}'
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
        - Accuracy
      original_task: craigslist_bargains
      is_mcq: False
      task_mode: CLASSIFICATION
    name: good deal for seller
    reference: asks the model whether the deal was good for the seller or not (it's
      good if the seller's answer_choices[label] is closer to the final price than the buyer's, or
      there is a tie)
  a1dbb258-2e5c-4160-986b-46fc03546965: !Template
    answer_choices: '{{ choices | join("|||") }}'
    choice_string: 'a) the buyer
      b) the seller
      c) neither - it is a fair compromise
      d) unknown'
    id: a1dbb258-2e5c-4160-986b-46fc03546965
    jinja: 'The following conversation is a negotiation on craigslist. The first speaker
        is the buyer, and the second speaker is the seller. The listed price was ${{additional_input_1 if additional_inputs is defined and (additional_inputs|length) > 0 else "N/A"}}.
        {{ input_sequence }}
        Question: Which party got the better deal? Choose from:
        {{ choice_string }}
        Answer:
        ||| {{answer_choices[label]}}'
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
        - Accuracy
      original_task: craigslist_bargains
      is_mcq: True
      task_mode: CLASSIFICATION
    name: best deal
    reference: explicitly asks model which party got the best deal
  2283cebf-988e-4bff-96bf-982a09963e49: !Template
    answer_choices: '{{ choices | join("|||") }}'
    choice_string: "N/A"
    id: 2283cebf-988e-4bff-96bf-982a09963e49
    jinja: 'Decide whether the question "{{ question }}" is answerable solely based
        on this passage:
        {{ context }}
        Answer: ||| {{answer_choices[label]}}'
    metadata: !TemplateMetadata
      choices_in_prompt: false
      metrics:
        - Accuracy
      original_task: zest
      is_mcq: false
      task_mode: QA
    name: answerable_or_not
    reference: 'Decide whether this question is answerable. Metric: F1 Score with
        modified precision and recall, please refer to the paper https://arxiv.org/abs/2011.08115'
  6f694e45-1d17-4067-a1f6-7dae89c148db: !Template
    answer_choices: '{{ choices | join("|||") }}'
    choice_string: 'N/A'
    id: 6f694e45-1d17-4067-a1f6-7dae89c148db
    jinja: 'My daughter is asking me a question about {{ domain }}:
        "{{ question }}"
        Here''s what I found on the internet: {{ context }}
        What''s the answer?
        Answer: |||{{answer_choices[label]}}'
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
        - Accuracy
      original_task: zest
      is_mcq: false
      task_mode: QA
    name: ask_question_as_kid
    reference: 'Answer the questions of a curious kid. Metric: F1 Score with modified
        precision and recall, please refer to the paper https://arxiv.org/abs/2011.08115'
  7425232a-9880-428c-9ddc-4070e50e22cc: !Template
    answer_choices: '{{ choices | join("|||") }}'
    choice_string: 'N/A'
    id: 7425232a-9880-428c-9ddc-4070e50e22cc
    jinja: 'Answer the question based on the context. If the question is not answerable
        with the context alone, say "Can''t answer".
        {{ context }}
        {{ question }} ||| {{answer_choices[label]}}'
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
        - Accuracy
      original_task: zest
      is_mcq: false
      task_mode: QA
    name: gpt3_instruct_format
    reference: 'Template format from GPT3 instruct. Metric: F1 Score with modified
        precision and recall, please refer to the paper https://arxiv.org/abs/2011.08115'
  cd563834-49ee-495d-ac46-99f0264e58d5: !Template
    answer_choices: '{{ choices | join("|||") }}'
    choice_string: 'N/A'
    id: cd563834-49ee-495d-ac46-99f0264e58d5
    jinja: 'I am giving my students the following question about {{ domain }}: "{{ question }}".
        What should be their answer based on this context: {{ context }} ||| {{answer_choices[label]}}'
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
        - Accuracy
      original_task: zest
      is_mcq: false
      task_mode: QA
    name: ask_question_as_teacher
    reference: 'I don''t know answer. Metric: F1 Score with modified precision and
        recall, please refer to the paper https://arxiv.org/abs/2011.08115'
  091ba88e-d208-4a3a-ada7-d9698aeb5568: !Template
    answer_choices: '{{ choices | join("|||") }}'
    choice_string: 'N/A'
    id: 091ba88e-d208-4a3a-ada7-d9698aeb5568
    jinja: 'You will receive full credit if you solve the following word problem:
        {{ input_sequence }}
        {{ choice_string }} |||
        {{answer_choices[label]}}'
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
        - Accuracy
      original_task: math_qa
      is_mcq: true
      task_mode: CLASSIFICATION
    name: choose_correct_variant
    reference: 'Variant of choose_correct. '
  6312d599-8ca4-4bc8-a76f-81f2e36727bd: !Template
    answer_choices: '{{ choices | join("|||") }}'
    choice_string: 'N/A'
    id: 6312d599-8ca4-4bc8-a76f-81f2e36727bd
    jinja: 'Given the following problem:
        {{input_sequence}}
        ===
        and the following options, select the correct option
        {{ choice_string }}|||
        {{answer_choices[label]}}'
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
        - Accuracy
      original_task: math_qa
      is_mcq: true
      task_mode: CLASSIFICATION
    name: choose_correct_og
    reference: The template asks the model to choose the correct answer.
  8c4c81cc-ca54-45fc-a69a-4b97a5f2b465: !Template
    answer_choices: '{{ choices | join("|||") }}'
    choice_string: 'N/A'
    id: 8c4c81cc-ca54-45fc-a69a-4b97a5f2b465
    jinja: "Solve the problem by choosing the correct answer: \n{{input_sequence}}\n\n{{choice_string}}|||\n\
        {{answer_choices[label]}}"
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
        - Accuracy
      original_task: math_qa
      is_mcq: true
      task_mode: CLASSIFICATION
    name: pick_the_correct
    reference: The template picks the correct the answer choice
  06719321-62e7-4f6e-8f95-464cd2b5ca5c: !Template
    answer_choices: '{{ choices | join("|||") }}'
    choice_string: '"negative", "neutral", "positive"'
    id: 06719321-62e7-4f6e-8f95-464cd2b5ca5c
    jinja: 'Which word between {{choice_string}}
        would you use to describe the effect of the following news on the related share
        prices?
        {{input_sequence}} |||
        {{answer_choices[label]}}'
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
        - Accuracy
      original_task: financial_phrasebank/sentences_allagree
      is_mcq: false
      task_mode: CLASSIFICATION
    name: share_price_option
    reference: 'Metrics: Accuracy, Precision, Recall, F1 per class'
  0beba048-f949-4034-83b6-a3e0e7363f46: !Template
    answer_choices: '{{ choices | join("|||") }}'
    choice_string: 'N/A'
    id: 0beba048-f949-4034-83b6-a3e0e7363f46
    jinja: 'What is the sentiment of the sentence?
        {{input_sequence}} |||
        {{answer_choices[label]}}'
    metadata: !TemplateMetadata
      choices_in_prompt: false
      metrics:
        - Accuracy
      original_task: financial_phrasebank/sentences_allagree
      is_mcq: false
      task_mode: CLASSIFICATION
    name: sentiment
    reference: 'Metrics: Accuracy, Precision, Recall, F1 per class'
  461efe04-6883-41e8-80f0-e722a75260fe: !Template
    answer_choices: '{{ choices | join("|||") }}'
    choice_string: 'N/A'
    id: 461efe04-6883-41e8-80f0-e722a75260fe
    jinja: 'What does the following argument mean for the complementary industries?
        {{input_sequence}} |||
        {{answer_choices[label]}}'
    metadata: !TemplateMetadata
      choices_in_prompt: false
      metrics:
        - Accuracy
      original_task: financial_phrasebank/sentences_allagree
      is_mcq: false
      task_mode: CLASSIFICATION
    name: complementary_industries
    reference: 'Metrics: Accuracy, Precision, Recall, F1 per class'
  5fa16d31-b513-480d-bd1b-1fa8c182fb76: !Template
    answer_choices: '{{ choices | join("|||") }}'
    choice_string: '"bullish", "neutral", or "bearish"'
    id: 5fa16d31-b513-480d-bd1b-1fa8c182fb76
    jinja: 'Should an investor be {{choice_string}}
        given the following news?
        {{input_sequence}} |||
        {{answer_choices[label]}}'
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
        - Accuracy
      original_task: financial_phrasebank/sentences_allagree
      is_mcq: false
      task_mode: CLASSIFICATION
    name: bullish_neutral_bearish
    reference: 'Metrics: Accuracy, Precision, Recall, F1 per class'
  13c02904-e4e2-4b4f-b115-44b437d22041: !Template
    answer_choices: '{{ choices | join("|||") }}'
    choice_string: 'N/A'
    id: 13c02904-e4e2-4b4f-b115-44b437d22041
    jinja: '{{input_sequence}}
        ===
        Write a summary of the text above : |||
        {{answer_choices[label]}}'
    metadata: !TemplateMetadata
      choices_in_prompt: false
      metrics:
        - Accuracy
      original_task: xsum
      is_mcq: false
      task_mode: CLASSIFICATION
    name: DOC_write_summary_of_above
    reference: ''
  3d388a1e-3361-407b-baa7-61397cc58382: !Template
    answer_choices: '{{ choices | join("|||") }}'
    choice_string: 'N/A'
    id: 3d388a1e-3361-407b-baa7-61397cc58382
    jinja: '{{ input_sequence }}
        How would you rephrase that in a few words? ||| {{answer_choices[label]}}'
    metadata: !TemplateMetadata
      choices_in_prompt: false
      metrics:
        - Accuracy
      original_task: xsum
      is_mcq: false
      task_mode: CLASSIFICATION
    name: DOC_how_would_you_rephrase_few_words
    reference: http://gptprompts.wikidot.com/prompt:summarization
  4cfe4126-b9f5-44eb-8a98-973987c5f32e: !Template
    answer_choices: '{{ choices | join("|||") }}'
    choice_string: 'N/A'
    id: 4cfe4126-b9f5-44eb-8a98-973987c5f32e
    jinja: 'My college roommate asked me what this article means:
       {{input_sequence}}
       So I recapped it in layman''s terms: ||| {{answer_choices[label]}}'
    metadata: !TemplateMetadata
      choices_in_prompt: false
      metrics:
        - Accuracy
      original_task: xsum
      is_mcq: false
      task_mode: CLASSIFICATION
    name: college_roommate_asked_DOC_so_I_recap
    reference: http://gptprompts.wikidot.com/prompt:summarization
  9a3f617f-628f-4fa5-9b74-47d0b166a487: !Template
    answer_choices: '{{ choices | join("|||") }}'
    choice_string: 'N/A'
    id: 9a3f617f-628f-4fa5-9b74-47d0b166a487
    jinja: 'First, please read the article below.
        {{input_sequence}}
        Now, can you write me an extremely short abstract for it?  |||  {{answer_choices[label]}}'
    metadata: !TemplateMetadata
      choices_in_prompt: false
      metrics:
        - Accuracy
      original_task: xsum
      is_mcq: false
      task_mode: CLASSIFICATION
    name: read_below_DOC_write_abstract
    reference: ''
  1ee5ddef-fffb-4b73-a2f7-f600ffac63cb: !Template
    answer_choices: '{{ choices | join("|||") }}'
    choice_string: 'N/A'
    id: 1ee5ddef-fffb-4b73-a2f7-f600ffac63cb
    jinja: '{{input_sequence}}...
        What comes after the ellipses? ||| {{ answer_choices[label] }}'
    metadata: !TemplateMetadata
      choices_in_prompt: false
      metrics:
        - Accuracy
      original_task: craffel/openai_lambada
      is_mcq: false
      task_mode: CLASSIFICATION
    name: ellipses
    reference: ''
  4f08e9d4-bcff-4bc0-9902-87c497625d17: !Template
    answer_choices: '{{ choices | join("|||") }}'
    choice_string: 'N/A'
    id: 4f08e9d4-bcff-4bc0-9902-87c497625d17
    jinja: 'Fill in the blank:
        {{ input_sequence }} ____. ||| {{ answer_choices[label] }}'
    metadata: !TemplateMetadata
      choices_in_prompt: false
      metrics:
        - Accuracy
      original_task: craffel/openai_lambada
      is_mcq: false
      task_mode: CLASSIFICATION
    name: GPT-3 style
    reference: Brown et al.
  774b4349-0524-4a34-881b-b344f8f5c34e: !Template
    answer_choices: '{{ choices | join("|||") }}'
    choice_string: 'N/A'
    id: 774b4349-0524-4a34-881b-b344f8f5c34e
    jinja: 'This story got cut short. What comes next?
       {{ input_sequence }} ||| {{ answer_choices[label] }}'
    metadata: !TemplateMetadata
      choices_in_prompt: false
      metrics:
        - Accuracy
      original_task: craffel/openai_lambada
      is_mcq: false
      task_mode: CLASSIFICATION
    name: what comes next
    reference: ''
  2bca0197-e3d4-4870-bd95-178411e52e09: !Template
    answer_choices: '{{ choices | join("|||") }}'
    choice_string: 'N/A'
    id: 2bca0197-e3d4-4870-bd95-178411e52e09
    jinja: 'Use the reference abstracts to generate related work:
        {{ input_sequence }}  |||
        {{  answer_choices[label]  }}'
    metadata: !TemplateMetadata
      choices_in_prompt: false
      metrics:
        - Accuracy
      original_task: multi_x_science_sum
      is_mcq: false
      task_mode: CLASSIFICATION
    name: ref_relatedwork
    reference: ''
  3bd082cb-4e28-4eb7-9fa2-dd03f1f86219: !Template
    answer_choices: '{{ choices | join("|||") }}'
    choice_string: 'N/A'
    id: 3bd082cb-4e28-4eb7-9fa2-dd03f1f86219
    jinja: 'Given the abstract of a paper, provide some related work for readers to
       learn further
       {{ input_sequence }}  |||
        {{  answer_choices[label]  }}'
    metadata: !TemplateMetadata
      choices_in_prompt: false
      metrics:
        - Accuracy
      original_task: multi_x_science_sum
      is_mcq: false
      task_mode: CLASSIFICATION
    name: abstract_relatedwork
    reference: ''
  af4d550e-54b8-471e-97af-2b2c50a1382e: !Template
    answer_choices: '{{ choices | join("|||") }}'
    choice_string: 'N/A'
    id: af4d550e-54b8-471e-97af-2b2c50a1382e
    jinja: 'Use the related work to guess the abstract:
        {{ input_sequence }}  |||
        {{  answer_choices[label]  }}'
    metadata: !TemplateMetadata
      choices_in_prompt: false
      metrics:
        - Accuracy
      original_task: multi_x_science_sum
      is_mcq: false
      task_mode: CLASSIFICATION
    name: relatedwork_abstract
    reference: ''
  202246b0-3f82-42b9-bc8d-d36997b5f2cb: !Template
    answer_choices: '{{ choices | join("|||") }}'
    choice_string: '{{ choices | join(", ") }}'
    id: 202246b0-3f82-42b9-bc8d-d36997b5f2cb
    jinja: "Given the sentence, {{input_sequence}}\n\nOut of the options {{choice_string}}, \n\nWhat is the semantic relations between the two nominals\
        \ (nouns or noun phrases) e1 and e2 in the sentence: ||| {{ answer_choices[label]\
        \ }}"
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
        - Accuracy
      original_task: sem_eval_2010_task_8
      is_mcq: false
      task_mode: CLASSIFICATION
    name: semantic relations with options
    reference: out of options; macro-averaged F1-score official metric
  5d7123a8-4ed4-42ce-bcfb-4af415962efc: !Template
    answer_choices: '{{ choices | join("|||") }}'
    choice_string: '{{ choices | join(", ") }}'
    id: 5d7123a8-4ed4-42ce-bcfb-4af415962efc
    jinja: 'How semantically related are the two nominals in the sentence, {{input_sequence}}
        Please answer {{choice_string}}:
        ||| {{ answer_choices[label] }}'
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
        - Accuracy
      original_task: sem_eval_2010_task_8
      is_mcq: false
      task_mode: CLASSIFICATION
    name: semantically related nominials with options
    reference: 'please answer; official metric:  macro-averaged F1-score'
  c97e7bbf-b7f0-4cee-ada5-431ce7d606cc: !Template
    answer_choices: '{{ choices | join("|||") }}'
    choice_string: '{{ choices | join(", ") }}'
    id: c97e7bbf-b7f0-4cee-ada5-431ce7d606cc
    jinja: 'Given the sentence, {{ input_sequence }}
        ===
        What is the semantic relations between the two nominals (nouns or noun phrases)
        e1 and e2 in the sentence: ||| {{ answer_choices[label] }}'
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
        - Accuracy
      original_task: sem_eval_2010_task_8
      is_mcq: false
      task_mode: CLASSIFICATION
    name: semantic relations nominials without options
    reference: mention e1,e2 after; macro-averaged F1-score official metric
  1f959d92-dca8-4647-9840-69391dfbd000: !Template
    answer_choices: '{{ choices | join("|||") }}'
    choice_string: 'N/A'
    id: 1f959d92-dca8-4647-9840-69391dfbd000
    jinja: "Fill in the blank in the following sentence using world knowledge:\n\n\
       {{ input_sequence }}\n\nChose from the following\
       \ options:\n\n{{ ', '.join(answer_choices) }} ||| {{ answer_choices[label] }}"
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
        - Accuracy
      original_task: numer_sense
      is_mcq: false
      task_mode: CLASSIFICATION
    name: fill_in_the_blank_with_choices_after
    reference: ''
  4e9da2b8-2502-44a7-a7da-ae62f2d554c9: !Template
    answer_choices: '{{ choices | join("|||") }}'
    choice_string: 'N/A'
    id: 4e9da2b8-2502-44a7-a7da-ae62f2d554c9
    jinja: 'The following sentence needs to be filled with a word which is a number
     word or "no". Using common sense and world knowledge fill in the blanks.
     {{ input_sequence }}
     Which is it?
     |||
     {{ answer_choices[label] }}'
    metadata: !TemplateMetadata
      choices_in_prompt: false
      metrics:
        - Accuracy
      original_task: numer_sense
      is_mcq: false
      task_mode: CLASSIFICATION
    name: fill_in_the_blank_with_instruction
    reference: ''
  5d8e8d21-8059-4373-bbf2-a25cbe1e6960: !Template
    answer_choices: '{{ choices | join("|||") }}'
    choice_string: 'N/A'
    id: 5d8e8d21-8059-4373-bbf2-a25cbe1e6960
    jinja: 'Using common sense reasoning of the world and only the following options,
     how would you fill in the blank?:
     {{ '', ''.join(answer_choices) }}
     {{ input_sequence }}
     |||
     {{answer_choices[label]}}'
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
        - Accuracy
      original_task: numer_sense
      is_mcq: false
      task_mode: CLASSIFICATION
    name: fill_in_the_blank_with_choices_before
    reference: with all the given options
  cacee36c-e2b7-458e-9d51-6fcfd83842b4: !Template
    answer_choices: '{{ choices | join("|||") }}'
    choice_string: 'N/A'
    id: cacee36c-e2b7-458e-9d51-6fcfd83842b4
    jinja: 'Fill in the blanks:
     {{ input_sequence }}
     The correct answer is:
     |||
     {{answer_choices[label]}}'
    metadata: !TemplateMetadata
      choices_in_prompt: false
      metrics:
        - Accuracy
      original_task: numer_sense
      is_mcq: false
      task_mode: CLASSIFICATION
    name: fill_in_the_blank_before_sentence
    reference: replace mask with fill in the blank
  fc76beb7-c258-412f-a623-42fc8d2331b6: !Template
    answer_choices: '{{ choices | join("|||") }}'
    choice_string: 'N/A'
    id: fc76beb7-c258-412f-a623-42fc8d2331b6
    jinja: "{{ input_sequence }}\n\nUsing only the following\
     \ options, what answer would make the most sense in the blank above?\n\n{{ ',\
     \ '.join(answer_choices) }}\n\n||| \n\n{{answer_choices[label]}}"
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
        - Accuracy
      original_task: numer_sense
      is_mcq: false
      task_mode: CLASSIFICATION
    name: fill_in_the_blank_with_instruction_and_choices
    reference: missing word simple
  b7012213-04c4-424d-85fb-39d63d8a0ca2: !Template
    answer_choices: '{{ choices | join("|||") }}'
    choice_string: 'N/A'
    id: b7012213-04c4-424d-85fb-39d63d8a0ca2
    jinja: 'What are the topics in the sentence: {{input_sequence}}
        |||
        {{ answer_choices[label] }}'
    metadata: !TemplateMetadata
      choices_in_prompt: false
      metrics:
        - Accuracy
      original_task: common_gen
      is_mcq: false
      task_mode: CLASSIFICATION
    name: topics from the sentence
    reference: The template generates a random topic from the sentence
  ed215962-8e51-45e7-b025-6e822f877098: !Template
    answer_choices: '{{ choices | join("|||") }}'
    choice_string: 'N/A'
    id: ed215962-8e51-45e7-b025-6e822f877098
    jinja: "We have the sentence: {{input_sequence}}; \nExtract all the key concepts: \n|||\n\
        {{ answer_choices[label] }}"
    metadata: !TemplateMetadata
      choices_in_prompt: false
      metrics:
        - Accuracy
      original_task: common_gen
      is_mcq: false
      task_mode: CLASSIFICATION
    name: sentence to concepts
    reference: Template identifies the concepts from the sentence
  c4ed37ae-d7d7-4197-a725-ef2152fa3b1f: !Template
    answer_choices: '{{ choices | join("|||") }}'
    choice_string: 'N/A'
    id: c4ed37ae-d7d7-4197-a725-ef2152fa3b1f
    jinja: 'Suppose {{premise}} Can we infer that "{{hypothesis}}"? {{ choice_string }}?
        ||| {{ answer_choices[label] }} '
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
        - Accuracy
      original_task: anli
      is_mcq: false
      task_mode: ENTAILMENT
    name: can we infer
    reference: Webson & Pavlick 2021
  ec249357-e672-4e7d-b8b6-d97ed7d090c5: !Template
    answer_choices: '{{ choices | join("|||") }}'
    choice_string: 'N/A'
    id: ec249357-e672-4e7d-b8b6-d97ed7d090c5
    jinja: '{{premise}} Based on that information, is the claim: "{{hypothesis}}"
        {{ choice_string }}? ||| {{ answer_choices[label]
        }}'
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
        - Accuracy
      original_task: anli
      is_mcq: false
      task_mode: ENTAILMENT
    name: claim true/false/inconclusive
    reference: v0.1
  620aa3fc-d5eb-46f5-a1ee-4c754527aa97: !Template
    answer_choices: '{{ choices | join("|||") }}'
    choice_string: 'N/A'
    id: 620aa3fc-d5eb-46f5-a1ee-4c754527aa97
    jinja: '{{premise}}
      Question: {{hypothesis}} {{choice_string}}? ||| {{ answer_choices[label]
      }}'
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
        - Accuracy
      original_task: anli
      is_mcq: false
      task_mode: ENTAILMENT
    name: GPT-3 style
    reference: 'Same as reported in Figure G7 of the GPT-3 paper, except that there
      is no task identifying tokens like "anli R1: ".'
  9b613182-c6ab-4427-9221-3d68f6d62765: !Template
    answer_choices: '{{ choices | join("|||") }}'
    choice_string: 'N/A'
    id: 9b613182-c6ab-4427-9221-3d68f6d62765
    jinja: '{{premise}} Based on the previous passage, is it true that "{{hypothesis}}"?
      {{ choice_string }}? ||| {{ answer_choices[label] }}'
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
        - Accuracy
      original_task: anli
      is_mcq: false
      task_mode: ENTAILMENT
    name: based on the previous passage
    reference: "Adapted from the BoolQ prompts in Schick & Sch\xFCtze 2021."
  a850110d-f1a3-49b4-949a-d3bfe9f81344: !Template
    answer_choices: '{{ choices | join("|||") }}'
    choice_string: 'N/A'
    id: a850110d-f1a3-49b4-949a-d3bfe9f81344
    jinja: '{{premise}} Are we justified in saying that "{{hypothesis}}"? {{ choice_string }}? ||| {{ answer_choices[label] }} '
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
        - Accuracy
      original_task: anli
      is_mcq: false
      task_mode: ENTAILMENT
    name: justified in saying
    reference: Webson & Pavlick 2021
  bab86d5a-4f9c-40db-b619-a7b7d5cae681: !Template
    answer_choices: '{{ choices | join("|||") }}'
    choice_string: 'N/A'
    id: bab86d5a-4f9c-40db-b619-a7b7d5cae681
    jinja: 'Take the following as truth: {{premise}}
      Then the following statement: "{{hypothesis}}" is {{ choice_string }}? ||| {{ answer_choices[label] }}'
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
        - Accuracy
      original_task: anli
      is_mcq: false
      task_mode: ENTAILMENT
    name: take the following as truth
    reference: v0.1
  0edd8660-f299-4819-a5ac-633c11177228: !Template
    answer_choices: '{{ choices | join("|||") }}'
    choice_string: 'N/A'
    id: 0edd8660-f299-4819-a5ac-633c11177228
    jinja: 'Exercise: choose the most plausible alternative.
        {{ input_sequence }} because...
        {% for choice in answer_choices %}
        - {{ choice }}
        {% endfor %} ||| {{ answer_choices[label] }}'
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
        - Accuracy
      original_task: super_glue/copa
      is_mcq: false
      task_mode: CLASSIFICATION
    name: exercise
    reference: ''
  a1f9951e-2b6b-4530-9636-9cdf4c1658c5: !Template
    answer_choices: '{{ choices | join("|||") }}'
    choice_string: 'N/A'
    id: a1f9951e-2b6b-4530-9636-9cdf4c1658c5
    jinja: 'Pick the more likely continuation to the following sentence:
       {{ input_sequence }} as a result of:
       {% for choice in answer_choices %}
        - {{ choice }}
        {% endfor %} ||| {{ answer_choices[label] }}'
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
        - Accuracy
      original_task: super_glue/copa
      is_mcq: false
      task_mode: CLASSIFICATION
    name: more likely
    reference: ''
  f32348cd-d3cb-4619-87b9-e24f99c78567: !Template
    answer_choices: '{{ choices | join("|||") }}'
    choice_string: 'N/A'
    id: f32348cd-d3cb-4619-87b9-e24f99c78567
    jinja: '{{ input_sequence }} because...
        Choose between:
        {% for choice in answer_choices %}
        - {{ choice }}
        {% endfor %} ||| {% if label != -1 %}{{ answer_choices[label] }}{%endif%}'
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
        - Accuracy
      original_task: super_glue/copa
      is_mcq: false
      task_mode: CLASSIFICATION
    name: choose
    reference: ''
  14e73f39-a0d1-44c2-b9a4-4e48f9f1608e: !Template
    answer_choices: '{{ choices | join("|||") }}'
    choice_string: 'N/A'
    id: 14e73f39-a0d1-44c2-b9a4-4e48f9f1608e
    jinja: 'Does the word "{{domain}}" have the same meaning in these two sentences?
        {{ choice_string }}?
        {{premise}}
        {{hypothesis}}
        ||| {{answer_choices[label]}}'
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
        - Accuracy
      original_task: super_glue/wic
      is_mcq: false
      task_mode: ENTAILMENT
    name: question-context-meaning-with-label
    reference: Generalized question-context format with label
  3503ead5-4fa5-4f77-95dc-f0c2ed3eecdc: !Template
    answer_choices: '{{ choices | join("|||") }}'
    choice_string: 'N/A'
    id: 3503ead5-4fa5-4f77-95dc-f0c2ed3eecdc
    jinja: 'Does the word "{{domain}}" have the same meaning in these two sentences?
      {{premise}}
      {{hypothesis}}
      ||| {{answer_choices[label]}}'
    metadata: !TemplateMetadata
      choices_in_prompt: false
      metrics:
        - Accuracy
      original_task: super_glue/wic
      is_mcq: false
      task_mode: ENTAILMENT
    name: question-context-meaning
    reference: Generalized question-context format
  611d13dc-d414-4b9b-9204-e4f325e859e7: !Template
    answer_choices: '{{ choices | join("|||") }}'
    choice_string: 'N/A'
    id: 611d13dc-d414-4b9b-9204-e4f325e859e7
    jinja: 'Homework
      Decide whether the word "{{domain}}" is used with the same meaning in the two
      following sentences. Answer by yes or no.
      {{premise}}
      {{hypothesis}}
      ||| {{answer_choices[label]}}'
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
        - Accuracy
      original_task: super_glue/wic
      is_mcq: false
      task_mode: ENTAILMENT
    name: grammar_homework
    reference: ''
  725b5ed0-7728-4890-95a4-a74cb7ae1bb4: !Template
    answer_choices: '{{ choices | join("|||") }}'
    choice_string: 'N/A'
    id: 725b5ed0-7728-4890-95a4-a74cb7ae1bb4
    jinja: 'Sentence A: {{premise}}
      Sentence B: {{ hypothesis}}
      "{{ domain }}" has a similar meaning in sentences A and B. {{choice_string}}?
      ||| {{answer_choices[label]}}'
    metadata: !TemplateMetadata
      choices_in_prompt: true
      metrics:
        - Accuracy
      original_task: super_glue/wic
      is_mcq: false
      task_mode: ENTAILMENT
    name: affirmation_true_or_false
    reference: ''