f1,f1_choice_3,logits/range_std,logits/range_mean,logits/choice_3_rank_mean,logits/diff_2_to_3_std,logits/choice_3_rank_std,f1_choice_2,f1_choice_4,logits/diff_3_to_4_mean,logits/choice_4_rank_mean,input_len/mean,logits/diff_1_to_2_mean,logits/choice_1_rank_mean,f1_choice_1,logits/diff_2_to_3_mean,logits/choice_1_rank_std,logits/diff_1_to_2_std,logits/choice_2_rank_std,logits/choice_2_rank_mean,accuracy,predictions,input_len/std,logits/diff_3_to_4_std,logits/choice_4_rank_std,debug,force,split,is_mcq,choices,num_proc,run_name,prompt_id,task.name,task_mode,base_model,batch_size,model_name,cuda_device,has_choices,prompt_name,prompt_path,prompt_task,task.splits,choice_count,group.suffix,prompt_count,prompt_group,prompt_tasks,original_task,task.category,task.dir_name,training_task,disable_caching,prompt_category,disable_tracking,force_generation,choices_in_prompt,add_default_choices,dont_add_extra_text,general_prompts.dir,group.override_name,original_choice_str,length_normalization,original_prompt_name,task.general_prompts,prompt_experiment_mode,task.preprocessor.name,prompt_filter.name_list,prompt_filter.choice_list,task.preprocessor.choices,evaluation.force_generation,prompt_filter.original_task,task.default_answer_choices,evaluation.lowercase_choices,general_prompts.answer_filter,evaluation.length_normalization,general_prompts.category_filter,prompt_filter.choices_in_prompt,evaluation.use_only_correct_choice,task.preprocessor.add_speaker_prefix,name,group,auc-pr,auc-roc,task.verbose_name,task.parent_dataset,task.preprocessor.choice_str,task.preprocessor.mcq_choice_str,task.preprocessor.context_template,task.preprocessor.premise_template,task.preprocessor.question_template,task.preprocessor.hypothesis_template,task.preprocessor.classification_template,logits/choice_5_rank_mean,logits/choice_5_rank_std,logits/diff_4_to_5_std,logits/diff_4_to_5_mean,f1_choice_5,task.target_key,task.override_name,task.prompt_blacklist,task.preprocessor.use_lowercase_choices,accuracy_rank,f1_rank,prompt_tokens
9.995859937607513,4.444444444444444,0.9164877318233732,3.674426374003643,3.2716535433070866,0.4469668442498261,0.9725684509476872,5.405405405405406,0.0,0.5911314900465837,3.5236220472440944,95.56299212598424,0.5370786471629706,1.0984251968503935,40.12944983818771,0.4313048058607447,0.4718007473413861,0.4463223764066559,1.0993279388079946,2.9881889763779528,25.590551181102363,"{'ncols': 15, 'nrows': 254, 'sha256': 'f4ab4f5de4682810a12d136e88b340e4ebdbde5aa5a4911c643309b4107ebf0c', 'artifact_path': 'wandb-client-artifact://rtlgxnhoxu8jdxg8fhn6kxtpasnqwujtkarv1t8x79lfkkgz8h0c21llgb7gl8a8fg3fbxqrn88oo666ghdaayaxy3v1kp5nqbudciklulw54t4g2quvlk6ba7v9j0ue:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://rtlgxnhoxu8jdxg8fhn6kxtpasnqwujtkarv1t8x79lfkkgz8h0c21llgb7gl8a8fg3fbxqrn88oo666ghdaayaxy3v1kp5nqbudciklulw54t4g2quvlk6ba7v9j0ue:latest/predictions.table.json', 'path': 'media/table/predictions_1_f4ab4f5de4682810a12d.table.json', 'size': 134865, '_type': 'table-file'}",24.348559119682264,0.6154328235339803,1.018255161384978,False,True,validation,False,A | B | C | D | E,4,CTBase,a64d5a15-68e2-4d1c-b30a-ca8250c860f9,raw,QA,False,12,bigscience/T0_3B,0,True,answer_the_following_q,prompts/general_fixed_choice.yaml,AdversarialQA,,5,,,GenFC,,False,['Math QA'],aqua_rat,True,False,GeneralFixedChoice,False,False,False,,False,prompts,,False,True,answer_the_following_q,,cross_task,aqua_rat,,,,False,,,False,,True,,,False,,CTBase.GenFC.adversarial_qa.answer_the_following_q.LenNorm,AQuA,,,AQuA,aqua_rat,,,,,,,,4.118110236220472,1.17127142189737,1.0637048938635785,2.114911430933344,0.0,,aqua_rat,['generate_rational_and_correct_choice'],False,59.5,46.0,23
10.704557091653866,4.444444444444444,0.8619329896955283,3.65944711054404,3.133858267716536,0.5403262390732037,0.8772021083918335,0.0,0.0,0.641725831144438,3.52755905511811,86.54330708661418,0.8157509349462554,1.1062992125984252,41.935483870967744,0.5685498338984692,0.525454139011298,0.5906937719836095,0.9068459873315255,2.661417322834646,26.37795275590551,"{'_type': 'table-file', 'ncols': 15, 'nrows': 254, 'sha256': 'bcd0e5089376e68d890e3eccea172aeb967858ace6dd0551286c78b80f591573', 'artifact_path': 'wandb-client-artifact://16zk7urqk427xvdr8qhtsckxteph4lc7xpzwps0tzqj26m56ft2ybyg7perqxhfobyfq2zwyeibbdt6ocapphz6elcnnw0pini08x7jfioky60pqg41zmze4fjulq6bx:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://16zk7urqk427xvdr8qhtsckxteph4lc7xpzwps0tzqj26m56ft2ybyg7perqxhfobyfq2zwyeibbdt6ocapphz6elcnnw0pini08x7jfioky60pqg41zmze4fjulq6bx:latest/predictions.table.json', 'path': 'media/table/predictions_1_bcd0e5089376e68d890e.table.json', 'size': 124832}",24.361695732941868,0.5826873672026623,0.9292005848187214,False,True,validation,False,A | B | C | D | E,4,CTBase,a0872cde-2f19-4ae6-919a-868da47bfbcb,raw,QA,False,12,bigscience/T0_3B,0,True,based_on,prompts/general_fixed_choice.yaml,AdversarialQA,,5,,,GenFC,,False,['Math QA'],aqua_rat,True,False,GeneralFixedChoice,False,False,False,,False,prompts,,False,True,based_on,,cross_task,aqua_rat,,,,False,,,False,,True,,,False,,CTBase.GenFC.adversarial_qa.based_on.LenNorm,AQuA,,,AQuA,aqua_rat,,,,,,,,4.570866141732283,0.8966789325428673,0.8707289922976559,1.633420510554877,7.142857142857144,,aqua_rat,['generate_rational_and_correct_choice'],False,43.0,38.0,16
10.692092717409174,4.545454545454545,0.8634944115002369,4.181489155987117,3.1811023622047245,0.4800636131748795,0.8821709338054122,0.0,0.0,0.6660939746015654,3.637795275590552,83.03149606299213,0.6128405398271215,1.0708661417322836,41.77215189873418,0.5074550129297212,0.4641663827776218,0.4848331006781066,0.921798079529025,2.763779527559055,26.77165354330709,"{'artifact_path': 'wandb-client-artifact://mlrf0tlfgegge3vwfu9g1lna0wo24p5o4newit7m75conbia9q6fwjz3e7egu1rzdn7newbd2ijfy61dagzjq4hbw20pkzaa0k66ha00wx5rsh793056gadmy24cm6ct:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://mlrf0tlfgegge3vwfu9g1lna0wo24p5o4newit7m75conbia9q6fwjz3e7egu1rzdn7newbd2ijfy61dagzjq4hbw20pkzaa0k66ha00wx5rsh793056gadmy24cm6ct:latest/predictions.table.json', 'path': 'media/table/predictions_1_918d111d11b34dbc399a.table.json', 'size': 112821, '_type': 'table-file', 'ncols': 15, 'nrows': 254, 'sha256': '918d111d11b34dbc399aad5b5a8bb493a77762dfa4aecda2806307ae33dc392a'}",24.43565776079581,0.6237885901561122,1.016937593131524,False,True,validation,False,A | B | C | D | E,4,CTBase,5bdb1815-5c6f-49a3-ad1d-367344420701,raw,QA,False,12,bigscience/T0_3B,0,True,question_context_answer,prompts/general_fixed_choice.yaml,AdversarialQA,,5,,,GenFC,,False,['Math QA'],aqua_rat,True,False,GeneralFixedChoice,False,False,False,,False,prompts,,False,True,question_context_answer,,cross_task,aqua_rat,,,,False,,,False,,True,,,False,,CTBase.GenFC.adversarial_qa.question_context_answer.LenNorm,AQuA,,,AQuA,aqua_rat,,,,,,,,4.346456692913386,1.0452589081813033,1.0309983538988192,2.3950996286287083,7.142857142857144,,aqua_rat,['generate_rational_and_correct_choice'],False,29.5,39.0,11
11.804540061833752,4.444444444444444,0.8517859368231658,3.371818439228328,3.228346456692913,0.4668744017770139,0.928032177506494,0.0,6.779661016949154,0.6026828044981468,3.484251968503937,94.09055118110236,0.6386232413644866,1.1732283464566928,40.65573770491803,0.4775786080698329,0.6826821603864162,0.491116446000932,1.0385644694636509,2.874015748031496,25.984251968503933,"{'sha256': '9f006300bd3ebffaa655fabf13d2cd12a230852231b12c2455592689a8872542', 'artifact_path': 'wandb-client-artifact://n3o5xj3ipeuayuqej44tbo6youak2j0fnn4otzixgjinsrjofanaolydj3limhmf5rjzryfwiptw4dri6hqp2r0wl1rt5boavgkfh52xt0tenlxier2wphhnqz92o0xz:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://n3o5xj3ipeuayuqej44tbo6youak2j0fnn4otzixgjinsrjofanaolydj3limhmf5rjzryfwiptw4dri6hqp2r0wl1rt5boavgkfh52xt0tenlxier2wphhnqz92o0xz:latest/predictions.table.json', 'path': 'media/table/predictions_1_9f006300bd3ebffaa655.table.json', 'size': 124782, '_type': 'table-file', 'ncols': 15, 'nrows': 254}",24.435590839924444,0.5925425711629657,1.0261099384584536,False,True,validation,False,A | B | C | D | E,4,CTBase,3b2459cc-6600-443c-abf8-8f60c34cd998,raw,QA,False,12,bigscience/T0_3B,0,True,tell_what_it_is,prompts/general_fixed_choice.yaml,AdversarialQA,,5,,,GenFC,,False,['Math QA'],aqua_rat,True,False,GeneralFixedChoice,False,False,False,,False,prompts,,False,True,tell_what_it_is,,cross_task,aqua_rat,,,,False,,,False,,True,,,False,,CTBase.GenFC.adversarial_qa.tell_what_it_is.LenNorm,AQuA,,,AQuA,aqua_rat,,,,,,,,4.24015748031496,1.1677260925270336,0.9345722900193654,1.652933785295862,7.142857142857144,,aqua_rat,['generate_rational_and_correct_choice'],False,52.0,31.0,22
8.5,0.0,0.814764923311978,4.54676717097365,3.255905511811024,0.404794015668044,0.8285414129430985,0.0,0.0,0.6964677619183157,3.531496062992126,81.54330708661418,0.6374029268429974,1.031496062992126,42.49999999999999,0.4321951978788601,0.3183868758922162,0.4912856075662516,0.917795829527662,2.618110236220472,26.77165354330709,"{'sha256': 'd192cf881f891698e2e7302cf566af98a3cc0d36c361297bd9ff0504560db902', 'artifact_path': 'wandb-client-artifact://ptjkvpi103pf5m96exvfp9gwtrhgfsumr0daeectui5gfjtbr5hel4till2uqok03qujiou6dpw659995atnbahawwhrj97s7f788c0k31dluvjxkg7zjnzcu60cw4q2:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://ptjkvpi103pf5m96exvfp9gwtrhgfsumr0daeectui5gfjtbr5hel4till2uqok03qujiou6dpw659995atnbahawwhrj97s7f788c0k31dluvjxkg7zjnzcu60cw4q2:latest/predictions.table.json', 'path': 'media/table/predictions_1_d192cf881f891698e2e7.table.json', 'size': 116632, '_type': 'table-file', 'ncols': 15, 'nrows': 254}",24.361695732941868,0.6241100906492069,0.8677240378657328,False,True,validation,False,A | B | C | D | E,4,CTBase,4dd990b3-7201-4cba-bb9a-baa462d68b1a,raw,SENTIMENT,False,12,bigscience/T0_3B,0,True,format_score,prompts/general_fixed_choice.yaml,Yelp,,5,,,GenFC,,False,['Math QA'],aqua_rat,True,False,GeneralFixedChoice,False,False,False,,False,prompts,,False,True,format_score,,cross_task,aqua_rat,,,,False,,,False,,True,,,False,,CTBase.GenFC.yelp.format_score.LenNorm,AQuA,,,AQuA,aqua_rat,,,,,,,,4.562992125984252,0.897266465535306,0.9006563350506801,2.780701284333477,0.0,,aqua_rat,['generate_rational_and_correct_choice'],False,29.5,79.5,12
9.435736677115989,4.545454545454545,0.8572616864479833,4.314180100058008,3.118110236220472,0.4438218583516096,0.8749728745252977,0.0,0.0,0.618061326620147,3.562992125984252,75.54330708661418,0.628127890309011,1.0393700787401574,42.63322884012539,0.4412777442631759,0.3414091872232881,0.5176533544454084,0.9126133714373964,2.807086614173228,27.165354330708663,"{'artifact_path': 'wandb-client-artifact://ey2qh044qyo2ov9xkxu4nrjpc3u36mzjd2taqck0b17xctk9cyckd6akxknucyp99v677qnqbsvihi67qsd0ze1d4rspohtkr7i130c3vtn4l035vmry21vhoirczreu:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://ey2qh044qyo2ov9xkxu4nrjpc3u36mzjd2taqck0b17xctk9cyckd6akxknucyp99v677qnqbsvihi67qsd0ze1d4rspohtkr7i130c3vtn4l035vmry21vhoirczreu:latest/predictions.table.json', 'path': 'media/table/predictions_1_98c2cd0252f7d162d66c.table.json', 'size': 110290, '_type': 'table-file', 'ncols': 15, 'nrows': 254, 'sha256': '98c2cd0252f7d162d66cfeaa2f86913c48ffdd312f76b2f99ef4c34b7b29671b'}",24.361695732941868,0.5504429249372615,0.9359237425701432,False,True,validation,False,A | B | C | D | E,4,CTBase,29fc6386-90b3-4976-b249-26e49fe7c924,raw,SENTIMENT,False,12,bigscience/T0_3B,0,True,format_star,prompts/general_fixed_choice.yaml,Yelp,,5,,,GenFC,,False,['Math QA'],aqua_rat,True,False,GeneralFixedChoice,False,False,False,,False,prompts,,False,True,format_star,,cross_task,aqua_rat,,,,False,,,False,,True,,,False,,CTBase.GenFC.yelp.format_star.LenNorm,AQuA,,,AQuA,aqua_rat,,,,,,,,4.47244094488189,1.0142820404286548,0.8732583940971493,2.6267131388656737,0.0,,aqua_rat,['generate_rational_and_correct_choice'],False,13.5,59.0,6
9.025687246507436,0.0,0.7050989333623441,3.4029083815146617,3.1023622047244093,0.4212976267416298,0.8019135153684419,2.857142857142857,0.0,0.5847389040969488,3.5196850393700787,79.54330708661418,0.6775887782179465,1.0433070866141732,42.27129337539432,0.4426254137294499,0.3351085265931757,0.4651673093095365,0.7874114172613196,2.5078740157480315,26.77165354330709,"{'sha256': '24030722b15c2e4eeffb8b26961927954539d614aea54e1aed7630f2c0567317', 'artifact_path': 'wandb-client-artifact://a0d8ww0zkfz9w8ky6rtgrk3std70jkb759emq5w8bxz7lmfhgkqaxsz1sb96jw4yoz2amkf2hlj9h31w0v6qtpghpn1ipzyyqvjzri4fpvm1yqvaifrfbenmuhsz96oa:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://a0d8ww0zkfz9w8ky6rtgrk3std70jkb759emq5w8bxz7lmfhgkqaxsz1sb96jw4yoz2amkf2hlj9h31w0v6qtpghpn1ipzyyqvjzri4fpvm1yqvaifrfbenmuhsz96oa:latest/predictions.table.json', 'path': 'media/table/predictions_1_24030722b15c2e4eeffb.table.json', 'size': 113431, '_type': 'table-file', 'ncols': 15, 'nrows': 254}",24.361695732941868,0.4914060369030745,0.8166610887453054,False,True,validation,False,A | B | C | D | E,4,CTBase,27b6bc81-bb1c-467b-91c0-22a4d6a19f44,raw,SENTIMENT,False,12,bigscience/T0_3B,0,True,based_on_that,prompts/general_fixed_choice.yaml,Yelp,,5,,,GenFC,,False,['Math QA'],aqua_rat,True,False,GeneralFixedChoice,False,False,False,,False,prompts,,False,True,based_on_that,,cross_task,aqua_rat,,,,False,,,False,,True,,,False,,CTBase.GenFC.yelp.based_on_that.LenNorm,AQuA,,,AQuA,aqua_rat,,,,,,,,4.826771653543307,0.5188492443948212,0.6898899556802112,1.6979552854703168,0.0,,aqua_rat,['generate_rational_and_correct_choice'],False,29.5,72.0,10
9.336763865065754,4.545454545454545,0.7587108528791228,3.911942735431701,3.1653543307086616,0.4886694459990856,0.9244174971815592,0.0,0.0,0.6314223845173993,3.543307086614173,76.54330708661418,0.6496434361915889,1.031496062992126,42.138364779874216,0.4539873637552336,0.2489982409581401,0.4882357114870805,0.9027774532044208,2.8464566929133857,26.77165354330709,"{'ncols': 15, 'nrows': 254, 'sha256': '6dd9cf8538a39d71ae419158892e93924254b1742a60a88784dedaffad970c8e', 'artifact_path': 'wandb-client-artifact://vnre20tdd2f9x7getp134utlj7rh24012s2kd9udsdbuiz69hqaft80v15hftxajy7mlkwqdhamrg29ktye722n1jj1wq1ddjurohsaoeii3llbyh74u4eii97twkvyu:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://vnre20tdd2f9x7getp134utlj7rh24012s2kd9udsdbuiz69hqaft80v15hftxajy7mlkwqdhamrg29ktye722n1jj1wq1ddjurohsaoeii3llbyh74u4eii97twkvyu:latest/predictions.table.json', 'path': 'media/table/predictions_1_6dd9cf8538a39d71ae41.table.json', 'size': 112091, '_type': 'table-file'}",24.361695732941868,0.5162117961614329,0.9980761455480162,False,True,validation,False,A | B | C | D | E,4,CTBase,135fcd11-9fcc-4b55-bf1b-9b76290d0f6b,raw,SENTIMENT,False,12,bigscience/T0_3B,0,True,so_i_would,prompts/general_fixed_choice.yaml,Yelp,,5,,,GenFC,,False,['Math QA'],aqua_rat,True,False,GeneralFixedChoice,False,False,False,,False,prompts,,False,True,so_i_would,,cross_task,aqua_rat,,,,False,,,False,,True,,,False,,CTBase.GenFC.yelp.so_i_would.LenNorm,AQuA,,,AQuA,aqua_rat,,,,,,,,4.413385826771654,1.026412006478497,0.8923100918260407,2.1768895509674797,0.0,,aqua_rat,['generate_rational_and_correct_choice'],False,29.5,65.5,7
8.625,0.0,0.4182061827674571,1.8953796334154025,3.984251968503937,0.1926406464650716,1.0385047698418692,0.0,0.0,0.3027176387666717,3.5118110236220472,102.87007874015748,0.3439739858071635,1.0393700787401574,43.125,0.2535671418107401,0.3637420303134203,0.2443820166814084,0.741747329201933,3.968503937007874,27.165354330708663,"{'size': 130202, '_type': 'table-file', 'ncols': 15, 'nrows': 254, 'sha256': '555adb3e66bcfe2232c5595a253dec776398ca81a144c723b7d110c5638085f8', 'artifact_path': 'wandb-client-artifact://qydpo4c3ak1w6200wzcxydjb6yix25k996sksgq6v6v130i75om0jcqyriouopitg2lwhkqg1eigph41rezzzdmxmcl3ial5245c6ymy7wvhm839r7zff52c1679udjv:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://qydpo4c3ak1w6200wzcxydjb6yix25k996sksgq6v6v130i75om0jcqyriouopitg2lwhkqg1eigph41rezzzdmxmcl3ial5245c6ymy7wvhm839r7zff52c1679udjv:latest/predictions.table.json', 'path': 'media/table/predictions_1_555adb3e66bcfe2232c5.table.json'}",24.470029282055755,0.2426103941517382,1.0376088633316056,False,True,validation,False,A | B | C | D | E,4,CTBase,2da8f134-58db-4f9d-b3b0-8c6b50693ab5,raw,SENTIMENT,False,12,bigscience/T0_3B,0,True,categorize_rating_using_review,prompts/general_fixed_choice.yaml,AppReviews,,5,,,GenFC,,False,['Math QA'],aqua_rat,True,False,GeneralFixedChoice,False,False,True,,False,prompts,,False,True,categorize_rating_using_review,,cross_task,aqua_rat,,,,False,,,False,,True,,,False,,CTBase.GenFC.app_reviews.categorize_rating_using_review.LenNorm,AQuA,,,AQuA,aqua_rat,,,,,,,,2.4960629921259843,0.9463898727837184,0.4181839166593763,0.995120867030827,0.0,,aqua_rat,['generate_rational_and_correct_choice'],False,13.5,73.0,18
8.544891640866874,0.0,0.7394943233096631,4.142484679935485,3.1653543307086616,0.3046013797251589,0.8763181704535583,0.0,0.0,0.476005685611034,3.3503937007874014,97.87007874015748,0.6564961042929822,1.0,42.72445820433437,0.3577850184102696,0.0,0.4741738288570716,0.8958747709268357,2.9763779527559056,27.165354330708663,"{'nrows': 254, 'sha256': '8d80953ce82f7ff0a037ae4a0028f954ca7c7041006c5abf30701ac8194588c9', 'artifact_path': 'wandb-client-artifact://tajtwjsc57pa92637tbv0lyfwnrgwfo4ol1awor0ygc0ao4c12ewsbxvb1tfacfqp0n976wg3cw4eni70fj3kmhqmr4r02vbkpsa2heh5d2v181owms0v1lz14czgnkw:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://tajtwjsc57pa92637tbv0lyfwnrgwfo4ol1awor0ygc0ao4c12ewsbxvb1tfacfqp0n976wg3cw4eni70fj3kmhqmr4r02vbkpsa2heh5d2v181owms0v1lz14czgnkw:latest/predictions.table.json', 'path': 'media/table/predictions_1_8d80953ce82f7ff0a037.table.json', 'size': 133970, '_type': 'table-file', 'ncols': 15}",24.470029282055755,0.4349313369318192,0.9676153019453264,False,True,validation,False,A | B | C | D | E,4,CTBase,d34e1413-2699-4701-baa2-05d931d012ba,raw,SENTIMENT,False,12,bigscience/T0_3B,0,True,convert_to_rating,prompts/general_fixed_choice.yaml,AppReviews,,5,,,GenFC,,False,['Math QA'],aqua_rat,True,False,GeneralFixedChoice,False,False,False,,False,prompts,,False,True,convert_to_rating,,cross_task,aqua_rat,,,,False,,,False,,True,,,False,,CTBase.GenFC.app_reviews.convert_to_rating.LenNorm,AQuA,,,AQuA,aqua_rat,,,,,,,,4.507874015748032,1.0338450743081746,0.7868707861863614,2.6521978716212,0.0,,aqua_rat,['generate_rational_and_correct_choice'],False,13.5,76.5,28
8.375,0.0,0.5268278235954554,3.4600168964055578,3.4606299212598426,0.2499508945248537,1.036928951492483,0.0,0.0,0.6860435290599433,3.15748031496063,79.54330708661418,0.2894943379980372,1.031496062992126,41.87499999999999,0.3107399152019831,0.3183868758922162,0.2323931609817823,1.2045764409155626,4.334645669291339,26.37795275590551,"{'artifact_path': 'wandb-client-artifact://dlaomwndyqrb1u40lcz16iczpkpxrs44yr9lqkiypcq0pdk5h6ycd3twr1wy02qlo3vdj1npwfc319ve6py19etbk4s1309dky7wslraxbcd5ali8xtve20cln57p2hw:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://dlaomwndyqrb1u40lcz16iczpkpxrs44yr9lqkiypcq0pdk5h6ycd3twr1wy02qlo3vdj1npwfc319ve6py19etbk4s1309dky7wslraxbcd5ali8xtve20cln57p2hw:latest/predictions.table.json', 'path': 'media/table/predictions_1_dbd15a92df8b83f2aad0.table.json', 'size': 118921, '_type': 'table-file', 'ncols': 15, 'nrows': 254, 'sha256': 'dbd15a92df8b83f2aad076ff6f755dd156bccd7b31885481cb4db72c2b480a23'}",24.361695732941868,0.5006390818937185,0.942648278612736,False,True,validation,False,A | B | C | D | E,4,CTBase,96538f30-f2c1-430e-8fc6-936a16966d9c,raw,SENTIMENT,False,12,bigscience/T0_3B,0,True,Writer_Expressed_Sentiment,prompts/general_fixed_choice.yaml,IMDB,,5,,,GenFC,,False,['Math QA'],aqua_rat,True,False,GeneralFixedChoice,False,False,False,,False,prompts,,False,True,Writer Expressed Sentiment,,cross_task,aqua_rat,,,,False,,,False,,True,,,False,,CTBase.GenFC.imdb.Writer_Expressed_Sentiment.LenNorm,AQuA,,,AQuA,aqua_rat,,,,,,,,3.015748031496063,0.7683119032049166,0.5838065277628549,2.173739114145594,0.0,,aqua_rat,['generate_rational_and_correct_choice'],False,43.0,86.0,10
8.473520249221183,0.0,0.661493186960789,4.297821844656636,3.393700787401575,0.3124931460467944,0.8753625149154292,0.0,0.0,0.4356757975000096,3.543307086614173,78.54330708661418,0.5515224013741561,1.0275590551181102,42.36760124610591,0.3724671498997005,0.312515112164821,0.4288510277040562,0.8980866400961691,3.2440944881889764,26.77165354330709,"{'artifact_path': 'wandb-client-artifact://f67osg7m2tufnvjkwbpv6svi2bxatrdurccwrlz3cacra3urimk3rbthr5ibckufihyu0o0xbxmniem7a5p53ye9p06qbbwhc4py0i4g6aaimxrmw81x557yvs6a11f2:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://f67osg7m2tufnvjkwbpv6svi2bxatrdurccwrlz3cacra3urimk3rbthr5ibckufihyu0o0xbxmniem7a5p53ye9p06qbbwhc4py0i4g6aaimxrmw81x557yvs6a11f2:latest/predictions.table.json', 'path': 'media/table/predictions_1_ccbaabcba0a741446b85.table.json', 'size': 115932, '_type': 'table-file', 'ncols': 15, 'nrows': 254, 'sha256': 'ccbaabcba0a741446b859074e44d49afc23a8be06871160fbbde0c6fc1228f72'}",24.361695732941868,0.4385452358517198,1.1065723876027715,False,True,validation,False,A | B | C | D | E,4,CTBase,866474a5-1498-46b7-bfee-ac0c5160707f,raw,SENTIMENT,False,12,bigscience/T0_3B,0,True,Reviewer_Sentiment_Feeling,prompts/general_fixed_choice.yaml,IMDB,,5,,,GenFC,,False,['Math QA'],aqua_rat,True,False,GeneralFixedChoice,False,False,False,,False,prompts,,False,True,Reviewer Sentiment Feeling,,cross_task,aqua_rat,,,,False,,,False,,True,,,False,,CTBase.GenFC.imdb.Reviewer_Sentiment_Feeling.LenNorm,AQuA,,,AQuA,aqua_rat,,,,,,,,3.7913385826771657,1.4417030405098388,0.7418097954186564,2.93815649588277,0.0,,aqua_rat,['generate_rational_and_correct_choice'],False,29.5,81.0,9
12.194809956050264,0.0,0.5091748433131116,1.1640752018906,3.4291338582677167,0.2029356940486503,1.2458188488416797,15.384615384615383,4.938271604938271,0.2491183205852358,3.3503937007874014,90.54330708661418,0.2898571735291969,1.7322834645669292,36.0,0.2362453411883256,1.3158561710745311,0.2328229821195034,1.3789254159926874,2.9881889763779528,21.65354330708661,"{'nrows': 254, 'sha256': '4a453a631a6f3247fe21ac3f2b342055c22d12801717bb7c16e4bfa88c3b64bf', 'artifact_path': 'wandb-client-artifact://uid5qppggs05seaqpqetywixxjb2i4y1dnwneneri7w4lc2ccaiu1l8qr6e1w70e9ut88rjbt49ym4vf8b8xtxb7z6da8js4ab5d7z8xesk4xp73rhn2su5v626l9hva:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://uid5qppggs05seaqpqetywixxjb2i4y1dnwneneri7w4lc2ccaiu1l8qr6e1w70e9ut88rjbt49ym4vf8b8xtxb7z6da8js4ab5d7z8xesk4xp73rhn2su5v626l9hva:latest/predictions.table.json', 'path': 'media/table/predictions_1_4a453a631a6f3247fe21.table.json', 'size': 118361, '_type': 'table-file', 'ncols': 15}",24.361695732941868,0.2491569571180329,1.2098919074350631,False,True,validation,False,A | B | C | D | E,4,CTBase,5f372fb1-795a-47b6-8ddf-c4fd1579e76a,raw,SENTIMENT,False,12,bigscience/T0_3B,0,True,Sentiment_with_choices,prompts/general_fixed_choice.yaml,IMDB,,5,,,GenFC,,False,['Math QA'],aqua_rat,True,False,GeneralFixedChoice,False,False,True,,False,prompts,,False,True,Sentiment with choices ,,cross_task,aqua_rat,,,,False,,,False,,True,,,False,,CTBase.GenFC.imdb.Sentiment_with_choices.LenNorm,AQuA,,,AQuA,aqua_rat,,,,,,,,3.5,1.0894989095982373,0.3736340063340961,0.3888543665878416,4.651162790697675,,aqua_rat,['generate_rational_and_correct_choice'],False,72.0,26.0,6
10.130125751776928,0.0,0.4294828780875914,1.317375744421651,3.7913385826771657,0.2041000063658867,1.180452577165459,0.0,6.779661016949154,0.2532706842647763,3.177165354330709,93.54330708661418,0.2255753400757557,1.169291338582677,43.87096774193549,0.2487430065635621,0.7363467827139389,0.2018394692027203,0.8963936674493044,3.9133858267716537,27.55905511811024,"{'nrows': 254, 'sha256': '76a4c9959382120f557a7fedf2799a4d06f0b147550305ca469ad0b1e8d2ce86', 'artifact_path': 'wandb-client-artifact://mirvtrsmyu88fjfupzybh8ep4nueisdhtsupwd94x7qluackcix7oq3wlg6v8xkflhyigkrvdlexfzfbedhrh9ymr1tz2i7pwj3vmtkk6rld7se7j1r2f59lz0vw5x2a:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://mirvtrsmyu88fjfupzybh8ep4nueisdhtsupwd94x7qluackcix7oq3wlg6v8xkflhyigkrvdlexfzfbedhrh9ymr1tz2i7pwj3vmtkk6rld7se7j1r2f59lz0vw5x2a:latest/predictions.table.json', 'path': 'media/table/predictions_1_76a4c9959382120f557a.table.json', 'size': 122122, '_type': 'table-file', 'ncols': 15}",24.361695732941868,0.193037585667048,1.1722304586763204,False,True,validation,False,A | B | C | D | E,4,CTBase,2351d12a-e630-4d19-8b41-e199266e38f7,raw,SENTIMENT,False,12,bigscience/T0_3B,0,True,Reviewer_Opinion_bad_good_choices,prompts/general_fixed_choice.yaml,IMDB,,5,,,GenFC,,False,['Math QA'],aqua_rat,True,False,GeneralFixedChoice,False,False,True,,False,prompts,,False,True,Reviewer Opinion bad good choices,,cross_task,aqua_rat,,,,False,,,False,,True,,,False,,CTBase.GenFC.imdb.Reviewer_Opinion_bad_good_choices.LenNorm,AQuA,,,AQuA,aqua_rat,,,,,,,,2.948818897637796,1.020140961522065,0.3472565559712881,0.589786713517557,0.0,,aqua_rat,['generate_rational_and_correct_choice'],False,4.5,45.0,9
8.30670926517572,0.0,0.7418220528059521,3.0254064582464264,3.503937007874016,0.3844131141179047,0.9669663231197558,0.0,0.0,0.5492969347736029,3.37007874015748,79.54330708661418,0.5265526546268012,1.0984251968503935,41.5335463258786,0.4466229498855711,0.5489408917836285,0.4254927887658784,1.237580123955264,3.177165354330709,25.590551181102363,"{'_latest_artifact_path': 'wandb-client-artifact://137c8nfbtfz35yuon2vjm0z7t66q16d4ofiian7luxxu3adukr7glxj1xrfgpeadia13oky1nbei0jjveiq09ssqqpaygrbvy9jiwpgckmu9as892umhgt0l1dmtgfc0:latest/predictions.table.json', 'path': 'media/table/predictions_1_d93b78d86f959e4f32e0.table.json', 'size': 118660, '_type': 'table-file', 'ncols': 15, 'nrows': 254, 'sha256': 'd93b78d86f959e4f32e0ffb34ca06a067b3dbdb77b75691d1b12607707d22dcb', 'artifact_path': 'wandb-client-artifact://137c8nfbtfz35yuon2vjm0z7t66q16d4ofiian7luxxu3adukr7glxj1xrfgpeadia13oky1nbei0jjveiq09ssqqpaygrbvy9jiwpgckmu9as892umhgt0l1dmtgfc0:latest/predictions.table.json'}",24.361695732941868,0.5036636683390167,0.9785345753011644,False,True,validation,False,A | B | C | D | E,4,CTBase,02ff2949-0f45-4d97-941e-6fa4c0afbc2d,raw,SENTIMENT,False,12,bigscience/T0_3B,0,True,Movie_Expressed_Sentiment_2,prompts/general_fixed_choice.yaml,IMDB,,5,,,GenFC,,False,['Math QA'],aqua_rat,True,False,GeneralFixedChoice,False,False,False,,False,prompts,,False,True,Movie Expressed Sentiment 2,,cross_task,aqua_rat,,,,False,,,False,,True,,,False,,CTBase.GenFC.imdb.Movie_Expressed_Sentiment_2.LenNorm,AQuA,,,AQuA,aqua_rat,,,,,,,,3.8503937007874014,1.230061391192347,0.7235799730137111,1.5029339189604511,0.0,,aqua_rat,['generate_rational_and_correct_choice'],False,59.5,88.0,10
10.49013599956996,0.0,0.5826122299595781,2.0644777384329966,3.618110236220472,0.3399190601749454,1.1011030491538245,0.0,3.7037037037037033,0.5067865698356327,2.905511811023622,92.54330708661418,0.4720397727695976,1.874015748031496,38.490566037735846,0.447865197039026,1.631347088325058,0.325307031806414,1.6357118790015257,3.716535433070866,22.04724409448819,"{'nrows': 254, 'sha256': '26383bfa335e650ba743c23d6ed9351d865148ec6ef7fcef204e6d9eef0f37d9', 'artifact_path': 'wandb-client-artifact://15nrhzeq3k6nsqiom0x0y2hx51ou6m1elrus4cns02tr9ecuz35aegpywmha9sj9uakioshggteb4rx4htt6gyroygu67wo7y8y0gjll0mcggts5kcw5wlitn92tf77k:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://15nrhzeq3k6nsqiom0x0y2hx51ou6m1elrus4cns02tr9ecuz35aegpywmha9sj9uakioshggteb4rx4htt6gyroygu67wo7y8y0gjll0mcggts5kcw5wlitn92tf77k:latest/predictions.table.json', 'path': 'media/table/predictions_1_26383bfa335e650ba743.table.json', 'size': 120116, '_type': 'table-file', 'ncols': 15}",24.361695732941868,0.374983044285145,0.9875849080701372,False,True,validation,False,A | B | C | D | E,4,CTBase,f56ffced-9b16-431a-8a17-501e63cddf73,raw,ENTAILMENT,False,12,bigscience/T0_3B,0,True,imply_separated,prompts/general_fixed_choice.yaml,RTE,,5,,,GenFC,,False,['Math QA'],aqua_rat,False,False,GeneralFixedChoice,False,False,True,,False,prompts,,False,True,imply separated,,cross_task,aqua_rat,,,,False,,,False,,True,,,False,,CTBase.GenFC.super_glue_rte.imply_separated.LenNorm,AQuA,,,AQuA,aqua_rat,,,,,,,,2.8858267716535435,0.5386223911314497,0.5167937817769693,0.6377861987887405,10.256410256410255,,aqua_rat,['generate_rational_and_correct_choice'],False,70.5,43.0,6
11.814026792750198,0.0,0.5608145333693898,1.5751528157962589,3.5551181102362204,0.2643675270859476,1.1884091570804431,0.0,6.666666666666667,0.3182653723739264,3.236220472440945,100.03149606299212,0.359453107428363,1.5708661417322836,37.58865248226951,0.3061363359135906,1.3431429961348926,0.2549554875150578,1.4446619584166909,3.645669291338583,23.228346456692915,"{'size': 124500, '_type': 'table-file', 'ncols': 15, 'nrows': 254, 'sha256': '3893ea29a5c2a7585221f691f53c9cdcb4efdb202693e91eb2b8cf5efa967502', 'artifact_path': 'wandb-client-artifact://yv1zi637o5x5vgu7k91whyd9hi87zm7edhgmojjona09fmft2x9j3a3mo4al21ip3si7jkdusxr66nkbj7jtceu49l6b06nnmdn3l8jej3hzwvuenovogpmsfszrndwp:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://yv1zi637o5x5vgu7k91whyd9hi87zm7edhgmojjona09fmft2x9j3a3mo4al21ip3si7jkdusxr66nkbj7jtceu49l6b06nnmdn3l8jej3hzwvuenovogpmsfszrndwp:latest/predictions.table.json', 'path': 'media/table/predictions_1_3893ea29a5c2a7585221.table.json'}",24.43565776079581,0.2516542658027175,1.1221232188672672,False,True,validation,False,A | B | C | D | E,4,CTBase,c8dfc879-40f2-412d-be1e-4cd70107f6e6,raw,ENTAILMENT,False,12,bigscience/T0_3B,0,True,imply,prompts/general_fixed_choice.yaml,RTE,,5,,,GenFC,,False,['Math QA'],aqua_rat,False,False,GeneralFixedChoice,False,False,True,,False,prompts,,False,True,imply,,cross_task,aqua_rat,,,,False,,,False,,True,,,False,,CTBase.GenFC.super_glue_rte.imply.LenNorm,AQuA,,,AQuA,aqua_rat,,,,,,,,2.9921259842519685,0.7836524920029645,0.4663693902787693,0.591298000080379,14.814814814814817,,aqua_rat,['generate_rational_and_correct_choice'],False,68.0,30.0,14
9.704258675078863,0.0,0.4090009412740095,2.46777983350078,3.0,0.3638036038943528,1.3804027713039488,0.0,0.0,0.4697301350240632,3.748031496062992,125.54330708661418,0.4532884913166677,1.094488188976378,42.27129337539432,0.7200031768618607,0.6074740636845956,0.3140783886389818,1.455032038903772,3.968503937007874,26.77165354330709,"{'size': 164394, '_type': 'table-file', 'ncols': 15, 'nrows': 254, 'sha256': 'c7c1986f4f3c56114c55ca16227763b562103daa0566be3a5be16e5860a001f2', 'artifact_path': 'wandb-client-artifact://hlnhp508jxmjsn4ubjm38t9rgxdpyeuwp3yav0n10kkr3o0jg71b6u2krzcfo8k66awog9xok3zdkz6glp9pkkit9w5ji53niqm1irlzq0ctxztv6jbfv2xsgwdxqduw:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://hlnhp508jxmjsn4ubjm38t9rgxdpyeuwp3yav0n10kkr3o0jg71b6u2krzcfo8k66awog9xok3zdkz6glp9pkkit9w5ji53niqm1irlzq0ctxztv6jbfv2xsgwdxqduw:latest/predictions.table.json', 'path': 'media/table/predictions_1_c7c1986f4f3c56114c55.table.json'}",24.361695732941868,0.3509169327560623,0.5319478977654972,False,True,validation,False,A | B | C | D | E,4,CTBase,9e2b4267-ec23-44c8-b82a-107e2c890fec,raw,ENTAILMENT,False,12,bigscience/T0_3B,0,True,entailment_explained,prompts/general_fixed_choice.yaml,RTE,,5,,,GenFC,,False,['Math QA'],aqua_rat,False,False,GeneralFixedChoice,False,False,True,,False,prompts,,False,True,entailment explained,,cross_task,aqua_rat,,,,False,,,False,,True,,,False,,CTBase.GenFC.super_glue_rte.entailment_explained.LenNorm,AQuA,,,AQuA,aqua_rat,,,,,,,,3.188976377952756,0.4014203809930987,0.4238395427814646,0.824758030298188,6.25,,aqua_rat,['generate_rational_and_correct_choice'],False,29.5,51.0,40
9.616695474041355,0.0,0.499576876540004,1.4110992104988398,3.236220472440945,0.2175952686265174,1.2514979554494945,5.333333333333334,0.0,0.359696223041204,3.3188976377952755,104.03149606299212,0.325352976641317,1.9645669291338583,35.43307086614173,0.2583326711429385,1.6656335277215384,0.2501098790598992,1.675986610287277,3.374015748031496,19.68503937007874,"{'path': 'media/table/predictions_1_d4592073d342db8c7379.table.json', 'size': 130627, '_type': 'table-file', 'ncols': 15, 'nrows': 254, 'sha256': 'd4592073d342db8c7379052dd617f006304232eb8120f702fb1e5d087b19a4fc', 'artifact_path': 'wandb-client-artifact://12j18e8vhbcw8clsk7ac9m3os7tgwaq7ev6mhwlw1m7l2ukmvyr1gjct6onj1s8si7fxerkfqi0m5owdgl6e8jquhp45410y8s2dxbadmeedseq7jxl342s2m5v7vtur:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://12j18e8vhbcw8clsk7ac9m3os7tgwaq7ev6mhwlw1m7l2ukmvyr1gjct6onj1s8si7fxerkfqi0m5owdgl6e8jquhp45410y8s2dxbadmeedseq7jxl342s2m5v7vtur:latest/predictions.table.json'}",24.43565776079581,0.2791120147868279,0.9983634075120076,False,True,validation,False,A | B | C | D | E,4,CTBase,4ee6ff27-de63-4e7b-a9d4-82a17eba407a,raw,ENTAILMENT,False,12,bigscience/T0_3B,0,True,does_the_claim_follow_the_fact,prompts/general_fixed_choice.yaml,RTE,,5,,,GenFC,,False,['Math QA'],aqua_rat,False,False,GeneralFixedChoice,False,False,True,,False,prompts,,False,True,does the claim follow the fact,,cross_task,aqua_rat,,,,False,,,False,,True,,,False,,CTBase.GenFC.super_glue_rte.does_the_claim_follow_the_fact.LenNorm,AQuA,,,AQuA,aqua_rat,,,,,,,,3.106299212598425,0.6877153814659752,0.3921818790077631,0.4677173396733802,7.317073170731707,,aqua_rat,['generate_rational_and_correct_choice'],False,79.5,52.0,18
11.167694551997544,0.0,0.4855549871812881,1.391729872996413,3.716535433070866,0.2532364559569436,1.0824122796941498,5.714285714285714,3.333333333333333,0.3238317553452619,2.7401574803149606,97.49212598425196,0.3486239515890286,2.204724409448819,34.024896265560166,0.3419780693654939,1.7894642785942412,0.234084143329492,1.6560723067399474,3.559055118110236,19.68503937007874,"{'size': 120676, '_type': 'table-file', 'ncols': 15, 'nrows': 254, 'sha256': 'c832ff9deea0da6c350e2d63585f88414b85672b8df631dc0e4146a2f6d1e78d', 'artifact_path': 'wandb-client-artifact://wwwq438toyj7650zh9zlgto9tgs6cg1mn8g9l12f5om7c17lw522suxa685ixts8ai8mmioujrkgb2zr0im25w71lv35h7p25pwkmpkyb918uetlp0xlkkbo7ugzvv83:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://wwwq438toyj7650zh9zlgto9tgs6cg1mn8g9l12f5om7c17lw522suxa685ixts8ai8mmioujrkgb2zr0im25w71lv35h7p25pwkmpkyb918uetlp0xlkkbo7ugzvv83:latest/predictions.table.json', 'path': 'media/table/predictions_1_c832ff9deea0da6c350e.table.json'}",24.36302576885821,0.2762098722075895,0.949202719113048,False,True,validation,False,A | B | C | D | E,4,CTBase,03a7ae07-5ddd-46c4-92f3-2152223d44ec,raw,ENTAILMENT,False,12,bigscience/T0_3B,0,True,mean,prompts/general_fixed_choice.yaml,RTE,,5,,,GenFC,,False,['Math QA'],aqua_rat,False,False,GeneralFixedChoice,False,False,True,,False,prompts,,False,True,mean,,cross_task,aqua_rat,,,,False,,,False,,True,,,False,,CTBase.GenFC.super_glue_rte.mean.LenNorm,AQuA,,,AQuA,aqua_rat,,,,,,,,2.779527559055118,0.6388151658888762,0.3227890125943153,0.3772960966966283,12.765957446808512,,aqua_rat,['generate_rational_and_correct_choice'],False,79.5,35.0,9
11.422601517179832,12.048192771084338,0.5974250533536237,1.3838435383293572,3.02755905511811,0.2364542947988181,1.2810045987214735,0.0,6.25,0.3095309100751802,2.720472440944882,111.49212598425196,0.3328046953584265,3.6535433070866143,24.0,0.2797452572762496,1.6380223949124544,0.2953175183020448,1.423286883060159,2.9015748031496065,13.385826771653544,"{'size': 138067, '_type': 'table-file', 'ncols': 15, 'nrows': 254, 'sha256': '1a6070925457c3a06878d92ca7af9bb8763dfb9f8decb49e9b4300c2e9203484', 'artifact_path': 'wandb-client-artifact://sla5yg4aiajvlnkfmssuzg96g8ghbf3dgx1thv20mx1pb15ztkgc74nywoctd0qx1ggua2ytcndfvs9rwyniig835dq5ei7csrafr3pxvgnydtta1mikfyrhtto8x7lz:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://sla5yg4aiajvlnkfmssuzg96g8ghbf3dgx1thv20mx1pb15ztkgc74nywoctd0qx1ggua2ytcndfvs9rwyniig835dq5ei7csrafr3pxvgnydtta1mikfyrhtto8x7lz:latest/predictions.table.json', 'path': 'media/table/predictions_1_1a6070925457c3a06878.table.json'}",27.34839990511245,0.3025993476843649,1.269189001560226,False,True,validation,True,A | B | C | D | E,4,CTBase,c0403841-68b0-4c08-8c3b-a00a81272d05,raw,MCQ,False,12,bigscience/T0_3B,0,True,Answer_questions_from_options,prompts/general_fixed_choice.yaml,AQuA,,5,,,GenFC,,True,['Math QA'],aqua_rat,False,False,GeneralFixedChoice,False,False,True,,False,prompts,,False,True,Answer questions from options,,cross_task,aqua_rat,,,,False,,,False,,True,,,False,,CTBase.GenFC.aqua_rat_raw.Answer_questions_from_options.LenNorm,AQuA,,,AQuA,aqua_rat,,,,,,,,2.6968503937007875,1.1965460139270565,0.3975903113419495,0.4617626756195009,14.814814814814817,,aqua_rat,['generate_rational_and_correct_choice'],False,90.0,34.0,11
13.766605377036074,10.169491525423728,0.6217708181120597,1.7018807849546118,3.078740157480315,0.2325408666803181,1.137107112819708,0.0,10.344827586206897,0.4293803948117053,3.015748031496063,123.49212598425196,0.4252740238595197,3.31496062992126,33.12883435582822,0.2726349150101969,1.8727250236481672,0.3416114278061797,1.6014671802426232,2.952755905511811,17.716535433070867,"{'ncols': 15, 'nrows': 254, 'sha256': '43654817d83b7ab9099cb35388bf951ffc4a5ae11376a1f142abb02718865148', 'artifact_path': 'wandb-client-artifact://cvydyj8bysdti7xmlgdvispoi99c334qej3i4y51vvr9hgu7lolrc15ut9brgug6gn26lnwgdg00wsbg8nsuji0t0eipo3ltj40rq24624xpff6i7p8y17vytywer75z:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://cvydyj8bysdti7xmlgdvispoi99c334qej3i4y51vvr9hgu7lolrc15ut9brgug6gn26lnwgdg00wsbg8nsuji0t0eipo3ltj40rq24624xpff6i7p8y17vytywer75z:latest/predictions.table.json', 'path': 'media/table/predictions_1_43654817d83b7ab9099c.table.json', 'size': 149179, '_type': 'table-file'}",27.34839990511245,0.3822077560527064,1.1117429882598513,False,True,validation,True,A | B | C | D | E,4,CTBase,815acaf5-2e59-4f81-8190-ae75dc237cf1,raw,MCQ,False,12,bigscience/T0_3B,0,True,answer_quiz,prompts/general_fixed_choice.yaml,AQuA,,5,,,GenFC,,True,['Math QA'],aqua_rat,False,False,GeneralFixedChoice,False,False,True,,False,prompts,,False,True,answer_quiz,,cross_task,aqua_rat,,,,False,,,False,,True,,,False,,CTBase.GenFC.aqua_rat_raw.answer_quiz.LenNorm,AQuA,,,AQuA,aqua_rat,,,,,,,,2.6377952755905514,1.0771008867755334,0.4439390306371064,0.5745914512731898,15.18987341772152,,aqua_rat,['generate_rational_and_correct_choice'],False,86.0,18.0,23
17.212677921218138,16.842105263157894,0.4427765074324231,0.9372309164738092,3.0354330708661417,0.1591764059526815,1.323145117296664,24.52830188679245,17.5,0.2145803735012144,2.598425196850393,107.87007874015748,0.2407844535947784,3.590551181102362,10.526315789473683,0.1709979368945745,1.4161850201015482,0.2319028485929713,1.338449507039457,3.177165354330709,17.322834645669293,"{'sha256': 'ef18599065786f0cea293bdec9368d9928c8a76a181a966600ce843a8e85e47f', 'artifact_path': 'wandb-client-artifact://7e73gw1x2hiddlk2aqht4hdomshc78e1tjkvuyw4k5kx9358c4h398yn10nnw984umbbumyya6kyooef8dfo36qmtceor0oldh14jzhzeg7i899phla2ydr21hjmfob3:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://7e73gw1x2hiddlk2aqht4hdomshc78e1tjkvuyw4k5kx9358c4h398yn10nnw984umbbumyya6kyooef8dfo36qmtceor0oldh14jzhzeg7i899phla2ydr21hjmfob3:latest/predictions.table.json', 'path': 'media/table/predictions_1_ef18599065786f0cea29.table.json', 'size': 137735, '_type': 'table-file', 'ncols': 15, 'nrows': 254}",27.4499338523381,0.189077135517708,1.3414050837592637,False,True,validation,True,A | B | C | D | E,4,CTBase,5acfaa48-e1b6-44df-8e92-c58b94bff595,raw,MCQ,False,12,bigscience/T0_3B,0,True,generate_rationale,prompts/general_fixed_choice.yaml,AQuA,,5,,,GenFC,,True,['Math QA'],aqua_rat,False,False,GeneralFixedChoice,False,False,True,,False,prompts,,False,True,generate_rationale,,cross_task,aqua_rat,,,,False,,,False,,True,,,False,,CTBase.GenFC.aqua_rat_raw.generate_rationale.LenNorm,AQuA,,,AQuA,aqua_rat,,,,,,,,2.598425196850393,1.3960565525607465,0.2765517748592321,0.3108681524832418,16.666666666666668,,aqua_rat,['generate_rational_and_correct_choice'],False,87.5,9.0,17
14.546636482220944,9.836065573770494,0.5594223069753519,1.401577157298411,2.9921259842519685,0.2156727581871595,1.2673741406839674,2.702702702702703,15.625,0.3322085048270037,3.0826771653543306,133.49212598425197,0.3459264420148895,3.25984251968504,31.055900621118017,0.2545535953964774,1.8409711508737872,0.2938250688588565,1.5532631217062518,3.02755905511811,17.322834645669293,"{'nrows': 254, 'sha256': '318c5d4e5043b25f2287a24ead61f85a80a9d0edf7d057f848b4742fdc3f3433', 'artifact_path': 'wandb-client-artifact://12gunjslhduq626jxseb0jqpnangrodr5rowzop5psrkpqkflx6nehhhttgxzdgqcgfkci8bg7bjghxaj3srsfbxy9by550bgb8x74vz39m1c91pe0f2gy0ht1n4fl38:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://12gunjslhduq626jxseb0jqpnangrodr5rowzop5psrkpqkflx6nehhhttgxzdgqcgfkci8bg7bjghxaj3srsfbxy9by550bgb8x74vz39m1c91pe0f2gy0ht1n4fl38:latest/predictions.table.json', 'path': 'media/table/predictions_1_318c5d4e5043b25f2287.table.json', 'size': 157416, '_type': 'table-file', 'ncols': 15}",27.34839990511245,0.2835791632387514,1.1140897550879665,False,True,validation,True,A | B | C | D | E,4,CTBase,58a6aa2b-ca26-473d-9bf8-385dd1a743cd,raw,MCQ,False,12,bigscience/T0_3B,0,True,generate_rational_and_correct_choice,prompts/general_fixed_choice.yaml,AQuA,,5,,,GenFC,,True,['Math QA'],aqua_rat,False,False,GeneralFixedChoice,False,False,True,,False,prompts,,False,True,generate_rational_and_correct_choice,,cross_task,aqua_rat,,,,False,,,False,,True,,,False,,CTBase.GenFC.aqua_rat_raw.generate_rational_and_correct_choice.LenNorm,AQuA,,,AQuA,aqua_rat,,,,,,,,2.6377952755905514,1.0697655298225763,0.3988732312626326,0.4688886150600403,13.513513513513514,,aqua_rat,['generate_rational_and_correct_choice'],False,87.5,13.0,33
15.124314163787847,11.428571428571429,0.8304516835514568,1.7070231217098988,3.192913385826772,0.2619082294830045,1.1996509402008388,5.405405405405406,12.5,0.4002138507647777,3.3858267716535435,112.49212598425196,0.3937874999571973,2.1968503937007875,38.39285714285714,0.3066114051135506,1.6339863340379197,0.4237560413436091,1.50764271164394,2.8976377952755907,22.04724409448819,"{'ncols': 15, 'nrows': 254, 'sha256': '6ebf90239574f5bf27c4f3ff66b88fbb298c1dfe18e2e8f9bd92243f74cfb9f8', 'artifact_path': 'wandb-client-artifact://hqeal6bfhbvm6bbkx111kosn52qjamsgwz35ibjls1bs2ck2qg9whcqfv8cmh9ufv8j7m900z7lorneh3rlf0h5k18xnqdh6yeqjcb7j8fxdkgn57z9m17z7lh6uer8z:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://hqeal6bfhbvm6bbkx111kosn52qjamsgwz35ibjls1bs2ck2qg9whcqfv8cmh9ufv8j7m900z7lorneh3rlf0h5k18xnqdh6yeqjcb7j8fxdkgn57z9m17z7lh6uer8z:latest/predictions.table.json', 'path': 'media/table/predictions_1_6ebf90239574f5bf27c4.table.json', 'size': 138529, '_type': 'table-file'}",27.34839990511245,0.3196311498392461,1.0762083053241287,False,True,validation,True,A | B | C | D | E,4,CTBase,13bd5099-33fa-4383-a441-33a7d2e1746f,raw,MCQ,False,12,bigscience/T0_3B,0,True,select_the_best_option,prompts/general_fixed_choice.yaml,AQuA,,5,,,GenFC,,True,['Math QA'],aqua_rat,False,False,GeneralFixedChoice,False,False,True,,False,prompts,,False,True,select_the_best_option,,cross_task,aqua_rat,,,,False,,,False,,True,,,False,,CTBase.GenFC.aqua_rat_raw.select_the_best_option.LenNorm,AQuA,,,AQuA,aqua_rat,,,,,,,,3.326771653543307,1.2293618355313645,0.4818928208371721,0.606410365874373,7.894736842105263,,aqua_rat,['generate_rational_and_correct_choice'],False,70.5,10.0,12
9.343147563967753,4.444444444444444,0.8354830841964908,3.6954749325128993,3.1968503937007875,0.4922683892352241,0.8232772045737153,0.0,0.0,0.6087499847562294,3.4960629921259843,70.54330708661418,0.7696786001911313,1.059055118110236,42.27129337539432,0.4763906171002726,0.4071901663936192,0.5754130761261499,0.985856959111152,2.755905511811024,26.77165354330709,"{'nrows': 254, 'sha256': '71f7cc397093bebb28abe0ac5fc16384b49c5acc97737b0d5fd70485dfbd8337', 'artifact_path': 'wandb-client-artifact://azlprjhf8q9ge9oasy0vs5cf32yuqqsy3ew9phf7v99axto3wfeo47cibzypqx9g3rl9z4szuh7r3tffi8aa4ke6wwca967q45584b73d5y3te5rcw3li2met6mij1vj:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://azlprjhf8q9ge9oasy0vs5cf32yuqqsy3ew9phf7v99axto3wfeo47cibzypqx9g3rl9z4szuh7r3tffi8aa4ke6wwca967q45584b73d5y3te5rcw3li2met6mij1vj:latest/predictions.table.json', 'path': 'media/table/predictions_1_71f7cc397093bebb28ab.table.json', 'size': 104294, '_type': 'table-file', 'ncols': 15}",24.361695732941868,0.5473755644254038,0.9296008435427846,False,True,validation,False,A | B | C | D | E,4,CTBase,f2004e15-9d9a-4ca1-9830-a341e684e97e,raw,QA,False,12,bigscience/T0_3B,0,True,qa_no_choices_and_answer,prompts/general_fixed_choice.yaml,No Prompt,,5,,,GenFC,,False,['Math QA'],aqua_rat,False,False,GeneralFixedChoice,False,False,False,,False,prompts,,False,True,qa no choices and answer,,cross_task,aqua_rat,,,,False,,,False,,True,,,False,,CTBase.GenFC.BAREBONES.qa_no_choices_and_answer.LenNorm,AQuA,,,AQuA,aqua_rat,,,,,,,,4.4921259842519685,0.991070867518024,0.8992675780127348,1.840655730465265,0.0,,aqua_rat,['generate_rational_and_correct_choice'],False,29.5,63.5,0
8.401253918495298,0.0,0.7976237099851617,4.413406920245313,3.2716535433070866,0.4448024119345194,0.9227140417282084,0.0,0.0,0.615374988458288,3.574803149606299,72.54330708661418,0.5391436467959186,1.0354330708661417,42.00626959247649,0.4573142641172634,0.3241044740317853,0.4364209422451908,0.9466273248784784,2.854330708661417,26.37795275590551,"{'nrows': 254, 'sha256': '0508aa91957040bed7c1d2bcd5e7d697955f31d72d040cc52e15ab6977d6c7d0', 'artifact_path': 'wandb-client-artifact://esv5d20jvuzmahnuq4q9307dirqvdzmgmuxosw0ante0gc8oit90bihov6llhxc53jycjho4txjqkdytn7x0eygrqanor7a9wufu81as3rk8xk92xufsglqecyykrsa0:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://esv5d20jvuzmahnuq4q9307dirqvdzmgmuxosw0ante0gc8oit90bihov6llhxc53jycjho4txjqkdytn7x0eygrqanor7a9wufu81as3rk8xk92xufsglqecyykrsa0:latest/predictions.table.json', 'path': 'media/table/predictions_1_0508aa91957040bed7c1.table.json', 'size': 106169, '_type': 'table-file', 'ncols': 15}",24.361695732941868,0.5877234398987041,1.0235009013714595,False,True,validation,False,A | B | C | D | E,4,CTBase,e5eaa3ee-e537-4d20-9dfa-6084db54f2ef,raw,ENTAILMENT,False,12,bigscience/T0_3B,0,True,entailment_no_choices_and_answer,prompts/general_fixed_choice.yaml,No Prompt,,5,,,GenFC,,False,['Math QA'],aqua_rat,False,False,GeneralFixedChoice,False,False,False,,False,prompts,,False,True,entailment no choices and answer,,cross_task,aqua_rat,,,,False,,,False,,True,,,False,,CTBase.GenFC.BAREBONES.entailment_no_choices_and_answer.LenNorm,AQuA,,,AQuA,aqua_rat,,,,,,,,4.263779527559056,1.103549697858629,0.9942956093973712,2.801574020873843,0.0,,aqua_rat,['generate_rational_and_correct_choice'],False,43.0,84.5,2
9.363349584169772,4.545454545454545,0.8015870572196162,4.533637852649989,3.15748031496063,0.4923261924277138,0.9257913988471854,0.0,0.0,0.6484053177157725,3.720472440944882,71.54330708661418,0.5002352740820937,1.047244094488189,42.27129337539432,0.5128380933145839,0.3517843764360421,0.4109569181283641,0.936710069792948,2.755905511811024,26.77165354330709,"{'size': 107049, '_type': 'table-file', 'ncols': 15, 'nrows': 254, 'sha256': '6b7d0541c9382138e9a4fe87795850ea2a372d7d7fbaa06330a7b466bc86e93c', 'artifact_path': 'wandb-client-artifact://6kz65ry6vhm1x38y8wied9af1n3j8rruybdlzh24yrc3vj93qenkm1vi7pc99wb28thbb8ecxk3bhqdz0bz7byblnhpg0iqazdshzrsupzuynfkgm32o9zs0wqht3g3u:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://6kz65ry6vhm1x38y8wied9af1n3j8rruybdlzh24yrc3vj93qenkm1vi7pc99wb28thbb8ecxk3bhqdz0bz7byblnhpg0iqazdshzrsupzuynfkgm32o9zs0wqht3g3u:latest/predictions.table.json', 'path': 'media/table/predictions_1_6b7d0541c9382138e9a4.table.json'}",24.361695732941868,0.5742091061765311,1.0178593085859873,False,True,validation,False,A | B | C | D | E,4,CTBase,cf005ddf-8cf2-409d-b884-45d22463f463,raw,CLASSIFICATION,False,12,bigscience/T0_3B,0,True,classification_no_choices_and_answer,prompts/general_fixed_choice.yaml,No Prompt,,5,,,GenFC,,False,['Math QA'],aqua_rat,False,False,GeneralFixedChoice,False,False,False,,False,prompts,,False,True,classification no choices and answer,,cross_task,aqua_rat,,,,False,,,False,,True,,,False,,CTBase.GenFC.BAREBONES.classification_no_choices_and_answer.LenNorm,AQuA,,,AQuA,aqua_rat,,,,,,,,4.318897637795276,0.9744154139640844,1.0054056448387538,2.872159167537539,0.0,,aqua_rat,['generate_rational_and_correct_choice'],False,29.5,62.0,2
12.585516178736516,0.0,0.524731545141223,2.0512712058119886,4.05511811023622,0.2551423344997264,0.9623387408764672,0.0,18.181818181818183,0.2746844028863381,3.47244094488189,54.56692913385827,0.5734708121442419,1.3228346456692914,44.74576271186441,0.3622404684231976,0.925422991293941,0.3340556662211214,1.0639540704356218,3.677165354330709,28.74015748031496,"{'ncols': 15, 'nrows': 254, 'sha256': '32d7d1b8c7f998ae451fd218b56289754c9ab2a1110e895bbe7afedeaf4e5af5', 'artifact_path': 'wandb-client-artifact://19pjv3ovbwuw9ymcol5me5tex250opslz2q0we7xlseo1tg7aoao42nr0rj9plq2u3f835x6uex4tsbdxf30nl1ibmzqwnq5uu1mn1l2edsbgr181wasac0wh48c9brm:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://19pjv3ovbwuw9ymcol5me5tex250opslz2q0we7xlseo1tg7aoao42nr0rj9plq2u3f835x6uex4tsbdxf30nl1ibmzqwnq5uu1mn1l2edsbgr181wasac0wh48c9brm:latest/predictions.table.json', 'path': 'media/table/predictions_1_32d7d1b8c7f998ae451f.table.json', 'size': 73725, '_type': 'table-file'}",16.28829372945568,0.2128322514481133,1.037310055877366,False,True,validation,False,A | B | C | D | E,4,CTBase,2e94d035-3c3d-44cf-98cb-3d11bea7c17b,raw,QA,False,12,bigscience/T0_3B,0,True,qa_choices_and_answer,prompts/general_fixed_choice.yaml,No Prompt,,5,,,GenFC,,False,['Math QA'],aqua_rat,False,False,GeneralFixedChoice,False,False,True,,False,prompts,,False,True,qa choices and answer,,cross_task,aqua_rat,,,,False,,,False,,True,,,False,,CTBase.GenFC.BAREBONES.qa_choices_and_answer.LenNorm,AQuA,,,AQuA,aqua_rat,,,,,,,,2.47244094488189,1.059837839724782,0.6167231086531294,0.8408755223582111,0.0,,aqua_rat,['generate_rational_and_correct_choice'],False,1.0,25.0,2
9.390103567318755,4.545454545454545,0.8111614059758945,2.760820473272969,3.421259842519685,0.2777654000531455,0.9514290884951022,0.0,0.0,0.4392481807648666,3.5511811023622046,88.54330708661418,0.3701806181059109,1.059055118110236,42.40506329113923,0.3233335121410099,0.3974038447972438,0.3056415461848867,1.134486921088625,3.1102362204724407,26.77165354330709,"{'_type': 'table-file', 'ncols': 15, 'nrows': 254, 'sha256': '1f8b84f7f26965a20e92faa805f7d679738fe4fc73ee9e157d983248cb40940f', 'artifact_path': 'wandb-client-artifact://yp0lkzidvgkn8w4k8ldbu6ts85mb3got80hipj9zw70i5c5l8n2rpx5jagqr3b3l4ig8n2247qmxuwnwr9py5hi9xc139cv9i2k8vit083olbive2i9ijfrqpzhrk4yk:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://yp0lkzidvgkn8w4k8ldbu6ts85mb3got80hipj9zw70i5c5l8n2rpx5jagqr3b3l4ig8n2247qmxuwnwr9py5hi9xc139cv9i2k8vit083olbive2i9ijfrqpzhrk4yk:latest/predictions.table.json', 'path': 'media/table/predictions_1_1f8b84f7f26965a20e92.table.json', 'size': 115136}",24.361695732941868,0.4403107492067581,1.0514980795495643,False,True,validation,False,A | B | C | D | E,4,CTBase,c225e598-1efe-4cb6-9f7c-a1b7eb5c7803,raw,ENTAILMENT,False,12,bigscience/T0_3B,0,True,entailment_choices_and_answer,prompts/general_fixed_choice.yaml,No Prompt,,5,,,GenFC,,False,['Math QA'],aqua_rat,False,False,GeneralFixedChoice,False,False,True,,False,prompts,,False,True,entailment choices and answer,,cross_task,aqua_rat,,,,False,,,False,,True,,,False,,CTBase.GenFC.BAREBONES.entailment_choices_and_answer.LenNorm,AQuA,,,AQuA,aqua_rat,,,,,,,,3.858267716535433,1.2437206654559485,0.7487210137866841,1.6280581622611818,0.0,,aqua_rat,['generate_rational_and_correct_choice'],False,29.5,61.0,2
9.336763865065754,4.545454545454545,0.7903535050138079,2.990069203020081,3.2401574803149606,0.325103305504717,0.960541173130382,0.0,0.0,0.5082123373437115,3.696850393700787,87.54330708661418,0.3586878175810566,1.0354330708661417,42.138364779874216,0.3474329372090617,0.2988238253408807,0.3018052052374675,1.0380942420027723,2.8307086614173227,26.77165354330709,"{'path': 'media/table/predictions_1_daaa762da14f326664ba.table.json', 'size': 116603, '_type': 'table-file', 'ncols': 15, 'nrows': 254, 'sha256': 'daaa762da14f326664ba1fd3b1dc3dc06f299c71a000a6ce7af8cfb9fff1edce', 'artifact_path': 'wandb-client-artifact://ll0gn6hm029ops4siltcef02ihlkyrz7my4fmwyaqhrtf35uajz510q4ogxc3lnqiatg98awdc4q2es9k51cf75ib6gph6dq00qlj2vjo80jwaawincizzetmab0v1c1:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://ll0gn6hm029ops4siltcef02ihlkyrz7my4fmwyaqhrtf35uajz510q4ogxc3lnqiatg98awdc4q2es9k51cf75ib6gph6dq00qlj2vjo80jwaawincizzetmab0v1c1:latest/predictions.table.json'}",24.361695732941868,0.4747780624342242,0.9713564675580094,False,True,validation,False,A | B | C | D | E,4,CTBase,32a28538-99bc-4c5a-8086-83b885fddb50,raw,CLASSIFICATION,False,12,bigscience/T0_3B,0,True,classification_choices_and_answer,prompts/general_fixed_choice.yaml,No Prompt,,5,,,GenFC,,False,['Math QA'],aqua_rat,False,False,GeneralFixedChoice,False,False,True,,False,prompts,,False,True,classification choices and answer,,cross_task,aqua_rat,,,,False,,,False,,True,,,False,,CTBase.GenFC.BAREBONES.classification_choices_and_answer.LenNorm,AQuA,,,AQuA,aqua_rat,,,,,,,,4.196850393700787,1.0502295967855848,0.7277057736883843,1.7757361108862508,0.0,,aqua_rat,['generate_rational_and_correct_choice'],False,29.5,65.5,2
8.571428571428571,0.0,0.8107497806897489,3.870236950596486,3.8976377952755903,0.3518920567307831,1.0297514849594738,0.0,0.0,0.4816642783758209,3.2440944881889764,36.56692913385827,0.4914889485817256,1.0078740157480317,42.85714285714285,0.4262970563933605,0.125243887563676,0.3870663891192218,0.734196552763057,4.090551181102362,27.165354330708663,"{'ncols': 15, 'nrows': 254, 'sha256': '5574cdcdef6b65c889b0f77ab2281c1431bd688a90b046837e79bd40d64e9d36', 'artifact_path': 'wandb-client-artifact://7y5pn9kxuhxfdhxwicjisvsmue091fqw9k4xa4upopslxb2w8fxekwta23x8tuxm60eru0qifc3lz883smoa00sbuaf2u9ipgufitx6r8itgcg0dxq95m3j93wy0so56:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://7y5pn9kxuhxfdhxwicjisvsmue091fqw9k4xa4upopslxb2w8fxekwta23x8tuxm60eru0qifc3lz883smoa00sbuaf2u9ipgufitx6r8itgcg0dxq95m3j93wy0so56:latest/predictions.table.json', 'path': 'media/table/predictions_1_5574cdcdef6b65c889b0.table.json', 'size': 62923, '_type': 'table-file'}",16.28829372945568,0.3898930955839384,0.9818553498758644,False,True,validation,False,A | B | C | D | E,4,CTBase,97030be6-9843-4fc2-98cf-b47b879b5447,raw,QA,False,12,bigscience/T0_3B,0,True,qa_no_choices,prompts/general_fixed_choice.yaml,No Prompt,,5,,,GenFC,,False,['Math QA'],aqua_rat,False,False,GeneralFixedChoice,False,False,False,,False,prompts,,False,True,qa no choices,,cross_task,aqua_rat,,,,False,,,False,,True,,,False,,CTBase.GenFC.BAREBONES.qa_no_choices.LenNorm,AQuA,,,AQuA,aqua_rat,,,,,,,,2.75984251968504,1.1575673543791567,0.8092593736444933,2.47078666724558,0.0,,aqua_rat,['generate_rational_and_correct_choice'],False,13.5,74.5,0
9.343147563967753,4.444444444444444,0.8354830841964908,3.6954749325128993,3.1968503937007875,0.4922683892352241,0.8232772045737153,0.0,0.0,0.6087499847562294,3.4960629921259843,70.54330708661418,0.7696786001911313,1.059055118110236,42.27129337539432,0.4763906171002726,0.4071901663936192,0.5754130761261499,0.985856959111152,2.755905511811024,26.77165354330709,"{'artifact_path': 'wandb-client-artifact://j3n2gxnjjwlv2uu2o6ljo43osxuni8rojvtb0irag0fgw1rotyd15pphn09mta8glpl3ci8vw4xyqvl5u6wmyhicw3kjihcnavjh5qb2ez6bsdoo5sc6c8gi4ag3sw0v:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://j3n2gxnjjwlv2uu2o6ljo43osxuni8rojvtb0irag0fgw1rotyd15pphn09mta8glpl3ci8vw4xyqvl5u6wmyhicw3kjihcnavjh5qb2ez6bsdoo5sc6c8gi4ag3sw0v:latest/predictions.table.json', 'path': 'media/table/predictions_1_71f7cc397093bebb28ab.table.json', 'size': 104294, '_type': 'table-file', 'ncols': 15, 'nrows': 254, 'sha256': '71f7cc397093bebb28abe0ac5fc16384b49c5acc97737b0d5fd70485dfbd8337'}",24.361695732941868,0.5473755644254038,0.9296008435427846,False,True,validation,False,A | B | C | D | E,4,CTBase,cc2958ca-e826-4fef-96aa-1c4caa188605,raw,ENTAILMENT,False,12,bigscience/T0_3B,0,True,entailment_no_choices,prompts/general_fixed_choice.yaml,No Prompt,,5,,,GenFC,,False,['Math QA'],aqua_rat,False,False,GeneralFixedChoice,False,False,False,,False,prompts,,False,True,entailment no choices,,cross_task,aqua_rat,,,,False,,,False,,True,,,False,,CTBase.GenFC.BAREBONES.entailment_no_choices.LenNorm,AQuA,,,AQuA,aqua_rat,,,,,,,,4.4921259842519685,0.991070867518024,0.8992675780127348,1.840655730465265,0.0,,aqua_rat,['generate_rational_and_correct_choice'],False,29.5,63.5,0
9.26984126984127,4.444444444444444,0.8795915807614824,3.654787844560278,3.094488188976378,0.543795646789405,0.817457849968225,0.0,0.0,0.6239900100888229,3.618110236220472,69.54330708661418,0.7109961641116405,1.059055118110236,41.90476190476191,0.566658605740765,0.3770699992886848,0.559092828540433,0.9366852485005354,2.704724409448819,26.37795275590551,"{'sha256': '2275f82e1c2a80cbf0f1ad1489f931db3ae5c516bb0d6ea983808fe58c8a778e', 'artifact_path': 'wandb-client-artifact://f4l42ysw51lhaacgdb5cze139hqnczaz4b5m5qws1qnmx061au0wi41vj4opsv026vcs0f9hgo426734xozcfy6urithsqgf2woj7jjc53yclpv55kqyb1pwqwkdgu4r:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://f4l42ysw51lhaacgdb5cze139hqnczaz4b5m5qws1qnmx061au0wi41vj4opsv026vcs0f9hgo426734xozcfy6urithsqgf2woj7jjc53yclpv55kqyb1pwqwkdgu4r:latest/predictions.table.json', 'path': 'media/table/predictions_1_2275f82e1c2a80cbf0f1.table.json', 'size': 105247, '_type': 'table-file', 'ncols': 15, 'nrows': 254}",24.361695732941868,0.5601866375552537,0.9347969018404456,False,True,validation,False,A | B | C | D | E,4,CTBase,74693ecc-f903-488c-968d-6a2bc8e76611,raw,CLASSIFICATION,False,12,bigscience/T0_3B,0,True,classification_no_choices,prompts/general_fixed_choice.yaml,No Prompt,,5,,,GenFC,,False,['Math QA'],aqua_rat,False,False,GeneralFixedChoice,False,False,False,,False,prompts,,False,True,classification no choices,,cross_task,aqua_rat,,,,False,,,False,,True,,,False,,CTBase.GenFC.BAREBONES.classification_no_choices.LenNorm,AQuA,,,AQuA,aqua_rat,,,,,,,,4.5236220472440944,0.933535881998376,0.8982155522843044,1.7531430646190491,0.0,,aqua_rat,['generate_rational_and_correct_choice'],False,43.0,68.0,0
14.135022810023187,0.0,0.3720457225707895,1.7196795339659443,3.606299212598425,0.3347495905131105,1.4669990811764704,0.0,16.867469879518072,0.2657715992664727,2.8661417322834644,52.56692913385827,0.4126870125297486,2.468503937007874,38.91402714932127,0.6633417643899993,1.8198901406404309,0.2782516681594729,1.4356913395361988,3.807086614173228,22.440944881889763,"{'_type': 'table-file', 'ncols': 15, 'nrows': 254, 'sha256': '4f36e28531693f66de4cfffba722a8feb7ac3b2de4e5f4716c11febe4ea3afd3', 'artifact_path': 'wandb-client-artifact://nojyqjtyvq6u2ekk0lpyih187oexjf28gyrc4xxqcgxsb4mk8npjy2yqpyqkxi1wxj7cpjzm4lsjmmjmbfxg1ax4gbux3uk8ugf5p73v5ioh460j2wad5kqrbdzsg8ep:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://nojyqjtyvq6u2ekk0lpyih187oexjf28gyrc4xxqcgxsb4mk8npjy2yqpyqkxi1wxj7cpjzm4lsjmmjmbfxg1ax4gbux3uk8ugf5p73v5ioh460j2wad5kqrbdzsg8ep:latest/predictions.table.json', 'path': 'media/table/predictions_1_4f36e28531693f66de4c.table.json', 'size': 71461}",16.28829372945568,0.2028780332580768,0.5800109247465479,False,True,validation,False,A | B | C | D | E,4,CTBase,d92fc0d4-5367-41e1-b35d-1058f22a3c1c,raw,QA,False,12,bigscience/T0_3B,0,True,qa_choices,prompts/general_fixed_choice.yaml,No Prompt,,5,,,GenFC,,False,['Math QA'],aqua_rat,False,False,GeneralFixedChoice,False,False,True,,False,prompts,,False,True,qa choices,,cross_task,aqua_rat,,,,False,,,False,,True,,,False,,CTBase.GenFC.BAREBONES.qa_choices.LenNorm,AQuA,,,AQuA,aqua_rat,,,,,,,,2.251968503937008,0.5092607570715,0.3337667690632485,0.3778791577797237,14.893617021276595,,aqua_rat,['generate_rational_and_correct_choice'],False,69.0,16.0,0
14.229155142584288,4.545454545454545,0.8013393771196868,1.9563727838786569,3.559055118110236,0.2767999490169037,1.1058437709644575,5.479452054794522,6.557377049180327,0.3860200070959377,3.358267716535433,86.54330708661418,0.3223793074840635,1.4173228346456692,40.27777777777777,0.3161121240751011,1.1255161187531109,0.2527293818857157,1.4366141192819508,3.3307086614173227,25.984251968503933,"{'artifact_path': 'wandb-client-artifact://z3d6szylcl4i09l30stayninilvi0ywgyhhc7q03flv12g3rfdh3bvn0xmcbbkgduolixfiomh7hd5dlax55a8nepp16rpot4ipqanf1twipe4y5e63v2acxl1idl6w4:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://z3d6szylcl4i09l30stayninilvi0ywgyhhc7q03flv12g3rfdh3bvn0xmcbbkgduolixfiomh7hd5dlax55a8nepp16rpot4ipqanf1twipe4y5e63v2acxl1idl6w4:latest/predictions.table.json', 'path': 'media/table/predictions_1_f43d748692682c8cc6c9.table.json', 'size': 112777, '_type': 'table-file', 'ncols': 15, 'nrows': 254, 'sha256': 'f43d748692682c8cc6c90663c2c3fcd91dc4c7b49a1866cd713b1672c899148f'}",24.361695732941868,0.376177304039038,1.069251040025481,False,True,validation,False,A | B | C | D | E,4,CTBase,bb648cf3-d9ab-45a8-9bd7-6ba4585c4b9a,raw,ENTAILMENT,False,12,bigscience/T0_3B,0,True,entailment_choices,prompts/general_fixed_choice.yaml,No Prompt,,5,,,GenFC,,False,['Math QA'],aqua_rat,False,False,GeneralFixedChoice,False,False,True,,False,prompts,,False,True,entailment choices,,cross_task,aqua_rat,,,,False,,,False,,True,,,False,,CTBase.GenFC.BAREBONES.entailment_choices.LenNorm,AQuA,,,AQuA,aqua_rat,,,,,,,,3.3346456692913384,1.0658535415748,0.6800022958314977,0.9318613452235543,14.285714285714285,,aqua_rat,['generate_rational_and_correct_choice'],False,52.0,15.0,0
13.31054131054131,4.444444444444444,0.8362229880754404,2.0795475460412933,3.437007874015748,0.2657785210544353,1.0471034776235757,10.256410256410255,0.0,0.4395972865772998,3.590551181102362,85.54330708661418,0.3421690989667036,1.2322834645669292,39.73063973063973,0.2864314083039291,0.801807199886339,0.2770677466929471,1.2008906629151417,2.81496062992126,25.984251968503933,"{'size': 114065, '_type': 'table-file', 'ncols': 15, 'nrows': 254, 'sha256': 'f672594408235f3d3e0bf0a3c6b76c793162a753aaf7cf8d470e2b1a8174c159', 'artifact_path': 'wandb-client-artifact://13sh0dfz0lzlgomgd8waofxz9k4ij9fr4ahzs4gz4liyke48wngrpy7o0a2o934s7tmpk1razn11k6ngr5u9ufq8kjbwblvmhh23n21pnmp4cyp3fpgzci6t6xrjbzah:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://13sh0dfz0lzlgomgd8waofxz9k4ij9fr4ahzs4gz4liyke48wngrpy7o0a2o934s7tmpk1razn11k6ngr5u9ufq8kjbwblvmhh23n21pnmp4cyp3fpgzci6t6xrjbzah:latest/predictions.table.json', 'path': 'media/table/predictions_1_f672594408235f3d3e0b.table.json'}",24.361695732941868,0.4320855221324166,1.0299019960152729,False,True,validation,False,A | B | C | D | E,4,CTBase,88bdb026-e9c9-445b-96ef-0cdb986b7fbd,raw,CLASSIFICATION,False,12,bigscience/T0_3B,0,True,classification_choices,prompts/general_fixed_choice.yaml,No Prompt,,5,,,GenFC,,False,['Math QA'],aqua_rat,False,False,GeneralFixedChoice,False,False,True,,False,prompts,,False,True,classification choices,,cross_task,aqua_rat,,,,False,,,False,,True,,,False,,CTBase.GenFC.BAREBONES.classification_choices.LenNorm,AQuA,,,AQuA,aqua_rat,,,,,,,,3.925196850393701,1.0968436106080997,0.6871910154004934,1.0113497521933608,12.121212121212125,,aqua_rat,['generate_rational_and_correct_choice'],False,52.0,21.0,0
8.544891640866874,0.0,0.6108801313859538,2.6697599399746874,3.763779527559055,0.2719495319661019,0.8690359661412299,0.0,0.0,0.6922363803142638,3.826771653543307,113.54330708661418,0.3429918758512482,1.0,42.72445820433437,0.3015266929085799,0.0,0.281694744010353,0.8112624829816998,2.3188976377952755,27.165354330708663,"{'path': 'media/table/predictions_1_5c04118ba75dedb1748a.table.json', 'size': 134065, '_type': 'table-file', 'ncols': 15, 'nrows': 254, 'sha256': '5c04118ba75dedb1748ac83aab11f021823555ab4196aac22e8391fa06c2fad7', 'artifact_path': 'wandb-client-artifact://nzlso7oni233vp4bfd50ymzcq5077xaip8n6e5ujbthu78j8aafy14vp6ywyhrgud5f6ealkq09vw0cvjkwiy3dzolxsa7ztria1zknoedeb8jr46hgee1g5d3wi6gu8:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://nzlso7oni233vp4bfd50ymzcq5077xaip8n6e5ujbthu78j8aafy14vp6ywyhrgud5f6ealkq09vw0cvjkwiy3dzolxsa7ztria1zknoedeb8jr46hgee1g5d3wi6gu8:latest/predictions.table.json'}",24.361695732941868,0.4546598895661462,0.8837508483906106,False,True,validation,False,A | B | C | D | E,4,CTBase,725b5ed0-7728-4890-95a4-a74cb7ae1bb4,raw,ENTAILMENT,False,12,bigscience/T0_3B,0,True,affirmation_true_or_false,prompts/general_fixed_choice.yaml,WiC,,5,,,GenFC,,False,['Math QA'],aqua_rat,False,False,GeneralFixedChoice,False,False,True,,False,prompts,,False,True,affirmation_true_or_false,,cross_task,aqua_rat,,,,False,,,False,,True,,,False,,CTBase.GenFC.super_glue_wic.affirmation_true_or_false.LenNorm,AQuA,,,AQuA,aqua_rat,,,,,,,,4.090551181102362,0.9410107709280175,0.510837171714853,1.3330049909005954,0.0,,aqua_rat,['generate_rational_and_correct_choice'],False,13.5,76.5,25
13.25848901220397,13.043478260869565,0.6060956303386883,2.028466356082226,3.692913385826772,0.3298525312797543,0.992188474472435,0.0,3.448275862068966,0.4554652491892416,3.232283464566929,112.54330708661418,0.42643544242138,1.547244094488189,42.25352112676056,0.3892800488809901,1.3175571987257115,0.3462387747430248,1.4435510616806513,3.767716535433071,25.984251968503933,"{'artifact_path': 'wandb-client-artifact://10yc4jaojnffntlqsv6he6560klimhigjbxzuhjry940agkfauvye3q71uf49wksrx5mp4o4vljbcp16um8yk1trfijth2c7zhkkqf8ojdmws77nf53f6dy21n3ahd8a:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://10yc4jaojnffntlqsv6he6560klimhigjbxzuhjry940agkfauvye3q71uf49wksrx5mp4o4vljbcp16um8yk1trfijth2c7zhkkqf8ojdmws77nf53f6dy21n3ahd8a:latest/predictions.table.json', 'path': 'media/table/predictions_1_600d7731365274296738.table.json', 'size': 143868, '_type': 'table-file', 'ncols': 15, 'nrows': 254, 'sha256': '600d7731365274296738c8840a967bebc253bdf89fcc5ea5b71f0e24597321d7'}",24.361695732941868,0.3448733102203647,0.9418010798350932,False,True,validation,False,A | B | C | D | E,4,CTBase,611d13dc-d414-4b9b-9204-e4f325e859e7,raw,ENTAILMENT,False,12,bigscience/T0_3B,0,True,grammar_homework,prompts/general_fixed_choice.yaml,WiC,,5,,,GenFC,,False,['Math QA'],aqua_rat,False,False,GeneralFixedChoice,False,False,True,,False,prompts,,False,True,grammar_homework,,cross_task,aqua_rat,,,,False,,,False,,True,,,False,,CTBase.GenFC.super_glue_wic.grammar_homework.LenNorm,AQuA,,,AQuA,aqua_rat,,,,,,,,2.75984251968504,1.0085274087773066,0.5583248721676524,0.7572856155906137,7.547169811320755,,aqua_rat,['generate_rational_and_correct_choice'],False,52.0,22.0,25
10.659542988656916,4.545454545454545,0.8376829007554679,3.5863071013623333,3.2244094488188977,0.4700799765464115,0.874414678057304,5.714285714285714,0.0,0.6454965261023814,3.5551181102362204,87.54330708661418,0.6240106567623108,1.0511811023622046,43.03797468354431,0.4627923627538005,0.356793714355381,0.4977846896107533,1.0550079270239878,2.87007874015748,27.95275590551181,"{'sha256': '306b76a59d24cc32bc267dc0436866c5fb8c4a95f3dd74cd964b1bcb2f799dca', 'artifact_path': 'wandb-client-artifact://6wegi886v3db8s40ufbeilot3ge1wiblpfi49rsau84ltez8fkp15ev8w8hfitr00sbvfv0evbd0foisvlfj8l7hfo0t7apfopb9edhktqsyo6s4b24mpi3hqoauykse:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://6wegi886v3db8s40ufbeilot3ge1wiblpfi49rsau84ltez8fkp15ev8w8hfitr00sbvfv0evbd0foisvlfj8l7hfo0t7apfopb9edhktqsyo6s4b24mpi3hqoauykse:latest/predictions.table.json', 'path': 'media/table/predictions_1_306b76a59d24cc32bc26.table.json', 'size': 123489, '_type': 'table-file', 'ncols': 15, 'nrows': 254}",24.361695732941868,0.6101464566405562,0.977559927189542,False,True,validation,False,A | B | C | D | E,4,CTBase,3503ead5-4fa5-4f77-95dc-f0c2ed3eecdc,raw,ENTAILMENT,False,12,bigscience/T0_3B,0,True,question_context_meaning,prompts/general_fixed_choice.yaml,WiC,,5,,,GenFC,,False,['Math QA'],aqua_rat,False,False,GeneralFixedChoice,False,False,False,,False,prompts,,False,True,question-context-meaning,,cross_task,aqua_rat,,,,False,,,False,,True,,,False,,CTBase.GenFC.super_glue_wic.question_context_meaning.LenNorm,AQuA,,,AQuA,aqua_rat,,,,,,,,4.299212598425197,1.085443852245114,0.8656001504791893,1.854007555743841,0.0,,aqua_rat,['generate_rational_and_correct_choice'],False,2.0,41.0,14
13.454334711941202,12.5,0.5498324771357773,1.6484489140548104,3.5826771653543306,0.3198733439996968,1.1901230326254784,2.9411764705882355,10.38961038961039,0.3130443171253355,3.2440944881889764,104.54330708661418,0.5366575605287327,2.720472440944882,32.51231527093596,0.3367732284575935,1.870990246155496,0.3882628081391105,1.663417275945536,3.02755905511811,18.11023622047244,"{'artifact_path': 'wandb-client-artifact://re0ibqpli1azuscsa259dw4glnhv72ebkx88o0i26e93d9szvtx4w26tbuww87qo5vvjm0c4dew2oovt936aksq9jb7yqsubu1wtz9meuz2wrviijpflqmcg4cbioy1n:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://re0ibqpli1azuscsa259dw4glnhv72ebkx88o0i26e93d9szvtx4w26tbuww87qo5vvjm0c4dew2oovt936aksq9jb7yqsubu1wtz9meuz2wrviijpflqmcg4cbioy1n:latest/predictions.table.json', 'path': 'media/table/predictions_1_8f994ff7b89ef2ca5edd.table.json', 'size': 132539, '_type': 'table-file', 'ncols': 15, 'nrows': 254, 'sha256': '8f994ff7b89ef2ca5edd2ae7bebfbac077befdbba32b0e15735d958921f3c667'}",24.361695732941868,0.270167774148291,0.9492353776043138,False,True,validation,False,A | B | C | D | E,4,CTBase,14e73f39-a0d1-44c2-b9a4-4e48f9f1608e,raw,ENTAILMENT,False,12,bigscience/T0_3B,0,True,question_context_meaning_with_label,prompts/general_fixed_choice.yaml,WiC,,5,,,GenFC,,False,['Math QA'],aqua_rat,False,False,GeneralFixedChoice,False,False,True,,False,prompts,,False,True,question-context-meaning-with-label,,cross_task,aqua_rat,,,,False,,,False,,True,,,False,,CTBase.GenFC.super_glue_wic.question_context_meaning_with_label.LenNorm,AQuA,,,AQuA,aqua_rat,,,,,,,,2.425196850393701,0.7788512137876056,0.4116437861530662,0.4619738079431489,8.928571428571427,,aqua_rat,['generate_rational_and_correct_choice'],False,85.0,19.0,16
19.218428833556757,25.64102564102564,0.4801534964878718,1.0611305837556133,3.0236220472440944,0.223683802319546,1.1464739983118926,22.222222222222225,26.436781609195403,0.2435655105771042,2.881889763779528,89.54330708661418,0.2788717122528497,3.090551181102362,8.88888888888889,0.2585454958630359,1.0775397079382478,0.233895368102914,1.1643962863378703,2.826771653543307,21.25984251968504,"{'artifact_path': 'wandb-client-artifact://fovfe3mq3uk8blw4inwgbbdd6j2nedaxla5g4knwneuhz3fjo9do4ikt980izhlvc5nnwhqmxzvf410z9lpu8vokntnkxkwkcfyc6eo7t3c9jahsur8k7p6ys6d50x0f:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://fovfe3mq3uk8blw4inwgbbdd6j2nedaxla5g4knwneuhz3fjo9do4ikt980izhlvc5nnwhqmxzvf410z9lpu8vokntnkxkwkcfyc6eo7t3c9jahsur8k7p6ys6d50x0f:latest/predictions.table.json', 'path': 'media/table/predictions_1_a3b3fa0e1a6dad924634.table.json', 'size': 118083, '_type': 'table-file', 'ncols': 15, 'nrows': 254, 'sha256': 'a3b3fa0e1a6dad924634ad10cf8f16971e88a49e287685b7bc7b57d98da59a3f'}",24.361695732941868,0.2472836640412944,1.6558851058907944,False,True,validation,False,A | B | C | D | E,4,CTBase,f32348cd-d3cb-4619-87b9-e24f99c78567,raw,COMPLETION,False,12,bigscience/T0_3B,0,True,choose,prompts/general_fixed_choice.yaml,COPA,,5,,,GenFC,,False,['Math QA'],aqua_rat,False,False,GeneralFixedChoice,False,False,True,,False,prompts,,False,True,choose,,cross_task,aqua_rat,,,,False,,,False,,True,,,False,,CTBase.GenFC.super_glue_copa.choose.LenNorm,AQuA,,,AQuA,aqua_rat,,,,,,,,3.177165354330709,1.8282855863503304,0.2344891906445644,0.2801478650626235,12.903225806451612,,aqua_rat,['generate_rational_and_correct_choice'],False,73.0,3.0,8
14.23630045442395,23.33333333333333,0.4402400089901658,1.160837880269749,3.0,0.2417828875991137,1.2327550605737048,24.8062015503876,18.390804597701145,0.2340966355143569,2.704724409448819,100.54330708661418,0.3230863945690665,2.763779527559055,4.651162790697675,0.3222962660113657,0.778214116573596,0.2799819667520221,1.054361286919928,2.7440944881889764,18.50393700787401,"{'_type': 'table-file', 'ncols': 15, 'nrows': 254, 'sha256': '891011854d3676e6f3daaf4e30ea178bca01ca1d5be2fc994ad83d8472b29be9', 'artifact_path': 'wandb-client-artifact://7m70gtiamh4p0wt3v6vty5766elvuhyxblvqwcdybfsadyuifkqla6nkr4umvh4u2cgan3i58xgy8g996nzc4ni1vwjiz0cykas0bd4ngsdzmve542c82dwajo2gd7pf:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://7m70gtiamh4p0wt3v6vty5766elvuhyxblvqwcdybfsadyuifkqla6nkr4umvh4u2cgan3i58xgy8g996nzc4ni1vwjiz0cykas0bd4ngsdzmve542c82dwajo2gd7pf:latest/predictions.table.json', 'path': 'media/table/predictions_1_891011854d3676e6f3da.table.json', 'size': 130950}",24.361695732941868,0.2054610152778361,1.6705583143159546,False,True,validation,False,A | B | C | D | E,4,CTBase,a1f9951e-2b6b-4530-9636-9cdf4c1658c5,raw,COMPLETION,False,12,bigscience/T0_3B,0,True,more_likely,prompts/general_fixed_choice.yaml,COPA,,5,,,GenFC,,False,['Math QA'],aqua_rat,False,False,GeneralFixedChoice,False,False,True,,False,prompts,,False,True,more likely,,cross_task,aqua_rat,,,,False,,,False,,True,,,False,,CTBase.GenFC.super_glue_copa.more_likely.LenNorm,AQuA,,,AQuA,aqua_rat,,,,,,,,3.7874015748031495,1.7730702996656886,0.2398440607681636,0.2813585841749597,0.0,,aqua_rat,['generate_rational_and_correct_choice'],False,84.0,14.0,19
18.23164145494747,28.07017543859649,0.4952360397935487,1.0927587217233312,2.8464566929133857,0.1820026928839619,1.1987720275802018,19.847328244274813,15.217391304347828,0.2302877504055894,3.0393700787401574,94.54330708661418,0.3536036648149565,2.358267716535433,21.12676056338028,0.2202394994225089,1.09831230193412,0.2860862979144197,1.069859705381775,2.5551181102362204,20.47244094488189,"{'_latest_artifact_path': 'wandb-client-artifact://qe6zy95xfg1zd51qmsgach6nxf8o3qqy90dfc9w73143ay1h2sdoadv4truzssk5rtzc4n3sg5zt7dyx7xk3dl20xwkxpg1qne2t8i4m348n56ruudivcru4vu68h2ma:latest/predictions.table.json', 'path': 'media/table/predictions_1_65c909d4b39597fe9031.table.json', 'size': 126591, '_type': 'table-file', 'ncols': 15, 'nrows': 254, 'sha256': '65c909d4b39597fe9031e7248e7ad62dc82cd3e90007793a4d7302fe3e32215b', 'artifact_path': 'wandb-client-artifact://qe6zy95xfg1zd51qmsgach6nxf8o3qqy90dfc9w73143ay1h2sdoadv4truzssk5rtzc4n3sg5zt7dyx7xk3dl20xwkxpg1qne2t8i4m348n56ruudivcru4vu68h2ma:latest/predictions.table.json'}",24.361695732941868,0.2505442092862776,1.4629361846521405,False,True,validation,False,A | B | C | D | E,4,CTBase,0edd8660-f299-4819-a5ac-633c11177228,raw,COMPLETION,False,12,bigscience/T0_3B,0,True,exercise,prompts/general_fixed_choice.yaml,COPA,,5,,,GenFC,,False,['Math QA'],aqua_rat,False,False,GeneralFixedChoice,False,False,True,,False,prompts,,False,True,exercise,,cross_task,aqua_rat,,,,False,,,False,,True,,,False,,CTBase.GenFC.super_glue_copa.exercise.LenNorm,AQuA,,,AQuA,aqua_rat,,,,,,,,4.200787401574803,1.41248627966256,0.2561763245769721,0.2886278070802763,6.896551724137931,,aqua_rat,['generate_rational_and_correct_choice'],False,74.5,7.0,13
11.020295348653557,0.0,0.5677262832679758,1.6358304774667334,3.830708661417322,0.2270386865241027,1.0456517999675483,2.985074626865672,3.7037037037037033,0.2992902064886619,3.15748031496063,99.49212598425196,0.3004628861044335,1.2086614173228347,42.85714285714285,0.2679577981393168,0.8555997686429841,0.2201551156306411,1.2780670040770683,3.858267716535433,27.165354330708663,"{'path': 'media/table/predictions_1_3f533ca970e50bd34ed8.table.json', 'size': 122141, '_type': 'table-file', 'ncols': 15, 'nrows': 254, 'sha256': '3f533ca970e50bd34ed89ac927d860367394b2ed4448782968082c451f32eb3b', 'artifact_path': 'wandb-client-artifact://9uassymhyuhfiaxxxka883ovdqe6kk7s6iotw8royrng6tvncm9cbztr5llj0e9r3y6ms1s7n3lnj7xe44l119fbt3zf8m1tuzm5dnjfcnznl9c61s8mnzj9tl25oe3f:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://9uassymhyuhfiaxxxka883ovdqe6kk7s6iotw8royrng6tvncm9cbztr5llj0e9r3y6ms1s7n3lnj7xe44l119fbt3zf8m1tuzm5dnjfcnznl9c61s8mnzj9tl25oe3f:latest/predictions.table.json'}",24.36302576885821,0.2984196806956281,1.118387455929743,False,True,validation,False,A | B | C | D | E,4,CTBase,2d0d63da-ffcf-4f6e-941a-b8da922be43e,raw,ENTAILMENT,False,12,bigscience/T0_3B,0,True,guaranteed_true,prompts/general_fixed_choice.yaml,ANLI,,5,,,GenFC,,False,['Math QA'],aqua_rat,False,False,GeneralFixedChoice,False,False,True,,False,prompts,,False,True,guaranteed true,,cross_task,aqua_rat,,,,False,,,False,,True,,,False,,CTBase.GenFC.anli.guaranteed_true.LenNorm,AQuA,,,AQuA,aqua_rat,,,,,,,,2.94488188976378,0.7917595934161502,0.4723098777110927,0.7681195867343211,5.555555555555555,,aqua_rat,['generate_rational_and_correct_choice'],False,13.5,36.0,12
8.571428571428571,0.0,0.6183379360830468,2.088866624306506,3.7874015748031495,0.2419377576435998,1.0358147256263022,0.0,0.0,0.3034592744872326,3.3346456692913384,110.92125984251967,0.3036755013653612,1.015748031496063,42.85714285714285,0.2783791718520517,0.2504877751273521,0.2373048839221878,1.0261703591759082,3.625984251968504,27.165354330708663,"{'path': 'media/table/predictions_1_33ee4936d5e8d5849e6f.table.json', 'size': 125139, '_type': 'table-file', 'ncols': 15, 'nrows': 254, 'sha256': '33ee4936d5e8d5849e6fbc5338d78b1fb017cd64a9919f862925a6387686e5a0', 'artifact_path': 'wandb-client-artifact://10lmxwbu4p8mxu29k7u2naf0ku2vejkjpg3gcudoz8dgbyw4uw6gcdkwjkpsx01w0xfhdbs3btirtx8joukz8du9q1m8uax1flwdkqz33lfzvmuhnu27wi62kmp9i39q:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://10lmxwbu4p8mxu29k7u2naf0ku2vejkjpg3gcudoz8dgbyw4uw6gcdkwjkpsx01w0xfhdbs3btirtx8joukz8du9q1m8uax1flwdkqz33lfzvmuhnu27wi62kmp9i39q:latest/predictions.table.json'}",24.46839719730172,0.3257262773609559,1.147669871649626,False,True,validation,False,A | B | C | D | E,4,CTBase,9e078fb4-505b-413c-bb5e-3cd16ddcf5d7,raw,ENTAILMENT,False,12,bigscience/T0_3B,0,True,does_this_imply,prompts/general_fixed_choice.yaml,ANLI,,5,,,GenFC,,False,['Math QA'],aqua_rat,False,False,GeneralFixedChoice,False,False,True,,False,prompts,,False,True,does this imply,,cross_task,aqua_rat,,,,False,,,False,,True,,,False,,CTBase.GenFC.anli.does_this_imply.LenNorm,AQuA,,,AQuA,aqua_rat,,,,,,,,3.236220472440945,1.1735717935181933,0.5342272575306088,1.2033526766018603,0.0,,aqua_rat,['generate_rational_and_correct_choice'],False,13.5,74.5,23
10.253078326353023,0.0,0.5852548872226656,1.6654259961421096,3.84251968503937,0.230990486830328,1.0716474685532522,0.0,3.389830508474577,0.29928735954555,3.2007874015748032,101.49212598425196,0.2892273617541696,1.18503937007874,41.42394822006472,0.2754686742317019,0.7743505015413876,0.2102129430518,1.2213357373474203,3.661417322834646,25.984251968503933,"{'path': 'media/table/predictions_1_0aecea6e8edd280a50ca.table.json', 'size': 124692, '_type': 'table-file', 'ncols': 15, 'nrows': 254, 'sha256': '0aecea6e8edd280a50ca562bd272d5654e297f0510c7540b2c8616883d3fe9c9', 'artifact_path': 'wandb-client-artifact://1dxhaekvahwxkq4pf8hea77yvejwax1t9rxwoxaw423f15ja5chxq5pn42fz8oluodt1ic9bqc1ns7b537ig2x0ufi4z2whvlzd20qscban7o9texv1kau1418p5e313:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://1dxhaekvahwxkq4pf8hea77yvejwax1t9rxwoxaw423f15ja5chxq5pn42fz8oluodt1ic9bqc1ns7b537ig2x0ufi4z2whvlzd20qscban7o9texv1kau1418p5e313:latest/predictions.table.json'}",24.36302576885821,0.3373232408291784,1.1025379499953107,False,True,validation,False,A | B | C | D | E,4,CTBase,fb4f8144-37f5-4977-88da-37a5d0bfd0e8,raw,ENTAILMENT,False,12,bigscience/T0_3B,0,True,must_be_true,prompts/general_fixed_choice.yaml,ANLI,,5,,,GenFC,,False,['Math QA'],aqua_rat,False,False,GeneralFixedChoice,False,False,True,,False,prompts,,False,True,must be true,,cross_task,aqua_rat,,,,False,,,False,,True,,,False,,CTBase.GenFC.anli.must_be_true.LenNorm,AQuA,,,AQuA,aqua_rat,,,,,,,,3.1102362204724407,1.0251049222787896,0.4679013091149076,0.801442600610688,6.451612903225806,,aqua_rat,['generate_rational_and_correct_choice'],False,52.0,44.0,14
12.173248120098751,0.0,0.4484389763458012,1.2065163991582677,3.531496062992126,0.2473585370954167,1.299981876760503,2.8169014084507045,10.416666666666666,0.225576612893052,3.070866141732284,104.49212598425196,0.2886675549304391,2.161417322834646,31.75965665236052,0.2891509157466137,1.631845833968899,0.2317431054068149,1.4837453969602756,3.4645669291338583,18.89763779527559,"{'_type': 'table-file', 'ncols': 15, 'nrows': 254, 'sha256': '7b3066e22b592e2a8f5648b5a66b36627fa7238e7a54ab6b0af8c6ebcf9fc8de', 'artifact_path': 'wandb-client-artifact://mjiqv0w4dlyf7f7y3ytge2ghvdnd2va8mp6tslkwf0kmnvwpkrj5xhc5u0dii6d7yicyrinpg4mii6bqb2mwiy8h2jxlab9ehlartnpf9ugp126yvhfm07vlivha3q40:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://mjiqv0w4dlyf7f7y3ytge2ghvdnd2va8mp6tslkwf0kmnvwpkrj5xhc5u0dii6d7yicyrinpg4mii6bqb2mwiy8h2jxlab9ehlartnpf9ugp126yvhfm07vlivha3q40:latest/predictions.table.json', 'path': 'media/table/predictions_1_7b3066e22b592e2a8f56.table.json', 'size': 129290}",24.36302576885821,0.2208581775046032,1.0475400682935183,False,True,validation,False,A | B | C | D | E,4,CTBase,bab86d5a-4f9c-40db-b619-a7b7d5cae681,raw,ENTAILMENT,False,12,bigscience/T0_3B,0,True,take_the_following_as_truth,prompts/general_fixed_choice.yaml,ANLI,,5,,,GenFC,,False,['Math QA'],aqua_rat,False,False,GeneralFixedChoice,False,False,True,,False,prompts,,False,True,take the following as truth,,cross_task,aqua_rat,,,,False,,,False,,True,,,False,,CTBase.GenFC.anli.take_the_following_as_truth.LenNorm,AQuA,,,AQuA,aqua_rat,,,,,,,,2.7716535433070866,1.0438343638625616,0.3275063042625222,0.4031213155881626,15.873015873015872,,aqua_rat,['generate_rational_and_correct_choice'],False,82.5,27.0,17
10.868671183888576,0.0,0.5808633126693089,1.6431820167331246,3.7086614173228334,0.2009621583462768,1.0656426564231287,2.898550724637681,3.636363636363636,0.2959925246050977,3.37007874015748,98.49212598425196,0.2832559018623172,1.1732283464566928,41.55844155844156,0.2411054382174033,0.7434171812234439,0.2115494065832689,1.3466408678200932,3.559055118110236,26.37795275590551,"{'sha256': '8ed1e3dfd54acdf8e0ad40b9807f16459e356cec4bcc68d5d6fde4790aa7fa6f', 'artifact_path': 'wandb-client-artifact://16oef1vmxnenp73roz2wfxcfp6wtr4t6iiwnj0a1uqij8yc17o75m8jba2na941ui61gr92qj65lbj5r1i5aw1bvc938m6bvudsmc77sqstb8y8joh8mqnmajlnvxxta:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://16oef1vmxnenp73roz2wfxcfp6wtr4t6iiwnj0a1uqij8yc17o75m8jba2na941ui61gr92qj65lbj5r1i5aw1bvc938m6bvudsmc77sqstb8y8joh8mqnmajlnvxxta:latest/predictions.table.json', 'path': 'media/table/predictions_1_8ed1e3dfd54acdf8e0ad.table.json', 'size': 121965, '_type': 'table-file', 'ncols': 15, 'nrows': 254}",24.36302576885821,0.3055623636980466,1.0925888465020934,False,True,validation,False,A | B | C | D | E,4,CTBase,a850110d-f1a3-49b4-949a-d3bfe9f81344,raw,ENTAILMENT,False,12,bigscience/T0_3B,0,True,justified_in_saying,prompts/general_fixed_choice.yaml,ANLI,,5,,,GenFC,,False,['Math QA'],aqua_rat,False,False,GeneralFixedChoice,False,False,True,,False,prompts,,False,True,justified in saying,,cross_task,aqua_rat,,,,False,,,False,,True,,,False,,CTBase.GenFC.anli.justified_in_saying.LenNorm,AQuA,,,AQuA,aqua_rat,,,,,,,,3.188976377952756,0.9899676560736316,0.4709967827574331,0.8228281520483062,6.25,,aqua_rat,['generate_rational_and_correct_choice'],False,43.0,37.0,11
8.4472049689441,0.0,0.5315033707164959,1.8701399104801688,3.614173228346457,0.1997441336746711,1.0351860428059714,0.0,0.0,0.2667516404249537,3.3622047244094486,102.49212598425196,0.2678538213564655,1.0118110236220472,42.2360248447205,0.2271658304169422,0.1878658313455142,0.2437598034802065,0.9482959973186628,3.6102362204724407,26.77165354330709,"{'_type': 'table-file', 'ncols': 15, 'nrows': 254, 'sha256': '4cc770ace0f095a10cb12a7fdd47402f69a1ca9dcd764ba723b4552659cd784b', 'artifact_path': 'wandb-client-artifact://ssi0oppzgl7hpatxjlilz9ovyqeja2ec2jzouesz0sjm6qrrn83nwmj6tpvc12adss5h8vzoojfw7lq9dbs3rpzl2buu6rpvsu347f7moho5ojjy2ics2dqbaopus60l:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://ssi0oppzgl7hpatxjlilz9ovyqeja2ec2jzouesz0sjm6qrrn83nwmj6tpvc12adss5h8vzoojfw7lq9dbs3rpzl2buu6rpvsu347f7moho5ojjy2ics2dqbaopus60l:latest/predictions.table.json', 'path': 'media/table/predictions_1_4cc770ace0f095a10cb1.table.json', 'size': 125657}",24.36302576885821,0.2598714137092477,1.0623795260171924,False,True,validation,False,A | B | C | D | E,4,CTBase,9b613182-c6ab-4427-9221-3d68f6d62765,raw,ENTAILMENT,False,12,bigscience/T0_3B,0,True,based_on_the_previous_passage,prompts/general_fixed_choice.yaml,ANLI,,5,,,GenFC,,False,['Math QA'],aqua_rat,False,False,GeneralFixedChoice,False,False,True,,False,prompts,,False,True,based on the previous passage,,cross_task,aqua_rat,,,,False,,,False,,True,,,False,,CTBase.GenFC.anli.based_on_the_previous_passage.LenNorm,AQuA,,,AQuA,aqua_rat,,,,,,,,3.4015748031496065,1.3675648944263965,0.4724273900799492,1.1083686182818075,0.0,,aqua_rat,['generate_rational_and_correct_choice'],False,29.5,83.0,15
12.706716285663653,0.0,0.739858384175201,1.9284747670015951,3.5866141732283463,0.2525741040669991,1.0340549494776752,0.0,6.666666666666667,0.3370359460199911,3.3858267716535435,89.54330708661418,0.323783166765228,1.330708661417323,41.07744107744108,0.2786725412203571,1.0199206245959342,0.2628264279620986,1.376377051838477,3.5354330708661417,25.984251968503933,"{'ncols': 15, 'nrows': 254, 'sha256': 'c7eb152c7f312b47274480445c41199be81c86b552dfc0d2858099043ff4b65e', 'artifact_path': 'wandb-client-artifact://xqtygpuylq5vvv6rila3nqwwhm91k197dwqegyli3slqvqms3dtbu547fx2ohmkr0710klnajvm3pmqteq3gees1qa28rw5xch34zvt4xit99sxk1cjmbzxibk2q2eos:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://xqtygpuylq5vvv6rila3nqwwhm91k197dwqegyli3slqvqms3dtbu547fx2ohmkr0710klnajvm3pmqteq3gees1qa28rw5xch34zvt4xit99sxk1cjmbzxibk2q2eos:latest/predictions.table.json', 'path': 'media/table/predictions_1_c7eb152c7f312b472744.table.json', 'size': 115054, '_type': 'table-file'}",24.361695732941868,0.334783159371224,1.0237128972403309,False,True,validation,False,A | B | C | D | E,4,CTBase,620aa3fc-d5eb-46f5-a1ee-4c754527aa97,raw,ENTAILMENT,False,12,bigscience/T0_3B,0,True,GPT_3_style,prompts/general_fixed_choice.yaml,ANLI,,5,,,GenFC,,False,['Math QA'],aqua_rat,False,False,GeneralFixedChoice,False,False,True,,False,prompts,,False,True,GPT-3 style,,cross_task,aqua_rat,,,,False,,,False,,True,,,False,,CTBase.GenFC.anli.GPT_3_style.LenNorm,AQuA,,,AQuA,aqua_rat,,,,,,,,3.161417322834646,1.1644029421417756,0.6633094251147948,0.9889831129960188,15.789473684210526,,aqua_rat,['generate_rational_and_correct_choice'],False,52.0,24.0,4
9.946524064171124,0.0,0.5757810901162921,1.8382692919002743,3.7992125984251968,0.2321994828839352,1.0917728169980088,2.9411764705882355,0.0,0.2477172153202567,3.070866141732284,100.49212598425196,0.3198870711439238,1.188976377952756,40.909090909090914,0.3001742982488917,0.7959769262726994,0.2422933064380124,1.203437117809565,3.9763779527559056,25.590551181102363,"{'_type': 'table-file', 'ncols': 15, 'nrows': 254, 'sha256': 'aa386442c3beea939641b517ed557e43e8c1b803a9a8234405ec6436823456c5', 'artifact_path': 'wandb-client-artifact://kaenxh251j9p851i7g023ad5uq3pjcrytvo0t219mq3qa66pkgwtzf4sv6eexeleqk8haldtp7heupbi2y6ombcpjk2213jhtedsbx1i1yfythiq8p1o0nclsw506jno:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://kaenxh251j9p851i7g023ad5uq3pjcrytvo0t219mq3qa66pkgwtzf4sv6eexeleqk8haldtp7heupbi2y6ombcpjk2213jhtedsbx1i1yfythiq8p1o0nclsw506jno:latest/predictions.table.json', 'path': 'media/table/predictions_1_aa386442c3beea939641.table.json', 'size': 124142}",24.36302576885821,0.2090473361769472,1.1131363250496122,False,True,validation,False,A | B | C | D | E,4,CTBase,ec249357-e672-4e7d-b8b6-d97ed7d090c5,raw,ENTAILMENT,False,12,bigscience/T0_3B,0,True,claim_true_false_inconclusive,prompts/general_fixed_choice.yaml,ANLI,,5,,,GenFC,,False,['Math QA'],aqua_rat,False,False,GeneralFixedChoice,False,False,True,,False,prompts,,False,True,claim true/false/inconclusive,,cross_task,aqua_rat,,,,False,,,False,,True,,,False,,CTBase.GenFC.anli.claim_true_false_inconclusive.LenNorm,AQuA,,,AQuA,aqua_rat,,,,,,,,2.9645669291338583,0.7803721663164543,0.5076028898466837,0.970490707187202,5.88235294117647,,aqua_rat,['generate_rational_and_correct_choice'],False,59.5,48.0,13
9.92207792207792,0.0,0.5915842185341876,1.6204416188668078,3.68503937007874,0.22574275810751,1.106180115202264,0.0,3.333333333333333,0.2924684877470722,3.3188976377952755,99.49212598425196,0.2794555247299314,1.188976377952756,39.6103896103896,0.2486108663513904,0.7657252592610129,0.2296173353791961,1.1660524084947634,3.5236220472440944,24.80314960629921,"{'nrows': 254, 'sha256': '14b63285a016205a740a13348a6eab448ed7b26703de980eb90606589fbe78f8', 'artifact_path': 'wandb-client-artifact://q01t2pyqw9rmxhbi918wb2slt64vwdht3vy3t0yequeg6dz2wd6eru8pv8cankdrsxjwr4hm70xdmmdy82jyp03h4ov2h3pcqfll4n1uz74ampfdmord6wp6tblxftne:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://q01t2pyqw9rmxhbi918wb2slt64vwdht3vy3t0yequeg6dz2wd6eru8pv8cankdrsxjwr4hm70xdmmdy82jyp03h4ov2h3pcqfll4n1uz74ampfdmord6wp6tblxftne:latest/predictions.table.json', 'path': 'media/table/predictions_1_14b63285a016205a740a.table.json', 'size': 120365, '_type': 'table-file', 'ncols': 15}",24.36302576885821,0.3435060844989223,1.1279716506367032,False,True,validation,False,A | B | C | D | E,4,CTBase,c4ed37ae-d7d7-4197-a725-ef2152fa3b1f,raw,ENTAILMENT,False,12,bigscience/T0_3B,0,True,can_we_infer,prompts/general_fixed_choice.yaml,ANLI,,5,,,GenFC,,False,['Math QA'],aqua_rat,False,False,GeneralFixedChoice,False,False,True,,False,prompts,,False,True,can we infer,,cross_task,aqua_rat,,,,False,,,False,,True,,,False,,CTBase.GenFC.anli.can_we_infer.LenNorm,AQuA,,,AQuA,aqua_rat,,,,,,,,3.283464566929134,1.163064359972143,0.4550462493077269,0.7999067400384137,6.666666666666668,,aqua_rat,['generate_rational_and_correct_choice'],False,65.0,49.0,12
11.572871572871575,4.444444444444444,1.118159096963171,3.806892175374069,3.173228346456693,0.5301854714345567,0.9646874422546,2.857142857142857,3.636363636363636,0.8464858550725021,3.7007874015748032,81.54330708661418,0.562006233245369,1.153543307086614,40.25974025974027,0.5437333058184526,0.6729059411275927,0.4605973046907575,1.1280540966691668,2.877952755905512,25.984251968503933,"{'size': 119151, '_type': 'table-file', 'ncols': 15, 'nrows': 254, 'sha256': '15bee06936ac7b1392189edcab39caa62a8a01d2f6213757071ab350d3de76ec', 'artifact_path': 'wandb-client-artifact://6frffeus397mh3z275rcypxe4ht6ahvkh5epjegkvsk6ubb9x40a9oihpuxbkjxg0m4e0orntetjvscgllajkwd16b6g5htvsv39n1gg80wazamoxycep1bifqni14dc:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://6frffeus397mh3z275rcypxe4ht6ahvkh5epjegkvsk6ubb9x40a9oihpuxbkjxg0m4e0orntetjvscgllajkwd16b6g5htvsv39n1gg80wazamoxycep1bifqni14dc:latest/predictions.table.json', 'path': 'media/table/predictions_1_15bee06936ac7b139218.table.json'}",24.361695732941868,0.792165003035094,1.05602851779318,False,True,validation,False,A | B | C | D | E,4,CTBase,ed215962-8e51-45e7-b025-6e822f877098,raw,CLASSIFICATION,False,12,bigscience/T0_3B,0,True,sentence_to_concepts,prompts/general_fixed_choice.yaml,CommonGen,,5,,,GenFC,,False,['Math QA'],aqua_rat,True,False,GeneralFixedChoice,False,False,False,,False,prompts,,False,True,sentence to concepts,,cross_task,aqua_rat,,,,False,,,False,,True,,,False,,CTBase.GenFC.common_gen.sentence_to_concepts.LenNorm,AQuA,,,AQuA,aqua_rat,,,,,,,,4.094488188976378,1.0419021888451634,1.0034260076462662,1.8546667812377449,6.666666666666668,,aqua_rat,['generate_rational_and_correct_choice'],False,52.0,32.0,13
15.072592215260055,4.166666666666666,1.220937375596496,3.0243110957108144,3.3858267716535435,0.5971840147483428,1.09793825461035,26.785714285714285,3.508771929824562,0.8295429447504479,3.7007874015748032,77.54330708661418,0.5474170568421131,1.4291338582677164,35.01945525291829,0.5883761972892941,0.9097555470071674,0.4605682243430193,1.3094088090061324,2.4960629921259843,24.80314960629921,"{'_type': 'table-file', 'ncols': 15, 'nrows': 254, 'sha256': '953d20c7256df5a17eb340c6fe8e6441662642eae4cf00bf1862ca41f7a98593', 'artifact_path': 'wandb-client-artifact://fig3uolwitambjsqlo0hd3txenfbtypjfby7hrwe7wa0fk2rdos86wh36ykc6ltq0oyquuljxa98qsaag8w9asy6zc2eoinn0fjp80n1h3qua7wwzkly9wvhnomuzxyw:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://fig3uolwitambjsqlo0hd3txenfbtypjfby7hrwe7wa0fk2rdos86wh36ykc6ltq0oyquuljxa98qsaag8w9asy6zc2eoinn0fjp80n1h3qua7wwzkly9wvhnomuzxyw:latest/predictions.table.json', 'path': 'media/table/predictions_1_953d20c7256df5a17eb3.table.json', 'size': 114676}",24.361695732941868,0.7342838670739262,1.0219246981359131,False,True,validation,False,A | B | C | D | E,4,CTBase,b7012213-04c4-424d-85fb-39d63d8a0ca2,raw,CLASSIFICATION,False,12,bigscience/T0_3B,0,True,topics_from_the_sentence,prompts/general_fixed_choice.yaml,CommonGen,,5,,,GenFC,,False,['Math QA'],aqua_rat,True,False,GeneralFixedChoice,False,False,False,,False,prompts,,False,True,topics from the sentence,,cross_task,aqua_rat,,,,False,,,False,,True,,,False,,CTBase.GenFC.common_gen.topics_from_the_sentence.LenNorm,AQuA,,,AQuA,aqua_rat,,,,,,,,3.9881889763779528,0.932705333896231,0.8398183054375065,1.0589748968289594,5.88235294117647,,aqua_rat,['generate_rational_and_correct_choice'],False,65.0,11.0,8
14.642222306585843,10.714285714285714,0.5152837210259102,1.275427218027941,3.043307086614173,0.1805092033282478,0.9526664238581258,15.555555555555555,8.45070422535211,0.230481419976302,3.125984251968504,97.54330708661418,0.4245670817968414,1.4448818897637796,38.490566037735846,0.2132896039429612,0.9194493954396736,0.31449780724287,1.0856508910675269,2.751968503937008,25.196850393700785,"{'ncols': 15, 'nrows': 254, 'sha256': 'b66ee16178f5e76a9caa5ac196f6c984458a76c636d6a0b9cd6568753d6bfd9b', 'artifact_path': 'wandb-client-artifact://1351iqzyiz3250nmhj5pmih6m9it1gh5nukik0dq4vzvfes5h1ntqdaif8txyaog41z56i6ourums6412m94sj7zp8rvfiojt8yrvsnqts9qlv04z83ws5u2jk2i7dz2:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://1351iqzyiz3250nmhj5pmih6m9it1gh5nukik0dq4vzvfes5h1ntqdaif8txyaog41z56i6ourums6412m94sj7zp8rvfiojt8yrvsnqts9qlv04z83ws5u2jk2i7dz2:latest/predictions.table.json', 'path': 'media/table/predictions_1_b66ee16178f5e76a9caa.table.json', 'size': 133438, '_type': 'table-file'}",24.361695732941868,0.2145334034876689,1.042348393283333,False,True,validation,False,A | B | C | D | E,4,CTBase,fc76beb7-c258-412f-a623-42fc8d2331b6,raw,COMPLETION,False,12,bigscience/T0_3B,0,True,fill_in_the_blank_with_instruction_and_choices,prompts/general_fixed_choice.yaml,NumerSense,,5,,,GenFC,,False,['Math QA'],aqua_rat,False,False,GeneralFixedChoice,False,False,True,,False,prompts,,False,True,fill_in_the_blank_with_instruction_and_choices,,cross_task,aqua_rat,,,,False,,,False,,True,,,False,,CTBase.GenFC.numer_sense.fill_in_the_blank_with_instruction_and_choices.LenNorm,AQuA,,,AQuA,aqua_rat,,,,,,,,4.633858267716535,0.9026400885836277,0.3179822438408305,0.4070891123118363,0.0,,aqua_rat,['generate_rational_and_correct_choice'],False,63.0,12.0,20
9.263521288837746,4.545454545454545,0.787912062938508,3.796872558556204,3.1141732283464565,0.4419617126624266,0.891095442756934,0.0,0.0,0.6273938398661576,3.6535433070866143,80.54330708661418,0.5477125682230071,1.0511811023622046,41.77215189873418,0.479554703855139,0.356793714355381,0.4349702011393207,0.936710069792948,2.755905511811024,26.37795275590551,"{'nrows': 254, 'sha256': 'dfbec065ad15905c03236b4c43267d7ee7ab8950db410285b1d8847130bd0f8e', 'artifact_path': 'wandb-client-artifact://pwqyqj0i8l39gfvge9fc6kqo7ol46idfdhnfol8w1jzoz47tibua669l156tko4z9tzlmfhusw5tnxdnkkqgs57m1jwp010uzwd5tyj5pqw0cc0i3srgymwuazvrxr42:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://pwqyqj0i8l39gfvge9fc6kqo7ol46idfdhnfol8w1jzoz47tibua669l156tko4z9tzlmfhusw5tnxdnkkqgs57m1jwp010uzwd5tyj5pqw0cc0i3srgymwuazvrxr42:latest/predictions.table.json', 'path': 'media/table/predictions_1_dfbec065ad15905c0323.table.json', 'size': 115694, '_type': 'table-file', 'ncols': 15}",24.361695732941868,0.562110362543165,0.9791363119687856,False,True,validation,False,A | B | C | D | E,4,CTBase,cacee36c-e2b7-458e-9d51-6fcfd83842b4,raw,COMPLETION,False,12,bigscience/T0_3B,0,True,fill_in_the_blank_before_sentence,prompts/general_fixed_choice.yaml,NumerSense,,5,,,GenFC,,False,['Math QA'],aqua_rat,False,False,GeneralFixedChoice,False,False,False,,False,prompts,,False,True,fill_in_the_blank_before_sentence,,cross_task,aqua_rat,,,,False,,,False,,True,,,False,,CTBase.GenFC.numer_sense.fill_in_the_blank_before_sentence.LenNorm,AQuA,,,AQuA,aqua_rat,,,,,,,,4.425196850393701,0.9558743784575746,0.842357653753192,2.1422114466119,0.0,,aqua_rat,['generate_rational_and_correct_choice'],False,43.0,69.0,11
13.110901577323784,4.444444444444444,0.5820125384727993,1.3969101680545355,3.3858267716535435,0.2419704156943344,1.3489409324663844,2.898550724637681,12.0,0.2438460663547666,3.098425196850393,101.54330708661418,0.333586823283218,1.9173228346456688,41.76706827309236,0.2840529821050448,1.4732039372265069,0.2713921885688061,1.2892964455743487,3.3307086614173227,24.015748031496063,"{'sha256': '523f7cdb1e8301b2ea2aeb66e17f9760ea5b1aa5ef4d96b94806cecf5806e055', 'artifact_path': 'wandb-client-artifact://h0hrvogtypvdwy1c65yw49zrytqdfoqnzd0t9f1hfso7f84flz3p105icij62uy65rmu130vu7gxkguyize9n7bri6g7dynff6wo0g2v4siak5v58tzi4yuqapan1d3i:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://h0hrvogtypvdwy1c65yw49zrytqdfoqnzd0t9f1hfso7f84flz3p105icij62uy65rmu130vu7gxkguyize9n7bri6g7dynff6wo0g2v4siak5v58tzi4yuqapan1d3i:latest/predictions.table.json', 'path': 'media/table/predictions_1_523f7cdb1e8301b2ea2a.table.json', 'size': 135890, '_type': 'table-file', 'ncols': 15, 'nrows': 254}",24.361695732941868,0.2261127314901223,1.0396459309434745,False,True,validation,False,A | B | C | D | E,4,CTBase,5d8e8d21-8059-4373-bbf2-a25cbe1e6960,raw,COMPLETION,False,12,bigscience/T0_3B,0,True,fill_in_the_blank_with_choices_before,prompts/general_fixed_choice.yaml,NumerSense,,5,,,GenFC,,False,['Math QA'],aqua_rat,False,False,GeneralFixedChoice,False,False,True,,False,prompts,,False,True,fill_in_the_blank_with_choices_before,,cross_task,aqua_rat,,,,False,,,False,,True,,,False,,CTBase.GenFC.numer_sense.fill_in_the_blank_with_choices_before.LenNorm,AQuA,,,AQuA,aqua_rat,,,,,,,,3.267716535433071,1.3248016871211403,0.4645212785375704,0.5354242963115061,4.444444444444445,,aqua_rat,['generate_rational_and_correct_choice'],False,67.0,23.0,24
8.526645768025078,0.0,0.6431310476818095,3.9991683922414714,3.248031496062992,0.4214995486325861,0.9828730498283408,0.0,0.0,0.6035816669464111,3.649606299212599,108.54330708661418,0.4664832175247312,1.0236220472440944,42.63322884012539,0.4000238527463177,0.2160696493545235,0.3923264770689014,1.0296084790769937,2.917322834645669,26.77165354330709,"{'path': 'media/table/predictions_1_7fc4ef4153d5f0838426.table.json', 'size': 145842, '_type': 'table-file', 'ncols': 15, 'nrows': 254, 'sha256': '7fc4ef4153d5f083842620aa5c53579c2eebfaa1204404a2437cd2b0ac7d85c2', 'artifact_path': 'wandb-client-artifact://jb40zvarcb1y7ie8v6movseo5tnvi9vuewnvllpgsbsp4cbc9dtz5mdlyqu2bvwyxngj6176hzhty8dbnnkft973jjswlg4xn27dh1iiwte2488r3h770svcat99taxn:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://jb40zvarcb1y7ie8v6movseo5tnvi9vuewnvllpgsbsp4cbc9dtz5mdlyqu2bvwyxngj6176hzhty8dbnnkft973jjswlg4xn27dh1iiwte2488r3h770svcat99taxn:latest/predictions.table.json'}",24.361695732941868,0.5647014040079218,0.9877496906093682,False,True,validation,False,A | B | C | D | E,4,CTBase,4e9da2b8-2502-44a7-a7da-ae62f2d554c9,raw,COMPLETION,False,12,bigscience/T0_3B,0,True,fill_in_the_blank_with_instruction,prompts/general_fixed_choice.yaml,NumerSense,,5,,,GenFC,,False,['Math QA'],aqua_rat,False,False,GeneralFixedChoice,False,False,False,,False,prompts,,False,True,fill_in_the_blank_with_instruction,,cross_task,aqua_rat,,,,False,,,False,,True,,,False,,CTBase.GenFC.numer_sense.fill_in_the_blank_with_instruction.LenNorm,AQuA,,,AQuA,aqua_rat,,,,,,,,4.161417322834645,1.0982840763918162,0.829245802467457,2.5290796550240104,0.0,,aqua_rat,['generate_rational_and_correct_choice'],False,29.5,78.0,39
13.35980566421154,7.272727272727272,0.5256703589428402,1.457284147345175,2.937007874015748,0.2194183557803382,1.0019511005094088,18.691588785046733,10.204081632653065,0.2545900753163916,2.81496062992126,97.54330708661418,0.5719913258327274,1.8228346456692912,30.630630630630627,0.2738336657914589,1.1722304586763204,0.3798445800951516,1.2010455382793652,2.641732283464567,20.078740157480315,"{'path': 'media/table/predictions_1_5e8bd88270e35077affd.table.json', 'size': 136508, '_type': 'table-file', 'ncols': 15, 'nrows': 254, 'sha256': '5e8bd88270e35077affdedc7b06a32a8105b130c5a7d6dd7631090d8571a215f', 'artifact_path': 'wandb-client-artifact://er23s658y931uf6pfuihc26xfopt9eh9c13wtw9i4hz0oww9kro3tbgznln2d9bdoyap190zpyl7ii1u7nhqnchnsi5n5cqxcno7jkbhs36mpbb1kiw58ql52wf9j3dq:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://er23s658y931uf6pfuihc26xfopt9eh9c13wtw9i4hz0oww9kro3tbgznln2d9bdoyap190zpyl7ii1u7nhqnchnsi5n5cqxcno7jkbhs36mpbb1kiw58ql52wf9j3dq:latest/predictions.table.json'}",24.361695732941868,0.2283052664359755,0.9645347897586282,False,True,validation,False,A | B | C | D | E,4,CTBase,1f959d92-dca8-4647-9840-69391dfbd000,raw,COMPLETION,False,12,bigscience/T0_3B,0,True,fill_in_the_blank_with_choices_after,prompts/general_fixed_choice.yaml,NumerSense,,5,,,GenFC,,False,['Math QA'],aqua_rat,False,False,GeneralFixedChoice,False,False,True,,False,prompts,,False,True,fill_in_the_blank_with_choices_after,,cross_task,aqua_rat,,,,False,,,False,,True,,,False,,CTBase.GenFC.numer_sense.fill_in_the_blank_with_choices_after.LenNorm,AQuA,,,AQuA,aqua_rat,,,,,,,,4.783464566929134,0.7184041565922795,0.3122972794484573,0.356869080404597,0.0,,aqua_rat,['generate_rational_and_correct_choice'],False,77.0,20.0,20
8.454258675078865,0.0,1.0367879474778043,4.49996016156955,3.440944881889764,0.5054345281515301,1.19152878248143,0.0,0.0,0.984537458795262,3.1811023622047245,106.54330708661418,0.5734123132360263,1.078740157480315,42.27129337539432,0.5392852167444905,0.5339836797853851,0.4214983572131325,1.371373494468419,3.885826771653543,26.37795275590551,"{'_latest_artifact_path': 'wandb-client-artifact://11g51wox4y9k3vxs103mv7709lmzp86isariqufnqehhu4hganq617b5tylqelur1stcl4c3ibtzzcat4tbqlpc01hrlnqmf4yzpj40ntr3a2tfvp4hyscrd5pidx871:latest/predictions.table.json', 'path': 'media/table/predictions_1_400b388396ca22a6d1c4.table.json', 'size': 138512, '_type': 'table-file', 'ncols': 15, 'nrows': 254, 'sha256': '400b388396ca22a6d1c419ddc2293047dc8544c4cadb8052802a649173b3023c', 'artifact_path': 'wandb-client-artifact://11g51wox4y9k3vxs103mv7709lmzp86isariqufnqehhu4hganq617b5tylqelur1stcl4c3ibtzzcat4tbqlpc01hrlnqmf4yzpj40ntr3a2tfvp4hyscrd5pidx871:latest/predictions.table.json'}",24.361695732941868,0.7761023578116795,0.9042099508362372,False,True,validation,False,A | B | C | D | E,4,CTBase,c97e7bbf-b7f0-4cee-ada5-431ce7d606cc,raw,CLASSIFICATION,False,12,bigscience/T0_3B,0,True,semantic_relations_nominials_without_options,prompts/general_fixed_choice.yaml,SemEval2010,,5,,,GenFC,,False,['Math QA'],aqua_rat,False,False,GeneralFixedChoice,False,False,False,,False,prompts,,False,True,semantic relations nominials without options,,cross_task,aqua_rat,,,,False,,,False,,True,,,False,,CTBase.GenFC.sem_eval_2010_task_8.semantic_relations_nominials_without_options.LenNorm,AQuA,,,AQuA,aqua_rat,,,,,,,,3.4133858267716537,0.8501840657327631,1.076950482369897,2.4027251727937715,0.0,,aqua_rat,['generate_rational_and_correct_choice'],False,43.0,82.0,37
11.4358663414038,4.444444444444444,0.6336351079517939,2.5397873046829944,3.248031496062992,0.3458575687700261,0.9208307096629608,10.38961038961039,0.0,0.554698906545564,3.688976377952756,101.54330708661418,0.4994247109871211,1.0984251968503935,42.34527687296417,0.3920575089342012,0.446064903290761,0.4006835113444598,1.0146792888140164,2.6535433070866143,27.55905511811024,"{'_type': 'table-file', 'ncols': 15, 'nrows': 254, 'sha256': '6df9f4bd26f2e40589894019345b5e297646dbaebaeb26b331a9ef002591e99d', 'artifact_path': 'wandb-client-artifact://n1exhbkun0hcus8rc92qdbuixb2mfxv8sk45rikn88yu9z396gkdva7f2wxyaa7rg7vyegbta68un9tiqcmewgzewp0ryy3sz7nzt6zyajjlpuac8vj7qykrfd56yogj:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://n1exhbkun0hcus8rc92qdbuixb2mfxv8sk45rikn88yu9z396gkdva7f2wxyaa7rg7vyegbta68un9tiqcmewgzewp0ryy3sz7nzt6zyajjlpuac8vj7qykrfd56yogj:latest/predictions.table.json', 'path': 'media/table/predictions_1_6df9f4bd26f2e4058989.table.json', 'size': 133446}",24.361695732941868,0.4833757041001023,0.9101984162380826,False,True,validation,False,A | B | C | D | E,4,CTBase,5d7123a8-4ed4-42ce-bcfb-4af415962efc,raw,CLASSIFICATION,False,12,bigscience/T0_3B,0,True,semantically_related_nominials_with_options,prompts/general_fixed_choice.yaml,SemEval2010,,5,,,GenFC,,False,['Math QA'],aqua_rat,False,False,GeneralFixedChoice,False,False,True,,False,prompts,,False,True,semantically related nominials with options,,cross_task,aqua_rat,,,,False,,,False,,True,,,False,,CTBase.GenFC.sem_eval_2010_task_8.semantically_related_nominials_with_options.LenNorm,AQuA,,,AQuA,aqua_rat,,,,,,,,4.311023622047244,1.050738648810167,0.6174177466521411,1.0936061782161082,0.0,,aqua_rat,['generate_rational_and_correct_choice'],False,4.5,33.0,17
10.567281639538631,4.545454545454545,0.5739474006870746,2.121482083177942,3.614173228346457,0.2981539790977747,1.0540304653853436,5.479452054794522,0.0,0.4906192539245125,3.6692913385826778,123.54330708661418,0.3539021484495148,1.062992125984252,42.8115015974441,0.3425906568061648,0.3711661023430764,0.2816929644846192,1.2297652315157757,2.893700787401575,27.55905511811024,"{'nrows': 254, 'sha256': 'b315b282fef21f5a997b02ebe37e49566701cf930d0d542369523867116d0db4', 'artifact_path': 'wandb-client-artifact://y2d4fwlgej2rh9bza5l5dxem2o7zvx50v420izfhzvf0mrdhlr42viqut4ecjso65493qvszmydmotdphlups5p0pk554qi5521ld04swwvsjctzblbnxksjj8vhlp6h:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://y2d4fwlgej2rh9bza5l5dxem2o7zvx50v420izfhzvf0mrdhlr42viqut4ecjso65493qvszmydmotdphlups5p0pk554qi5521ld04swwvsjctzblbnxksjj8vhlp6h:latest/predictions.table.json', 'path': 'media/table/predictions_1_b315b282fef21f5a997b.table.json', 'size': 152959, '_type': 'table-file', 'ncols': 15}",24.361695732941868,0.42807142944918,1.0799177433696814,False,True,validation,False,A | B | C | D | E,4,CTBase,202246b0-3f82-42b9-bc8d-d36997b5f2cb,raw,CLASSIFICATION,False,12,bigscience/T0_3B,0,True,semantic_relations_with_options,prompts/general_fixed_choice.yaml,SemEval2010,,5,,,GenFC,,False,['Math QA'],aqua_rat,False,False,GeneralFixedChoice,False,False,True,,False,prompts,,False,True,semantic relations with options,,cross_task,aqua_rat,,,,False,,,False,,True,,,False,,CTBase.GenFC.sem_eval_2010_task_8.semantic_relations_with_options.LenNorm,AQuA,,,AQuA,aqua_rat,,,,,,,,3.75984251968504,0.9523084131638382,0.5486199404035702,0.9343700239977498,0.0,,aqua_rat,['generate_rational_and_correct_choice'],False,4.5,42.0,40
9.14695340501792,4.444444444444444,0.8727997699071283,3.509691815676652,3.090551181102362,0.5224604205054273,0.8532414406496629,0.0,0.0,0.5981586420629906,3.5866141732283463,78.54330708661418,0.7329849840149166,1.094488188976378,41.29032258064515,0.5771696248392421,0.4684212194562472,0.5607951177861297,0.8818546112229105,2.677165354330709,25.590551181102363,"{'_type': 'table-file', 'ncols': 15, 'nrows': 254, 'sha256': 'a585b25682e916c9b856dd4d44717eb27e094682b29b2afc31ddfe5aac0b8d9e', 'artifact_path': 'wandb-client-artifact://ec8wj01g3ua77iprc7va550z5bs25es2vrkz4y88aejfij5xy9abzaoj12fozrukthpd9ia388qlh29ixctznvwxnzkkug2mwokvlf3cdlbhs87cel56mko9255bb43v:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://ec8wj01g3ua77iprc7va550z5bs25es2vrkz4y88aejfij5xy9abzaoj12fozrukthpd9ia388qlh29ixctznvwxnzkkug2mwokvlf3cdlbhs87cel56mko9255bb43v:latest/predictions.table.json', 'path': 'media/table/predictions_1_a585b25682e916c9b856.table.json', 'size': 116387}",24.361695732941868,0.5259921497548998,0.975274013966744,False,True,validation,False,A | B | C | D | E,4,CTBase,af4d550e-54b8-471e-97af-2b2c50a1382e,raw,SUMMARIZATION,False,12,bigscience/T0_3B,0,True,relatedwork_abstract,prompts/general_fixed_choice.yaml,Multi-XSci,,5,,,GenFC,,False,['Math QA'],aqua_rat,False,False,GeneralFixedChoice,False,False,False,,False,prompts,,False,True,relatedwork_abstract,,cross_task,aqua_rat,,,,False,,,False,,True,,,False,,CTBase.GenFC.multi_x_science_sum.relatedwork_abstract.LenNorm,AQuA,,,AQuA,aqua_rat,,,,,,,,4.551181102362205,0.9110750024642976,0.8376504826599986,1.6013785647595022,0.0,,aqua_rat,['generate_rational_and_correct_choice'],False,59.5,71.0,9
9.51668584579977,4.545454545454545,0.8497883825108958,3.811286501997099,3.1968503937007875,0.5123701522278029,0.8787909561136193,0.0,0.0,0.6349185714571495,3.622047244094488,86.54330708661418,0.6627602351932075,1.0511811023622046,43.03797468354431,0.5171571209674745,0.356793714355381,0.5401080764424475,0.9333283142621808,2.7007874015748032,27.165354330708663,"{'artifact_path': 'wandb-client-artifact://7mkj38dl1mc00o4hadl43ec76tbp3yn2ywq8fhuott5z1mctkue780e9oyocwjqq7k2z1erqghwz21eikhg33juzyydddk3k39v6fuiv0nupvu3wz0kt3ijx9vg77ac3:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://7mkj38dl1mc00o4hadl43ec76tbp3yn2ywq8fhuott5z1mctkue780e9oyocwjqq7k2z1erqghwz21eikhg33juzyydddk3k39v6fuiv0nupvu3wz0kt3ijx9vg77ac3:latest/predictions.table.json', 'path': 'media/table/predictions_1_ab8fe681a9933bf3026b.table.json', 'size': 127066, '_type': 'table-file', 'ncols': 15, 'nrows': 254, 'sha256': 'ab8fe681a9933bf3026b4575003950166cb054fc31317d3b51f1cbb03f7bb57a'}",24.361695732941868,0.5639237033023171,0.9384954776382904,False,True,validation,False,A | B | C | D | E,4,CTBase,3bd082cb-4e28-4eb7-9fa2-dd03f1f86219,raw,SUMMARIZATION,False,12,bigscience/T0_3B,0,True,abstract_relatedwork,prompts/general_fixed_choice.yaml,Multi-XSci,,5,,,GenFC,,False,['Math QA'],aqua_rat,False,False,GeneralFixedChoice,False,False,False,,False,prompts,,False,True,abstract_relatedwork,,cross_task,aqua_rat,,,,False,,,False,,True,,,False,,CTBase.GenFC.multi_x_science_sum.abstract_relatedwork.LenNorm,AQuA,,,AQuA,aqua_rat,,,,,,,,4.429133858267717,0.9964986131545652,0.906235534687998,1.996450574379268,0.0,,aqua_rat,['generate_rational_and_correct_choice'],False,13.5,53.0,17
9.435736677115989,4.545454545454545,0.862556802830686,3.915539253415085,3.2007874015748032,0.5284729090043678,0.8846010767787534,0.0,0.0,0.6454970611362006,3.5826771653543306,79.54330708661418,0.6307805147696668,1.0393700787401574,42.63322884012539,0.5383270763036773,0.3414091872232881,0.5153106982283524,0.961565311986502,2.7401574803149606,27.165354330708663,"{'artifact_path': 'wandb-client-artifact://latzcjd83nb0cjvw1idm2vxu8ao1rx26wy7j372mkiee3uotxsat0oo6xs66jrfix2ykaw38a3s72mfutwmuu2yvuq2fh6p1q9ps2gwqgg1d5vqzbxq66lleohzlpnnj:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://latzcjd83nb0cjvw1idm2vxu8ao1rx26wy7j372mkiee3uotxsat0oo6xs66jrfix2ykaw38a3s72mfutwmuu2yvuq2fh6p1q9ps2gwqgg1d5vqzbxq66lleohzlpnnj:latest/predictions.table.json', 'path': 'media/table/predictions_1_c51f9936c5f48376a81d.table.json', 'size': 118980, '_type': 'table-file', 'ncols': 15, 'nrows': 254, 'sha256': 'c51f9936c5f48376a81d69a8b52ea4ddce34ce2c5287f0108734e738d1d4ef69'}",24.361695732941868,0.5852546006538807,0.9343905747445724,False,True,validation,False,A | B | C | D | E,4,CTBase,2bca0197-e3d4-4870-bd95-178411e52e09,raw,SUMMARIZATION,False,12,bigscience/T0_3B,0,True,ref_relatedwork,prompts/general_fixed_choice.yaml,Multi-XSci,,5,,,GenFC,,False,['Math QA'],aqua_rat,False,False,GeneralFixedChoice,False,False,False,,False,prompts,,False,True,ref_relatedwork,,cross_task,aqua_rat,,,,False,,,False,,True,,,False,,CTBase.GenFC.multi_x_science_sum.ref_relatedwork.LenNorm,AQuA,,,AQuA,aqua_rat,,,,,,,,4.437007874015748,0.9730464498875618,0.9114408227928557,2.1009346012055405,0.0,,aqua_rat,['generate_rational_and_correct_choice'],False,13.5,59.0,10
9.462550028587764,4.545454545454545,0.857169438143014,3.8597680987335568,3.1653543307086616,0.5495590396275356,0.853559287411785,0.0,0.0,0.6617727063772246,3.618110236220472,79.54330708661418,0.7099559156913456,1.0433070866141732,42.767295597484285,0.5511735048819715,0.3466579587193704,0.5533465043051982,0.8618720819512435,2.6377952755905514,27.165354330708663,"{'size': 116110, '_type': 'table-file', 'ncols': 15, 'nrows': 254, 'sha256': '70427749858c0ba0f42a5f318423e3a02928374ff865b4a505824bf1ce6bda9e', 'artifact_path': 'wandb-client-artifact://15cc85z0ozpceqaoggi5s3m5be2zxpsrey64fojw81wnxq8ea92s0jb4vuiejaxjew1st6jibhibdahcfzh2h0imnw74ozni401poa6mf56ogryyn52km2o4f1k4l60j:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://15cc85z0ozpceqaoggi5s3m5be2zxpsrey64fojw81wnxq8ea92s0jb4vuiejaxjew1st6jibhibdahcfzh2h0imnw74ozni401poa6mf56ogryyn52km2o4f1k4l60j:latest/predictions.table.json', 'path': 'media/table/predictions_1_70427749858c0ba0f42a.table.json'}",24.361695732941868,0.5811167095664002,0.926335369180316,False,True,validation,False,A | B | C | D | E,4,CTBase,774b4349-0524-4a34-881b-b344f8f5c34e,raw,COMPLETION,False,12,bigscience/T0_3B,0,True,what_comes_next,prompts/general_fixed_choice.yaml,LAMBADA,,5,,,GenFC,,False,['Math QA'],aqua_rat,False,False,GeneralFixedChoice,False,False,False,,False,prompts,,False,True,what comes next,,cross_task,aqua_rat,,,,False,,,False,,True,,,False,,CTBase.GenFC.craffel_openai_lambada.what_comes_next.LenNorm,AQuA,,,AQuA,aqua_rat,,,,,,,,4.535433070866142,0.907495260095222,0.8837328270436807,1.9368659717830148,0.0,,aqua_rat,['generate_rational_and_correct_choice'],False,13.5,56.5,10
9.237166618870088,4.545454545454545,0.9086937210321614,4.205683489484112,3.1535433070866143,0.514908203116536,0.9157669885174692,0.0,0.0,0.696144354625011,3.5826771653543306,80.54330708661418,0.7213623242115411,1.047244094488189,41.640378548895896,0.5069781410412526,0.3517843764360421,0.539727246283233,0.914708518263248,2.787401574803149,26.37795275590551,"{'nrows': 254, 'sha256': '93193948dea2e28e4935fcbe2b77957dae4cf6d062d35c1ed8ca84e383eb6b7d', 'artifact_path': 'wandb-client-artifact://11xezoiz2hstizcbxlzrcvermor3hgnnxlxa9o8189mm5c15m1urq6zra6q5j5krs00l8bfaj1xewzljr5nxc84omgwgxbm7vsesbbf63jtd2vx8g820lihndudjmm40:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://11xezoiz2hstizcbxlzrcvermor3hgnnxlxa9o8189mm5c15m1urq6zra6q5j5krs00l8bfaj1xewzljr5nxc84omgwgxbm7vsesbbf63jtd2vx8g820lihndudjmm40:latest/predictions.table.json', 'path': 'media/table/predictions_1_93193948dea2e28e4935.table.json', 'size': 111524, '_type': 'table-file', 'ncols': 15}",24.361695732941868,0.5937717392482124,0.9675111741761664,False,True,validation,False,A | B | C | D | E,4,CTBase,4f08e9d4-bcff-4bc0-9902-87c497625d17,raw,COMPLETION,False,12,bigscience/T0_3B,0,True,GPT_3_style,prompts/general_fixed_choice.yaml,LAMBADA,,5,,,GenFC,,False,['Math QA'],aqua_rat,False,False,GeneralFixedChoice,False,False,False,,False,prompts,,False,True,GPT-3 style,,cross_task,aqua_rat,,,,False,,,False,,True,,,False,,CTBase.GenFC.craffel_openai_lambada.GPT_3_style.LenNorm,AQuA,,,AQuA,aqua_rat,,,,,,,,4.429133858267717,1.000441653354659,0.9897287466998488,2.2811986696063062,0.0,,aqua_rat,['generate_rational_and_correct_choice'],False,43.0,70.0,11
10.669353634870877,4.545454545454545,0.9513399525325612,3.890358029388067,3.4763779527559056,0.5602548020324541,1.0710181110324832,0.0,0.0,0.7077866032367616,3.515748031496063,79.53543307086615,0.5266406554875411,1.078740157480315,41.90476190476191,0.496782373255632,0.4957504327148723,0.4363443549855612,1.2607341824910427,3.1692913385826773,26.77165354330709,"{'artifact_path': 'wandb-client-artifact://nqwj3b1hpql60sya6690gp2c4dhmwy91eaa5xvdm63x2dz05381u2ik1u4v89alu7o974koe475gtmqh3nsw09bobysqg0va4fxa9fr1vq5i4ugr64jy418kj4pv2dmy:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://nqwj3b1hpql60sya6690gp2c4dhmwy91eaa5xvdm63x2dz05381u2ik1u4v89alu7o974koe475gtmqh3nsw09bobysqg0va4fxa9fr1vq5i4ugr64jy418kj4pv2dmy:latest/predictions.table.json', 'path': 'media/table/predictions_1_a93901535ab8f9c74920.table.json', 'size': 113810, '_type': 'table-file', 'ncols': 15, 'nrows': 254, 'sha256': 'a93901535ab8f9c74920c7ca519884515e070d3a349acb48914191a9b9687ba8'}",24.340528813538253,0.6539022539814745,1.0637865214804738,False,True,validation,False,A | B | C | D | E,4,CTBase,1ee5ddef-fffb-4b73-a2f7-f600ffac63cb,raw,COMPLETION,False,12,bigscience/T0_3B,0,True,ellipses,prompts/general_fixed_choice.yaml,LAMBADA,,5,,,GenFC,,False,['Math QA'],aqua_rat,False,False,GeneralFixedChoice,False,False,False,,False,prompts,,False,True,ellipses,,cross_task,aqua_rat,,,,False,,,False,,True,,,False,,CTBase.GenFC.craffel_openai_lambada.ellipses.LenNorm,AQuA,,,AQuA,aqua_rat,,,,,,,,3.75984251968504,1.046836993870289,0.9140239972021932,2.1591483974081327,6.896551724137931,,aqua_rat,['generate_rational_and_correct_choice'],False,29.5,40.0,11
8.401253918495298,0.0,0.8836377265117068,4.916495733373747,3.307086614173228,0.4737085203532007,0.9761874337870836,0.0,0.0,0.6856978127336878,3.566929133858268,90.54330708661418,0.5270702275704211,1.0354330708661417,42.00626959247649,0.4559500470874816,0.3241044740317853,0.458480618665596,0.9899676560736316,2.811023622047244,26.37795275590551,"{'size': 129431, '_type': 'table-file', 'ncols': 15, 'nrows': 254, 'sha256': '119ac8f3dac72650ee0f3dc5f17fa284abb2792e960f152b11ea2268a2937674', 'artifact_path': 'wandb-client-artifact://xc1naeh22klxqu8yzsil72jkw2ha8fp38b53yjjyt9cuh1mg0idmrerruk0r1v73yp62p2hulxg0d6c4ghz197ycr217eiucdxf5pyguapa38pzgucruf5dknufoedtp:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://xc1naeh22klxqu8yzsil72jkw2ha8fp38b53yjjyt9cuh1mg0idmrerruk0r1v73yp62p2hulxg0d6c4ghz197ycr217eiucdxf5pyguapa38pzgucruf5dknufoedtp:latest/predictions.table.json', 'path': 'media/table/predictions_1_119ac8f3dac72650ee0f.table.json'}",24.361695732941868,0.635831557778611,0.9928131603458642,False,True,validation,False,A | B | C | D | E,4,CTBase,9a3f617f-628f-4fa5-9b74-47d0b166a487,raw,SUMMARIZATION,False,12,bigscience/T0_3B,0,True,read_below_DOC_write_abstract,prompts/general_fixed_choice.yaml,XSum,,5,,,GenFC,,False,['Math QA'],aqua_rat,True,False,GeneralFixedChoice,False,False,False,,False,prompts,,False,True,read_below_DOC_write_abstract,,cross_task,aqua_rat,,,,False,,,False,,True,,,False,,CTBase.GenFC.xsum.read_below_DOC_write_abstract.LenNorm,AQuA,,,AQuA,aqua_rat,,,,,,,,4.279527559055119,1.0139840020074835,1.0683735130559031,3.247777645982157,0.0,,aqua_rat,['generate_rational_and_correct_choice'],False,43.0,84.5,21
8.5,0.0,0.9312733880662184,4.863345613160472,3.2007874015748032,0.483063127146385,0.9364866544775254,0.0,0.0,0.6446052508091363,3.618110236220472,93.54330708661418,0.5006460946375929,1.031496062992126,42.49999999999999,0.4682214006664246,0.3183868758922162,0.4467535764154869,0.9623145806329158,2.877952755905512,26.77165354330709,"{'artifact_path': 'wandb-client-artifact://694wkol33bx7lr574yxilofbkxv35y6cqrmqytntrrbyy8aifvc3rqphxrzsnisflu60r7yhljbtoyqu596aeq4ltfib3laioax6d6a7kkazobgjwqayyxmi4xtnzzar:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://694wkol33bx7lr574yxilofbkxv35y6cqrmqytntrrbyy8aifvc3rqphxrzsnisflu60r7yhljbtoyqu596aeq4ltfib3laioax6d6a7kkazobgjwqayyxmi4xtnzzar:latest/predictions.table.json', 'path': 'media/table/predictions_1_8f565f71427d80d3570e.table.json', 'size': 127807, '_type': 'table-file', 'ncols': 15, 'nrows': 254, 'sha256': '8f565f71427d80d3570e87dd8d3ecc559af1519507970840494a0f951bf3a82c'}",24.361695732941868,0.6001812521329767,1.0077586671197931,False,True,validation,False,A | B | C | D | E,4,CTBase,4cfe4126-b9f5-44eb-8a98-973987c5f32e,raw,SUMMARIZATION,False,12,bigscience/T0_3B,0,True,college_roommate_asked_DOC_so_I_recap,prompts/general_fixed_choice.yaml,XSum,,5,,,GenFC,,False,['Math QA'],aqua_rat,True,False,GeneralFixedChoice,False,False,False,,False,prompts,,False,True,college_roommate_asked_DOC_so_I_recap,,cross_task,aqua_rat,,,,False,,,False,,True,,,False,,CTBase.GenFC.xsum.college_roommate_asked_DOC_so_I_recap.LenNorm,AQuA,,,AQuA,aqua_rat,,,,,,,,4.271653543307087,1.072666677597287,1.0943056813090104,3.249872867047318,0.0,,aqua_rat,['generate_rational_and_correct_choice'],False,29.5,79.5,24
9.435736677115989,4.545454545454545,0.9057914230140108,4.931996412164583,3.188976377952756,0.5234259982793966,0.8982247010716347,0.0,0.0,0.7398273334728451,3.7401574803149606,82.54330708661418,0.5350341064723458,1.0393700787401574,42.63322884012539,0.5172986308420737,0.3414091872232881,0.4396672933404612,0.9810025100537968,2.7086614173228347,27.165354330708663,"{'_type': 'table-file', 'ncols': 15, 'nrows': 254, 'sha256': '3401177abbf98bb4b2fcb6c324cd3840c79cfdab83cfd42cf1b14e7e432af410', 'artifact_path': 'wandb-client-artifact://122tj8qs4939811p6phlkh88whldkk50cqgb1u2r0pualitsafstxjyvulxyr6w4ovwhhxr47mvc9mcq3jfno780rlquo1p3jn6itf5aqtjr5rbeacj7yjxkw66jv0a4:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://122tj8qs4939811p6phlkh88whldkk50cqgb1u2r0pualitsafstxjyvulxyr6w4ovwhhxr47mvc9mcq3jfno780rlquo1p3jn6itf5aqtjr5rbeacj7yjxkw66jv0a4:latest/predictions.table.json', 'path': 'media/table/predictions_1_3401177abbf98bb4b2fc.table.json', 'size': 116216}",24.361695732941868,0.6421833322454185,0.9977344290681674,False,True,validation,False,A | B | C | D | E,4,CTBase,3d388a1e-3361-407b-baa7-61397cc58382,raw,SUMMARIZATION,False,12,bigscience/T0_3B,0,True,DOC_how_would_you_rephrase_few_words,prompts/general_fixed_choice.yaml,XSum,,5,,,GenFC,,False,['Math QA'],aqua_rat,True,False,GeneralFixedChoice,False,False,False,,False,prompts,,False,True,DOC_how_would_you_rephrase_few_words,,cross_task,aqua_rat,,,,False,,,False,,True,,,False,,CTBase.GenFC.xsum.DOC_how_would_you_rephrase_few_words.LenNorm,AQuA,,,AQuA,aqua_rat,,,,,,,,4.322834645669292,0.925422991293941,1.0986544593888572,3.1398363413773183,0.0,,aqua_rat,['generate_rational_and_correct_choice'],False,13.5,59.0,13
9.462550028587764,4.545454545454545,1.1244055119975047,5.4203636505472375,3.1850393700787403,0.5407495120987345,0.952210750522502,0.0,0.0,0.7668336113606851,3.645669291338583,82.54330708661418,0.5651892188965805,1.0551181102362204,42.767295597484285,0.5425497340405081,0.4219767246291106,0.4877819788026974,0.9848816883178813,2.826771653543307,27.165354330708663,"{'ncols': 15, 'nrows': 254, 'sha256': 'f33fe49a94d0042567addbe0b9fd0c8a5407e93bbbdf9300d3e17e62f7ea3589', 'artifact_path': 'wandb-client-artifact://9dvk2rzin47j4w89er6itkowsvjr8vjn0vwlkz4r3pzy9zso6l34gc6hkf6zzqrm6a5nfd8wjzwbqyum54g3i6osyp9oubg77z6xko6cd7xsabt3qgx9xhuf3kecjiv1:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://9dvk2rzin47j4w89er6itkowsvjr8vjn0vwlkz4r3pzy9zso6l34gc6hkf6zzqrm6a5nfd8wjzwbqyum54g3i6osyp9oubg77z6xko6cd7xsabt3qgx9xhuf3kecjiv1:latest/predictions.table.json', 'path': 'media/table/predictions_1_f33fe49a94d0042567ad.table.json', 'size': 115191, '_type': 'table-file'}",24.361695732941868,0.7327581321403803,1.0119565445769378,False,True,validation,False,A | B | C | D | E,4,CTBase,13c02904-e4e2-4b4f-b115-44b437d22041,raw,SUMMARIZATION,False,12,bigscience/T0_3B,0,True,DOC_write_summary_of_above,prompts/general_fixed_choice.yaml,XSum,,5,,,GenFC,,False,['Math QA'],aqua_rat,True,False,GeneralFixedChoice,False,False,False,,False,prompts,,False,True,DOC_write_summary_of_above,,cross_task,aqua_rat,,,,False,,,False,,True,,,False,,CTBase.GenFC.xsum.DOC_write_summary_of_above.LenNorm,AQuA,,,AQuA,aqua_rat,,,,,,,,4.28740157480315,1.0000387493267449,1.284034575545827,3.545791086249464,0.0,,aqua_rat,['generate_rational_and_correct_choice'],False,13.5,56.5,13
18.03451105312489,28.30188679245283,0.5426723892507823,1.2757847534389946,3.232283464566929,0.1981132637678825,1.3030782386433255,5.333333333333334,8.955223880597014,0.2663901865951658,3.456692913385827,94.54330708661418,0.3584268562437042,1.905511811023622,36.771300448430495,0.2350429793981116,1.2259212885687285,0.3036095487719286,1.2344387581723508,2.8346456692913384,24.80314960629921,"{'_type': 'table-file', 'ncols': 15, 'nrows': 254, 'sha256': '81f4484c8ee24b7ae34ada5b0050ef19898670843e2f1986fbc83aeb3bf7ff01', 'artifact_path': 'wandb-client-artifact://c65ee0cnq0pq63q3xz9ec7plucoqkqhuqa4wmp0u6n9b4k3uhneu04uso6h8sr81q32wdd8y1qeiz9nu5d3r5cn0ai0dgutvipkzaey6gxhj898anvbumvefvsa8b6nc:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://c65ee0cnq0pq63q3xz9ec7plucoqkqhuqa4wmp0u6n9b4k3uhneu04uso6h8sr81q32wdd8y1qeiz9nu5d3r5cn0ai0dgutvipkzaey6gxhj898anvbumvefvsa8b6nc:latest/predictions.table.json', 'path': 'media/table/predictions_1_81f4484c8ee24b7ae34a.table.json', 'size': 125753}",24.361695732941868,0.2268665355872084,1.243920051560465,False,True,validation,False,A | B | C | D | E,4,CTBase,5fa16d31-b513-480d-bd1b-1fa8c182fb76,raw,SENTIMENT,False,12,bigscience/T0_3B,0,True,bullish_neutral_bearish,prompts/general_fixed_choice.yaml,FinNews,,5,,,GenFC,,False,['Math QA'],aqua_rat,False,False,GeneralFixedChoice,False,False,True,,False,prompts,,False,True,bullish_neutral_bearish,,cross_task,aqua_rat,,,,False,,,False,,True,,,False,,CTBase.GenFC.financial_phrasebank_sentences_allagree.bullish_neutral_bearish.LenNorm,AQuA,,,AQuA,aqua_rat,,,,,,,,3.570866141732284,1.3835712227921833,0.3950222581719245,0.4159247312020129,10.81081081081081,,aqua_rat,['generate_rational_and_correct_choice'],False,65.0,8.0,9
9.489532549469455,4.545454545454545,0.8624123631037963,3.651957678982592,3.047244094488189,0.5941282751512769,0.9949341585190248,0.0,0.0,0.6627859750131923,3.822834645669291,80.54330708661418,0.6004326625133124,1.047244094488189,42.90220820189275,0.6546517901533232,0.3517843764360421,0.5004713796337857,0.8115681223936994,2.767716535433071,27.165354330708663,"{'nrows': 254, 'sha256': 'ad6c2a4801bfe3f58b23d8c9fcc08b788bdb0e3fc7525009d5a7c33f3e2c2c28', 'artifact_path': 'wandb-client-artifact://s7mvy6tztlryzf19si30mr2yf0ftjl65oudi2kn2y6tdeezdrw5hxokyd7n78brwu1ga7t7k1zm8rgwgftt2e0xs3uj05zrlurdptuvj5mr4iubythwtsa3scwjd15h7:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://s7mvy6tztlryzf19si30mr2yf0ftjl65oudi2kn2y6tdeezdrw5hxokyd7n78brwu1ga7t7k1zm8rgwgftt2e0xs3uj05zrlurdptuvj5mr4iubythwtsa3scwjd15h7:latest/predictions.table.json', 'path': 'media/table/predictions_1_ad6c2a4801bfe3f58b23.table.json', 'size': 123526, '_type': 'table-file', 'ncols': 15}",24.361695732941868,0.5507339654336134,0.9660120943128676,False,True,validation,False,A | B | C | D | E,4,CTBase,461efe04-6883-41e8-80f0-e722a75260fe,raw,SENTIMENT,False,12,bigscience/T0_3B,0,True,complementary_industries,prompts/general_fixed_choice.yaml,FinNews,,5,,,GenFC,,False,['Math QA'],aqua_rat,False,False,GeneralFixedChoice,False,False,False,,False,prompts,,False,True,complementary_industries,,cross_task,aqua_rat,,,,False,,,False,,True,,,False,,CTBase.GenFC.financial_phrasebank_sentences_allagree.complementary_industries.LenNorm,AQuA,,,AQuA,aqua_rat,,,,,,,,4.31496062992126,1.0094107379159762,0.8186834946902101,1.734087251302764,0.0,,aqua_rat,['generate_rational_and_correct_choice'],False,13.5,54.0,11
11.824936491387792,4.545454545454545,0.8733018136555739,3.4512225098497287,3.3464566929133857,0.5114534878132565,0.9669983816800006,12.195121951219512,0.0,0.8391546414593073,3.7913385826771657,77.54330708661418,0.5327497767651175,1.1299212598425197,42.3841059602649,0.5554173649765375,0.5350421222110883,0.4259408036628375,1.2593995284159607,2.755905511811024,27.55905511811024,"{'_type': 'table-file', 'ncols': 15, 'nrows': 254, 'sha256': '97dd4d8539015a33ce014e1cf390d43f21116cda081c7499c8c2b4ddf1c8b516', 'artifact_path': 'wandb-client-artifact://1olnrllaemhurhvjr57ks9bczo5no8e6okmh9uocdtujwnv6fmkgas0qbcae67k31nfe4dmjk91j2sf6tsvbzjage6qky9mtm1ilr4efoixp49ycg5oi03g08cehe0k3:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://1olnrllaemhurhvjr57ks9bczo5no8e6okmh9uocdtujwnv6fmkgas0qbcae67k31nfe4dmjk91j2sf6tsvbzjage6qky9mtm1ilr4efoixp49ycg5oi03g08cehe0k3:latest/predictions.table.json', 'path': 'media/table/predictions_1_97dd4d8539015a33ce01.table.json', 'size': 115112}",24.361695732941868,0.6827023489247968,1.02707624340709,False,True,validation,False,A | B | C | D | E,4,CTBase,0beba048-f949-4034-83b6-a3e0e7363f46,raw,SENTIMENT,False,12,bigscience/T0_3B,0,True,sentiment,prompts/general_fixed_choice.yaml,FinNews,,5,,,GenFC,,False,['Math QA'],aqua_rat,False,False,GeneralFixedChoice,False,False,False,,False,prompts,,False,True,sentiment,,cross_task,aqua_rat,,,,False,,,False,,True,,,False,,CTBase.GenFC.financial_phrasebank_sentences_allagree.sentiment.LenNorm,AQuA,,,AQuA,aqua_rat,,,,,,,,3.9763779527559056,0.9387927154934284,0.8427082168650862,1.5239007266487663,0.0,,aqua_rat,['generate_rational_and_correct_choice'],False,4.5,29.0,8
12.009478046199964,11.320754716981131,0.4487964207180802,1.1855766679358295,3.2401574803149606,0.2123612453806604,1.1677260925270336,2.857142857142857,0.0,0.2860460074867789,2.9803149606299213,105.54330708661418,0.249271167544868,2.417322834645669,38.39285714285714,0.2581978689028522,1.8462174349294924,0.1891941339793827,1.681263707243842,3.125984251968504,20.078740157480315,"{'sha256': '19df5857a2af76e6e4bba95a5b68efb787a4c338cf62427e3672736eda95f964', 'artifact_path': 'wandb-client-artifact://10wgtp8wgnkqk19dj3o6yjcpwn8mr7s8uhqxgaufxa7poftzm8p8rtzovp5uhbv819zt8nqupkot0dejj79f9ja58qqos1ii4o6fkulxj1mcf11ye430q5gkec2lsvwe:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://10wgtp8wgnkqk19dj3o6yjcpwn8mr7s8uhqxgaufxa7poftzm8p8rtzovp5uhbv819zt8nqupkot0dejj79f9ja58qqos1ii4o6fkulxj1mcf11ye430q5gkec2lsvwe:latest/predictions.table.json', 'path': 'media/table/predictions_1_19df5857a2af76e6e4bb.table.json', 'size': 140676, '_type': 'table-file', 'ncols': 15, 'nrows': 254}",24.361695732941868,0.2261980699587218,1.0056955418251816,False,True,validation,False,A | B | C | D | E,4,CTBase,06719321-62e7-4f6e-8f95-464cd2b5ca5c,raw,SENTIMENT,False,12,bigscience/T0_3B,0,True,share_price_option,prompts/general_fixed_choice.yaml,FinNews,,5,,,GenFC,,False,['Math QA'],aqua_rat,False,False,GeneralFixedChoice,False,False,True,,False,prompts,,False,True,share_price_option,,cross_task,aqua_rat,,,,False,,,False,,True,,,False,,CTBase.GenFC.financial_phrasebank_sentences_allagree.share_price_option.LenNorm,AQuA,,,AQuA,aqua_rat,,,,,,,,3.236220472440945,0.9594674779041144,0.3380128216650409,0.3920616240013302,7.476635514018692,,aqua_rat,['generate_rational_and_correct_choice'],False,77.0,28.0,20
19.086660189086064,25.0,0.444403589271281,1.0477343220410384,3.279527559055118,0.2379606902665732,1.2441256350132777,20.75471698113208,30.61224489795918,0.2061708212837459,2.5826771653543306,98.49212598425196,0.2916715088791735,3.6535433070866143,2.702702702702702,0.2585169616646654,1.1493096370540377,0.2520096825307524,1.1809251835609986,3.4291338582677167,20.078740157480315,"{'nrows': 254, 'sha256': 'e74d0ea735f9b1dc32d86fde867a5821f97f6b0df3f46d858ae01521d759efb0', 'artifact_path': 'wandb-client-artifact://tx483tmkadq1e7k1ene79u4vk1kgdl2p4rkknih9u79hyo1j6z8i0uwdslonnkd80ybp2ccgtaasgouh3fdobafdk46lo7c18m6lp5smsrlo7bh45963xd9ynlsqt2gs:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://tx483tmkadq1e7k1ene79u4vk1kgdl2p4rkknih9u79hyo1j6z8i0uwdslonnkd80ybp2ccgtaasgouh3fdobafdk46lo7c18m6lp5smsrlo7bh45963xd9ynlsqt2gs:latest/predictions.table.json', 'path': 'media/table/predictions_1_e74d0ea735f9b1dc32d8.table.json', 'size': 127247, '_type': 'table-file', 'ncols': 15}",27.34839990511245,0.1745878188959011,1.3857596619398622,False,True,validation,True,A | B | C | D | E,4,CTBase,eb89c860-5849-461a-9081-3bd466f5642c,raw,MCQ,False,12,bigscience/T0_3B,0,True,gre_problem,prompts/general_fixed_choice.yaml,MathQA,,5,,,GenFC,,False,['Math QA'],aqua_rat,False,False,GeneralFixedChoice,False,False,True,,False,prompts,,False,True,gre_problem,,cross_task,aqua_rat,,,,False,,,False,,True,,,False,,CTBase.GenFC.math_qa.gre_problem.LenNorm,AQuA,,,AQuA,aqua_rat,,,,,,,,2.0551181102362204,1.435254026264424,0.2593425980642949,0.2913750302134536,16.363636363636363,,aqua_rat,['generate_rational_and_correct_choice'],False,77.0,4.0,8
13.939473225187513,22.22222222222222,0.4553079502810935,1.4500160747625697,3.5118110236220472,0.3438659559355915,1.0106997788800025,5.555555555555555,24.17582417582418,0.2869790191725483,1.905511811023622,111.49212598425196,0.3523470688992598,4.066929133858268,2.7777777777777777,0.4540443462649668,0.999728712659088,0.2817134980140422,1.037967318730368,3.779527559055118,15.354330708661418,"{'ncols': 15, 'nrows': 254, 'sha256': 'b734cd8bfcd0e4d892de2ab68e150de76b18923055197828c03c20b24c801626', 'artifact_path': 'wandb-client-artifact://qm0pxfvivyy4ttsqycx26hnsu7g7ssd1fmr3bgvhad34r05ll3zkp4hnk1hv6bhlievrs74iw204ozgn8le6ax3d6p8xo28w0t9oteocz8ebwfglc4wogvzetjdfyqyt:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://qm0pxfvivyy4ttsqycx26hnsu7g7ssd1fmr3bgvhad34r05ll3zkp4hnk1hv6bhlievrs74iw204ozgn8le6ax3d6p8xo28w0t9oteocz8ebwfglc4wogvzetjdfyqyt:latest/predictions.table.json', 'path': 'media/table/predictions_1_b734cd8bfcd0e4d892de.table.json', 'size': 145175, '_type': 'table-file'}",27.34839990511245,0.2454768484725059,1.0680254123177797,False,True,validation,True,A | B | C | D | E,4,CTBase,a313a5f8-53cd-4b76-abb6-fea2ac4e9ef4,raw,MCQ,False,12,bigscience/T0_3B,0,True,first_choice_then_problem,prompts/general_fixed_choice.yaml,MathQA,,5,,,GenFC,,False,['Math QA'],aqua_rat,False,False,GeneralFixedChoice,False,False,True,,False,prompts,,False,True,first_choice_then_problem,,cross_task,aqua_rat,,,,False,,,False,,True,,,False,,CTBase.GenFC.math_qa.first_choice_then_problem.LenNorm,AQuA,,,AQuA,aqua_rat,,,,,,,,1.736220472440945,0.9787642289943128,0.2696891854237573,0.3566456404257947,14.965986394557826,,aqua_rat,['generate_rational_and_correct_choice'],False,89.0,17.0,21
20.355501231766468,23.300970873786405,0.4577681219602427,0.9850114790473398,3.2086614173228347,0.2149004593834635,1.2579525686166906,21.818181818181817,27.65957446808511,0.204648738770973,2.606299212598425,100.49212598425196,0.2675034981074295,3.598425196850393,11.904761904761903,0.2181948343599875,1.287491869982343,0.2451515376978404,1.2587347491931482,3.2913385826771653,20.47244094488189,"{'artifact_path': 'wandb-client-artifact://11tymggdrhefc8y2ac0fmh8u7d9j8fngao71dsfokmildsjbawlc7pclni5lzipsr627l4x6w3ovfc8333c1f2dqdgy0karcle472pkae2otansvzig22qkqt6igo5v4:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://11tymggdrhefc8y2ac0fmh8u7d9j8fngao71dsfokmildsjbawlc7pclni5lzipsr627l4x6w3ovfc8333c1f2dqdgy0karcle472pkae2otansvzig22qkqt6igo5v4:latest/predictions.table.json', 'path': 'media/table/predictions_1_d0620468e86d68b0c49e.table.json', 'size': 131492, '_type': 'table-file', 'ncols': 15, 'nrows': 254, 'sha256': 'd0620468e86d68b0c49ef455e2c7dffa5dc9db19d9e584dc0197c16c345b8849'}",27.34839990511245,0.1893745768646474,1.409514800725394,False,True,validation,True,A | B | C | D | E,4,CTBase,8c4c81cc-ca54-45fc-a69a-4b97a5f2b465,raw,MCQ,False,12,bigscience/T0_3B,0,True,pick_the_correct,prompts/general_fixed_choice.yaml,MathQA,,5,,,GenFC,,False,['Math QA'],aqua_rat,False,False,GeneralFixedChoice,False,False,True,,False,prompts,,False,True,pick_the_correct,,cross_task,aqua_rat,,,,False,,,False,,True,,,False,,CTBase.GenFC.math_qa.pick_the_correct.LenNorm,AQuA,,,AQuA,aqua_rat,,,,,,,,2.295275590551181,1.4319942741558718,0.2756968185219613,0.2946644078089496,17.09401709401709,,aqua_rat,['generate_rational_and_correct_choice'],False,74.5,2.0,10
18.8080565966472,17.5,0.4258195865943436,1.1561366849996912,3.1692913385826773,0.2082874965408758,1.097097947882419,28.571428571428577,26.66666666666666,0.2200119382753146,2.6496062992125986,107.49212598425196,0.36722398085857,3.881889763779528,5.194805194805195,0.2288692476242546,1.2743018667845132,0.2890172792077722,1.1515731206663795,3.5511811023622046,19.291338582677163,"{'ncols': 15, 'nrows': 254, 'sha256': 'e15f3f4b22fed2789da46de5687155661f97074fb1fd1f3777c9d12dba041b25', 'artifact_path': 'wandb-client-artifact://j015zqlzky4ji2ctsowbe258c84xkzc5uocz71vloyqu1otf17upk8fy2grp6bvptnwdgcjmjp7cczp1q5f1educf2ibki1n8s9ez4jemsuzemskkuayso3yuh5nehjn:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://j015zqlzky4ji2ctsowbe258c84xkzc5uocz71vloyqu1otf17upk8fy2grp6bvptnwdgcjmjp7cczp1q5f1educf2ibki1n8s9ez4jemsuzemskkuayso3yuh5nehjn:latest/predictions.table.json', 'path': 'media/table/predictions_1_e15f3f4b22fed2789da4.table.json', 'size': 139325, '_type': 'table-file'}",27.34839990511245,0.2066078921332684,1.2671111676334568,False,True,validation,True,A | B | C | D | E,4,CTBase,6312d599-8ca4-4bc8-a76f-81f2e36727bd,raw,MCQ,False,12,bigscience/T0_3B,0,True,choose_correct_og,prompts/general_fixed_choice.yaml,MathQA,,5,,,GenFC,,False,['Math QA'],aqua_rat,False,False,GeneralFixedChoice,False,False,True,,False,prompts,,False,True,choose_correct_og,,cross_task,aqua_rat,,,,False,,,False,,True,,,False,,CTBase.GenFC.math_qa.choose_correct_og.LenNorm,AQuA,,,AQuA,aqua_rat,,,,,,,,1.748031496062992,1.2001870191340025,0.2838290912674422,0.3400315182415519,16.107382550335572,,aqua_rat,['generate_rational_and_correct_choice'],False,81.0,5.0,17
18.32863292160746,20.370370370370377,0.4278367418970942,1.033358054367576,3.236220472440945,0.2265016328594061,1.1935304139525302,20.560747663551403,30.0,0.2003686920864375,2.5196850393700787,104.49212598425196,0.2870702119324151,3.681102362204725,5.194805194805195,0.2511381567932489,1.1990305981703513,0.2576744337261711,1.114507058861436,3.5,18.89763779527559,"{'_type': 'table-file', 'ncols': 15, 'nrows': 254, 'sha256': 'e0c04467d2359d43b397870fe640549c0c78fefc48f92503fbb17b9380e86cab', 'artifact_path': 'wandb-client-artifact://13nk87zg14bvm32vs7fzlqxsm2oo2kau32p2hinvlspil3m5kv7bif2y4tnmoq6lh4dc7g5987zp3m39nw8lszy7keiiwdf9e139jq5nbbckeg9shbn7oy58te29fciv:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://13nk87zg14bvm32vs7fzlqxsm2oo2kau32p2hinvlspil3m5kv7bif2y4tnmoq6lh4dc7g5987zp3m39nw8lszy7keiiwdf9e139jq5nbbckeg9shbn7oy58te29fciv:latest/predictions.table.json', 'path': 'media/table/predictions_1_e0c04467d2359d43b397.table.json', 'size': 135372}",27.34839990511245,0.1779729242391599,1.382400022446341,False,True,validation,True,A | B | C | D | E,4,CTBase,091ba88e-d208-4a3a-ada7-d9698aeb5568,raw,MCQ,False,12,bigscience/T0_3B,0,True,choose_correct_variant,prompts/general_fixed_choice.yaml,MathQA,,5,,,GenFC,,False,['Math QA'],aqua_rat,False,False,GeneralFixedChoice,False,False,True,,False,prompts,,False,True,choose_correct_variant,,cross_task,aqua_rat,,,,False,,,False,,True,,,False,,CTBase.GenFC.math_qa.choose_correct_variant.LenNorm,AQuA,,,AQuA,aqua_rat,,,,,,,,2.062992125984252,1.4512988019482498,0.2505169876833504,0.2947809935554745,15.517241379310349,,aqua_rat,['generate_rational_and_correct_choice'],False,82.5,6.0,14
9.47863247863248,4.444444444444444,0.8304563045139803,3.6662775475209153,3.2401574803149606,0.529832702347086,0.861125416576451,0.0,0.0,0.6716946297743189,3.543307086614173,95.92125984251967,0.7746819886635607,1.0748031496062993,42.94871794871795,0.5230510798026258,0.3947427157575213,0.591927458417698,0.964366040465818,2.6692913385826773,26.77165354330709,"{'sha256': '872d34111292d77e552c4a0cfc30772e4dce448c574e480bf63d9bae90e9de0e', 'artifact_path': 'wandb-client-artifact://9ehdybud3ndmanfjfnph1ms6o86piaebl6hhnle7mk9ggfamumhkzvj2qat0m3ah3t6vshky70latenvv5yez4uqqgbygcdju22cmdhn7u6kmeej0wyw7n21k0vlmhfh:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://9ehdybud3ndmanfjfnph1ms6o86piaebl6hhnle7mk9ggfamumhkzvj2qat0m3ah3t6vshky70latenvv5yez4uqqgbygcdju22cmdhn7u6kmeej0wyw7n21k0vlmhfh:latest/predictions.table.json', 'path': 'media/table/predictions_1_872d34111292d77e552c.table.json', 'size': 135227, '_type': 'table-file', 'ncols': 15, 'nrows': 254}",24.46839719730172,0.611068946683713,0.9114832206921436,False,True,validation,False,A | B | C | D | E,4,CTBase,cd563834-49ee-495d-ac46-99f0264e58d5,raw,QA,False,12,bigscience/T0_3B,0,True,ask_question_as_teacher,prompts/general_fixed_choice.yaml,ZEST,,5,,,GenFC,,False,['Math QA'],aqua_rat,False,False,GeneralFixedChoice,False,False,False,,False,prompts,,False,True,ask_question_as_teacher,,cross_task,aqua_rat,,,,False,,,False,,True,,,False,,CTBase.GenFC.zest.ask_question_as_teacher.LenNorm,AQuA,,,AQuA,aqua_rat,,,,,,,,4.47244094488189,1.0025697034580792,0.8799268962106995,1.6968498492804098,0.0,,aqua_rat,['generate_rational_and_correct_choice'],False,29.5,55.0,24
8.328075709779178,0.0,0.7668853882817848,3.9468550710227546,3.145669291338583,0.4410019858505237,0.8997161324430266,0.0,0.0,0.5506049206876379,3.594488188976378,98.54330708661418,0.5781502535962683,1.047244094488189,41.640378548895896,0.4576655006784154,0.3517843764360421,0.4572002508363695,0.8626360694301952,2.8464566929133857,25.984251968503933,"{'size': 134461, '_type': 'table-file', 'ncols': 15, 'nrows': 254, 'sha256': 'b045ec03e72e9d1cbacf92ee3869cbcd51cda92b9b449256b1a6aa0fbe671658', 'artifact_path': 'wandb-client-artifact://ror5bgr8muw9ajv043jb2gj8tywdqvyseqd4n0l62khyb9wuo70i4js0zhiha0135vvp1c6bmezf607vmuhu71nlh89sfpr8a44axirodc02g4m73lyqu71u7kzoowu7:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://ror5bgr8muw9ajv043jb2gj8tywdqvyseqd4n0l62khyb9wuo70i4js0zhiha0135vvp1c6bmezf607vmuhu71nlh89sfpr8a44axirodc02g4m73lyqu71u7kzoowu7:latest/predictions.table.json', 'path': 'media/table/predictions_1_b045ec03e72e9d1cbacf.table.json'}",24.361695732941868,0.5299882761866641,1.02571711704115,False,True,validation,False,A | B | C | D | E,4,CTBase,7425232a-9880-428c-9ddc-4070e50e22cc,raw,QA,False,12,bigscience/T0_3B,0,True,gpt3_instruct_format,prompts/general_fixed_choice.yaml,ZEST,,5,,,GenFC,,False,['Math QA'],aqua_rat,False,False,GeneralFixedChoice,False,False,False,,False,prompts,,False,True,gpt3_instruct_format,,cross_task,aqua_rat,,,,False,,,False,,True,,,False,,CTBase.GenFC.zest.gpt3_instruct_format.LenNorm,AQuA,,,AQuA,aqua_rat,,,,,,,,4.366141732283465,1.0921134947539888,0.922584695418678,2.360434396060433,0.0,,aqua_rat,['generate_rational_and_correct_choice'],False,52.0,87.0,28
9.882830103650294,0.0,0.7694242794759194,3.8191747177304247,3.3661417322834644,0.4349745859496712,0.9156315726111424,0.0,0.0,0.6292522498003141,3.4133858267716537,102.08267716535433,0.5906380330483745,1.0551181102362204,42.27129337539432,0.4397755983307606,0.4125413196040862,0.4695733844276357,0.9720184615735338,2.9921259842519685,26.77165354330709,"{'ncols': 15, 'nrows': 254, 'sha256': '508131664c09dda9f59079100d2323558a449536fdf6ce2498de5052e3e6876b', 'artifact_path': 'wandb-client-artifact://kv89tnve21dyyqh5x0fxi83ib6jh6289tzczie6qd5dn41gz7mp68mtbbuk562v88vcaip9spe0k2r18o4etq9vo85bhusx794zfwsa4j2sfe00c0pxhf17stb5duyfp:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://kv89tnve21dyyqh5x0fxi83ib6jh6289tzczie6qd5dn41gz7mp68mtbbuk562v88vcaip9spe0k2r18o4etq9vo85bhusx794zfwsa4j2sfe00c0pxhf17stb5duyfp:latest/predictions.table.json', 'path': 'media/table/predictions_1_508131664c09dda9f590.table.json', 'size': 135346, '_type': 'table-file'}",24.43432977539885,0.604448022374314,1.0416418146538378,False,True,validation,False,A | B | C | D | E,4,CTBase,6f694e45-1d17-4067-a1f6-7dae89c148db,raw,QA,False,12,bigscience/T0_3B,0,True,ask_question_as_kid,prompts/general_fixed_choice.yaml,ZEST,,5,,,GenFC,,False,['Math QA'],aqua_rat,False,False,GeneralFixedChoice,False,False,False,,False,prompts,,False,True,ask_question_as_kid,,cross_task,aqua_rat,,,,False,,,False,,True,,,False,,CTBase.GenFC.zest.ask_question_as_kid.LenNorm,AQuA,,,AQuA,aqua_rat,,,,,,,,4.173228346456693,1.2237446609084717,0.8823235321320898,2.159508836550976,7.142857142857144,,aqua_rat,['generate_rational_and_correct_choice'],False,29.5,50.0,31
9.955217196596507,0.0,0.7924883255374856,4.276496825255747,3.2755905511811023,0.4423099251059529,0.969431730239814,0.0,0.0,0.6224110727235088,3.562992125984252,90.08267716535433,0.5476736421660175,1.047244094488189,42.63322884012539,0.4441295721399502,0.4038840504955011,0.4464723646073112,0.937545336494463,2.917322834645669,27.165354330708663,"{'nrows': 254, 'sha256': '744abd93b282839c4fabd5a973c06f520172d95f244397c69a49ff38a0df9d70', 'artifact_path': 'wandb-client-artifact://ft3r3megirokqtgzws59e8xi9r51cz6tqxeoi1ux3m4jav2276z74ufzmsrrlvg0az1vq4dpd0ue1jssbmjr3mkrs09i8m3n8yd5iu7aeptar6wyjam357rly180doqh:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://ft3r3megirokqtgzws59e8xi9r51cz6tqxeoi1ux3m4jav2276z74ufzmsrrlvg0az1vq4dpd0ue1jssbmjr3mkrs09i8m3n8yd5iu7aeptar6wyjam357rly180doqh:latest/predictions.table.json', 'path': 'media/table/predictions_1_744abd93b282839c4fab.table.json', 'size': 125336, '_type': 'table-file', 'ncols': 15}",24.43432977539885,0.5960049472553983,1.0242956596428576,False,True,validation,False,A | B | C | D | E,4,CTBase,2283cebf-988e-4bff-96bf-982a09963e49,raw,QA,False,12,bigscience/T0_3B,0,True,answerable_or_not,prompts/general_fixed_choice.yaml,ZEST,,5,,,GenFC,,False,['Math QA'],aqua_rat,False,False,GeneralFixedChoice,False,False,False,,False,prompts,,False,True,answerable_or_not,,cross_task,aqua_rat,,,,False,,,False,,True,,,False,,CTBase.GenFC.zest.answerable_or_not.LenNorm,AQuA,,,AQuA,aqua_rat,,,,,,,,4.196850393700787,1.1504149889971416,0.9465734630664872,2.6622825382262705,7.142857142857144,,aqua_rat,['generate_rational_and_correct_choice'],False,13.5,47.0,20
22.380987772292123,24.17582417582417,0.5630047056155493,1.200161384315941,2.720472440944882,0.2346811466187917,1.2409571225264635,26.66666666666666,7.4074074074074066,0.2135738697577649,3.716535433070866,143.49212598425197,0.4189145396074911,2.0118110236220472,36.26373626373626,0.2844643808725312,1.1854839985190109,0.3771246109114874,1.2040101325490573,2.2244094488188977,26.77165354330709,"{'_type': 'table-file', 'ncols': 15, 'nrows': 254, 'sha256': '5f5782444f4a93f01e2b60de8222e013c8a62252e7c58623ab8050be949d41d0', 'artifact_path': 'wandb-client-artifact://97z8c88xtfocunza7mffmvdzt6up7h0n0ocd1d1qrm4rqxy4q3ccqbg9yn4c38aw7yi8yz5a2s5bwy4r1ljm9xut3dnzo5mmjxi1gghtnlkdb4joykj5gadd0nu5d381:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://97z8c88xtfocunza7mffmvdzt6up7h0n0ocd1d1qrm4rqxy4q3ccqbg9yn4c38aw7yi8yz5a2s5bwy4r1ljm9xut3dnzo5mmjxi1gghtnlkdb4joykj5gadd0nu5d381:latest/predictions.table.json', 'path': 'media/table/predictions_1_5f5782444f4a93f01e2b.table.json', 'size': 173442}",27.34839990511245,0.2057259659665918,1.0751131622934504,False,True,validation,True,A | B | C | D | E,4,CTBase,a1dbb258-2e5c-4160-986b-46fc03546965,raw,MCQ,False,12,bigscience/T0_3B,0,True,best_deal,prompts/general_fixed_choice.yaml,Craigslist,,5,,,GenFC,,False,['Math QA'],aqua_rat,False,False,GeneralFixedChoice,False,False,True,,False,prompts,,False,True,best deal,,cross_task,aqua_rat,,,,False,,,False,,True,,,False,,CTBase.GenFC.craigslist_bargains.best_deal.LenNorm,AQuA,,,AQuA,aqua_rat,,,,,,,,4.326771653543307,0.7205584906231255,0.2639409693130263,0.2832085940781541,17.391304347826086,,aqua_rat,['generate_rational_and_correct_choice'],False,29.5,1.0,53
9.316239316239315,0.0,0.4733430325190019,1.3446698751975232,3.421259842519685,0.1870161128823153,1.0683809165627989,5.555555555555555,0.0,0.243587219808984,3.405511811023622,135.54330708661416,0.2472688138015626,1.0905511811023625,41.02564102564102,0.2151772806963582,0.497700708671377,0.2184232434164651,1.213799384831733,3.3307086614173227,25.984251968503933,"{'path': 'media/table/predictions_1_c631023dbcaf0c89ef90.table.json', 'size': 164579, '_type': 'table-file', 'ncols': 15, 'nrows': 254, 'sha256': 'c631023dbcaf0c89ef90fb100e6e498233aaff4eecd33539287af4c8ca9d705b', 'artifact_path': 'wandb-client-artifact://q0w95avj3wh9a572l6lgg70g9nc44gtabeny695gw3mrgfi9rm90oc9kte69fqxff6zhkus4eoezj1v4znfl3n6qo9zxiehxhib884iuulx5mvd23yi3by4giycx3odc:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://q0w95avj3wh9a572l6lgg70g9nc44gtabeny695gw3mrgfi9rm90oc9kte69fqxff6zhkus4eoezj1v4znfl3n6qo9zxiehxhib884iuulx5mvd23yi3by4giycx3odc:latest/predictions.table.json'}",24.361695732941865,0.2397959416549019,1.138503444167028,False,True,validation,False,A | B | C | D | E,4,CTBase,78d1b487-c535-4a0d-ae49-055d321db3fd,raw,CLASSIFICATION,False,12,bigscience/T0_3B,0,True,good_deal_for_seller,prompts/general_fixed_choice.yaml,Craigslist,,5,,,GenFC,,False,['Math QA'],aqua_rat,False,False,GeneralFixedChoice,False,False,True,,False,prompts,,False,True,good deal for seller,,cross_task,aqua_rat,,,,False,,,False,,True,,,False,,CTBase.GenFC.craigslist_bargains.good_deal_for_seller.LenNorm,AQuA,,,AQuA,aqua_rat,,,,,,,,3.751968503937008,1.0856508910675269,0.3504346922690628,0.6386365608906183,0.0,,aqua_rat,['generate_rational_and_correct_choice'],False,52.0,67.0,52
8.227848101265824,0.0,0.4885803062244364,1.4450699879428532,3.409448818897638,0.1981491991767576,1.1037112105785971,0.0,0.0,0.2566700554269505,3.4921259842519685,126.54330708661418,0.2754931036881574,1.0551181102362204,41.13924050632912,0.227699084544745,0.3828423868076605,0.2235586920908344,1.1529720979665194,3.220472440944882,25.590551181102363,"{'ncols': 15, 'nrows': 254, 'sha256': '4c2b45227415b13c12ab724866a645ea71ccc167622c102f93839202a7fe4fdf', 'artifact_path': 'wandb-client-artifact://h4aq67x8caqrtu2g1q7mexg4i7mflu00xiawfkrqw9ehxnbn1cvhzdga2fn7bg68tnuu4sy6l7z3vvqery64q1ove2gpaxw8hfl02fm1qk6uf2hp30s79scf27jvjuwe:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://h4aq67x8caqrtu2g1q7mexg4i7mflu00xiawfkrqw9ehxnbn1cvhzdga2fn7bg68tnuu4sy6l7z3vvqery64q1ove2gpaxw8hfl02fm1qk6uf2hp30s79scf27jvjuwe:latest/predictions.table.json', 'path': 'media/table/predictions_1_4c2b45227415b13c12ab.table.json', 'size': 157720, '_type': 'table-file'}",24.361695732941868,0.2394966837152822,1.1320044447210116,False,True,validation,False,A | B | C | D | E,4,CTBase,27010b55-dd5b-4ee9-9e14-a4b809aa6cdb,raw,CLASSIFICATION,False,12,bigscience/T0_3B,0,True,good_deal_for_seller_no_list_price,prompts/general_fixed_choice.yaml,Craigslist,,5,,,GenFC,,False,['Math QA'],aqua_rat,False,False,GeneralFixedChoice,False,False,True,,False,prompts,,False,True,good deal for seller no list price,,cross_task,aqua_rat,,,,False,,,False,,True,,,False,,CTBase.GenFC.craigslist_bargains.good_deal_for_seller_no_list_price.LenNorm,AQuA,,,AQuA,aqua_rat,,,,,,,,3.822834645669291,1.0518591696683666,0.3798592568533168,0.6852077442830004,0.0,,aqua_rat,['generate_rational_and_correct_choice'],False,59.5,90.0,43
8.280254777070065,0.0,0.7385486957631011,4.82709773318974,3.232283464566929,0.5104481188190024,0.7079283172221638,0.0,0.0,0.9726706902811848,3.688976377952756,111.54330708661418,1.006742736485999,1.0551181102362204,41.40127388535032,0.5830240756507934,0.3506369146175168,0.5850483088661389,0.5695069347043084,2.161417322834646,25.590551181102363,"{'size': 153773, '_type': 'table-file', 'ncols': 15, 'nrows': 254, 'sha256': '36843d46cae2b4fd3b00b65c84f1acd0750a4cf127a656ae4f15e80b1e668f2f', 'artifact_path': 'wandb-client-artifact://46m4ioftit10wte8kw3qa4cvrzpcrignze75z184v2rtvm6l4b95ypma7ug700m6ik45ectyx61eju92s70ukvksrgycutpl2gkeata6wux6nllqi2ku0gx7tagn15u7:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://46m4ioftit10wte8kw3qa4cvrzpcrignze75z184v2rtvm6l4b95ypma7ug700m6ik45ectyx61eju92s70ukvksrgycutpl2gkeata6wux6nllqi2ku0gx7tagn15u7:latest/predictions.table.json', 'path': 'media/table/predictions_1_36843d46cae2b4fd3b00.table.json'}",24.361695732941868,0.6404345967938982,0.6032364609242843,False,True,validation,False,A | B | C | D | E,4,CTBase,145dd841-b971-4550-bc88-305ad3278d58,raw,CLASSIFICATION,False,12,bigscience/T0_3B,0,True,good_deal_for_seller_no_list_price_implicit,prompts/general_fixed_choice.yaml,Craigslist,,5,,,GenFC,,False,['Math QA'],aqua_rat,False,False,GeneralFixedChoice,False,False,False,,False,prompts,,False,True,good deal for seller no list price implicit,,cross_task,aqua_rat,,,,False,,,False,,True,,,False,,CTBase.GenFC.craigslist_bargains.good_deal_for_seller_no_list_price_implicit.LenNorm,AQuA,,,AQuA,aqua_rat,,,,,,,,4.862204724409449,0.4532349400077422,0.8509029715848191,2.264660230771763,0.0,,aqua_rat,['generate_rational_and_correct_choice'],False,59.5,89.0,42
74.52229299363057,,0.8087819483953451,1.2007611449875126,,,,74.52229299363057,,,,121.5956678700361,1.2007611449875126,1.660649819494585,66.66666666666666,,0.4734887913101611,0.8087819483953451,0.4734887913101611,1.339350180505415,71.11913357400722,"{'sha256': '34981dedb6de76eb2f5c99d5d66de0730020108ca779a19024a7b32c6d132f69', 'artifact_path': 'wandb-client-artifact://k5wl28zoa4m9z3y0qov5i7r6i53eejvs3zufrm1m6z9awy8tulrn6z8qjlyfy0javx7pahae07ylvnxvs41md6o91vgdsc5oh2jn76dzoxvdaqenz452v5e5bfey2rb6:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://k5wl28zoa4m9z3y0qov5i7r6i53eejvs3zufrm1m6z9awy8tulrn6z8qjlyfy0javx7pahae07ylvnxvs41md6o91vgdsc5oh2jn76dzoxvdaqenz452v5e5bfey2rb6:latest/predictions.table.json', 'path': 'media/table/predictions_1_34981dedb6de76eb2f5c.table.json', 'size': 162256, '_type': 'table-file', 'ncols': 9, 'nrows': 277}",46.467282647943954,,,False,True,validation,False,Yes | No,4,CTBase,a64d5a15-68e2-4d1c-b30a-ca8250c860f9,rte,QA,False,28,bigscience/T0_3B,0,True,answer_the_following_q,prompts/general_fixed_choice.yaml,AdversarialQA,,2,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,NLI,rte,True,False,GeneralFixedChoice,False,False,False,,,prompts,,False,True,answer_the_following_q,,cross_task,two_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.adversarial_qa.answer_the_following_q.LenNorm,RTE,75.7070372595198,78.8716929833734,RecognizingTextualEntailment,super_glue,,,,,,,,,,,,,,,,,11.5,13.0,23
73.61963190184049,,1.0494028737220458,1.5465629625836863,,,,73.61963190184049,,,,114.5956678700361,1.5465629625836863,1.703971119133574,62.28070175438596,,0.4565038691614753,1.0494028737220458,0.4565038691614753,1.296028880866426,68.95306859205776,"{'_latest_artifact_path': 'wandb-client-artifact://ooaa01y1nag48uenv08vg3z4btyvjg3y5m26dmasig11bgyf488a8lsuxb06kljzt9swzah2eo8tz8eu5p9fff9tvvo8oayvhfpa7l7b3jauyeiqlny3luywlhamawot:latest/predictions.table.json', 'path': 'media/table/predictions_1_0f54389a7cafdb28889d.table.json', 'size': 150818, '_type': 'table-file', 'ncols': 9, 'nrows': 277, 'sha256': '0f54389a7cafdb28889d09e636928c80a23ad87e0963333dc6c8888bc8c76e79', 'artifact_path': 'wandb-client-artifact://ooaa01y1nag48uenv08vg3z4btyvjg3y5m26dmasig11bgyf488a8lsuxb06kljzt9swzah2eo8tz8eu5p9fff9tvvo8oayvhfpa7l7b3jauyeiqlny3luywlhamawot:latest/predictions.table.json'}",46.467282647943954,,,False,True,validation,False,Yes | No,4,CTBase,a0872cde-2f19-4ae6-919a-868da47bfbcb,rte,QA,False,28,bigscience/T0_3B,0,True,based_on,prompts/general_fixed_choice.yaml,AdversarialQA,,2,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,NLI,rte,True,False,GeneralFixedChoice,False,False,False,,,prompts,,False,True,based_on,,cross_task,two_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.adversarial_qa.based_on.LenNorm,RTE,76.16490976296426,79.63505176199936,RecognizingTextualEntailment,super_glue,,,,,,,,,,,,,,,,,19.0,19.0,16
72.72727272727272,,0.9587269330452702,1.4384000628433502,,,,72.72727272727272,,,,109.5956678700361,1.4384000628433502,1.7184115523465704,59.82142857142857,,0.449773713995784,0.9587269330452702,0.449773713995784,1.2815884476534296,67.50902527075813,"{'ncols': 9, 'nrows': 277, 'sha256': '2e7d2f309222debf52ef17c7afb0f778fff539034f9ed60088497bbe1f845388', 'artifact_path': 'wandb-client-artifact://tz0nunsmadtka7y21sn6k8gm7m02zktl1rdh6ai7w47wuycvp8843ugiq4zhcveb09ibtpwgtv0q31vnlfbgtds5d4ws6gg6lkfgr1y0jzedlcqv5wcr9twdrkdk6gz1:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://tz0nunsmadtka7y21sn6k8gm7m02zktl1rdh6ai7w47wuycvp8843ugiq4zhcveb09ibtpwgtv0q31vnlfbgtds5d4ws6gg6lkfgr1y0jzedlcqv5wcr9twdrkdk6gz1:latest/predictions.table.json', 'path': 'media/table/predictions_1_2e7d2f309222debf52ef.table.json', 'size': 137767, '_type': 'table-file'}",46.467282647943954,,,False,True,validation,False,Yes | No,4,CTBase,5bdb1815-5c6f-49a3-ad1d-367344420701,rte,QA,False,28,bigscience/T0_3B,0,True,question_context_answer,prompts/general_fixed_choice.yaml,AdversarialQA,,2,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,NLI,rte,True,False,GeneralFixedChoice,False,False,False,,,prompts,,False,True,question_context_answer,,cross_task,two_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.adversarial_qa.question_context_answer.LenNorm,RTE,75.74480428828339,78.8716929833734,RecognizingTextualEntailment,super_glue,,,,,,,,,,,,,,,,,26.5,24.5,11
73.17073170731707,,0.9473144046559928,1.4371392692469518,,,,73.17073170731707,,,,121.5956678700361,1.4371392692469518,1.711191335740072,61.06194690265486,,0.4532088036527137,0.9473144046559928,0.4532088036527137,1.288808664259928,68.23104693140795,"{'_latest_artifact_path': 'wandb-client-artifact://70t9bgyp3t9t3wnpo1ctu0k104v3xrp79s9cjoxaox5v1liojnp25abj7weuo9p57e1lk7apw2ay8c1y4md83kplfb5vemyfp4192aa2f3a9tvsxa0v4dl1g9yhv2ucr:latest/predictions.table.json', 'path': 'media/table/predictions_1_43d7d56dd335ec283eaf.table.json', 'size': 150817, '_type': 'table-file', 'ncols': 9, 'nrows': 277, 'sha256': '43d7d56dd335ec283eaf9b33adf2e4b0488b2036fa7ab0d457aac10af72f73cb', 'artifact_path': 'wandb-client-artifact://70t9bgyp3t9t3wnpo1ctu0k104v3xrp79s9cjoxaox5v1liojnp25abj7weuo9p57e1lk7apw2ay8c1y4md83kplfb5vemyfp4192aa2f3a9tvsxa0v4dl1g9yhv2ucr:latest/predictions.table.json'}",46.467282647943954,,,False,True,validation,False,Yes | No,4,CTBase,3b2459cc-6600-443c-abf8-8f60c34cd998,rte,QA,False,28,bigscience/T0_3B,0,True,tell_what_it_is,prompts/general_fixed_choice.yaml,AdversarialQA,,2,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,NLI,rte,True,False,GeneralFixedChoice,False,False,False,,,prompts,,False,True,tell_what_it_is,,cross_task,two_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.adversarial_qa.tell_what_it_is.LenNorm,RTE,74.25329999950809,77.97762208511972,RecognizingTextualEntailment,super_glue,,,,,,,,,,,,,,,,,23.0,22.0,22
70.55393586005832,,0.9517108452620044,1.3876849322542817,,,,70.55393586005832,,,,101.5956678700361,1.3876849322542817,1.7653429602888089,52.13270142180095,,0.4237842769914567,0.9517108452620044,0.4237842769914567,1.2346570397111911,63.53790613718411,"{'path': 'media/table/predictions_1_7c00a1976776a9ef5c80.table.json', 'size': 129871, '_type': 'table-file', 'ncols': 9, 'nrows': 277, 'sha256': '7c00a1976776a9ef5c80eaacfb81b68f822d4ab9f64a68431f6a74c2e6010590', 'artifact_path': 'wandb-client-artifact://fnj95klzmx62a8z3ox28af6r6gbjjaceiq7er5o8bmopmtmfrpn0em2wrnjld49andxkz5f8elvy132rl2flu3izz9y2qd0ix86p8st1pk6u5b2q1wjqwni42j3vtxk8:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://fnj95klzmx62a8z3ox28af6r6gbjjaceiq7er5o8bmopmtmfrpn0em2wrnjld49andxkz5f8elvy132rl2flu3izz9y2qd0ix86p8st1pk6u5b2q1wjqwni42j3vtxk8:latest/predictions.table.json'}",46.467282647943954,,,False,True,validation,False,Yes | No,4,CTBase,4dd990b3-7201-4cba-bb9a-baa462d68b1a,rte,SENTIMENT,False,28,bigscience/T0_3B,0,True,format_score,prompts/general_fixed_choice.yaml,Yelp,,2,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,NLI,rte,True,False,GeneralFixedChoice,False,False,False,,,prompts,,False,True,format_score,,cross_task,two_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.yelp.format_score.LenNorm,RTE,68.13068494655228,73.85757607445362,RecognizingTextualEntailment,super_glue,,,,,,,,,,,,,,,,,41.0,40.0,12
69.83240223463687,,0.977218144857962,1.5097686004982958,,,,69.83240223463687,,,,95.5956678700361,1.5097686004982958,1.8194945848375448,44.89795918367347,,0.3846078655715256,0.977218144857962,0.3846078655715256,1.1805054151624548,61.01083032490975,"{'path': 'media/table/predictions_1_f97d633107867426d4fb.table.json', 'size': 122843, '_type': 'table-file', 'ncols': 9, 'nrows': 277, 'sha256': 'f97d633107867426d4fbc5d507b9c90e5d7292935c8b3c964f162563b85aa331', 'artifact_path': 'wandb-client-artifact://109ci4fo62xj81570hji7mj7w56hbqx4ofoc4binq0l6sn8jert12t1kbyqqkni92zl5d8lsqlj05advluhu23jd0kli107n5nxx8syuudb27v5juykn1frjnp0vx4gi:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://109ci4fo62xj81570hji7mj7w56hbqx4ofoc4binq0l6sn8jert12t1kbyqqkni92zl5d8lsqlj05advluhu23jd0kli107n5nxx8syuudb27v5juykn1frjnp0vx4gi:latest/predictions.table.json'}",46.467282647943954,,,False,True,validation,False,Yes | No,4,CTBase,29fc6386-90b3-4976-b249-26e49fe7c924,rte,SENTIMENT,False,28,bigscience/T0_3B,0,True,format_star,prompts/general_fixed_choice.yaml,Yelp,,2,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,NLI,rte,True,False,GeneralFixedChoice,False,False,False,,,prompts,,False,True,format_star,,cross_task,two_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.yelp.format_star.LenNorm,RTE,67.55563691262182,72.84847851092754,RecognizingTextualEntailment,super_glue,,,,,,,,,,,,,,,,,47.5,45.5,6
67.93478260869566,,0.944271931072562,1.475146482997853,,,,67.93478260869566,,,,99.5956678700361,1.475146482997853,1.855595667870036,36.55913978494624,,0.3514992474985728,0.944271931072562,0.3514992474985728,1.144404332129964,57.400722021660656,"{'sha256': 'fbe68d0a400f44896b8c948525cf45b2c475fd6986879bedf54b21fcfc83e999', 'artifact_path': 'wandb-client-artifact://txqei8rmif3apf1534dhhjax20mxhy20et3mwbjsj9ws1a5c5j17x6n1zgj8nzhukvuys0g9n47q4fwna3smi5rlv0g3cpuikilwd4cn80l2mephivrq18sslmo44r6c:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://txqei8rmif3apf1534dhhjax20mxhy20et3mwbjsj9ws1a5c5j17x6n1zgj8nzhukvuys0g9n47q4fwna3smi5rlv0g3cpuikilwd4cn80l2mephivrq18sslmo44r6c:latest/predictions.table.json', 'path': 'media/table/predictions_1_fbe68d0a400f44896b8c.table.json', 'size': 126486, '_type': 'table-file', 'ncols': 9, 'nrows': 277}",46.467282647943954,,,False,True,validation,False,Yes | No,4,CTBase,27b6bc81-bb1c-467b-91c0-22a4d6a19f44,rte,SENTIMENT,False,28,bigscience/T0_3B,0,True,based_on_that,prompts/general_fixed_choice.yaml,Yelp,,2,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,NLI,rte,True,False,GeneralFixedChoice,False,False,False,,,prompts,,False,True,based_on_that,,cross_task,two_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.yelp.based_on_that.LenNorm,RTE,69.22829745795526,74.3490536442539,RecognizingTextualEntailment,super_glue,,,,,,,,,,,,,,,,,62.5,64.0,10
72.12121212121212,,0.9001349437390501,1.2807978068878505,,,,72.12121212121212,,,,96.5956678700361,1.2807978068878505,1.7184115523465704,58.92857142857143,,0.449773713995784,0.9001349437390501,0.449773713995784,1.2815884476534296,66.78700361010831,"{'_latest_artifact_path': 'wandb-client-artifact://ey8rl4bj67ntxqg72v6b1te0v0j3b4sru7qs3jjdtanoitex1k5nke881g3sbfwtzimnclauzdis452oxdg7rmlg63nehx9mpdfhrparzx7ulf292iih2ki5ksm1nxm1:latest/predictions.table.json', 'path': 'media/table/predictions_1_1f8515fc820a0cc759d3.table.json', 'size': 124805, '_type': 'table-file', 'ncols': 9, 'nrows': 277, 'sha256': '1f8515fc820a0cc759d3908e53fa26a7567fe3a3bed4ed08a646cfad96d476ae', 'artifact_path': 'wandb-client-artifact://ey8rl4bj67ntxqg72v6b1te0v0j3b4sru7qs3jjdtanoitex1k5nke881g3sbfwtzimnclauzdis452oxdg7rmlg63nehx9mpdfhrparzx7ulf292iih2ki5ksm1nxm1:latest/predictions.table.json'}",46.467282647943954,,,False,True,validation,False,Yes | No,4,CTBase,135fcd11-9fcc-4b55-bf1b-9b76290d0f6b,rte,SENTIMENT,False,28,bigscience/T0_3B,0,True,so_i_would,prompts/general_fixed_choice.yaml,Yelp,,2,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,NLI,rte,True,False,GeneralFixedChoice,False,False,False,,,prompts,,False,True,so_i_would,,cross_task,two_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.yelp.so_i_would.LenNorm,RTE,70.03472420306107,75.0287566663181,RecognizingTextualEntailment,super_glue,,,,,,,,,,,,,,,,,29.5,33.0,7
71.42857142857143,,0.5756079845289791,0.8157931802935549,,,,71.42857142857143,,,,112.5956678700361,0.8157931802935549,1.740072202166065,55.96330275229357,,0.4385947306422366,0.5756079845289791,0.4385947306422366,1.259927797833935,65.34296028880865,"{'_type': 'table-file', 'ncols': 9, 'nrows': 277, 'sha256': '400ddffb288ae0fee760c59b241ebaf03f0ce7508d78030be8846fdd13c4ddff', 'artifact_path': 'wandb-client-artifact://oqp0lipyi2xlfkelht5zujf9p01j2k372lv1eekwiwr1ekgxt330zq85aoh6euiy4twl7j9thlg1p1sijb7gyuohtcqliqdrap726d7fgzrbx964d7jzgrs8wd8rz4dr:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://oqp0lipyi2xlfkelht5zujf9p01j2k372lv1eekwiwr1ekgxt330zq85aoh6euiy4twl7j9thlg1p1sijb7gyuohtcqliqdrap726d7fgzrbx964d7jzgrs8wd8rz4dr:latest/predictions.table.json', 'path': 'media/table/predictions_1_400ddffb288ae0fee760.table.json', 'size': 140535}",46.467282647943954,,,False,True,validation,False,Yes | No,4,CTBase,2da8f134-58db-4f9d-b3b0-8c6b50693ab5,rte,SENTIMENT,False,28,bigscience/T0_3B,0,True,categorize_rating_using_review,prompts/general_fixed_choice.yaml,AppReviews,,2,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,NLI,rte,True,False,GeneralFixedChoice,False,False,True,,,prompts,,False,True,categorize_rating_using_review,,cross_task,two_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.app_reviews.categorize_rating_using_review.LenNorm,RTE,71.71704652972495,77.30314754784064,RecognizingTextualEntailment,super_glue,,,,,,,,,,,,,,,,,37.5,38.0,18
68.46361185983827,,0.928944513188344,1.4157870650721802,,,,68.46361185983827,,,,116.5956678700361,1.4157870650721802,1.8664259927797835,36.0655737704918,,0.3401940502350828,0.928944513188344,0.3401940502350828,1.1335740072202165,57.76173285198555,"{'ncols': 9, 'nrows': 277, 'sha256': '976a38f8bd5b64351fd10d8712ae81445c4d2260129f7b17fa6871a2c2dc9102', 'artifact_path': 'wandb-client-artifact://1475q9h3u9m6xbhfjanq9k02pcwefft2he6ry5xqb02rz0z0rnz0qv5866g98p78e8chmyrhjqfjvxu08nief39fdxrj9kf8a74w8l3exkehnv3b2k4vsrufa2zqhnqi:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://1475q9h3u9m6xbhfjanq9k02pcwefft2he6ry5xqb02rz0z0rnz0qv5866g98p78e8chmyrhjqfjvxu08nief39fdxrj9kf8a74w8l3exkehnv3b2k4vsrufa2zqhnqi:latest/predictions.table.json', 'path': 'media/table/predictions_1_976a38f8bd5b64351fd1.table.json', 'size': 148987, '_type': 'table-file'}",46.467282647943954,,,False,True,validation,False,Yes | No,4,CTBase,d34e1413-2699-4701-baa2-05d931d012ba,rte,SENTIMENT,False,28,bigscience/T0_3B,0,True,convert_to_rating,prompts/general_fixed_choice.yaml,AppReviews,,2,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,NLI,rte,True,False,GeneralFixedChoice,False,False,False,,,prompts,,False,True,convert_to_rating,,cross_task,two_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.app_reviews.convert_to_rating.LenNorm,RTE,69.43437659971838,75.14378333159051,RecognizingTextualEntailment,super_glue,,,,,,,,,,,,,,,,,60.0,58.0,28
67.70833333333334,,0.6492547652465077,1.1026697227670827,,,,67.70833333333334,,,,99.5956678700361,1.1026697227670827,1.913357400722021,27.058823529411764,,0.281310609946255,0.6492547652465077,0.281310609946255,1.0866425992779782,55.23465703971119,"{'_latest_artifact_path': 'wandb-client-artifact://y9n8gj101syfzhlymugh0erklm0aokylkfskezczm54pe1mtiiems05upqm732141ktl926p61pjco0ip7oh9iu9qltfi1fyquw5yv87dcvg3rvmun8zfog3d2pckmh2:latest/predictions.table.json', 'path': 'media/table/predictions_1_a6525d2a25fd9481ac1f.table.json', 'size': 132562, '_type': 'table-file', 'ncols': 9, 'nrows': 277, 'sha256': 'a6525d2a25fd9481ac1f69e1ee8430014e675fe8f74121087251b4cb47906462', 'artifact_path': 'wandb-client-artifact://y9n8gj101syfzhlymugh0erklm0aokylkfskezczm54pe1mtiiems05upqm732141ktl926p61pjco0ip7oh9iu9qltfi1fyquw5yv87dcvg3rvmun8zfog3d2pckmh2:latest/predictions.table.json'}",46.467282647943954,,,False,True,validation,False,Yes | No,4,CTBase,96538f30-f2c1-430e-8fc6-936a16966d9c,rte,SENTIMENT,False,28,bigscience/T0_3B,0,True,Writer_Expressed_Sentiment,prompts/general_fixed_choice.yaml,IMDB,,2,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,NLI,rte,True,False,GeneralFixedChoice,False,False,False,,,prompts,,False,True,Writer Expressed Sentiment,,cross_task,two_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.imdb.Writer_Expressed_Sentiment.LenNorm,RTE,70.81935784226249,76.53456028442957,RecognizingTextualEntailment,super_glue,,,,,,,,,,,,,,,,,72.5,68.5,10
64.85148514851485,,0.9790779330897408,2.201143695128954,,,,64.85148514851485,,,,98.5956678700361,2.201143695128954,1.985559566787004,5.333333333333332,,0.1192975569809264,0.9790779330897408,0.1192975569809264,1.0144404332129964,48.73646209386281,"{'ncols': 9, 'nrows': 277, 'sha256': 'd1cdb507596b6edb0bb567d6b26ee410d9475893b2c330b86a0783172d26c500', 'artifact_path': 'wandb-client-artifact://19us2xqjhaihfn4bzbhd4s764dei82zpwxwpfjzv02o3fcay74xzw5r8djbf9qzbno7geffeyzt7x03uyv4lfoq5o7ohwrvhe9sqmfmrxi3gro32gs86gzwj38y4gqcv:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://19us2xqjhaihfn4bzbhd4s764dei82zpwxwpfjzv02o3fcay74xzw5r8djbf9qzbno7geffeyzt7x03uyv4lfoq5o7ohwrvhe9sqmfmrxi3gro32gs86gzwj38y4gqcv:latest/predictions.table.json', 'path': 'media/table/predictions_1_d1cdb507596b6edb0bb5.table.json', 'size': 129304, '_type': 'table-file'}",46.467282647943954,,,False,True,validation,False,Yes | No,4,CTBase,866474a5-1498-46b7-bfee-ac0c5160707f,rte,SENTIMENT,False,28,bigscience/T0_3B,0,True,Reviewer_Sentiment_Feeling,prompts/general_fixed_choice.yaml,IMDB,,2,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,NLI,rte,True,False,GeneralFixedChoice,False,False,False,,,prompts,,False,True,Reviewer Sentiment Feeling,,cross_task,two_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.imdb.Reviewer_Sentiment_Feeling.LenNorm,RTE,65.25675055346136,73.109902750183,RecognizingTextualEntailment,super_glue,,,,,,,,,,,,,,,,,89.0,85.0,9
74.25149700598803,,0.7763111831131527,1.1509075061508895,,,,74.25149700598803,,,,101.5956678700361,1.1509075061508895,1.7328519855595668,60.909090909090914,,0.4424702846756687,0.7763111831131527,0.4424702846756687,1.2671480144404332,68.95306859205776,"{'size': 127250, '_type': 'table-file', 'ncols': 9, 'nrows': 277, 'sha256': '251d66b049a4f4c8c5cb80b8e2042467d9b0a0f0669c949732d2d88c53f6f67a', 'artifact_path': 'wandb-client-artifact://zxg0idx0lpfra9p4jkpjcb6x1qirmlz5rojmly5aly6fkt4u1nqr3iv10si3qxwtm8gsd8hoeqsefb3wpx3sguer4enmjyf6o0z9rgtot7dzoto9p0pyxge0v00fdeh3:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://zxg0idx0lpfra9p4jkpjcb6x1qirmlz5rojmly5aly6fkt4u1nqr3iv10si3qxwtm8gsd8hoeqsefb3wpx3sguer4enmjyf6o0z9rgtot7dzoto9p0pyxge0v00fdeh3:latest/predictions.table.json', 'path': 'media/table/predictions_1_251d66b049a4f4c8c5cb.table.json'}",46.467282647943954,,,False,True,validation,False,Yes | No,4,CTBase,5f372fb1-795a-47b6-8ddf-c4fd1579e76a,rte,SENTIMENT,False,28,bigscience/T0_3B,0,True,Sentiment_with_choices,prompts/general_fixed_choice.yaml,IMDB,,2,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,NLI,rte,True,False,GeneralFixedChoice,False,False,True,,,prompts,,False,True,Sentiment with choices ,,cross_task,two_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.imdb.Sentiment_with_choices.LenNorm,RTE,78.17159987295105,82.16563839799227,RecognizingTextualEntailment,super_glue,,,,,,,,,,,,,,,,,19.0,15.0,6
66.66666666666666,,0.9297644254205328,1.6950441870018034,,,,66.66666666666666,,,,104.5956678700361,1.6950441870018034,1.935018050541516,20.73170731707317,,0.2464940074384341,0.9297644254205328,0.2464940074384341,1.0649819494584838,53.06859205776173,"{'artifact_path': 'wandb-client-artifact://160k0zr248q05b2df05i659lldj2nzdbi4jli1a1tbrbwri77426wd3ug3vvcbx0hk442oqeopu7kg6kobxnk6mvdglrfuu14iwjfxqi96ld2c3xcbse5r4iyq5d048t:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://160k0zr248q05b2df05i659lldj2nzdbi4jli1a1tbrbwri77426wd3ug3vvcbx0hk442oqeopu7kg6kobxnk6mvdglrfuu14iwjfxqi96ld2c3xcbse5r4iyq5d048t:latest/predictions.table.json', 'path': 'media/table/predictions_1_133eaaf8da6790377abf.table.json', 'size': 131659, '_type': 'table-file', 'ncols': 9, 'nrows': 277, 'sha256': '133eaaf8da6790377abf36b4e5d758b2a5a37066d43d025706650720991f7958'}",46.467282647943954,,,False,True,validation,False,Yes | No,4,CTBase,2351d12a-e630-4d19-8b41-e199266e38f7,rte,SENTIMENT,False,28,bigscience/T0_3B,0,True,Reviewer_Opinion_bad_good_choices,prompts/general_fixed_choice.yaml,IMDB,,2,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,NLI,rte,True,False,GeneralFixedChoice,False,False,True,,,prompts,,False,True,Reviewer Opinion bad good choices,,cross_task,two_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.imdb.Reviewer_Opinion_bad_good_choices.LenNorm,RTE,74.44009529036737,79.04946146606713,RecognizingTextualEntailment,super_glue,,,,,,,,,,,,,,,,,78.5,74.0,9
73.41040462427746,,0.736368527236247,1.1271633843652609,,,,73.41040462427746,,,,99.5956678700361,1.1271633843652609,1.776173285198556,55.76923076923077,,0.4168072894547756,0.736368527236247,0.4168072894547756,1.223826714801444,66.78700361010831,"{'_type': 'table-file', 'ncols': 9, 'nrows': 277, 'sha256': '8d59c2ef4eb23565850502184b25fedc870fe7f66aa02b4dbe98439a983e8035', 'artifact_path': 'wandb-client-artifact://es6ns8uhsghw2u0gumuw7phnqdft26yddweneho9t9gn5e351dvkeutln1c5clriujwgd86pzxbb2y2ssoe1nug2w5083gusexqd3sb9hv6ujb0l42lr9ag4fllz3ub1:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://es6ns8uhsghw2u0gumuw7phnqdft26yddweneho9t9gn5e351dvkeutln1c5clriujwgd86pzxbb2y2ssoe1nug2w5083gusexqd3sb9hv6ujb0l42lr9ag4fllz3ub1:latest/predictions.table.json', 'path': 'media/table/predictions_1_8d59c2ef4eb235658505.table.json', 'size': 132335}",46.467282647943954,,,False,True,validation,False,Yes | No,4,CTBase,02ff2949-0f45-4d97-941e-6fa4c0afbc2d,rte,SENTIMENT,False,28,bigscience/T0_3B,0,True,Movie_Expressed_Sentiment_2,prompts/general_fixed_choice.yaml,IMDB,,2,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,NLI,rte,True,False,GeneralFixedChoice,False,False,False,,,prompts,,False,True,Movie Expressed Sentiment 2,,cross_task,two_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.imdb.Movie_Expressed_Sentiment_2.LenNorm,RTE,73.45065832372295,78.28087420265607,RecognizingTextualEntailment,super_glue,,,,,,,,,,,,,,,,,29.5,20.0,10
72.36467236467237,,0.9379989125302168,1.3728195312651486,,,,72.36467236467237,,,,87.03971119133574,1.3728195312651486,1.7942238267148014,52.2167487684729,,0.4042676586041709,0.9379989125302168,0.4042676586041709,1.2057761732851986,64.98194945848375,"{'nrows': 277, 'sha256': '63240202bad1ab248a53473e24fcbc354cd1456c99e095b5f7a4e92b39a9859c', 'artifact_path': 'wandb-client-artifact://1nn7920svwagxe66grekuf5o8rlh01awug51j35sy82ybbkyw8120ujg510j76s7pvyzbxmw2s3vmib2c9oms9wf6q5k3rzt7b8eyf7uuqd8hv24v35niz2i9h6w94vx:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://1nn7920svwagxe66grekuf5o8rlh01awug51j35sy82ybbkyw8120ujg510j76s7pvyzbxmw2s3vmib2c9oms9wf6q5k3rzt7b8eyf7uuqd8hv24v35niz2i9h6w94vx:latest/predictions.table.json', 'path': 'media/table/predictions_1_63240202bad1ab248a53.table.json', 'size': 121967, '_type': 'table-file', 'ncols': 9}",46.50913357668334,,,False,True,validation,False,Yes | No,4,CTBase,f56ffced-9b16-431a-8a17-501e63cddf73,rte,ENTAILMENT,False,28,bigscience/T0_3B,0,True,imply_separated,prompts/general_fixed_choice.yaml,RTE,,2,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",True,NLI,rte,False,False,GeneralFixedChoice,False,False,True,,,prompts,,False,True,imply separated,,cross_task,two_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.super_glue_rte.imply_separated.LenNorm,RTE,80.46181957507478,82.7512286939245,RecognizingTextualEntailment,super_glue,,,,,,,,,,,,,,,,,39.0,30.0,6
70.52341597796142,,0.977531317057502,1.4246228533100995,,,,70.52341597796142,,,,92.71480144404332,1.4246228533100995,1.8375451263537903,43.97905759162304,,0.3688675747132073,0.977531317057502,0.3688675747132073,1.1624548736462097,61.371841155234655,"{'_type': 'table-file', 'ncols': 9, 'nrows': 277, 'sha256': '758686986f343ce44ae43ed539df62adea2ed9b45470b410cb803db0ee8f1c4a', 'artifact_path': 'wandb-client-artifact://tbwc3dxnid1s1graub9fgrwz9t4ubb2fe4mc6emqrwtp5y2zgn985yakk1rgrwa3e5ko82hh1zh3i5o32f4ywsvf5le4ks5db1ti28ddwuspc3fwxdauejf888z1pfyp:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://tbwc3dxnid1s1graub9fgrwz9t4ubb2fe4mc6emqrwtp5y2zgn985yakk1rgrwa3e5ko82hh1zh3i5o32f4ywsvf5le4ks5db1ti28ddwuspc3fwxdauejf888z1pfyp:latest/predictions.table.json', 'path': 'media/table/predictions_1_758686986f343ce44ae4.table.json', 'size': 126692}",46.52061649695331,,,False,True,validation,False,Yes | No,4,CTBase,c8dfc879-40f2-412d-be1e-4cd70107f6e6,rte,ENTAILMENT,False,28,bigscience/T0_3B,0,True,imply,prompts/general_fixed_choice.yaml,RTE,,2,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",True,NLI,rte,False,False,GeneralFixedChoice,False,False,True,,,prompts,,False,True,imply,,cross_task,two_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.super_glue_rte.imply.LenNorm,RTE,81.54889020119668,84.13154867719335,RecognizingTextualEntailment,super_glue,,,,,,,,,,,,,,,,,44.5,41.5,14
69.56521739130434,,0.8332001999801127,1.3823795077602783,,,,69.56521739130434,,,,120.03971119133574,1.3823795077602783,1.855595667870036,39.784946236559136,,0.3514992474985728,0.8332001999801127,0.3514992474985728,1.144404332129964,59.56678700361011,"{'artifact_path': 'wandb-client-artifact://mvhd4jukcd2s1z3j1qiwsdrmpnt7d64z6yd1vxgw4xjh27kg2gzt8jeiuupuauyppg86fno3txgkhfbqr2cqxodryq7nuskuv9bhd0xwo9kb0hvx0fk6k6gzogvkg92e:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://mvhd4jukcd2s1z3j1qiwsdrmpnt7d64z6yd1vxgw4xjh27kg2gzt8jeiuupuauyppg86fno3txgkhfbqr2cqxodryq7nuskuv9bhd0xwo9kb0hvx0fk6k6gzogvkg92e:latest/predictions.table.json', 'path': 'media/table/predictions_1_0f6ef6c1b001fca4172e.table.json', 'size': 170167, '_type': 'table-file', 'ncols': 9, 'nrows': 277, 'sha256': '0f6ef6c1b001fca4172ee29fe1570d5693ca25d79d3afdb1d84131c684f2d3d5'}",46.50913357668334,,,False,True,validation,False,Yes | No,4,CTBase,9e2b4267-ec23-44c8-b82a-107e2c890fec,rte,ENTAILMENT,False,28,bigscience/T0_3B,0,True,entailment_explained,prompts/general_fixed_choice.yaml,RTE,,2,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",True,NLI,rte,False,False,GeneralFixedChoice,False,False,True,,,prompts,,False,True,entailment explained,,cross_task,two_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.super_glue_rte.entailment_explained.LenNorm,RTE,74.72369002240215,78.0194499634006,RecognizingTextualEntailment,super_glue,,,,,,,,,,,,,,,,,51.0,47.0,40
68.60158311345647,,0.9163981175172304,1.5894213910567632,,,,68.60158311345647,,,,96.71480144404332,1.5894213910567632,1.895306859205776,32.0,,0.3061576180088692,0.9163981175172304,0.3061576180088692,1.1046931407942238,57.03971119133574,"{'ncols': 9, 'nrows': 277, 'sha256': 'a7c34ad3ec4cd316dbc4e81b1ef968af35bd717fa3e781ea7a6f29b9b39c6055', 'artifact_path': 'wandb-client-artifact://196kaidvrvxnuwloozxc8rizv8ilbb4pv0emlud3a4mi9tl6ko2tit3euif4knt9uh4ctjuhilrw1l4c9507f3vnrcers8m195zdvn9r4attk2gmpudk66tne87v4sdt:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://196kaidvrvxnuwloozxc8rizv8ilbb4pv0emlud3a4mi9tl6ko2tit3euif4knt9uh4ctjuhilrw1l4c9507f3vnrcers8m195zdvn9r4attk2gmpudk66tne87v4sdt:latest/predictions.table.json', 'path': 'media/table/predictions_1_a7c34ad3ec4cd316dbc4.table.json', 'size': 133601, '_type': 'table-file'}",46.52061649695331,,,False,True,validation,False,Yes | No,4,CTBase,4ee6ff27-de63-4e7b-a9d4-82a17eba407a,rte,ENTAILMENT,False,28,bigscience/T0_3B,0,True,does_the_claim_follow_the_fact,prompts/general_fixed_choice.yaml,RTE,,2,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",True,NLI,rte,False,False,GeneralFixedChoice,False,False,True,,,prompts,,False,True,does the claim follow the fact,,cross_task,two_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.super_glue_rte.does_the_claim_follow_the_fact.LenNorm,RTE,75.69578216039609,78.17630450695388,RecognizingTextualEntailment,super_glue,,,,,,,,,,,,,,,,,66.0,56.0,18
72.62247838616716,,0.8824267404888134,1.3094770882534206,,,,72.62247838616716,,,,89.93862815884476,1.3094770882534206,1.779783393501805,54.10628019323672,,0.4143926311128301,0.8824267404888134,0.4143926311128301,1.220216606498195,65.70397111913357,"{'nrows': 277, 'sha256': '375ccaee4bc2e152c7e7ce12f231a77caec891a6cda430e7331495fa69db0e44', 'artifact_path': 'wandb-client-artifact://uk5gh5v27vohs67cy3fv24ghfhip1efh1r4yxhq516cjl3dkip7a1j2ur39uemrnmsno8gn0dqtaiu3x47zddu20kb052g389cl431koba1sbw3rk3xmlmyo7wgiyin2:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://uk5gh5v27vohs67cy3fv24ghfhip1efh1r4yxhq516cjl3dkip7a1j2ur39uemrnmsno8gn0dqtaiu3x47zddu20kb052g389cl431koba1sbw3rk3xmlmyo7wgiyin2:latest/predictions.table.json', 'path': 'media/table/predictions_1_375ccaee4bc2e152c7e7.table.json', 'size': 122796, '_type': 'table-file', 'ncols': 9}",46.47129297794757,,,False,True,validation,False,Yes | No,4,CTBase,03a7ae07-5ddd-46c4-92f3-2152223d44ec,rte,ENTAILMENT,False,28,bigscience/T0_3B,0,True,mean,prompts/general_fixed_choice.yaml,RTE,,2,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",True,NLI,rte,False,False,GeneralFixedChoice,False,False,True,,,prompts,,False,True,mean,,cross_task,two_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.super_glue_rte.mean.LenNorm,RTE,80.17073961620599,82.57346021123078,RecognizingTextualEntailment,super_glue,,,,,,,,,,,,,,,,,34.5,26.0,9
73.21428571428571,,1.1485561910797015,1.7134547620904144,,,,73.21428571428571,,,,98.5956678700361,1.7134547620904144,1.740072202166065,58.71559633027523,,0.4385947306422366,1.1485561910797015,0.4385947306422366,1.259927797833935,67.50902527075813,"{'size': 128360, '_type': 'table-file', 'ncols': 9, 'nrows': 277, 'sha256': '3bd91ba79c54f69d570e8af9baa495fa03188cfe9d5bf4b6fb1858da55a34cd2', 'artifact_path': 'wandb-client-artifact://g7643uo2po08zi8t18v1d5obf790muntb9djt5hu0zz5b2px2rj0w94n0sr8z1zsiw9o93109zih48zhwv25n4fsari3htysn8jjgd5w2u36otztryrgrl47nlhm83si:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://g7643uo2po08zi8t18v1d5obf790muntb9djt5hu0zz5b2px2rj0w94n0sr8z1zsiw9o93109zih48zhwv25n4fsari3htysn8jjgd5w2u36otztryrgrl47nlhm83si:latest/predictions.table.json', 'path': 'media/table/predictions_1_3bd91ba79c54f69d570e.table.json'}",46.467282647943954,,,False,True,validation,False,Yes | No,4,CTBase,f2004e15-9d9a-4ca1-9830-a341e684e97e,rte,QA,False,28,bigscience/T0_3B,0,True,qa_no_choices_and_answer,prompts/general_fixed_choice.yaml,No Prompt,,2,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,NLI,rte,False,False,GeneralFixedChoice,False,False,False,,,prompts,,False,True,qa no choices and answer,,cross_task,two_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.BAREBONES.qa_no_choices_and_answer.LenNorm,RTE,76.48464395398219,79.29520025096727,RecognizingTextualEntailment,super_glue,,,,,,,,,,,,,,,,,26.5,21.0,0
69.46778711484595,,1.0668087903884058,1.6641776273396902,,,,69.46778711484595,,,,76.03971119133574,1.6641776273396902,1.815884476534296,44.67005076142133,,0.3875783759249911,1.0668087903884058,0.3875783759249911,1.184115523465704,60.64981949458483,"{'size': 111507, '_type': 'table-file', 'ncols': 9, 'nrows': 277, 'sha256': 'a889847f4de034dddf0df8fba09caaa62c4bd5673289528f04cfe9cdcc9d1da9', 'artifact_path': 'wandb-client-artifact://16ey16560rgt9dtxl97pydptxapy5yu38pwnw8ynfp1z0gbnqarswv5njahmr0hrmxurikj23iwaqhdmtmyjtklu8nskh6s66ku24e4pn7zy6uv6mhavpg9fcnifo51o:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://16ey16560rgt9dtxl97pydptxapy5yu38pwnw8ynfp1z0gbnqarswv5njahmr0hrmxurikj23iwaqhdmtmyjtklu8nskh6s66ku24e4pn7zy6uv6mhavpg9fcnifo51o:latest/predictions.table.json', 'path': 'media/table/predictions_1_a889847f4de034dddf0d.table.json'}",46.50913357668334,,,False,True,validation,False,Yes | No,4,CTBase,e5eaa3ee-e537-4d20-9dfa-6084db54f2ef,rte,ENTAILMENT,False,28,bigscience/T0_3B,0,True,entailment_no_choices_and_answer,prompts/general_fixed_choice.yaml,No Prompt,,2,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,NLI,rte,False,False,GeneralFixedChoice,False,False,False,,,prompts,,False,True,entailment no choices and answer,,cross_task,two_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.BAREBONES.entailment_no_choices_and_answer.LenNorm,RTE,66.60785117348851,71.50998640593956,RecognizingTextualEntailment,super_glue,,,,,,,,,,,,,,,,,50.0,49.0,2
71.976401179941,,0.9479634407855,1.4629453928462004,,,,71.976401179941,,,,91.5956678700361,1.4629453928462004,1.7509025270758125,55.81395348837209,,0.4324903720396227,0.9479634407855,0.4324903720396227,1.2490974729241875,65.70397111913357,"{'_latest_artifact_path': 'wandb-client-artifact://ykgxal1ncb3qgmo8p20kelrnlaid8btddy63h5j0gz8d3n3cjv6owscfvuauawdg77u828c54ppphhhc7g6yhodjoupr03sqlfsq5oda52ij1w2bjd06165zpuz0j9c9:latest/predictions.table.json', 'path': 'media/table/predictions_1_563a71418b5f2569a4be.table.json', 'size': 119784, '_type': 'table-file', 'ncols': 9, 'nrows': 277, 'sha256': '563a71418b5f2569a4beec865c249e83819999236561c48f713ad62b5895ebe9', 'artifact_path': 'wandb-client-artifact://ykgxal1ncb3qgmo8p20kelrnlaid8btddy63h5j0gz8d3n3cjv6owscfvuauawdg77u828c54ppphhhc7g6yhodjoupr03sqlfsq5oda52ij1w2bjd06165zpuz0j9c9:latest/predictions.table.json'}",46.467282647943954,,,False,True,validation,False,Yes | No,4,CTBase,cf005ddf-8cf2-409d-b884-45d22463f463,rte,CLASSIFICATION,False,28,bigscience/T0_3B,0,True,classification_no_choices_and_answer,prompts/general_fixed_choice.yaml,No Prompt,,2,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,NLI,rte,False,False,GeneralFixedChoice,False,False,False,,,prompts,,False,True,classification no choices and answer,,cross_task,two_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.BAREBONES.classification_no_choices_and_answer.LenNorm,RTE,72.93889863827914,76.6129875562062,RecognizingTextualEntailment,super_glue,,,,,,,,,,,,,,,,,34.5,34.5,2
7.2992700729927,,0.9169193961161266,1.959564443529728,,,,7.2992700729927,,,,187.1913357400722,1.959564443529728,1.021660649819495,69.54436450839329,,0.1455728891960718,0.9169193961161266,0.1455728891960718,1.978339350180505,54.151624548736464,"{'sha256': '52cfb4ce6d79c4307b0a1fcfb951a86708d5c6fafac20926a5de2ffc9c86506f', 'artifact_path': 'wandb-client-artifact://5lmkypt9eem8fke3b8d244tx1sieotlnh0isckya6i0bo74hubyzvmmi6hg9syfv65dgnntr74fgnmh871dc0wt0xwg6tjlvuriqio44uhnj3c7kg3ygenjnt5ilk9jy:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://5lmkypt9eem8fke3b8d244tx1sieotlnh0isckya6i0bo74hubyzvmmi6hg9syfv65dgnntr74fgnmh871dc0wt0xwg6tjlvuriqio44uhnj3c7kg3ygenjnt5ilk9jy:latest/predictions.table.json', 'path': 'media/table/predictions_1_52cfb4ce6d79c4307b0a.table.json', 'size': 220149, '_type': 'table-file', 'ncols': 9, 'nrows': 277}",92.93456529588792,,,False,True,validation,False,Yes | No,4,CTBase,2e94d035-3c3d-44cf-98cb-3d11bea7c17b,rte,QA,False,28,bigscience/T0_3B,0,True,qa_choices_and_answer,prompts/general_fixed_choice.yaml,No Prompt,,2,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,NLI,rte,False,False,GeneralFixedChoice,False,False,True,,,prompts,,False,True,qa choices and answer,,cross_task,two_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.BAREBONES.qa_choices_and_answer.LenNorm,RTE,68.86978901350291,73.04716093276168,RecognizingTextualEntailment,super_glue,,,,,,,,,,,,,,,,,75.0,89.0,2
70.52341597796142,,0.9206451998445676,1.5074064146310413,,,,70.52341597796142,,,,83.03971119133574,1.5074064146310413,1.8375451263537903,43.97905759162304,,0.3688675747132073,0.9206451998445676,0.3688675747132073,1.1624548736462097,61.371841155234655,"{'_latest_artifact_path': 'wandb-client-artifact://54h33ygpyc6se9gfgqms23kirmcvtg7paj057a7m7f644brnbln7bqcviitbjge5854y7qiaqfkocdzjpe0oge8eadroemivi568agc8ifrwvr7qb6b5a528o7lsqjwt:latest/predictions.table.json', 'path': 'media/table/predictions_1_bb6d2585f5733010ce84.table.json', 'size': 116797, '_type': 'table-file', 'ncols': 9, 'nrows': 277, 'sha256': 'bb6d2585f5733010ce84c3c8e95ba7887bc2ca598aeca44bfe890e821a8d0df0', 'artifact_path': 'wandb-client-artifact://54h33ygpyc6se9gfgqms23kirmcvtg7paj057a7m7f644brnbln7bqcviitbjge5854y7qiaqfkocdzjpe0oge8eadroemivi568agc8ifrwvr7qb6b5a528o7lsqjwt:latest/predictions.table.json'}",46.50913357668334,,,False,True,validation,False,Yes | No,4,CTBase,c225e598-1efe-4cb6-9f7c-a1b7eb5c7803,rte,ENTAILMENT,False,28,bigscience/T0_3B,0,True,entailment_choices_and_answer,prompts/general_fixed_choice.yaml,No Prompt,,2,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,NLI,rte,False,False,GeneralFixedChoice,False,False,True,,,prompts,,False,True,entailment choices and answer,,cross_task,two_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.BAREBONES.entailment_choices_and_answer.LenNorm,RTE,72.81290202927775,76.80644149325525,RecognizingTextualEntailment,super_glue,,,,,,,,,,,,,,,,,44.5,41.5,2
73.96449704142012,,0.8669941781720663,1.3064229694944858,,,,73.96449704142012,,,,98.5956678700361,1.3064229694944858,1.7472924187725631,59.25925925925925,,0.4345646782903729,0.8669941781720663,0.4345646782903729,1.2527075812274369,68.23104693140795,"{'nrows': 277, 'sha256': '5623469a851cd6a545975b63d5a8dede44e1a5f5e40c7ba4555bb51c4c41a20f', 'artifact_path': 'wandb-client-artifact://12eqmai1o0d7h76dzr5lvvzvnhj502v7c170hkv9iogjzjyftc6kzcaxc6gg9uutttrnf3f0hpwaqt6wg49ff28ppzhy69s29wahdlofwpq65e8g2ageygokyznvk2nj:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://12eqmai1o0d7h76dzr5lvvzvnhj502v7c170hkv9iogjzjyftc6kzcaxc6gg9uutttrnf3f0hpwaqt6wg49ff28ppzhy69s29wahdlofwpq65e8g2ageygokyznvk2nj:latest/predictions.table.json', 'path': 'media/table/predictions_1_5623469a851cd6a54597.table.json', 'size': 125727, '_type': 'table-file', 'ncols': 9}",46.467282647943954,,,False,True,validation,False,Yes | No,4,CTBase,32a28538-99bc-4c5a-8086-83b885fddb50,rte,CLASSIFICATION,False,28,bigscience/T0_3B,0,True,classification_choices_and_answer,prompts/general_fixed_choice.yaml,No Prompt,,2,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,NLI,rte,False,False,GeneralFixedChoice,False,False,True,,,prompts,,False,True,classification choices and answer,,cross_task,two_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.BAREBONES.classification_choices_and_answer.LenNorm,RTE,79.74685263455908,82.6362020286521,RecognizingTextualEntailment,super_glue,,,,,,,,,,,,,,,,,23.0,17.0,2
38.94736842105263,,1.1623465458517932,1.5162615276846214,,,,38.94736842105263,,,,178.1913357400722,1.5162615276846214,1.212996389891697,68.13186813186813,,0.4094251186539501,1.1623465458517932,0.4094251186539501,1.787003610108303,58.12274368231047,"{'path': 'media/table/predictions_1_a63840c3a2ca5e6297c8.table.json', 'size': 212284, '_type': 'table-file', 'ncols': 9, 'nrows': 277, 'sha256': 'a63840c3a2ca5e6297c85a938772131c4375bfbb32ccce2fa0b185db0be7f3ac', 'artifact_path': 'wandb-client-artifact://fw1hsena1cwid6f2rxoh8kh1j7489lq01d1l4rgmz5g4cklvxkvilywmy292o6683wwt8fpfvmkzfk35a2kgbzzlzok63fviniw8lrnjg7ypkycesoi9gfm0mau11s22:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://fw1hsena1cwid6f2rxoh8kh1j7489lq01d1l4rgmz5g4cklvxkvilywmy292o6683wwt8fpfvmkzfk35a2kgbzzlzok63fviniw8lrnjg7ypkycesoi9gfm0mau11s22:latest/predictions.table.json'}",92.93456529588792,,,False,True,validation,False,Yes | No,4,CTBase,97030be6-9843-4fc2-98cf-b47b879b5447,rte,QA,False,28,bigscience/T0_3B,0,True,qa_no_choices,prompts/general_fixed_choice.yaml,No Prompt,,2,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,NLI,rte,False,False,GeneralFixedChoice,False,False,False,,,prompts,,False,True,qa no choices,,cross_task,two_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.BAREBONES.qa_no_choices.LenNorm,RTE,62.84118783411974,69.5022482484576,RecognizingTextualEntailment,super_glue,,,,,,,,,,,,,,,,,58.0,88.0,0
65.16290726817043,,1.3210582498952872,2.5834142535602145,,,,65.16290726817043,,,,74.03971119133574,2.5834142535602145,1.967509025270758,10.32258064516129,,0.1773000600405584,1.3210582498952872,0.1773000600405584,1.032490974729242,49.81949458483754,"{'nrows': 277, 'sha256': '283808cd133fcca6e39eea2f7e49120ad401ce5efb3e21357f5974d717a355fe', 'artifact_path': 'wandb-client-artifact://8f8h4rngtetee8m31xu7na598jrc425stcvr44xriezpg5kg5ebcebik3e4r8qjs9gs766tnbkiviq5z1d32c719s9bm2ur6avwxmtn0zb1em8qc5ad5o59scczsjmqh:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://8f8h4rngtetee8m31xu7na598jrc425stcvr44xriezpg5kg5ebcebik3e4r8qjs9gs766tnbkiviq5z1d32c719s9bm2ur6avwxmtn0zb1em8qc5ad5o59scczsjmqh:latest/predictions.table.json', 'path': 'media/table/predictions_1_283808cd133fcca6e39e.table.json', 'size': 109008, '_type': 'table-file', 'ncols': 9}",46.50913357668334,,,False,True,validation,False,Yes | No,4,CTBase,cc2958ca-e826-4fef-96aa-1c4caa188605,rte,ENTAILMENT,False,28,bigscience/T0_3B,0,True,entailment_no_choices,prompts/general_fixed_choice.yaml,No Prompt,,2,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,NLI,rte,False,False,GeneralFixedChoice,False,False,False,,,prompts,,False,True,entailment no choices,,cross_task,two_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.BAREBONES.entailment_no_choices.LenNorm,RTE,66.90682534586617,70.77277005123915,RecognizingTextualEntailment,super_glue,,,,,,,,,,,,,,,,,87.0,84.0,0
67.75956284153006,,1.1749266899100097,1.962448888952551,,,,67.75956284153006,,,,89.5956678700361,1.962448888952551,1.848375451263538,37.234042553191486,,0.3586565835962395,1.1749266899100097,0.3586565835962395,1.151624548736462,57.400722021660656,"{'path': 'media/table/predictions_1_097752b98fb2e85b0bdc.table.json', 'size': 117323, '_type': 'table-file', 'ncols': 9, 'nrows': 277, 'sha256': '097752b98fb2e85b0bdc2024089c655ef97710e5f7f56983f5230951c828220f', 'artifact_path': 'wandb-client-artifact://zuem4q7piilc25o81kobcjcrdelb8uckbngfk2j4dnfy56c21a0k1y2goyosdrvwa0u4xqyqeiqclrf7irolpamm69c6o3dmhpniel4mnc2towqp714m25jsqkgjb2m6:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://zuem4q7piilc25o81kobcjcrdelb8uckbngfk2j4dnfy56c21a0k1y2goyosdrvwa0u4xqyqeiqclrf7irolpamm69c6o3dmhpniel4mnc2towqp714m25jsqkgjb2m6:latest/predictions.table.json'}",46.467282647943954,,,False,True,validation,False,Yes | No,4,CTBase,74693ecc-f903-488c-968d-6a2bc8e76611,rte,CLASSIFICATION,False,28,bigscience/T0_3B,0,True,classification_no_choices,prompts/general_fixed_choice.yaml,No Prompt,,2,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,NLI,rte,False,False,GeneralFixedChoice,False,False,False,,,prompts,,False,True,classification no choices,,cross_task,two_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.BAREBONES.classification_no_choices.LenNorm,RTE,71.97412873892979,75.311094844714,RecognizingTextualEntailment,super_glue,,,,,,,,,,,,,,,,,62.5,65.0,0
2.985074626865672,,1.0158159648139276,2.403031850980077,,,,2.985074626865672,,,,185.1913357400722,2.403031850980077,1.0108303249097472,69.04761904761904,,0.1035037630818155,1.0158159648139276,0.1035037630818155,1.9891696750902528,53.06859205776173,"{'path': 'media/table/predictions_1_58fec1ad8fdf87023315.table.json', 'size': 217602, '_type': 'table-file', 'ncols': 9, 'nrows': 277, 'sha256': '58fec1ad8fdf8702331554ca8f0094d905418f45a701a7ba8d47205b594e0b29', 'artifact_path': 'wandb-client-artifact://l5xokt6g7hbarplhqhiuwhhtx4o5m7yxll1kmfpljos5uiz9ygq66jlyrjzqnok2i4h4zlzuuz7oimebyrr0vcq7wejpdjggype6qx11vl73wz2nsxx033r2dmbj83ht:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://l5xokt6g7hbarplhqhiuwhhtx4o5m7yxll1kmfpljos5uiz9ygq66jlyrjzqnok2i4h4zlzuuz7oimebyrr0vcq7wejpdjggype6qx11vl73wz2nsxx033r2dmbj83ht:latest/predictions.table.json'}",92.93456529588792,,,False,True,validation,False,Yes | No,4,CTBase,d92fc0d4-5367-41e1-b35d-1058f22a3c1c,rte,QA,False,28,bigscience/T0_3B,0,True,qa_choices,prompts/general_fixed_choice.yaml,No Prompt,,2,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,NLI,rte,False,False,GeneralFixedChoice,False,False,True,,,prompts,,False,True,qa choices,,cross_task,two_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.BAREBONES.qa_choices.LenNorm,RTE,68.23700927767537,73.27198577852138,RecognizingTextualEntailment,super_glue,,,,,,,,,,,,,,,,,78.5,90.0,0
69.00269541778977,,0.9508380705593554,1.55619881729787,,,,69.00269541778977,,,,81.03971119133574,1.55619881729787,1.8664259927797835,37.15846994535519,,0.3401940502350828,0.9508380705593554,0.3401940502350828,1.1335740072202165,58.48375451263538,"{'artifact_path': 'wandb-client-artifact://rfsiq37kdda8yebrzg0rwfi0msyjl6r1kqwj5rzlwvy4b653zjnsqdvbmzqjmzav54b6qf0fcz2lf1ql00b1rglwwphomv523pncxz8irgfytttgwsyx2gjq2fp17jio:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://rfsiq37kdda8yebrzg0rwfi0msyjl6r1kqwj5rzlwvy4b653zjnsqdvbmzqjmzav54b6qf0fcz2lf1ql00b1rglwwphomv523pncxz8irgfytttgwsyx2gjq2fp17jio:latest/predictions.table.json', 'path': 'media/table/predictions_1_5700216307770d588337.table.json', 'size': 114241, '_type': 'table-file', 'ncols': 9, 'nrows': 277, 'sha256': '5700216307770d58833771e9e4017f6680422592a6ca46354e5d0dda17db76d4'}",46.50913357668334,,,False,True,validation,False,Yes | No,4,CTBase,bb648cf3-d9ab-45a8-9bd7-6ba4585c4b9a,rte,ENTAILMENT,False,28,bigscience/T0_3B,0,True,entailment_choices,prompts/general_fixed_choice.yaml,No Prompt,,2,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,NLI,rte,False,False,GeneralFixedChoice,False,False,True,,,prompts,,False,True,entailment choices,,cross_task,two_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.BAREBONES.entailment_choices.LenNorm,RTE,69.80690471772056,74.67844818571578,RecognizingTextualEntailment,super_glue,,,,,,,,,,,,,,,,,56.5,54.5,0
75.4601226993865,,0.821672918919848,1.2373485109005593,,,,75.4601226993865,,,,96.5956678700361,1.2373485109005593,1.703971119133574,64.91228070175438,,0.4565038691614753,0.821672918919848,0.4565038691614753,1.296028880866426,71.11913357400722,"{'_latest_artifact_path': 'wandb-client-artifact://li9j6hp769bm0k4rpegdvcp2bei2vt7i9jjuvefjc02aj3hr8k3unhqo18nibqot6f6h88p54mvzf986rwrgcz53cuyvlqb1tzfxwurmd7qif7q0od31ukned7dd1rtc:latest/predictions.table.json', 'path': 'media/table/predictions_1_626de62d4abd3f06b8a5.table.json', 'size': 122866, '_type': 'table-file', 'ncols': 9, 'nrows': 277, 'sha256': '626de62d4abd3f06b8a5e2a306664b51142481a7c90c5b37eb2fb1d62567d7fa', 'artifact_path': 'wandb-client-artifact://li9j6hp769bm0k4rpegdvcp2bei2vt7i9jjuvefjc02aj3hr8k3unhqo18nibqot6f6h88p54mvzf986rwrgcz53cuyvlqb1tzfxwurmd7qif7q0od31ukned7dd1rtc:latest/predictions.table.json'}",46.467282647943954,,,False,True,validation,False,Yes | No,4,CTBase,88bdb026-e9c9-445b-96ef-0cdb986b7fbd,rte,CLASSIFICATION,False,28,bigscience/T0_3B,0,True,classification_choices,prompts/general_fixed_choice.yaml,No Prompt,,2,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,NLI,rte,False,False,GeneralFixedChoice,False,False,True,,,prompts,,False,True,classification choices,,cross_task,two_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.BAREBONES.classification_choices.LenNorm,RTE,78.73634639027942,82.45843354595839,RecognizingTextualEntailment,super_glue,,,,,,,,,,,,,,,,,11.5,8.0,0
69.20980926430518,,1.017647231773149,1.5993001925816177,,,,69.20980926430518,,,,108.03971119133574,1.5993001925816177,1.851985559566787,39.57219251336898,,0.3551142997070884,1.017647231773149,0.3551142997070884,1.148014440433213,59.2057761732852,"{'nrows': 277, 'sha256': 'bc51793c1f1385a711c2902ed4c66f930a82180181dee4db8a1582247c2fc3bb', 'artifact_path': 'wandb-client-artifact://4yvc0yvwdwqhob8nv1c3wxr7xhqekyol1oxjxykgzh7k6hs98ir1rzey4eqnhxau3h9uzbzx9bctrpj7m8e5kagq05s53nwfq158vcb0fjs2mrmqhm03y5wotxnsj7eu:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://4yvc0yvwdwqhob8nv1c3wxr7xhqekyol1oxjxykgzh7k6hs98ir1rzey4eqnhxau3h9uzbzx9bctrpj7m8e5kagq05s53nwfq158vcb0fjs2mrmqhm03y5wotxnsj7eu:latest/predictions.table.json', 'path': 'media/table/predictions_1_bc51793c1f1385a711c2.table.json', 'size': 137039, '_type': 'table-file', 'ncols': 9}",46.50913357668334,,,False,True,validation,False,Yes | No,4,CTBase,725b5ed0-7728-4890-95a4-a74cb7ae1bb4,rte,ENTAILMENT,False,28,bigscience/T0_3B,0,True,affirmation_true_or_false,prompts/general_fixed_choice.yaml,WiC,,2,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,NLI,rte,False,False,GeneralFixedChoice,False,False,True,,,prompts,,False,True,affirmation_true_or_false,,cross_task,two_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.super_glue_wic.affirmation_true_or_false.LenNorm,RTE,76.95805045157493,80.19449963400606,RecognizingTextualEntailment,super_glue,,,,,,,,,,,,,,,,,53.0,51.0,25
65.65656565656566,,1.0745010748875048,2.069873919771036,,,,65.65656565656566,,,,107.03971119133574,2.069873919771036,1.9566787003610109,13.924050632911392,,0.2035793816587968,1.0745010748875048,0.2035793816587968,1.0433212996389891,50.90252707581227,"{'sha256': 'b989067950b0d2780231644bc4cfe93fb383116815a3257e0402f7bc73b7cde6', 'artifact_path': 'wandb-client-artifact://1457qgybtg9j2vqbydzhk5osnb4jqdb9398uhqxu2zle7mqlvqrxnmobovwxxk14nyv6e4jevwjgsqaw2enlknfodjwhxmnrockv3l61ojg0jppmaykomabunswo7aij:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://1457qgybtg9j2vqbydzhk5osnb4jqdb9398uhqxu2zle7mqlvqrxnmobovwxxk14nyv6e4jevwjgsqaw2enlknfodjwhxmnrockv3l61ojg0jppmaykomabunswo7aij:latest/predictions.table.json', 'path': 'media/table/predictions_1_b989067950b0d2780231.table.json', 'size': 147314, '_type': 'table-file', 'ncols': 9, 'nrows': 277}",46.50913357668334,,,False,True,validation,False,Yes | No,4,CTBase,611d13dc-d414-4b9b-9204-e4f325e859e7,rte,ENTAILMENT,False,28,bigscience/T0_3B,0,True,grammar_homework,prompts/general_fixed_choice.yaml,WiC,,2,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,NLI,rte,False,False,GeneralFixedChoice,False,False,True,,,prompts,,False,True,grammar_homework,,cross_task,two_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.super_glue_wic.grammar_homework.LenNorm,RTE,72.03175994219436,76.28359301474433,RecognizingTextualEntailment,super_glue,,,,,,,,,,,,,,,,,82.5,77.0,25
69.04109589041096,,1.0810896652362791,1.7437197998542648,,,,69.04109589041096,,,,91.03971119133574,1.7437197998542648,1.8447653429602888,40.21164021164021,,0.3621282345985665,1.0810896652362791,0.3621282345985665,1.1552346570397112,59.2057761732852,"{'sha256': 'dc1b346922164133603c85b769a19a5208b15a420c24717aaf5a9e98bc92572e', 'artifact_path': 'wandb-client-artifact://n00y8itod0qtl8t5bvsklui1vydzv6fg9bm4dldm5enp2wxap2v6xz3hf0n0gtvv1k6hkaoausg5vxkc43jxuak4uqr94my4gfvwn8h539mcagoeitj12nf0muu9f5jj:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://n00y8itod0qtl8t5bvsklui1vydzv6fg9bm4dldm5enp2wxap2v6xz3hf0n0gtvv1k6hkaoausg5vxkc43jxuak4uqr94my4gfvwn8h539mcagoeitj12nf0muu9f5jj:latest/predictions.table.json', 'path': 'media/table/predictions_1_dc1b346922164133603c.table.json', 'size': 129500, '_type': 'table-file', 'ncols': 9, 'nrows': 277}",46.50913357668334,,,False,True,validation,False,Yes | No,4,CTBase,3503ead5-4fa5-4f77-95dc-f0c2ed3eecdc,rte,ENTAILMENT,False,28,bigscience/T0_3B,0,True,question_context_meaning,prompts/general_fixed_choice.yaml,WiC,,2,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,NLI,rte,False,False,GeneralFixedChoice,False,False,False,,,prompts,,False,True,question-context-meaning,,cross_task,two_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.super_glue_wic.question_context_meaning.LenNorm,RTE,68.89256694624547,72.7805082087211,RecognizingTextualEntailment,super_glue,,,,,,,,,,,,,,,,,53.0,52.5,14
65.32663316582915,,1.0108618245298535,2.144425533308449,,,,65.32663316582915,,,,99.03971119133574,2.144425533308449,1.963898916967509,11.538461538461538,,0.1865416705092247,1.0108618245298535,0.1865416705092247,1.036101083032491,50.18050541516246,"{'artifact_path': 'wandb-client-artifact://xql3gf6pbujnhbki2scmp2jsnqdv4m1oavoqwrrurifajt1f6pt52gjogifsxhpognt6zkde3fwpojp1pp01v0t3w78oubmplpkgse0d4qqgof36vgkbe5nv7tv30ctf:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://xql3gf6pbujnhbki2scmp2jsnqdv4m1oavoqwrrurifajt1f6pt52gjogifsxhpognt6zkde3fwpojp1pp01v0t3w78oubmplpkgse0d4qqgof36vgkbe5nv7tv30ctf:latest/predictions.table.json', 'path': 'media/table/predictions_1_1b83d6df215217a60127.table.json', 'size': 134717, '_type': 'table-file', 'ncols': 9, 'nrows': 277, 'sha256': '1b83d6df215217a60127f8db7f0f945db4b4f03503e2e0f16f0b7c4d312833ee'}",46.50913357668334,,,False,True,validation,False,Yes | No,4,CTBase,14e73f39-a0d1-44c2-b9a4-4e48f9f1608e,rte,ENTAILMENT,False,28,bigscience/T0_3B,0,True,question_context_meaning_with_label,prompts/general_fixed_choice.yaml,WiC,,2,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,NLI,rte,False,False,GeneralFixedChoice,False,False,True,,,prompts,,False,True,question-context-meaning-with-label,,cross_task,two_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.super_glue_wic.question_context_meaning_with_label.LenNorm,RTE,72.47585121987969,76.45613301265294,RecognizingTextualEntailment,super_glue,,,,,,,,,,,,,,,,,85.0,81.0,16
72.35294117647058,,1.0602974101091345,1.5696880300983196,,,,72.35294117647058,,,,127.5956678700361,1.5696880300983196,1.7545126353790614,56.07476635514018,,0.4303757874606853,1.0602974101091345,0.4303757874606853,1.2454873646209386,66.06498194945848,"{'sha256': 'a35c7057c24380ae860443ea39b27e7a2179c88dab1419d544835c37e9639eb6', 'artifact_path': 'wandb-client-artifact://14fn00lenf3z69laxznhocucy52vh2176q9uxvk9scpb6gr6y32ajlfjybj2jsrx91ja66vtebeslxojdud92r1eqac3e5b27tv2wwug6yxf9qyy325h3gpzesfliont:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://14fn00lenf3z69laxznhocucy52vh2176q9uxvk9scpb6gr6y32ajlfjybj2jsrx91ja66vtebeslxojdud92r1eqac3e5b27tv2wwug6yxf9qyy325h3gpzesfliont:latest/predictions.table.json', 'path': 'media/table/predictions_1_a35c7057c24380ae8604.table.json', 'size': 161615, '_type': 'table-file', 'ncols': 9, 'nrows': 277}",46.467282647943954,,,False,True,validation,False,Yes | No,4,CTBase,cd563834-49ee-495d-ac46-99f0264e58d5,rte,QA,False,28,bigscience/T0_3B,0,True,ask_question_as_teacher,prompts/general_fixed_choice.yaml,ZEST,,2,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,NLI,rte,False,False,GeneralFixedChoice,False,False,False,,,prompts,,False,True,ask_question_as_teacher,,cross_task,two_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.zest.ask_question_as_teacher.LenNorm,RTE,74.34563989580661,78.72006692460525,RecognizingTextualEntailment,super_glue,,,,,,,,,,,,,,,,,31.5,31.0,24
72.72727272727272,,0.8021149031108918,1.213318859196742,,,,72.72727272727272,,,,126.5956678700361,1.213318859196742,1.7184115523465704,59.82142857142857,,0.449773713995784,0.8021149031108918,0.449773713995784,1.2815884476534296,67.50902527075813,"{'ncols': 9, 'nrows': 277, 'sha256': 'c64234a1930a3de052b954ed75384b8424477c87e13025c3b71fa85593fc827a', 'artifact_path': 'wandb-client-artifact://am31uqfranodx323vrc1rtjijfe3q7nhhjf1my16y2o01nhh4ngf8he14a2c676ql043rpya8znlzb5pj84otkih6qo51eclfjxo354s8wcev05whpg4zp8unbazy7ad:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://am31uqfranodx323vrc1rtjijfe3q7nhhjf1my16y2o01nhh4ngf8he14a2c676ql043rpya8znlzb5pj84otkih6qo51eclfjxo354s8wcev05whpg4zp8unbazy7ad:latest/predictions.table.json', 'path': 'media/table/predictions_1_c64234a1930a3de052b9.table.json', 'size': 161976, '_type': 'table-file'}",46.467282647943954,,,False,True,validation,False,Yes | No,4,CTBase,7425232a-9880-428c-9ddc-4070e50e22cc,rte,QA,False,28,bigscience/T0_3B,0,True,gpt3_instruct_format,prompts/general_fixed_choice.yaml,ZEST,,2,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,NLI,rte,False,False,GeneralFixedChoice,False,False,False,,,prompts,,False,True,gpt3_instruct_format,,cross_task,two_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.zest.gpt3_instruct_format.LenNorm,RTE,78.27185873450213,80.76440447558298,RecognizingTextualEntailment,super_glue,,,,,,,,,,,,,,,,,26.5,24.5,28
72.39263803680981,,0.8562328098164818,1.251393248458201,,,,72.39263803680981,,,,133.5956678700361,1.251393248458201,1.703971119133574,60.526315789473685,,0.4565038691614753,0.8562328098164818,0.4565038691614753,1.296028880866426,67.50902527075813,"{'_type': 'table-file', 'ncols': 9, 'nrows': 277, 'sha256': 'd73e7b1855d1c5bab57b0d54e5eedd0d93a8456321449fdfbae3c7f74e4a3a3e', 'artifact_path': 'wandb-client-artifact://ptkj3bsyreoxp076plpqocomunsfguj9c3jqsn2b4qpadtmzetvofub9yasjo5nclro09q97tjijrjmn5ol52scjqupy4b71113lw9ylp1tzm6rnchxvtciujhmwj0ai:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://ptkj3bsyreoxp076plpqocomunsfguj9c3jqsn2b4qpadtmzetvofub9yasjo5nclro09q97tjijrjmn5ol52scjqupy4b71113lw9ylp1tzm6rnchxvtciujhmwj0ai:latest/predictions.table.json', 'path': 'media/table/predictions_1_d73e7b1855d1c5bab57b.table.json', 'size': 161900}",46.467282647943954,,,False,True,validation,False,Yes | No,4,CTBase,6f694e45-1d17-4067-a1f6-7dae89c148db,rte,QA,False,28,bigscience/T0_3B,0,True,ask_question_as_kid,prompts/general_fixed_choice.yaml,ZEST,,2,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,NLI,rte,False,False,GeneralFixedChoice,False,False,False,,,prompts,,False,True,ask_question_as_kid,,cross_task,two_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.zest.ask_question_as_kid.LenNorm,RTE,76.39539905558563,79.23245843354596,RecognizingTextualEntailment,super_glue,,,,,,,,,,,,,,,,,26.5,29.0,31
71.976401179941,,0.9593240610855016,1.4515908866152436,,,,71.976401179941,,,,119.5956678700361,1.4515908866152436,1.7509025270758125,55.81395348837209,,0.4324903720396227,0.9593240610855016,0.4324903720396227,1.2490974729241875,65.70397111913357,"{'ncols': 9, 'nrows': 277, 'sha256': '5fe55874dc310d92bb54a8a8fc8ffed26724f75d0f73a4acf129fc6a99902d6c', 'artifact_path': 'wandb-client-artifact://4xwftrdd5fuz0zu8s62yvgthohhf22rruh6s5i6qtli1btxcfl23rvkswm8extck05itx2ozfh1mg2xat221l2fdoql7ijkxrsutr9od9njdy207xadttg2z0ubhyeoq:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://4xwftrdd5fuz0zu8s62yvgthohhf22rruh6s5i6qtli1btxcfl23rvkswm8extck05itx2ozfh1mg2xat221l2fdoql7ijkxrsutr9od9njdy207xadttg2z0ubhyeoq:latest/predictions.table.json', 'path': 'media/table/predictions_1_5fe55874dc310d92bb54.table.json', 'size': 151401, '_type': 'table-file'}",46.467282647943954,,,False,True,validation,False,Yes | No,4,CTBase,2283cebf-988e-4bff-96bf-982a09963e49,rte,QA,False,28,bigscience/T0_3B,0,True,answerable_or_not,prompts/general_fixed_choice.yaml,ZEST,,2,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,NLI,rte,False,False,GeneralFixedChoice,False,False,False,,,prompts,,False,True,answerable_or_not,,cross_task,two_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.zest.answerable_or_not.LenNorm,RTE,74.6388832634341,78.8664644985883,RecognizingTextualEntailment,super_glue,,,,,,,,,,,,,,,,,34.5,34.5,20
7.934037142636974,4.210526315789474,1.3252668197734578,3.808482334442074,2.221105527638191,0.576295671590372,0.5770804912544961,0.0,0.0,1.4505719367782874,3.842546063651591,181.8894472361809,1.3383576474597108,1.0268006700167505,27.52562225475842,1.0195527502040769,0.2299631799226869,1.3459651764179152,0.3302594733657428,2.909547738693467,16.08040201005025,"{'ncols': 13, 'nrows': 597, 'sha256': '1bae16d7b30ed2c45eb93ed40ab50e825e884724ae33cb8da453aae1d17482e7', 'artifact_path': 'wandb-client-artifact://102yj0krh6s1q0hmcoi1jlb3r1wsee8fginwyrw9xd6ahrsunefw02421kj5zi0c5o4qv2onvmt3am5t57ufwt28wlbkjkhrjyxxxf5vtf7bs530ir9qo9tzfbjl2rqb:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://102yj0krh6s1q0hmcoi1jlb3r1wsee8fginwyrw9xd6ahrsunefw02421kj5zi0c5o4qv2onvmt3am5t57ufwt28wlbkjkhrjyxxxf5vtf7bs530ir9qo9tzfbjl2rqb:latest/predictions.table.json', 'path': 'media/table/predictions_1_1bae16d7b30ed2c45eb9.table.json', 'size': 543593, '_type': 'table-file'}",78.40801568599385,0.5388463530959001,0.5355054125525855,False,True,validation,False,Seller | Buyer | Neither | Unknown,4,CTBase,a64d5a15-68e2-4d1c-b30a-ca8250c860f9,craigslist_bargains,QA,False,12,bigscience/T0_3B,0,True,answer_the_following_q,prompts/general_fixed_choice.yaml,AdversarialQA,['validation'],4,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,['Dialogue'],craigslist_bargains,True,False,GeneralFixedChoice,False,False,False,,,prompts,,False,True,answer_the_following_q,,cross_task,craigslist,,,,False,,,False,,True,,,False,False,CTBase.GenFC.adversarial_qa.answer_the_following_q.LenNorm,Craigslist,,,,,,,,,,,,,,,,,,,,,69.5,78.0,23
10.950380469245404,15.789473684210527,1.265096890698746,3.555019152074603,2.768844221105528,0.5551946688569275,0.966872128438586,0.0,0.0,1.3377820322761185,3.224455611390285,173.5075376884422,0.8877222214511891,1.0904522613065326,28.01204819277109,1.3295148983472955,0.4155994598620168,1.1957735453334175,0.4404436535010481,2.916247906197655,17.08542713567839,"{'nrows': 597, 'sha256': 'cdd6aa744e696b524118e3e0785910a7b183c9d0d8a7df41a11feab38b522f81', 'artifact_path': 'wandb-client-artifact://187aeeb9lvz7u0twgdd3z7m3tr0ywm5jpqf1v8e2yz8woy3x6v466hfna4ghw804ft2hiknn5silabmhlnwatbq1qj49svwvk6exmv14qof6oqdd0ut6cm58mmns89vk:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://187aeeb9lvz7u0twgdd3z7m3tr0ywm5jpqf1v8e2yz8woy3x6v466hfna4ghw804ft2hiknn5silabmhlnwatbq1qj49svwvk6exmv14qof6oqdd0ut6cm58mmns89vk:latest/predictions.table.json', 'path': 'media/table/predictions_1_cdd6aa744e696b524118.table.json', 'size': 515258, '_type': 'table-file', 'ncols': 13}",78.326585290588,0.6271583272886435,0.970177545161286,False,True,validation,False,Seller | Buyer | Neither | Unknown,4,CTBase,a0872cde-2f19-4ae6-919a-868da47bfbcb,craigslist_bargains,QA,False,12,bigscience/T0_3B,0,True,based_on,prompts/general_fixed_choice.yaml,AdversarialQA,['validation'],4,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,['Dialogue'],craigslist_bargains,True,False,GeneralFixedChoice,False,False,False,,,prompts,,False,True,based_on,,cross_task,craigslist,,,,False,,,False,,True,,,False,False,CTBase.GenFC.adversarial_qa.based_on.LenNorm,Craigslist,,,,,,,,,,,,,,,,,,,,,55.0,59.0,16
11.239330637915543,16.9811320754717,1.2038236075591509,3.207737857971958,3.256281407035176,0.4721714145918123,0.9683335810350502,0.0,0.0,1.2029834163049158,2.7370184254606365,167.89782244556113,0.7529737022853576,1.0636515912897822,27.97619047619047,1.2517807393816849,0.35107215427294,1.0970785461185997,0.3474329203691905,2.943048576214405,17.252931323283082,"{'path': 'media/table/predictions_1_32d017814f58ece787dc.table.json', 'size': 490758, '_type': 'table-file', 'ncols': 13, 'nrows': 597, 'sha256': '32d017814f58ece787dcd6955c41fb1c6a947df1ce72044812c8ff07fa82febc', 'artifact_path': 'wandb-client-artifact://14rw7api1eb48xvbc6cxc8dv0iw9cnj7y1qw71n5eivr21embowvcw0od31gyx5y3gwuas4kp22i7tuu8z2u5hm2zrsxxzixr5x6t22b0trfsu4580lr9ktmu3smeht3:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://14rw7api1eb48xvbc6cxc8dv0iw9cnj7y1qw71n5eivr21embowvcw0od31gyx5y3gwuas4kp22i7tuu8z2u5hm2zrsxxzixr5x6t22b0trfsu4580lr9ktmu3smeht3:latest/predictions.table.json'}",78.39876557809747,0.5575587943823079,0.9648008558520236,False,True,validation,False,Seller | Buyer | Neither | Unknown,4,CTBase,5bdb1815-5c6f-49a3-ad1d-367344420701,craigslist_bargains,QA,False,12,bigscience/T0_3B,0,True,question_context_answer,prompts/general_fixed_choice.yaml,AdversarialQA,['validation'],4,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,['Dialogue'],craigslist_bargains,True,False,GeneralFixedChoice,False,False,False,,,prompts,,False,True,question_context_answer,,cross_task,craigslist,,,,False,,,False,,True,,,False,False,CTBase.GenFC.adversarial_qa.question_context_answer.LenNorm,Craigslist,,,,,,,,,,,,,,,,,,,,,52.5,56.0,11
14.966310060060058,29.0,1.4717703703230565,3.0026196881354954,3.2981574539363483,0.533412650962198,0.9501194257997042,0.0,1.351351351351351,0.8659567155031304,2.676716917922948,179.8894472361809,0.982859986111946,1.3886097152428811,29.51388888888889,1.153802986520419,0.7976541675192893,1.3397376561419423,0.8104468162943124,2.6365159128978224,19.262981574539364,"{'ncols': 13, 'nrows': 597, 'sha256': 'faad9d7c5b3eb2043b4c0604c5f7adf2a8bdb86b05a48af6559cd13b82710126', 'artifact_path': 'wandb-client-artifact://mz3xd26s8xi4kcp74y7fy5xaxlw8hfx2jnyn5z22ziwafblpz7bwy1kudvnh5s5swoeua28151gut90gptjrbykuz8xu0sb94qmnjwbjuwgieetm3dewi9fh38u4fuzw:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://mz3xd26s8xi4kcp74y7fy5xaxlw8hfx2jnyn5z22ziwafblpz7bwy1kudvnh5s5swoeua28151gut90gptjrbykuz8xu0sb94qmnjwbjuwgieetm3dewi9fh38u4fuzw:latest/predictions.table.json', 'path': 'media/table/predictions_1_faad9d7c5b3eb2043b4c.table.json', 'size': 518763, '_type': 'table-file'}",78.40801568599385,0.5870521736888246,0.9391952479832864,False,True,validation,False,Seller | Buyer | Neither | Unknown,4,CTBase,3b2459cc-6600-443c-abf8-8f60c34cd998,craigslist_bargains,QA,False,12,bigscience/T0_3B,0,True,tell_what_it_is,prompts/general_fixed_choice.yaml,AdversarialQA,['validation'],4,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,['Dialogue'],craigslist_bargains,True,False,GeneralFixedChoice,False,False,False,,,prompts,,False,True,tell_what_it_is,,cross_task,craigslist,,,,False,,,False,,True,,,False,False,CTBase.GenFC.adversarial_qa.tell_what_it_is.LenNorm,Craigslist,,,,,,,,,,,,,,,,,,,,,40.5,36.0,22
16.892402046070252,0.0,0.7827075371655328,5.63020502981828,3.782244556113903,1.021140369242853,0.6493029277241104,31.932773109243698,10.112359550561797,0.5303180317583196,3.0016750418760467,164.47068676716918,3.4647224768122635,1.306532663316583,25.524475524475527,1.6351645212476975,0.730875112339742,0.9701936598157558,0.6113329176179116,1.9095477386934672,23.28308207705193,"{'size': 482861, '_type': 'table-file', 'ncols': 13, 'nrows': 597, 'sha256': 'd2a30332e2bc9b66fc199e9a841818320ad8b1b10351e740dd20ab9be15f5cd9', 'artifact_path': 'wandb-client-artifact://3idm5xz1rtws1ekozg414v68if4pwg32d2jfu4kim58muhjglzjly07hfmoufsbytri51a8fbwwzie7e5l9gyuf8k3rziqmair2uyelo0ypzuyz55htanx6mz1u5sbo7:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://3idm5xz1rtws1ekozg414v68if4pwg32d2jfu4kim58muhjglzjly07hfmoufsbytri51a8fbwwzie7e5l9gyuf8k3rziqmair2uyelo0ypzuyz55htanx6mz1u5sbo7:latest/predictions.table.json', 'path': 'media/table/predictions_1_d2a30332e2bc9b66fc19.table.json'}",78.1171728355754,0.3599821460279399,0.0408929836372988,False,True,validation,False,Seller | Buyer | Neither | Unknown,4,CTBase,4dd990b3-7201-4cba-bb9a-baa462d68b1a,craigslist_bargains,SENTIMENT,False,12,bigscience/T0_3B,0,True,format_score,prompts/general_fixed_choice.yaml,Yelp,['validation'],4,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,['Dialogue'],craigslist_bargains,True,False,GeneralFixedChoice,False,False,False,,,prompts,,False,True,format_score,,cross_task,craigslist,,,,False,,,False,,True,,,False,False,CTBase.GenFC.yelp.format_score.LenNorm,Craigslist,,,,,,,,,,,,,,,,,,,,,22.0,27.0,12
17.1867159119865,2.150537634408602,1.2012357351012293,5.826885472190639,1.9932998324958124,0.5837248888000985,0.7765115473270828,7.719298245614035,40.06514657980456,1.2495286664371714,2.959798994974874,158.47068676716918,3.985369039340634,3.396984924623116,18.81188118811881,0.591987766412834,1.1726322041479562,1.4323330594609576,0.9752657120323612,1.6499162479061975,25.79564489112228,"{'_type': 'table-file', 'ncols': 13, 'nrows': 597, 'sha256': '24ed29111950f1faffe85a646b007f500ac2d308bc2f0fc7959b32f794d072de', 'artifact_path': 'wandb-client-artifact://4ai06cz5xxg4yuzl5stzwvuvf1lgkppz7le6aq6x8773m3z16se9eo3igr5r3aqdx2k72f70i2b04zgdr8e0ygnb1b9k7thp0mo7clap78qg0odh3dolu3sqyp0smvpl:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://4ai06cz5xxg4yuzl5stzwvuvf1lgkppz7le6aq6x8773m3z16se9eo3igr5r3aqdx2k72f70i2b04zgdr8e0ygnb1b9k7thp0mo7clap78qg0odh3dolu3sqyp0smvpl:latest/predictions.table.json', 'path': 'media/table/predictions_1_24ed29111950f1faffe8.table.json', 'size': 467897}",78.1171728355754,0.8871629025318563,0.2746557945740946,False,True,validation,False,Seller | Buyer | Neither | Unknown,4,CTBase,29fc6386-90b3-4976-b249-26e49fe7c924,craigslist_bargains,SENTIMENT,False,12,bigscience/T0_3B,0,True,format_star,prompts/general_fixed_choice.yaml,Yelp,['validation'],4,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,['Dialogue'],craigslist_bargains,True,False,GeneralFixedChoice,False,False,False,,,prompts,,False,True,format_star,,cross_task,craigslist,,,,False,,,False,,True,,,False,False,CTBase.GenFC.yelp.format_star.LenNorm,Craigslist,,,,,,,,,,,,,,,,,,,,,12.5,24.0,6
14.231717424729723,27.06422018348624,0.7082341995984968,2.6632085317742686,2.14070351758794,0.3447863656260366,0.7208092703520693,6.382978723404256,2.684563758389262,0.7017035124888972,3.85929648241206,162.47068676716918,1.4807608954271478,2.204355108877722,20.795107033639145,0.4807441238582234,0.9763267198266334,0.7034554382611675,0.8398259737543798,1.795644891122278,17.42043551088777,"{'size': 475499, '_type': 'table-file', 'ncols': 13, 'nrows': 597, 'sha256': '54a6c834d531586b91eb55e333c20d06a2d87adbc57853b4e52da23cfff6b94c', 'artifact_path': 'wandb-client-artifact://10f437xsvzv2ca0jmvompj9znei7clmlv7r49gaq67y0cjfublr1ad5e9io4jcadcb313ql1uupdhllv9q6p7ztn95rirpo8fyb49o9vyiifpq5k3csqzk40hu08laoa:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://10f437xsvzv2ca0jmvompj9znei7clmlv7r49gaq67y0cjfublr1ad5e9io4jcadcb313ql1uupdhllv9q6p7ztn95rirpo8fyb49o9vyiifpq5k3csqzk40hu08laoa:latest/predictions.table.json', 'path': 'media/table/predictions_1_54a6c834d531586b91eb.table.json'}",78.1171728355754,0.5765438513795187,0.5114778150753557,False,True,validation,False,Seller | Buyer | Neither | Unknown,4,CTBase,27b6bc81-bb1c-467b-91c0-22a4d6a19f44,craigslist_bargains,SENTIMENT,False,12,bigscience/T0_3B,0,True,based_on_that,prompts/general_fixed_choice.yaml,Yelp,['validation'],4,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,['Dialogue'],craigslist_bargains,True,False,GeneralFixedChoice,False,False,False,,,prompts,,False,True,based_on_that,,cross_task,craigslist,,,,False,,,False,,True,,,False,False,CTBase.GenFC.yelp.based_on_that.LenNorm,Craigslist,,,,,,,,,,,,,,,,,,,,,50.5,43.0,10
11.62553418756725,0.0,2.529936575453317,9.593884129819758,1.338358458961474,0.617642044494954,0.6543906486865567,4.964539007092198,39.55739972337483,3.867084851816072,2.9011725293132327,159.47068676716918,5.013688287143931,3.9229480737018414,1.98019801980198,0.7131109908597553,0.426224929785901,2.425994479909938,0.5132083387624703,1.8375209380234503,25.29313232830821,"{'ncols': 13, 'nrows': 597, 'sha256': 'f99b91bbbdb84f1011e9b3752d351160d6781c718e8a06cb9d712e553654a5d9', 'artifact_path': 'wandb-client-artifact://kwwrhe9w5717s1oubsy20insjnklargbzwz0fj6u7a2dyh81tdy4wfki7pzzwhpmdwtflr3fkpjdyt47co377ydrv2qi9vvmgybunjugdksms0tu9ct94luojxwoanor:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://kwwrhe9w5717s1oubsy20insjnklargbzwz0fj6u7a2dyh81tdy4wfki7pzzwhpmdwtflr3fkpjdyt47co377ydrv2qi9vvmgybunjugdksms0tu9ct94luojxwoanor:latest/predictions.table.json', 'path': 'media/table/predictions_1_f99b91bbbdb84f1011e9.table.json', 'size': 472112, '_type': 'table-file'}",78.1171728355754,1.2070092050566636,0.3907840746681031,False,True,validation,False,Seller | Buyer | Neither | Unknown,4,CTBase,135fcd11-9fcc-4b55-bf1b-9b76290d0f6b,craigslist_bargains,SENTIMENT,False,12,bigscience/T0_3B,0,True,so_i_would,prompts/general_fixed_choice.yaml,Yelp,['validation'],4,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,['Dialogue'],craigslist_bargains,True,False,GeneralFixedChoice,False,False,False,,,prompts,,False,True,so_i_would,,cross_task,craigslist,,,,False,,,False,,True,,,False,False,CTBase.GenFC.yelp.so_i_would.LenNorm,Craigslist,,,,,,,,,,,,,,,,,,,,,15.5,54.0,7
22.740302293203605,25.31645569620253,0.4419266486371894,4.85282508811759,2.251256281407035,0.3379983163288512,0.7460802739590844,47.78761061946903,0.0,0.3603391679287756,4.0,185.4070351758794,4.077409876850582,2.0720268006700167,17.857142857142854,0.4150760433382325,0.8306350092216831,0.5447600376224289,0.7619581196797792,1.676716917922948,28.97822445561139,"{'nrows': 597, 'sha256': '46e2e3e2cf9cd79d1584829a98d50d6b1077541435b04a1ff321c451fc6c5322', 'artifact_path': 'wandb-client-artifact://7w1tlqrkzsim1vh1kbjuz1rrcoceda78uwerifxcd33xrfufkememu8kwdsd64gdkcodsr8z0zif6nz7huwnzh409uq5e8cm69fdqzg7vg2s3ntp93uxnv309t85h6hc:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://7w1tlqrkzsim1vh1kbjuz1rrcoceda78uwerifxcd33xrfufkememu8kwdsd64gdkcodsr8z0zif6nz7huwnzh409uq5e8cm69fdqzg7vg2s3ntp93uxnv309t85h6hc:latest/predictions.table.json', 'path': 'media/table/predictions_1_46e2e3e2cf9cd79d1584.table.json', 'size': 524560, '_type': 'table-file', 'ncols': 13}",78.14407184109768,0.3320270522970393,0.0,False,True,validation,False,Seller | Buyer | Neither | Unknown,4,CTBase,2da8f134-58db-4f9d-b3b0-8c6b50693ab5,craigslist_bargains,SENTIMENT,False,12,bigscience/T0_3B,0,True,categorize_rating_using_review,prompts/general_fixed_choice.yaml,AppReviews,['validation'],4,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,['Dialogue'],craigslist_bargains,True,False,GeneralFixedChoice,False,False,True,,,prompts,,False,True,categorize_rating_using_review,,cross_task,craigslist,,,,False,,,False,,True,,,False,False,CTBase.GenFC.app_reviews.categorize_rating_using_review.LenNorm,Craigslist,,,,,,,,,,,,,,,,,,,,,6.0,5.0,18
31.058995521116216,40.43715846994536,1.0232356475997215,2.598793558539258,2.648241206030151,0.4947721323376338,0.7230711687095407,59.13757700205339,2.4390243902439024,0.3841104539395177,3.8609715242881073,180.4070351758794,1.5710692876946786,1.7755443886097153,22.222222222222225,0.6436138169050616,0.8225496050207358,0.918700333278576,0.7475154713246787,1.7152428810720268,37.3534338358459,"{'nrows': 597, 'sha256': '45d6494398650ce37f44a796c15e3b7b65214f6d5701495afdebd947525fda87', 'artifact_path': 'wandb-client-artifact://utbh0w2f997beyyweia6uljida4xbdfg0imi1jshpo4ac38soy8ez24gt3h1u2t22bjczama0flakqhi8mxxqb49mxbs6n124okrfx4tem18arlou80iz05vwsxktv4x:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://utbh0w2f997beyyweia6uljida4xbdfg0imi1jshpo4ac38soy8ez24gt3h1u2t22bjczama0flakqhi8mxxqb49mxbs6n124okrfx4tem18arlou80iz05vwsxktv4x:latest/predictions.table.json', 'path': 'media/table/predictions_1_45d6494398650ce37f44.table.json', 'size': 523061, '_type': 'table-file', 'ncols': 13}",78.14407184109768,0.4367906986590803,0.4763425644639812,False,True,validation,False,Seller | Buyer | Neither | Unknown,4,CTBase,d34e1413-2699-4701-baa2-05d931d012ba,craigslist_bargains,SENTIMENT,False,12,bigscience/T0_3B,0,True,convert_to_rating,prompts/general_fixed_choice.yaml,AppReviews,['validation'],4,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,['Dialogue'],craigslist_bargains,True,False,GeneralFixedChoice,False,False,False,,,prompts,,False,True,convert_to_rating,,cross_task,craigslist,,,,False,,,False,,True,,,False,False,CTBase.GenFC.app_reviews.convert_to_rating.LenNorm,Craigslist,,,,,,,,,,,,,,,,,,,,,2.0,1.0,28
6.359649122807016,25.438596491228065,0.886436798345311,8.282846212786446,1.2428810720268006,1.001457048060856,0.4288238063329888,0.0,0.0,3.13867900119954,1.7571189279731994,162.47068676716918,0.3371421871472843,3.0,0.0,4.807025024439621,0.0,0.2551396378356323,0.0,4.0,14.57286432160804,"{'sha256': 'aa09cad255749b215e199d1325eb7356ee1a800f64e85e4cd3920538fa0768d5', 'artifact_path': 'wandb-client-artifact://26l2d1n8q2nd26xg0d18enp8g4jn5ip987e0gl765ab76vvzvhqns9lkp0pjrpkzwyolc705n65grkvp02y7hn1qts7ohx4bwugn6igzo8dii5m0r7vbj4izfea61nzf:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://26l2d1n8q2nd26xg0d18enp8g4jn5ip987e0gl765ab76vvzvhqns9lkp0pjrpkzwyolc705n65grkvp02y7hn1qts7ohx4bwugn6igzo8dii5m0r7vbj4izfea61nzf:latest/predictions.table.json', 'path': 'media/table/predictions_1_aa09cad255749b215e19.table.json', 'size': 488391, '_type': 'table-file', 'ncols': 13, 'nrows': 597}",78.1171728355754,0.6756400872186248,0.4288238063329888,False,True,validation,False,Seller | Buyer | Neither | Unknown,4,CTBase,96538f30-f2c1-430e-8fc6-936a16966d9c,craigslist_bargains,SENTIMENT,False,12,bigscience/T0_3B,0,True,Writer_Expressed_Sentiment,prompts/general_fixed_choice.yaml,IMDB,['validation'],4,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,['Dialogue'],craigslist_bargains,True,False,GeneralFixedChoice,False,False,False,,,prompts,,False,True,Writer Expressed Sentiment,,cross_task,craigslist,,,,False,,,False,,True,,,False,False,CTBase.GenFC.imdb.Writer_Expressed_Sentiment.LenNorm,Craigslist,,,,,,,,,,,,,,,,,,,,,84.5,87.0,10
6.709096522942999,25.47584187408492,1.0552425370357892,7.761861613447742,1.949748743718593,1.1048261762013214,0.2184629660229564,0.0,1.3605442176870748,3.207753386729127,1.050251256281407,161.47068676716918,0.8282929361365748,3.0016750418760467,0.0,3.72581529058204,0.0408929836372988,0.4791772535532375,0.0408929836372988,3.9983249581239537,14.74036850921273,"{'_latest_artifact_path': 'wandb-client-artifact://uud7dpnxrwbn7jvnqvry3qphjaikp9wldbezo4uv2v19o5510oabz3fvqo9ioo3u4jl66nthrmgiou81y9kzgifrz000zejkd07ndbjmmemskjbofwk11zusf0q54uv8:latest/predictions.table.json', 'path': 'media/table/predictions_1_68041d300c431a27fa8b.table.json', 'size': 481210, '_type': 'table-file', 'ncols': 13, 'nrows': 597, 'sha256': '68041d300c431a27fa8b4a9a8a36133e627ee4c59e66ef30e92bd476520eb7fb', 'artifact_path': 'wandb-client-artifact://uud7dpnxrwbn7jvnqvry3qphjaikp9wldbezo4uv2v19o5510oabz3fvqo9ioo3u4jl66nthrmgiou81y9kzgifrz000zejkd07ndbjmmemskjbofwk11zusf0q54uv8:latest/predictions.table.json'}",78.1171728355754,0.7037211932629795,0.2184629660229564,False,True,validation,False,Seller | Buyer | Neither | Unknown,4,CTBase,866474a5-1498-46b7-bfee-ac0c5160707f,craigslist_bargains,SENTIMENT,False,12,bigscience/T0_3B,0,True,Reviewer_Sentiment_Feeling,prompts/general_fixed_choice.yaml,IMDB,['validation'],4,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,['Dialogue'],craigslist_bargains,True,False,GeneralFixedChoice,False,False,False,,,prompts,,False,True,Reviewer Sentiment Feeling,,cross_task,craigslist,,,,False,,,False,,True,,,False,False,CTBase.GenFC.imdb.Reviewer_Sentiment_Feeling.LenNorm,Craigslist,,,,,,,,,,,,,,,,,,,,,82.0,85.0,9
16.0729036188043,31.197771587743738,0.5798266754865252,2.6606799545799267,2.157453936348409,0.3067732341082965,0.6739957228928126,16.560509554140125,0.0,0.4624424172406221,3.949748743718593,173.47068676716918,1.7809607331676898,1.984924623115578,16.533333333333335,0.4172768041716149,0.9623257714857943,0.6715835972665207,0.8286464496803019,1.9078726968174204,18.927973199329983,"{'_type': 'table-file', 'ncols': 13, 'nrows': 597, 'sha256': '3ca4eb0b36b3e7d46c1686c16f3d80d68408ee2298d5e14f33af189583ed4fb4', 'artifact_path': 'wandb-client-artifact://a17m5uwlh14nb6k41am4i6jjanr2utkmytp77g7527rfgkqbve4u2lvh48l8dgn776zuic39wjg21cjakwup4dkxcn0wboombbmxy3sjhu4goc8su602occ8q13a3ry8:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://a17m5uwlh14nb6k41am4i6jjanr2utkmytp77g7527rfgkqbve4u2lvh48l8dgn776zuic39wjg21cjakwup4dkxcn0wboombbmxy3sjhu4goc8su602occ8q13a3ry8:latest/predictions.table.json', 'path': 'media/table/predictions_1_3ca4eb0b36b3e7d46c16.table.json', 'size': 496995}",78.1171728355754,0.3827031827851685,0.3130132965306017,False,True,validation,False,Seller | Buyer | Neither | Unknown,4,CTBase,5f372fb1-795a-47b6-8ddf-c4fd1579e76a,craigslist_bargains,SENTIMENT,False,12,bigscience/T0_3B,0,True,Sentiment_with_choices,prompts/general_fixed_choice.yaml,IMDB,['validation'],4,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,['Dialogue'],craigslist_bargains,True,False,GeneralFixedChoice,False,False,True,,,prompts,,False,True,Sentiment with choices ,,cross_task,craigslist,,,,False,,,False,,True,,,False,False,CTBase.GenFC.imdb.Sentiment_with_choices.LenNorm,Craigslist,,,,,,,,,,,,,,,,,,,,,43.0,31.0,6
6.359649122807016,25.438596491228065,0.6138722134212582,4.630671319051005,1.6917922948073705,0.2941816148069054,0.9034549192015102,0.0,0.0,3.2975335847992,3.5510887772194306,176.47068676716918,0.944970579802291,3.0,0.0,0.388167154449514,0.0,0.6324795970260536,0.8641203198800913,1.7571189279731994,14.57286432160804,"{'size': 506457, '_type': 'table-file', 'ncols': 13, 'nrows': 597, 'sha256': 'e20d2c76bf1d5ff94c2fc687096bb3eaafb7def3f36b2ea3d710b791a3f430e2', 'artifact_path': 'wandb-client-artifact://7dkgd2r6hz4f8zya5vgmmxns6u145ybukh3m0np27qmqbjvtfjepimx7d7kibia6ccimtc88zsto3q0cihog86r4gcuffihr0tbq4cakfz32snztfvqlkf72rvjzpq98:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://7dkgd2r6hz4f8zya5vgmmxns6u145ybukh3m0np27qmqbjvtfjepimx7d7kibia6ccimtc88zsto3q0cihog86r4gcuffihr0tbq4cakfz32snztfvqlkf72rvjzpq98:latest/predictions.table.json', 'path': 'media/table/predictions_1_e20d2c76bf1d5ff94c2f.table.json'}",78.1171728355754,0.7346770735106086,0.9365925913842468,False,True,validation,False,Seller | Buyer | Neither | Unknown,4,CTBase,2351d12a-e630-4d19-8b41-e199266e38f7,craigslist_bargains,SENTIMENT,False,12,bigscience/T0_3B,0,True,Reviewer_Opinion_bad_good_choices,prompts/general_fixed_choice.yaml,IMDB,['validation'],4,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,['Dialogue'],craigslist_bargains,True,False,GeneralFixedChoice,False,False,True,,,prompts,,False,True,Reviewer Opinion bad good choices,,cross_task,craigslist,,,,False,,,False,,True,,,False,False,CTBase.GenFC.imdb.Reviewer_Opinion_bad_good_choices.LenNorm,Craigslist,,,,,,,,,,,,,,,,,,,,,84.5,87.0,9
7.97505657001526,25.448613376835237,1.0735692534701735,7.704248378025228,1.7922948073701843,1.144946955682449,0.4056645727499838,0.0,6.451612903225806,1.1598065262863184,1.2110552763819096,162.47068676716918,0.4790853583433321,3.11892797319933,0.0,6.065356493395577,0.3237037386099046,0.3430484410940493,0.3326803533298922,3.877721943048576,14.23785594639866,"{'nrows': 597, 'sha256': 'ad2a2bab9515f1789cf1343d712c28c772b7a966d8ab6b6a23641cc19c14f8bc', 'artifact_path': 'wandb-client-artifact://124nqg4hx09wgem9tm65qdnw0rwz8in6npoafvf3o8cysnordrit4o02p54ej4mpxzjgqnwluf8d6gid3uoxfsst201mw86se723xsu6cfa836zy0w4lxatcjpuxzz3t:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://124nqg4hx09wgem9tm65qdnw0rwz8in6npoafvf3o8cysnordrit4o02p54ej4mpxzjgqnwluf8d6gid3uoxfsst201mw86se723xsu6cfa836zy0w4lxatcjpuxzz3t:latest/predictions.table.json', 'path': 'media/table/predictions_1_ad2a2bab9515f1789cf1.table.json', 'size': 484280, '_type': 'table-file', 'ncols': 13}",78.1171728355754,0.8310853850969592,0.4201918584998366,False,True,validation,False,Seller | Buyer | Neither | Unknown,4,CTBase,02ff2949-0f45-4d97-941e-6fa4c0afbc2d,craigslist_bargains,SENTIMENT,False,12,bigscience/T0_3B,0,True,Movie_Expressed_Sentiment_2,prompts/general_fixed_choice.yaml,IMDB,['validation'],4,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,['Dialogue'],craigslist_bargains,True,False,GeneralFixedChoice,False,False,False,,,prompts,,False,True,Movie Expressed Sentiment 2,,cross_task,craigslist,,,,False,,,False,,True,,,False,False,CTBase.GenFC.imdb.Movie_Expressed_Sentiment_2.LenNorm,Craigslist,,,,,,,,,,,,,,,,,,,,,88.0,77.0,10
17.171054576631978,28.571428571428577,0.6376419390449685,6.538341927168957,2.0251256281407035,0.4287599037125706,0.4818708577835501,15.89403973509934,0.0,0.572403378223055,4.0,174.5075376884422,5.358863196380973,2.403685092127303,24.218750000000004,0.6070753525649283,0.8851197695005293,0.6228356740434795,0.7980550641692683,1.5711892797319933,20.938023450586265,"{'size': 502805, '_type': 'table-file', 'ncols': 13, 'nrows': 597, 'sha256': '1c9fd7baf1434327aded7a0fff1589df3a3c5680506f40c5c3bb1117669d8b0d', 'artifact_path': 'wandb-client-artifact://11q2un949kzzzpjexpekfxvwkspi92qp86s6yz2eo0vi5ubgk8fqhc27zf2y3452rnsbifj0rcb8nloouhyu80pzueqsmiapkiu07ryipv8tefawhp52qvok0iquk6kn:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://11q2un949kzzzpjexpekfxvwkspi92qp86s6yz2eo0vi5ubgk8fqhc27zf2y3452rnsbifj0rcb8nloouhyu80pzueqsmiapkiu07ryipv8tefawhp52qvok0iquk6kn:latest/predictions.table.json', 'path': 'media/table/predictions_1_1c9fd7baf1434327aded.table.json'}",78.326585290588,0.473405141924909,0.0,False,True,validation,False,Seller | Buyer | Neither | Unknown,4,CTBase,f56ffced-9b16-431a-8a17-501e63cddf73,craigslist_bargains,ENTAILMENT,False,12,bigscience/T0_3B,0,True,imply_separated,prompts/general_fixed_choice.yaml,RTE,['validation'],4,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,['Dialogue'],craigslist_bargains,False,False,GeneralFixedChoice,False,False,True,,,prompts,,False,True,imply separated,,cross_task,craigslist,,,,False,,,False,,True,,,False,False,CTBase.GenFC.super_glue_rte.imply_separated.LenNorm,Craigslist,,,,,,,,,,,,,,,,,,,,,32.0,25.0,6
14.953368421891716,23.36448598130841,0.5769139291939581,7.236794668226386,2.3467336683417086,0.4527284810024178,0.4829177974398937,7.773851590106007,0.0,0.5274653306957865,4.0,179.89782244556113,6.076182398165091,1.4472361809045229,28.67513611615245,0.6331469393655084,0.8201686508946636,0.666054434211534,0.7911341766875533,2.2060301507537687,19.262981574539364,"{'nrows': 597, 'sha256': 'af3708afd3445b8303f795229c4de284ce9aa8e4414315255176f466b05db2a9', 'artifact_path': 'wandb-client-artifact://5nhobx4peu2hxgfcnfd6j1yasci2vdfxgdxavvswliyemxnsdppionm8sd5igl3f2cmae7dn2fee1n1366fjnf23u48so7ulpxx4nnibll3hse5uy3xs9be9fq22fqe4:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://5nhobx4peu2hxgfcnfd6j1yasci2vdfxgdxavvswliyemxnsdppionm8sd5igl3f2cmae7dn2fee1n1366fjnf23u48so7ulpxx4nnibll3hse5uy3xs9be9fq22fqe4:latest/predictions.table.json', 'path': 'media/table/predictions_1_af3708afd3445b8303f7.table.json', 'size': 512746, '_type': 'table-file', 'ncols': 13}",78.39876557809747,0.3685075213030848,0.0,False,True,validation,False,Seller | Buyer | Neither | Unknown,4,CTBase,c8dfc879-40f2-412d-be1e-4cd70107f6e6,craigslist_bargains,ENTAILMENT,False,12,bigscience/T0_3B,0,True,imply,prompts/general_fixed_choice.yaml,RTE,['validation'],4,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,['Dialogue'],craigslist_bargains,False,False,GeneralFixedChoice,False,False,True,,,prompts,,False,True,imply,,cross_task,craigslist,,,,False,,,False,,True,,,False,False,CTBase.GenFC.super_glue_rte.imply.LenNorm,Craigslist,,,,,,,,,,,,,,,,,,,,,40.5,37.0,14
17.540125075824793,26.900584795321635,0.3969892443623345,6.357915014078469,2.207705192629816,0.3431967496367853,0.5115820309541249,14.61794019933555,0.0,0.423719204051211,4.0,207.5075376884422,5.450476969107112,1.9061976549413733,28.64197530864197,0.4837188409201464,0.9691619172790727,0.481179178765495,0.8567933344932676,1.8860971524288108,21.105527638190956,"{'sha256': 'fc9615104af27f1260bb05b8983fdb487ee405a7134f8f6a1a6bfaf646839685', 'artifact_path': 'wandb-client-artifact://v5yk4zl9p0419qljc04yh97eozjgnrq9gyrie20rfy0we2qp0c0svu6ou2zjpr25e7lk18qhnm9y0ftis3rsop189ah7pqx3o4pvfbdj4pfaicgftgvo3xr7v0q5yhva:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://v5yk4zl9p0419qljc04yh97eozjgnrq9gyrie20rfy0we2qp0c0svu6ou2zjpr25e7lk18qhnm9y0ftis3rsop189ah7pqx3o4pvfbdj4pfaicgftgvo3xr7v0q5yhva:latest/predictions.table.json', 'path': 'media/table/predictions_1_fc9615104af27f1260bb.table.json', 'size': 606592, '_type': 'table-file', 'ncols': 13, 'nrows': 597}",78.326585290588,0.333410198720046,0.0,False,True,validation,False,Seller | Buyer | Neither | Unknown,4,CTBase,9e2b4267-ec23-44c8-b82a-107e2c890fec,craigslist_bargains,ENTAILMENT,False,12,bigscience/T0_3B,0,True,entailment_explained,prompts/general_fixed_choice.yaml,RTE,['validation'],4,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,['Dialogue'],craigslist_bargains,False,False,GeneralFixedChoice,False,False,True,,,prompts,,False,True,entailment explained,,cross_task,craigslist,,,,False,,,False,,True,,,False,False,CTBase.GenFC.super_glue_rte.entailment_explained.LenNorm,Craigslist,,,,,,,,,,,,,,,,,,,,,30.5,20.0,40
15.822068559148727,16.666666666666668,0.541295061446438,7.14606613609659,2.658291457286432,0.4231169999348276,0.5181649383423748,20.858895705521476,0.0,0.5365508852691906,4.0,183.89782244556116,6.011463539085197,1.2445561139028476,25.76271186440678,0.5980517117422031,0.5792255086749944,0.708543434227481,0.6184829864847964,2.09715242881072,20.268006700167504,"{'size': 527510, '_type': 'table-file', 'ncols': 13, 'nrows': 597, 'sha256': '5d38b632b00552cc12dbb752615c48eb82a7412d5cc8cd744997bc0a1ab9dc65', 'artifact_path': 'wandb-client-artifact://z336u5al2zmgombglmauyc72vnosrrr16h5cehr3vh5fknvg1y35empzt49o02vps2h0e37rozfun3bm5jv7kih8vrk0syzxjp6goxqzbwzutlrilsttket6wp002x8p:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://z336u5al2zmgombglmauyc72vnosrrr16h5cehr3vh5fknvg1y35empzt49o02vps2h0e37rozfun3bm5jv7kih8vrk0syzxjp6goxqzbwzutlrilsttket6wp002x8p:latest/predictions.table.json', 'path': 'media/table/predictions_1_5d38b632b00552cc12db.table.json'}",78.39876557809747,0.3843152855215292,0.0,False,True,validation,False,Seller | Buyer | Neither | Unknown,4,CTBase,4ee6ff27-de63-4e7b-a9d4-82a17eba407a,craigslist_bargains,ENTAILMENT,False,12,bigscience/T0_3B,0,True,does_the_claim_follow_the_fact,prompts/general_fixed_choice.yaml,RTE,['validation'],4,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,['Dialogue'],craigslist_bargains,False,False,GeneralFixedChoice,False,False,True,,,prompts,,False,True,does the claim follow the fact,,cross_task,craigslist,,,,False,,,False,,True,,,False,False,CTBase.GenFC.super_glue_rte.does_the_claim_follow_the_fact.LenNorm,Craigslist,,,,,,,,,,,,,,,,,,,,,33.5,33.0,18
8.692778360027491,25.74850299401197,0.56017062219548,6.823886019900017,1.5812395309882747,0.3027294146637534,0.5034385661240967,4.98220640569395,0.0,1.1142799091498856,4.0,176.5075376884422,5.288954011159926,2.9648241206030157,4.040404040404041,0.4206520995902056,0.2251420788437886,0.6253974115606832,0.5398418553421879,1.4539363484087102,15.912897822445563,"{'ncols': 13, 'nrows': 597, 'sha256': 'b565b22cde4e922fb64c0cf523bcfe10b428780ec12dff107966dfd6640c686e', 'artifact_path': 'wandb-client-artifact://1d7hqdyocxmx4zh5k9nxqodl1oxn8xw9xl1j80jcj3uapr7l3oz21prszh3s1tw4vndhfqwfu80lsk9r4xf7wuqanq7nyjb9vpzpd7blddy1sqo0hkvcja47dzld9oo3:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://1d7hqdyocxmx4zh5k9nxqodl1oxn8xw9xl1j80jcj3uapr7l3oz21prszh3s1tw4vndhfqwfu80lsk9r4xf7wuqanq7nyjb9vpzpd7blddy1sqo0hkvcja47dzld9oo3:latest/predictions.table.json', 'path': 'media/table/predictions_1_b565b22cde4e922fb64c.table.json', 'size': 504736, '_type': 'table-file'}",78.326585290588,0.5967554489955728,0.0,False,True,validation,False,Seller | Buyer | Neither | Unknown,4,CTBase,03a7ae07-5ddd-46c4-92f3-2152223d44ec,craigslist_bargains,ENTAILMENT,False,12,bigscience/T0_3B,0,True,mean,prompts/general_fixed_choice.yaml,RTE,['validation'],4,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,['Dialogue'],craigslist_bargains,False,False,GeneralFixedChoice,False,False,True,,,prompts,,False,True,mean,,cross_task,craigslist,,,,False,,,False,,True,,,False,False,CTBase.GenFC.super_glue_rte.mean.LenNorm,Craigslist,,,,,,,,,,,,,,,,,,,,,72.0,71.0,9
14.19261726079228,29.82005141388175,1.3458208954701203,3.1365744727141096,3.056951423785595,0.6509076309525134,1.2264967279903378,0.0,8.823529411764707,0.7171032970874154,2.1943048576214403,157.5075376884422,1.5947862450201906,2.303182579564489,18.12688821752266,0.8246849306065034,1.095234043426693,1.146620411643161,1.2288278906972638,2.4455611390284755,16.24790619765494,"{'_latest_artifact_path': 'wandb-client-artifact://d2hvvzy9eu4bxyx4el6ltp5julzis35vhuhquh67kbrsbh6d633xv7vr7g6msh3308aq85omrmi31djyzal78h1dsxalvexse107rw52zxafybhaqzkkqufqipz7uuzz:latest/predictions.table.json', 'path': 'media/table/predictions_1_11e231f7566123dfce3c.table.json', 'size': 466956, '_type': 'table-file', 'ncols': 13, 'nrows': 597, 'sha256': '11e231f7566123dfce3c857db78bd240784f1dd99288465a29c22cdb55e0ffff', 'artifact_path': 'wandb-client-artifact://d2hvvzy9eu4bxyx4el6ltp5julzis35vhuhquh67kbrsbh6d633xv7vr7g6msh3308aq85omrmi31djyzal78h1dsxalvexse107rw52zxafybhaqzkkqufqipz7uuzz:latest/predictions.table.json'}",78.326585290588,0.5966185435904988,0.5837851370935297,False,True,validation,False,Seller | Buyer | Neither | Unknown,4,CTBase,f2004e15-9d9a-4ca1-9830-a341e684e97e,craigslist_bargains,QA,False,12,bigscience/T0_3B,0,True,qa_no_choices_and_answer,prompts/general_fixed_choice.yaml,No Prompt,['validation'],4,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,['Dialogue'],craigslist_bargains,False,False,GeneralFixedChoice,False,False,False,,,prompts,,False,True,qa no choices and answer,,cross_task,craigslist,,,,False,,,False,,True,,,False,False,CTBase.GenFC.BAREBONES.qa_no_choices_and_answer.LenNorm,Craigslist,,,,,,,,,,,,,,,,,,,,,66.0,45.0,0
11.01880779525374,26.32375189107413,1.6101665495490085,4.373602574893977,1.4539363484087102,1.0093739091441876,0.7135717712083297,0.0,17.75147928994083,2.0702465975304545,1.9078726968174204,154.5075376884422,0.7850826389625843,3.038525963149078,0.0,1.518273338400938,0.1924622386664837,1.139285477064533,0.9344692175722852,3.5996649916247905,17.08542713567839,"{'nrows': 597, 'sha256': 'bf8fb7716a0adac8aea316086211dba61818a350b62933b59933a700a60a2d51', 'artifact_path': 'wandb-client-artifact://h0g2snraerntrsdc0eh5o3sez7eewnjm7y30r2tpsrl8f5fphojldlegknf7un1bkb76109rlm1nzchnrzyrytqyabi44y2b82r9kp1g5zjkmnv8s5z7c3rodntdjx7k:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://h0g2snraerntrsdc0eh5o3sez7eewnjm7y30r2tpsrl8f5fphojldlegknf7un1bkb76109rlm1nzchnrzyrytqyabi44y2b82r9kp1g5zjkmnv8s5z7c3rodntdjx7k:latest/predictions.table.json', 'path': 'media/table/predictions_1_bf8fb7716a0adac8aea3.table.json', 'size': 461088, '_type': 'table-file', 'ncols': 13}",78.326585290588,1.0674181896181676,0.7977491349330076,False,True,validation,False,Seller | Buyer | Neither | Unknown,4,CTBase,e5eaa3ee-e537-4d20-9dfa-6084db54f2ef,craigslist_bargains,ENTAILMENT,False,12,bigscience/T0_3B,0,True,entailment_no_choices_and_answer,prompts/general_fixed_choice.yaml,No Prompt,['validation'],4,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,['Dialogue'],craigslist_bargains,False,False,GeneralFixedChoice,False,False,False,,,prompts,,False,True,entailment no choices and answer,,cross_task,craigslist,,,,False,,,False,,True,,,False,False,CTBase.GenFC.BAREBONES.entailment_no_choices_and_answer.LenNorm,Craigslist,,,,,,,,,,,,,,,,,,,,,55.0,58.0,2
13.205128205128204,26.15384615384615,1.5997652309351542,4.297998430541212,1.4489112227805696,1.0129882626621645,0.8364515786194002,0.0,26.666666666666668,1.8537378958122217,2.0150753768844223,154.47068676716918,0.9035363412981656,3.056951423785595,0.0,1.5407241934308256,0.2317497769457141,1.0885878619196596,1.0773970390452616,3.479061976549413,18.257956448911223,"{'nrows': 597, 'sha256': 'a1f838fb6ddbe7eb1cd797a62b79a131fb658dd5cad1d7df7d6fdff9b3e518bb', 'artifact_path': 'wandb-client-artifact://x39uhli5qcjr716ypledp922io8ryedmsgkwskh26nqfkx4h5ynrxq6jfqbew8m44io0uf5n5bw17dm5ecxxi3ywhybu2yrb8igjfiz2cdd5no0r58806qer1bs4hndh:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://x39uhli5qcjr716ypledp922io8ryedmsgkwskh26nqfkx4h5ynrxq6jfqbew8m44io0uf5n5bw17dm5ecxxi3ywhybu2yrb8igjfiz2cdd5no0r58806qer1bs4hndh:latest/predictions.table.json', 'path': 'media/table/predictions_1_a1f838fb6ddbe7eb1cd7.table.json', 'size': 460497, '_type': 'table-file', 'ncols': 13}",78.1171728355754,1.046902154400013,0.6907674483392797,False,True,validation,False,Seller | Buyer | Neither | Unknown,4,CTBase,cf005ddf-8cf2-409d-b884-45d22463f463,craigslist_bargains,CLASSIFICATION,False,12,bigscience/T0_3B,0,True,classification_no_choices_and_answer,prompts/general_fixed_choice.yaml,No Prompt,['validation'],4,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,['Dialogue'],craigslist_bargains,False,False,GeneralFixedChoice,False,False,False,,,prompts,,False,True,classification no choices and answer,,cross_task,craigslist,,,,False,,,False,,True,,,False,False,CTBase.GenFC.BAREBONES.classification_no_choices_and_answer.LenNorm,Craigslist,,,,,,,,,,,,,,,,,,,,,46.0,51.0,2
10.099825947040394,26.644736842105267,1.1909749145923407,6.661064747190555,1.6666666666666667,0.6191986790727776,0.5680886680660303,8.080808080808081,0.0,1.603236546069134,3.9899497487437183,277.4857621440536,4.447364033965809,2.8006700167504186,5.673758865248227,0.6104641671556125,0.568991779272688,0.9767453193455948,0.6342549989702574,1.542713567839196,16.24790619765494,"{'_latest_artifact_path': 'wandb-client-artifact://qqm0igiwapg7dvz8ohk88j9y54dnpwyfm0o2qwp8eq46i2u778mkd9gk7ob01wlfa5pawxtjl47k7cczpril2bjiktdw0i3ifbpvxl8czjo33chz4hkx7hqd2tm2vi44:latest/predictions.table.json', 'path': 'media/table/predictions_1_d675d67fee8190acfa77.table.json', 'size': 750546, '_type': 'table-file', 'ncols': 13, 'nrows': 597, 'sha256': 'd675d67fee8190acfa77a6a97d9b584fe4a56769b1b0ac06671262d724544ebc', 'artifact_path': 'wandb-client-artifact://qqm0igiwapg7dvz8ohk88j9y54dnpwyfm0o2qwp8eq46i2u778mkd9gk7ob01wlfa5pawxtjl47k7cczpril2bjiktdw0i3ifbpvxl8czjo33chz4hkx7hqd2tm2vi44:latest/predictions.table.json'}",154.69274203125838,1.061172919998477,0.1733486262377924,False,True,validation,False,Seller | Buyer | Neither | Unknown,4,CTBase,2e94d035-3c3d-44cf-98cb-3d11bea7c17b,craigslist_bargains,QA,False,12,bigscience/T0_3B,0,True,qa_choices_and_answer,prompts/general_fixed_choice.yaml,No Prompt,['validation'],4,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,['Dialogue'],craigslist_bargains,False,False,GeneralFixedChoice,False,False,True,,,prompts,,False,True,qa choices and answer,,cross_task,craigslist,,,,False,,,False,,True,,,False,False,CTBase.GenFC.BAREBONES.qa_choices_and_answer.LenNorm,Craigslist,,,,,,,,,,,,,,,,,,,,,66.0,68.0,2
16.360028860028862,27.77777777777778,0.7763520290236907,6.835233524017398,2.018425460636516,0.5381162131534013,0.5317354412226615,16.883116883116884,0.0,0.5322554428972791,4.0,170.5075376884422,5.662802533288697,2.219430485762144,20.77922077922078,0.6401755478314219,0.9424429269873096,0.8408315016478608,0.8508784067072414,1.76214405360134,19.76549413735344,"{'sha256': 'a8f451ff6dec2bce8061d793df16419e63c4d547a18b0f5b9272318d3c433b0f', 'artifact_path': 'wandb-client-artifact://11xci282x0hkzkrg2tnb24bg83mnb39styxycozr5tgpy64csoj9oi5nzqc06esysc8jm94kprvpskc8p2scs3kplub39juevxb70kucgixitrv650vd0mji4ljmvuk0:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://11xci282x0hkzkrg2tnb24bg83mnb39styxycozr5tgpy64csoj9oi5nzqc06esysc8jm94kprvpskc8p2scs3kplub39juevxb70kucgixitrv650vd0mji4ljmvuk0:latest/predictions.table.json', 'path': 'media/table/predictions_1_a8f451ff6dec2bce8061.table.json', 'size': 491486, '_type': 'table-file', 'ncols': 13, 'nrows': 597}",78.326585290588,0.4541554713139189,0.0,False,True,validation,False,Seller | Buyer | Neither | Unknown,4,CTBase,c225e598-1efe-4cb6-9f7c-a1b7eb5c7803,craigslist_bargains,ENTAILMENT,False,12,bigscience/T0_3B,0,True,entailment_choices_and_answer,prompts/general_fixed_choice.yaml,No Prompt,['validation'],4,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,['Dialogue'],craigslist_bargains,False,False,GeneralFixedChoice,False,False,True,,,prompts,,False,True,entailment choices and answer,,cross_task,craigslist,,,,False,,,False,,True,,,False,False,CTBase.GenFC.BAREBONES.entailment_choices_and_answer.LenNorm,Craigslist,,,,,,,,,,,,,,,,,,,,,36.5,29.0,2
14.215100697891796,23.85786802030457,0.975106461594658,6.367006467015699,2.134003350083752,0.5666204510906185,0.6277765555306036,15.479876160990711,0.0,0.6606914300215704,4.0,170.47068676716918,5.0914205139006805,2.117252931323283,17.522658610271904,0.6148945230934488,0.9473513237788882,1.0286904812810558,0.7833180701199589,1.7487437185929648,16.917922948073702,"{'path': 'media/table/predictions_1_c7a53f3704ecd5da3a90.table.json', 'size': 492056, '_type': 'table-file', 'ncols': 13, 'nrows': 597, 'sha256': 'c7a53f3704ecd5da3a901162236a5a2a89cfd4c60c0347f06eb4eae23344f2e0', 'artifact_path': 'wandb-client-artifact://v55ys5rh95uzswp884e0nv5u9xqw5s7fo4muv4ciqapvhxwmt7yjf97inqvrhaabonng4ihkhufghjhs1nysn7ce0m8fapqwv0jwdhu4h7szlbc9wx35gdc5rg2dlda6:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://v55ys5rh95uzswp884e0nv5u9xqw5s7fo4muv4ciqapvhxwmt7yjf97inqvrhaabonng4ihkhufghjhs1nysn7ce0m8fapqwv0jwdhu4h7szlbc9wx35gdc5rg2dlda6:latest/predictions.table.json'}",78.1171728355754,0.5704718423678206,0.0,False,True,validation,False,Seller | Buyer | Neither | Unknown,4,CTBase,32a28538-99bc-4c5a-8086-83b885fddb50,craigslist_bargains,CLASSIFICATION,False,12,bigscience/T0_3B,0,True,classification_choices_and_answer,prompts/general_fixed_choice.yaml,No Prompt,['validation'],4,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,['Dialogue'],craigslist_bargains,False,False,GeneralFixedChoice,False,False,True,,,prompts,,False,True,classification choices and answer,,cross_task,craigslist,,,,False,,,False,,True,,,False,False,CTBase.GenFC.BAREBONES.classification_choices_and_answer.LenNorm,Craigslist,,,,,,,,,,,,,,,,,,,,,57.0,44.0,2
15.38308020835412,25.57726465364121,1.9290435297271,9.101072868110746,1.3685092127303182,2.2271560278564584,0.5350808470658431,0.0,35.95505617977528,2.270631856055715,1.7202680067001674,259.5460636515913,0.707646408272748,3.202680067001675,0.0,6.122794603782284,0.4019960913266092,0.5800194334780304,0.6251116244183285,3.708542713567839,20.100502512562816,"{'_type': 'table-file', 'ncols': 13, 'nrows': 597, 'sha256': '26d6f5bedf30ba8635237cb18a65910937e272214ca36f073835824e59c07533', 'artifact_path': 'wandb-client-artifact://145zvbbyls4aw2tzsnvon63dpawketewve8kpn0kbhhespix8p85dgjbwimz4zt317mho9rkvgvdv1yedtl9l4okkn53bk9d3p2adjz5vsxyqs552seslce6ftski13h:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://145zvbbyls4aw2tzsnvon63dpawketewve8kpn0kbhhespix8p85dgjbwimz4zt317mho9rkvgvdv1yedtl9l4okkn53bk9d3p2adjz5vsxyqs552seslce6ftski13h:latest/predictions.table.json', 'path': 'media/table/predictions_1_26d6f5bedf30ba863523.table.json', 'size': 711652}",154.98696105122986,1.7048800445502743,0.56456614895654,False,True,validation,False,Seller | Buyer | Neither | Unknown,4,CTBase,97030be6-9843-4fc2-98cf-b47b879b5447,craigslist_bargains,QA,False,12,bigscience/T0_3B,0,True,qa_no_choices,prompts/general_fixed_choice.yaml,No Prompt,['validation'],4,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,['Dialogue'],craigslist_bargains,False,False,GeneralFixedChoice,False,False,False,,,prompts,,False,True,qa no choices,,cross_task,craigslist,,,,False,,,False,,True,,,False,False,CTBase.GenFC.BAREBONES.qa_no_choices.LenNorm,Craigslist,,,,,,,,,,,,,,,,,,,,,35.0,34.0,0
10.509469191784476,26.08695652173913,1.5806676640980275,4.4817626622054645,1.64321608040201,1.045147413486895,0.6787082828496771,0.0,15.950920245398772,2.219503086615647,1.6164154103852597,152.5075376884422,0.6328116253991822,3.0284757118927974,0.0,1.6294479501906352,0.1663275254580423,0.927669097705268,0.7617813483398237,3.711892797319933,16.750418760469014,"{'nrows': 597, 'sha256': '4e76774ac2e8d3854221de4025ad1da5119d22bb473daa234e3ea6eee9ea8918', 'artifact_path': 'wandb-client-artifact://gwf6ohim18fa9rub7fq050mukt18b4l40kkbzg6dtj5yn2bv4bext4mcyr9uezkrh60onoxo4fme9pl82r3oarm0t383xb018cbrdfsaitf4g6p7shgy6n413evpg537:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://gwf6ohim18fa9rub7fq050mukt18b4l40kkbzg6dtj5yn2bv4bext4mcyr9uezkrh60onoxo4fme9pl82r3oarm0t383xb018cbrdfsaitf4g6p7shgy6n413evpg537:latest/predictions.table.json', 'path': 'media/table/predictions_1_4e76774ac2e8d3854221.table.json', 'size': 455694, '_type': 'table-file', 'ncols': 13}",78.326585290588,1.1305673714560518,0.8176846924364746,False,True,validation,False,Seller | Buyer | Neither | Unknown,4,CTBase,cc2958ca-e826-4fef-96aa-1c4caa188605,craigslist_bargains,ENTAILMENT,False,12,bigscience/T0_3B,0,True,entailment_no_choices,prompts/general_fixed_choice.yaml,No Prompt,['validation'],4,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,['Dialogue'],craigslist_bargains,False,False,GeneralFixedChoice,False,False,False,,,prompts,,False,True,entailment no choices,,cross_task,craigslist,,,,False,,,False,,True,,,False,False,CTBase.GenFC.BAREBONES.entailment_no_choices.LenNorm,Craigslist,,,,,,,,,,,,,,,,,,,,,58.5,65.0,0
13.849325337331331,26.086956521739125,1.5541133118963353,5.091925836687711,1.3031825795644891,1.304939797535578,0.5431528300722149,0.0,29.310344827586203,1.84763772204094,1.88107202680067,152.47068676716918,0.737192161119164,3.1440536013400333,0.0,2.507095953527607,0.3511440748197243,0.8169026103644984,0.7587033716680979,3.671691792294808,18.76046901172529,"{'path': 'media/table/predictions_1_e0add884b0637768012e.table.json', 'size': 451687, '_type': 'table-file', 'ncols': 13, 'nrows': 597, 'sha256': 'e0add884b0637768012e68db618f44791770629045eaa35ebdabe6720a94f5f8', 'artifact_path': 'wandb-client-artifact://s4f0j9zivs26yfqv310i48kbml88x8j7j9fxta0kz133iheg964zwjgcuv6s6xot67ymshsivkfm5vs1i24dwhp255rwgrrkxftk9d03qt215nrlizcadnj1me82owge:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://s4f0j9zivs26yfqv310i48kbml88x8j7j9fxta0kz133iheg964zwjgcuv6s6xot67ymshsivkfm5vs1i24dwhp255rwgrrkxftk9d03qt215nrlizcadnj1me82owge:latest/predictions.table.json'}",78.1171728355754,1.2741216888127591,0.6347767830713233,False,True,validation,False,Seller | Buyer | Neither | Unknown,4,CTBase,74693ecc-f903-488c-968d-6a2bc8e76611,craigslist_bargains,CLASSIFICATION,False,12,bigscience/T0_3B,0,True,classification_no_choices,prompts/general_fixed_choice.yaml,No Prompt,['validation'],4,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,['Dialogue'],craigslist_bargains,False,False,GeneralFixedChoice,False,False,False,,,prompts,,False,True,classification no choices,,cross_task,craigslist,,,,False,,,False,,True,,,False,False,CTBase.GenFC.BAREBONES.classification_no_choices.LenNorm,Craigslist,,,,,,,,,,,,,,,,,,,,,44.0,47.0,0
6.268436578171093,25.07374631268437,1.0367755611021037,7.843590509552053,1.490787269681742,0.5676994319898951,0.5098679994433505,0.0,0.0,3.2015643167735344,3.9899497487437183,275.4924623115578,4.089208967921323,2.991624790619765,0.0,0.5528172248571961,0.1582892416070679,0.8763546281207301,0.5092017101866694,1.5276381909547738,14.23785594639866,"{'path': 'media/table/predictions_1_e94bf6fd36f383842cfd.table.json', 'size': 745642, '_type': 'table-file', 'ncols': 13, 'nrows': 597, 'sha256': 'e94bf6fd36f383842cfd7e459843c4c7868dc5073c0d10a224f057fb6030889f', 'artifact_path': 'wandb-client-artifact://lhb2has3513gr1j5c6tob72jf1ojeqbyqt5vu4far65meborecyfow57ur2si4fzaidjzugb6n0eiv6hrpk1qp0kd7gffp5rqkholr74ejvepx7dm63wg5seo3a97r6f:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://lhb2has3513gr1j5c6tob72jf1ojeqbyqt5vu4far65meborecyfow57ur2si4fzaidjzugb6n0eiv6hrpk1qp0kd7gffp5rqkholr74ejvepx7dm63wg5seo3a97r6f:latest/predictions.table.json'}",154.72511539329355,1.1020913300538355,0.1733486262377924,False,True,validation,False,Seller | Buyer | Neither | Unknown,4,CTBase,d92fc0d4-5367-41e1-b35d-1058f22a3c1c,craigslist_bargains,QA,False,12,bigscience/T0_3B,0,True,qa_choices,prompts/general_fixed_choice.yaml,No Prompt,['validation'],4,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,['Dialogue'],craigslist_bargains,False,False,GeneralFixedChoice,False,False,True,,,prompts,,False,True,qa choices,,cross_task,craigslist,,,,False,,,False,,True,,,False,False,CTBase.GenFC.BAREBONES.qa_choices.LenNorm,Craigslist,,,,,,,,,,,,,,,,,,,,,88.0,89.0,0
6.870370370370371,25.48148148148148,0.6732156683746243,7.656287221253617,1.6331658291457287,0.3589078977539165,0.4922571616586314,0.0,0.0,1.7547060361060265,4.0,168.5075376884422,5.421687211622944,2.9748743718592965,2.0,0.4798939735246464,0.2111748883361879,0.7314759156432677,0.5083579619513758,1.3919597989949748,14.57286432160804,"{'path': 'media/table/predictions_1_fdab912e377a50ed48ed.table.json', 'size': 486402, '_type': 'table-file', 'ncols': 13, 'nrows': 597, 'sha256': 'fdab912e377a50ed48ed899f8e7ad2ffe5f51314596bbc87accf66c52c50529e', 'artifact_path': 'wandb-client-artifact://58pofl624cdn01we15rw7a0mb3oth1eh5xf7gnimgn8k2vfqe61rlcvce9soblv0ur39t4wov6rw2gpx051ok6ftmytzfq6d9lwmdgu04afuum3v1u14o4bwdtfpg7lt:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://58pofl624cdn01we15rw7a0mb3oth1eh5xf7gnimgn8k2vfqe61rlcvce9soblv0ur39t4wov6rw2gpx051ok6ftmytzfq6d9lwmdgu04afuum3v1u14o4bwdtfpg7lt:latest/predictions.table.json'}",78.326585290588,0.7355183026058493,0.0,False,True,validation,False,Seller | Buyer | Neither | Unknown,4,CTBase,bb648cf3-d9ab-45a8-9bd7-6ba4585c4b9a,craigslist_bargains,ENTAILMENT,False,12,bigscience/T0_3B,0,True,entailment_choices,prompts/general_fixed_choice.yaml,No Prompt,['validation'],4,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,['Dialogue'],craigslist_bargains,False,False,GeneralFixedChoice,False,False,True,,,prompts,,False,True,entailment choices,,cross_task,craigslist,,,,False,,,False,,True,,,False,False,CTBase.GenFC.BAREBONES.entailment_choices.LenNorm,Craigslist,,,,,,,,,,,,,,,,,,,,,84.5,82.0,0
10.685764465708315,26.4026402640264,0.977587595410118,6.918532681824574,1.747068676716918,0.3819140482645459,0.5885669081198499,9.395973154362416,0.0,1.3814244601794423,4.0,168.47068676716918,5.040756911688314,2.7855946398659968,6.944444444444446,0.4963513099568173,0.579603217110207,0.8589631766138672,0.5939576618452801,1.4673366834170851,16.582914572864322,"{'ncols': 13, 'nrows': 597, 'sha256': '4a56c51c2162b8bcb79776ef2d062a208574e4cf268565f66cd8bf1a5312b9fa', 'artifact_path': 'wandb-client-artifact://1ppwqakbnz521vujhd2i6k0j4qih78f6981hjf1kcrlo9fcpnrbg3kltxnqmwq1lez6nd1eg3rqan325tvmqo5dgnrl1x5sshq2jlury0h823qwg64m2e601k47q379j:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://1ppwqakbnz521vujhd2i6k0j4qih78f6981hjf1kcrlo9fcpnrbg3kltxnqmwq1lez6nd1eg3rqan325tvmqo5dgnrl1x5sshq2jlury0h823qwg64m2e601k47q379j:latest/predictions.table.json', 'path': 'media/table/predictions_1_4a56c51c2162b8bcb797.table.json', 'size': 486308, '_type': 'table-file'}",78.1171728355754,0.8543510113499164,0.0,False,True,validation,False,Seller | Buyer | Neither | Unknown,4,CTBase,88bdb026-e9c9-445b-96ef-0cdb986b7fbd,craigslist_bargains,CLASSIFICATION,False,12,bigscience/T0_3B,0,True,classification_choices,prompts/general_fixed_choice.yaml,No Prompt,['validation'],4,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,['Dialogue'],craigslist_bargains,False,False,GeneralFixedChoice,False,False,True,,,prompts,,False,True,classification choices,,cross_task,craigslist,,,,False,,,False,,True,,,False,False,CTBase.GenFC.BAREBONES.classification_choices.LenNorm,Craigslist,,,,,,,,,,,,,,,,,,,,,61.5,62.0,0
23.00334131061457,23.404255319148938,0.6663861097465141,7.345532008351593,1.4271356783919598,0.3278753850122728,0.778780993516618,62.83987915407856,0.0,0.5941525280375776,4.0,195.1591289782245,6.321254768163914,2.3098827470686767,5.769230769230768,0.4301247121501009,0.4973492411362314,0.6077381043180006,0.8079503326498552,2.2629815745393635,40.87102177554439,"{'ncols': 13, 'nrows': 597, 'sha256': '8603da5cb37cc4329879bf9628b35a1996ebe875a550ef007171fa378ce3e749', 'artifact_path': 'wandb-client-artifact://11zdnxrirl8wqcsqgxrs0ofl5dgxjmzvrqewurvxh4zld8cgkfxzm7khf96tpuoagym61mnxktyh4mo5hmy3fobyjlgkurfdayzafdmwbgmh58g35r753cl10yo6xbme:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://11zdnxrirl8wqcsqgxrs0ofl5dgxjmzvrqewurvxh4zld8cgkfxzm7khf96tpuoagym61mnxktyh4mo5hmy3fobyjlgkurfdayzafdmwbgmh58g35r753cl10yo6xbme:latest/predictions.table.json', 'path': 'media/table/predictions_1_8603da5cb37cc4329879.table.json', 'size': 532941, '_type': 'table-file'}",78.22077036071836,0.4153838761893241,0.0,False,True,validation,False,Seller | Buyer | Neither | Unknown,4,CTBase,725b5ed0-7728-4890-95a4-a74cb7ae1bb4,craigslist_bargains,ENTAILMENT,False,12,bigscience/T0_3B,0,True,affirmation_true_or_false,prompts/general_fixed_choice.yaml,WiC,['validation'],4,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,['Dialogue'],craigslist_bargains,False,False,GeneralFixedChoice,False,False,True,,,prompts,,False,True,affirmation_true_or_false,,cross_task,craigslist,,,,False,,,False,,True,,,False,False,CTBase.GenFC.super_glue_wic.affirmation_true_or_false.LenNorm,Craigslist,,,,,,,,,,,,,,,,,,,,,1.0,4.0,25
16.19246437061726,25.821596244131456,0.6876981562243365,7.87905894452004,2.0217755443886096,0.3684924870848323,0.7120839235011494,24.444444444444446,0.0,0.7134060787795177,4.0,194.1591289782245,6.705714430241928,2.28643216080402,14.50381679389313,0.4599384354985938,0.8759011636097528,0.7321855750468725,0.7404215629368873,1.6917922948073705,19.76549413735344,"{'path': 'media/table/predictions_1_96e5c0d6bd051fc30c72.table.json', 'size': 555389, '_type': 'table-file', 'ncols': 13, 'nrows': 597, 'sha256': '96e5c0d6bd051fc30c720718deff2fa4add0d2013e8b2d064d337a951d200512', 'artifact_path': 'wandb-client-artifact://15ljkdzjbyvd2mbfc2jnr5lgu487036nrq29jz2ig2lfdk9k8792s73pkfpoja2qzyhm5pbb31a17kx02h3qhrfe081c49nm6ryrh8no02c2ec0d9rx9o81vck2qq428:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://15ljkdzjbyvd2mbfc2jnr5lgu487036nrq29jz2ig2lfdk9k8792s73pkfpoja2qzyhm5pbb31a17kx02h3qhrfe081c49nm6ryrh8no02c2ec0d9rx9o81vck2qq428:latest/predictions.table.json'}",78.22077036071836,0.6918138850879455,0.0,False,True,validation,False,Seller | Buyer | Neither | Unknown,4,CTBase,611d13dc-d414-4b9b-9204-e4f325e859e7,craigslist_bargains,ENTAILMENT,False,12,bigscience/T0_3B,0,True,grammar_homework,prompts/general_fixed_choice.yaml,WiC,['validation'],4,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,['Dialogue'],craigslist_bargains,False,False,GeneralFixedChoice,False,False,True,,,prompts,,False,True,grammar_homework,,cross_task,craigslist,,,,False,,,False,,True,,,False,False,CTBase.GenFC.super_glue_wic.grammar_homework.LenNorm,Craigslist,,,,,,,,,,,,,,,,,,,,,36.5,30.0,25
6.359649122807016,25.438596491228065,1.1505390967064757,8.686961487909059,1.949748743718593,1.2974572753973266,0.2965249948127021,0.0,0.0,3.761296127709112,1.1289782244556117,169.15912897822446,1.135434415871574,3.0,0.0,3.790230944328372,0.0,0.6554892285477278,0.4078374403054833,3.921273031825795,14.57286432160804,"{'ncols': 13, 'nrows': 597, 'sha256': '562ced100d62fd8eed1f3424e147c6a5e5dc71723e48934f8ff454880209d404', 'artifact_path': 'wandb-client-artifact://rskejubzo9apmecx9trh8fmb5egxfuz5mv3b8nrw5dsrik2v593icp8ouxwyxoaa4zmvpkv836p2wz4z2m930wz4sik8jz0rk8sugvueqwgpu34e5hhkn96qv9c6xcj3:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://rskejubzo9apmecx9trh8fmb5egxfuz5mv3b8nrw5dsrik2v593icp8ouxwyxoaa4zmvpkv836p2wz4z2m930wz4sik8jz0rk8sugvueqwgpu34e5hhkn96qv9c6xcj3:latest/predictions.table.json', 'path': 'media/table/predictions_1_562ced100d62fd8eed1f.table.json', 'size': 499091, '_type': 'table-file'}",78.22077036071836,1.151686332557874,0.5415231894249356,False,True,validation,False,Seller | Buyer | Neither | Unknown,4,CTBase,3503ead5-4fa5-4f77-95dc-f0c2ed3eecdc,craigslist_bargains,ENTAILMENT,False,12,bigscience/T0_3B,0,True,question_context_meaning,prompts/general_fixed_choice.yaml,WiC,['validation'],4,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,['Dialogue'],craigslist_bargains,False,False,GeneralFixedChoice,False,False,False,,,prompts,,False,True,question-context-meaning,,cross_task,craigslist,,,,False,,,False,,True,,,False,False,CTBase.GenFC.super_glue_wic.question_context_meaning.LenNorm,Craigslist,,,,,,,,,,,,,,,,,,,,,84.5,87.0,14
8.462406427448297,25.48725637181409,0.7394017310626683,6.639958552180024,1.204355108877722,0.3947063169566933,0.423490870165775,8.362369337979096,0.0,1.920319087940644,3.9949748743718594,186.1591289782245,4.171734568661382,2.9715242881072026,0.0,0.5479048955779978,0.1663275254580423,0.6806757003925661,0.4380802958332335,1.829145728643216,16.24790619765494,"{'artifact_path': 'wandb-client-artifact://16vw78krkjxc52aegm16ynsukjosaw6jh18xv6g7g7lgwq46q7lydo0j600nwasmh7r6245w2sku24qgjczc2ozcfhcet47h3vbm9372ifs88nc6i3jygxkq7y7r8vlk:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://16vw78krkjxc52aegm16ynsukjosaw6jh18xv6g7g7lgwq46q7lydo0j600nwasmh7r6245w2sku24qgjczc2ozcfhcet47h3vbm9372ifs88nc6i3jygxkq7y7r8vlk:latest/predictions.table.json', 'path': 'media/table/predictions_1_cfc5b253bb234229819f.table.json', 'size': 528628, '_type': 'table-file', 'ncols': 13, 'nrows': 597, 'sha256': 'cfc5b253bb234229819fc36828d6b2e2d57d99e0dec4c5fc1c8f196d43306918'}",78.22077036071836,0.970957750146314,0.1226789509118964,False,True,validation,False,Seller | Buyer | Neither | Unknown,4,CTBase,14e73f39-a0d1-44c2-b9a4-4e48f9f1608e,craigslist_bargains,ENTAILMENT,False,12,bigscience/T0_3B,0,True,question_context_meaning_with_label,prompts/general_fixed_choice.yaml,WiC,['validation'],4,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,['Dialogue'],craigslist_bargains,False,False,GeneralFixedChoice,False,False,True,,,prompts,,False,True,question-context-meaning-with-label,,cross_task,craigslist,,,,False,,,False,,True,,,False,False,CTBase.GenFC.super_glue_wic.question_context_meaning_with_label.LenNorm,Craigslist,,,,,,,,,,,,,,,,,,,,,66.0,72.0,16
13.536631930010214,23.481781376518217,1.4152809944141056,2.811141977358104,2.663316582914573,0.5433591067555977,0.9609865753134704,0.0,3.896103896103896,0.7079650381302315,3.241206030150754,181.5075376884422,0.9528982882923016,1.576214405360134,26.76864244741874,1.1502786509355707,0.927688942911826,1.276598392732591,0.9288133634773053,2.5192629815745398,17.08542713567839,"{'path': 'media/table/predictions_1_ad10618e9ecb2c7fde23.table.json', 'size': 536513, '_type': 'table-file', 'ncols': 13, 'nrows': 597, 'sha256': 'ad10618e9ecb2c7fde237ada71b49ba7f09f462a664aac364d49126e026b01d7', 'artifact_path': 'wandb-client-artifact://19486w3sepqcbb48m5pogcqgcsynldob2w8ju6z32rpzngrdo6woura57fgoy4ssh6y4u1jp2ee6l9fp7lro3av23hzjeze3hzws2fphdktgbif6uwhxodn73j2w980e:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://19486w3sepqcbb48m5pogcqgcsynldob2w8ju6z32rpzngrdo6woura57fgoy4ssh6y4u1jp2ee6l9fp7lro3av23hzjeze3hzws2fphdktgbif6uwhxodn73j2w980e:latest/predictions.table.json'}",78.326585290588,0.5351342084759778,0.960934019786165,False,True,validation,False,Seller | Buyer | Neither | Unknown,4,CTBase,cd563834-49ee-495d-ac46-99f0264e58d5,craigslist_bargains,QA,False,12,bigscience/T0_3B,0,True,ask_question_as_teacher,prompts/general_fixed_choice.yaml,ZEST,['validation'],4,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,['Dialogue'],craigslist_bargains,False,False,GeneralFixedChoice,False,False,False,,,prompts,,False,True,ask_question_as_teacher,,cross_task,craigslist,,,,False,,,False,,True,,,False,False,CTBase.GenFC.zest.ask_question_as_teacher.LenNorm,Craigslist,,,,,,,,,,,,,,,,,,,,,55.0,49.0,24
14.550580431177446,32.0,1.162614876463989,3.239197783334371,2.2428810720268006,0.5087312104925383,0.6442403555912848,0.0,0.0,0.7647035567205356,3.768844221105528,185.5075376884422,1.1410977181477762,1.2948073701842546,26.202321724709783,1.3333965084660593,0.7090157648836541,1.140076827568257,0.7123045414855081,2.693467336683417,17.922948073701843,"{'ncols': 13, 'nrows': 597, 'sha256': 'ec3cf14f57dd27b79aec4b26f0d4f6f6f129fef6afd2be01ee55f5fb6ed87b45', 'artifact_path': 'wandb-client-artifact://x5zcs7cji3qgjp33c4p9r3xih29jdfo7cj78un2ev948yabwtczpsgaw5wzpn38lhnxhy2yi8pghcrw64yrtewy7qo1ibyddkmzrk22i79h0cfb0ac9agwx3dnopga87:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://x5zcs7cji3qgjp33c4p9r3xih29jdfo7cj78un2ev948yabwtczpsgaw5wzpn38lhnxhy2yi8pghcrw64yrtewy7qo1ibyddkmzrk22i79h0cfb0ac9agwx3dnopga87:latest/predictions.table.json', 'path': 'media/table/predictions_1_ec3cf14f57dd27b79aec.table.json', 'size': 543025, '_type': 'table-file'}",78.326585290588,0.4548047459707156,0.6394361294708287,False,True,validation,False,Seller | Buyer | Neither | Unknown,4,CTBase,7425232a-9880-428c-9ddc-4070e50e22cc,craigslist_bargains,QA,False,12,bigscience/T0_3B,0,True,gpt3_instruct_format,prompts/general_fixed_choice.yaml,ZEST,['validation'],4,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,['Dialogue'],craigslist_bargains,False,False,GeneralFixedChoice,False,False,False,,,prompts,,False,True,gpt3_instruct_format,,cross_task,craigslist,,,,False,,,False,,True,,,False,False,CTBase.GenFC.zest.gpt3_instruct_format.LenNorm,Craigslist,,,,,,,,,,,,,,,,,,,,,48.0,41.0,28
13.516170174740244,25.339366515837103,1.253207531364967,2.8526463786161926,3.2328308207705194,0.4991033165135791,0.9895911511428668,0.0,0.0,0.6880497900485194,2.730318257956449,187.5075376884422,0.8873262305555232,1.4489112227805696,28.72531418312388,1.2772703580121498,0.8344466187976276,1.104491265367505,0.8333834147388093,2.5879396984924625,18.09045226130653,"{'sha256': 'f07b8a5bf9c220927effa7f32de9a2f220d890092ba90709d22bc842075712d5', 'artifact_path': 'wandb-client-artifact://16z7cv4difbs6oqleelldbdx6y25gknr1yfudhyjk6pe5u04vd96icu30lb2imkuvfq1nas0c0yvt2w5w1rpkel3l10lq5x6vlbr276iowv2o6yj64udzxj9zng8a6v7:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://16z7cv4difbs6oqleelldbdx6y25gknr1yfudhyjk6pe5u04vd96icu30lb2imkuvfq1nas0c0yvt2w5w1rpkel3l10lq5x6vlbr276iowv2o6yj64udzxj9zng8a6v7:latest/predictions.table.json', 'path': 'media/table/predictions_1_f07b8a5bf9c220927eff.table.json', 'size': 540824, '_type': 'table-file', 'ncols': 13, 'nrows': 597}",78.326585290588,0.5012995662147256,0.9629495095841504,False,True,validation,False,Seller | Buyer | Neither | Unknown,4,CTBase,6f694e45-1d17-4067-a1f6-7dae89c148db,craigslist_bargains,QA,False,12,bigscience/T0_3B,0,True,ask_question_as_kid,prompts/general_fixed_choice.yaml,ZEST,['validation'],4,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,['Dialogue'],craigslist_bargains,False,False,GeneralFixedChoice,False,False,False,,,prompts,,False,True,ask_question_as_kid,,cross_task,craigslist,,,,False,,,False,,True,,,False,False,CTBase.GenFC.zest.ask_question_as_kid.LenNorm,Craigslist,,,,,,,,,,,,,,,,,,,,,47.0,50.0,31
12.759740023435736,20.66420664206642,1.0837267001665691,3.631592714956258,2.7872696817420435,0.5435208898376641,0.9873430580129844,0.0,0.0,0.6342890331992752,3.1926298157453936,176.5075376884422,0.8642927542004354,1.6164154103852597,30.37475345167653,2.133010927556548,0.9235057458457372,1.0283171159363278,0.9258179350751062,2.403685092127303,17.587939698492463,"{'path': 'media/table/predictions_1_8a8d3553fb276ccdb8ec.table.json', 'size': 520154, '_type': 'table-file', 'ncols': 13, 'nrows': 597, 'sha256': '8a8d3553fb276ccdb8ecf437c784779a105bf2ac4575bbbd4cb9b951d99887a8', 'artifact_path': 'wandb-client-artifact://4xbb7xarjo9jaory2z51atutpisb8fei8xtgrtc8j55a4shakuqx4pqtncxdjndur9cqk5uu1z93k40lox78srtmvprrrm0secuvxasgacgl3ypchp3d3gu3irz1ilwi:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://4xbb7xarjo9jaory2z51atutpisb8fei8xtgrtc8j55a4shakuqx4pqtncxdjndur9cqk5uu1z93k40lox78srtmvprrrm0secuvxasgacgl3ypchp3d3gu3irz1ilwi:latest/predictions.table.json'}",78.326585290588,0.4770000971256775,0.9812714986617596,False,True,validation,False,Seller | Buyer | Neither | Unknown,4,CTBase,2283cebf-988e-4bff-96bf-982a09963e49,craigslist_bargains,QA,False,12,bigscience/T0_3B,0,True,answerable_or_not,prompts/general_fixed_choice.yaml,ZEST,['validation'],4,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,['Dialogue'],craigslist_bargains,False,False,GeneralFixedChoice,False,False,False,,,prompts,,False,True,answerable_or_not,,cross_task,craigslist,,,,False,,,False,,True,,,False,False,CTBase.GenFC.zest.answerable_or_not.LenNorm,Craigslist,,,,,,,,,,,,,,,,,,,,,49.0,53.0,20
26.00271780456336,40.54336468129572,1.0445893798936088,12.32701182603836,2.0,0.7309796929443366,0.0,0.0,,,,146.051,11.431264615535737,2.248,37.46478873239436,0.8957472105026245,0.9687600322061184,1.0940961486755312,0.9687600322061188,1.752,32.7,"{'path': 'media/table/predictions_1_c5c6b128ff22dc0985b9.table.json', 'size': 700285, '_type': 'table-file', 'ncols': 11, 'nrows': 1000, 'sha256': 'c5c6b128ff22dc0985b951bd7f217ec3e8aa3aa129f4df26822a2ca922b2b428', 'artifact_path': 'wandb-client-artifact://gpyxsifvqmbf3f9apn2i5wxl7dgaic3r3offpk5vysm26pfkhx6o5bqh31wqqrf6rgdow3lylgj409gctahy3o1y1xpen35spfk4kirbhm2sjk1pqfkt7qcx5jqatq0o:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://gpyxsifvqmbf3f9apn2i5wxl7dgaic3r3offpk5vysm26pfkhx6o5bqh31wqqrf6rgdow3lylgj409gctahy3o1y1xpen35spfk4kirbhm2sjk1pqfkt7qcx5jqatq0o:latest/predictions.table.json'}",17.873231353059804,,,False,True,dev_r2,False,Yes | Maybe | No,4,CTBase,a64d5a15-68e2-4d1c-b30a-ca8250c860f9,anli,QA,False,28,bigscience/T0_3B,0,True,answer_the_following_q,prompts/general_fixed_choice.yaml,AdversarialQA,,3,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,['NLI'],anli,True,False,GeneralFixedChoice,False,False,False,,,prompts,,False,True,answer_the_following_q,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.adversarial_qa.answer_the_following_q.LenNorm,ANLI R2,,,,,,,,,,,,,,,,,,,,,61.5,32.0,23
25.57647753159484,42.38921001926782,1.2777772816188937,12.916444185972214,2.0,0.9790447160896388,0.0,0.0,,,,139.051,11.687885719537736,2.41,34.34022257551669,1.2285584664344789,0.9120855223058856,1.3586337311304673,0.9120855223058856,1.59,32.800000000000004,"{'artifact_path': 'wandb-client-artifact://pru31vkdv3wlzpkenvmevuspnv0shu9egwmw5i3nreqolg7jdbc182xwgjjig7ewpvkla7szkdarcicoi21df5nbsqxnzptj16slaaw4wi17f62ye1wdq7uqxfp7az1d:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://pru31vkdv3wlzpkenvmevuspnv0shu9egwmw5i3nreqolg7jdbc182xwgjjig7ewpvkla7szkdarcicoi21df5nbsqxnzptj16slaaw4wi17f62ye1wdq7uqxfp7az1d:latest/predictions.table.json', 'path': 'media/table/predictions_1_96f4a5353444b598530c.table.json', 'size': 659022, '_type': 'table-file', 'ncols': 11, 'nrows': 1000, 'sha256': '96f4a5353444b598530c327d4844505cf60178cee1ef889bbf8c0002085e3b82'}",17.873231353059804,,,False,True,dev_r2,False,Yes | Maybe | No,4,CTBase,a0872cde-2f19-4ae6-919a-868da47bfbcb,anli,QA,False,28,bigscience/T0_3B,0,True,based_on,prompts/general_fixed_choice.yaml,AdversarialQA,,3,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,['NLI'],anli,True,False,GeneralFixedChoice,False,False,False,,,prompts,,False,True,based_on,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.adversarial_qa.based_on.LenNorm,ANLI R2,,,,,,,,,,,,,,,,,,,,,57.5,35.0,16
25.574731718110417,41.30434782608695,1.2347637140626124,12.519597816586494,2.0,0.9043328885761052,0.0,0.0,,,,134.051,11.37568215560913,2.358,35.41984732824428,1.1439156609773635,0.9337215859130602,1.3098313973772204,0.9337215859130602,1.642,32.5,"{'artifact_path': 'wandb-client-artifact://154px4um3irser4s34epmj7wrpeo8kca33cafg2mm52cjcs6326j2bv95rn2134wrh5km7qez1ut2b1x8dgqakd0rf1bnjo0sgs47300qvxs3xtsu97hp813eg3o8jux:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://154px4um3irser4s34epmj7wrpeo8kca33cafg2mm52cjcs6326j2bv95rn2134wrh5km7qez1ut2b1x8dgqakd0rf1bnjo0sgs47300qvxs3xtsu97hp813eg3o8jux:latest/predictions.table.json', 'path': 'media/table/predictions_1_c9c61ef1b8f0c2de2973.table.json', 'size': 611900, '_type': 'table-file', 'ncols': 11, 'nrows': 1000, 'sha256': 'c9c61ef1b8f0c2de2973b381b2d49849039f61c7251a63c5ce5386ce2134b5d6'}",17.873231353059804,,,False,True,dev_r2,False,Yes | Maybe | No,4,CTBase,5bdb1815-5c6f-49a3-ad1d-367344420701,anli,QA,False,28,bigscience/T0_3B,0,True,question_context_answer,prompts/general_fixed_choice.yaml,AdversarialQA,,3,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,['NLI'],anli,True,False,GeneralFixedChoice,False,False,False,,,prompts,,False,True,question_context_answer,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.adversarial_qa.question_context_answer.LenNorm,ANLI R2,,,,,,,,,,,,,,,,,,,,,66.5,36.0,11
25.93341126501456,41.247484909456745,1.2363504254936135,12.21567177081108,2.0,0.9067228512117746,0.0,0.0,,,,146.051,11.083908467292783,2.322,36.55274888558693,1.1317633035182952,0.9467396685467446,1.3149320560458084,0.9467396685467446,1.678,32.800000000000004,"{'_latest_artifact_path': 'wandb-client-artifact://l6unvdpcwjvmdmhjqtb4wpeh1j3wqj2ipmrxbtl45sbbyrt6oxd3tqd8wxnm5vnxs19eclbvqcmiklry8ddlqahd6y1csbxrp6d28zgeuujhlgkwpqqwarkh8494ewif:latest/predictions.table.json', 'path': 'media/table/predictions_1_0a4319a850a5100e101c.table.json', 'size': 658960, '_type': 'table-file', 'ncols': 11, 'nrows': 1000, 'sha256': '0a4319a850a5100e101c4cafd642fa0f96df4fa81eeab04bd3f1c234b5b268b4', 'artifact_path': 'wandb-client-artifact://l6unvdpcwjvmdmhjqtb4wpeh1j3wqj2ipmrxbtl45sbbyrt6oxd3tqd8wxnm5vnxs19eclbvqcmiklry8ddlqahd6y1csbxrp6d28zgeuujhlgkwpqqwarkh8494ewif:latest/predictions.table.json'}",17.873231353059804,,,False,True,dev_r2,False,Yes | Maybe | No,4,CTBase,3b2459cc-6600-443c-abf8-8f60c34cd998,anli,QA,False,28,bigscience/T0_3B,0,True,tell_what_it_is,prompts/general_fixed_choice.yaml,AdversarialQA,,3,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,['NLI'],anli,True,False,GeneralFixedChoice,False,False,False,,,prompts,,False,True,tell_what_it_is,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.adversarial_qa.tell_what_it_is.LenNorm,ANLI R2,,,,,,,,,,,,,,,,,,,,,57.5,33.0,22
24.5883764038818,40.43179587831207,0.85791224681624,4.407000211238861,2.0,0.7427967636810615,0.0,0.0,,,,126.051,3.446118869304657,2.372,33.33333333333333,0.960881341934204,0.9282327294380436,0.956156206246618,0.9282327294380436,1.628,31.4,"{'_type': 'table-file', 'ncols': 11, 'nrows': 1000, 'sha256': '460f3e3cbfb40f2521719bd7c27ed514f1568e0491ec9a46655ccd2bd32a742a', 'artifact_path': 'wandb-client-artifact://10mn9w353mfmre4mc8v17x47przxtzptamx8phef6y9r6sa0shwugxhn87u7k1whaleapxygbfvxpk1wdggzs52taw2wvrynlgeq6fifas98dlkjykbcar2tj5nml6ba:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://10mn9w353mfmre4mc8v17x47przxtzptamx8phef6y9r6sa0shwugxhn87u7k1whaleapxygbfvxpk1wdggzs52taw2wvrynlgeq6fifas98dlkjykbcar2tj5nml6ba:latest/predictions.table.json', 'path': 'media/table/predictions_1_460f3e3cbfb40f252171.table.json', 'size': 584089}",17.873231353059808,,,False,True,dev_r2,False,Yes | Maybe | No,4,CTBase,4dd990b3-7201-4cba-bb9a-baa462d68b1a,anli,SENTIMENT,False,28,bigscience/T0_3B,0,True,format_score,prompts/general_fixed_choice.yaml,Yelp,,3,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,['NLI'],anli,True,False,GeneralFixedChoice,False,False,False,,,prompts,,False,True,format_score,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.yelp.format_score.LenNorm,ANLI R2,,,,,,,,,,,,,,,,,,,,,84.5,45.0,12
23.956058669199944,41.90301921317475,0.94749322829021,4.174399198293686,1.997,0.7529982333374903,0.0546900356555012,0.0,,,,120.051,3.153991492271423,2.52,29.965156794425084,1.0204077060222625,0.8541662601625049,0.9729729750586084,0.8542312333320528,1.483,31.5,"{'_type': 'table-file', 'ncols': 11, 'nrows': 1000, 'sha256': '47d8f826e37beeffa744d4e1c60928bb09a7c77750ede416312dbea77c085af8', 'artifact_path': 'wandb-client-artifact://wytedd7aqt24zu88n2sg5kxftmj2c0129rnjyygafqg84it1buvqe2iovtgrcbsqpbzdz62h94c9q4f9e26g5atpi2trr1zcsjkqko6bryx64kkryqwfh4fkjrqrn7lv:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://wytedd7aqt24zu88n2sg5kxftmj2c0129rnjyygafqg84it1buvqe2iovtgrcbsqpbzdz62h94c9q4f9e26g5atpi2trr1zcsjkqko6bryx64kkryqwfh4fkjrqrn7lv:latest/predictions.table.json', 'path': 'media/table/predictions_1_47d8f826e37beeffa744.table.json', 'size': 558261}",17.873231353059808,,,False,True,dev_r2,False,Yes | Maybe | No,4,CTBase,29fc6386-90b3-4976-b249-26e49fe7c924,anli,SENTIMENT,False,28,bigscience/T0_3B,0,True,format_star,prompts/general_fixed_choice.yaml,Yelp,,3,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,['NLI'],anli,True,False,GeneralFixedChoice,False,False,False,,,prompts,,False,True,format_star,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.yelp.format_star.LenNorm,ANLI R2,,,,,,,,,,,,,,,,,,,,,82.5,51.0,6
23.665397137344957,45.89331075359864,0.8296696554188198,3.878954821109771,1.998,0.8468657728208328,0.0446766158073773,0.0,,,,124.051,2.6499823303222656,2.696,25.102880658436217,1.228972490787506,0.7180417815141401,0.8979770521702986,0.7185847201270008,1.306,33.2,"{'nrows': 1000, 'sha256': '55e8c4a92efa4bb97bfdf5abcf9ffed9ab54e784f4e477fa440ce159251a52ce', 'artifact_path': 'wandb-client-artifact://3raecj41f9c2oxu4w5izcuddwegv5oyhwdjbb4kdafbx4pbws2semzofrmkr4m36yucqxrxh4iivqm3q0ppxas9syut2lp2sh72xnzjvs19mtu6ba6miqwt2afbn41l7:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://3raecj41f9c2oxu4w5izcuddwegv5oyhwdjbb4kdafbx4pbws2semzofrmkr4m36yucqxrxh4iivqm3q0ppxas9syut2lp2sh72xnzjvs19mtu6ba6miqwt2afbn41l7:latest/predictions.table.json', 'path': 'media/table/predictions_1_55e8c4a92efa4bb97bfd.table.json', 'size': 571297, '_type': 'table-file', 'ncols': 11}",17.873231353059808,,,False,True,dev_r2,False,Yes | Maybe | No,4,CTBase,27b6bc81-bb1c-467b-91c0-22a4d6a19f44,anli,SENTIMENT,False,28,bigscience/T0_3B,0,True,based_on_that,prompts/general_fixed_choice.yaml,Yelp,,3,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,['NLI'],anli,True,False,GeneralFixedChoice,False,False,False,,,prompts,,False,True,based_on_that,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.yelp.based_on_that.LenNorm,ANLI R2,,,,,,,,,,,,,,,,,,,,,40.5,53.0,10
26.978737165494387,37.32718894009218,1.134822272435971,3.1965933854579927,1.991,0.6390394451716047,0.1044940189675945,0.0,,,,121.051,2.364575455665588,2.071,43.609022556390975,0.8320179297924042,0.9969749244589856,1.0697044793290744,0.9930538756784548,1.938,33.6,"{'artifact_path': 'wandb-client-artifact://17jxygrzhicsp9ycx41309r5gaw6oe830xnsrrtl6fmz8ni5k92jc1dm6923naiodthvzxwpmnx4ru033phyfqx5tlakl1z80e7odatmw0q5f8ry3t7uy5iybgw22dnp:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://17jxygrzhicsp9ycx41309r5gaw6oe830xnsrrtl6fmz8ni5k92jc1dm6923naiodthvzxwpmnx4ru033phyfqx5tlakl1z80e7odatmw0q5f8ry3t7uy5iybgw22dnp:latest/predictions.table.json', 'path': 'media/table/predictions_1_def98c48a5e21bd3a965.table.json', 'size': 566198, '_type': 'table-file', 'ncols': 11, 'nrows': 1000, 'sha256': 'def98c48a5e21bd3a9654272c106e0fdd0f75e20a4956449d1d870a7785a09bf'}",17.873231353059808,,,False,True,dev_r2,False,Yes | Maybe | No,4,CTBase,135fcd11-9fcc-4b55-bf1b-9b76290d0f6b,anli,SENTIMENT,False,28,bigscience/T0_3B,0,True,so_i_would,prompts/general_fixed_choice.yaml,Yelp,,3,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,['NLI'],anli,True,False,GeneralFixedChoice,False,False,False,,,prompts,,False,True,so_i_would,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.yelp.so_i_would.LenNorm,ANLI R2,,,,,,,,,,,,,,,,,,,,,23.0,13.0,7
24.85574477608904,27.086614173228345,0.4182474058611496,1.129858505010605,2.008,0.3643683604651784,0.2047828117787233,0.0,,,,141.051,0.6183013367652893,1.604,47.48062015503877,0.5115571682453155,0.9182505104817528,0.34144634789944,0.8985855551921588,2.388,33.1,"{'ncols': 11, 'nrows': 1000, 'sha256': '2dafd2fd9136eeee39f79215dd3db803cec81a0ece5f4d094df565cb37a04432', 'artifact_path': 'wandb-client-artifact://qgeyd1t1ledqdj9r6ls8rfp4o4u6c18hley2x241fq1w2xoyumul7ewafdgmailsq1ih4l4bkofcmmufbhdkn4w6lghv5p0mbaohbawe2155i3xau9xigjodtf8hszj4:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://qgeyd1t1ledqdj9r6ls8rfp4o4u6c18hley2x241fq1w2xoyumul7ewafdgmailsq1ih4l4bkofcmmufbhdkn4w6lghv5p0mbaohbawe2155i3xau9xigjodtf8hszj4:latest/predictions.table.json', 'path': 'media/table/predictions_1_2dafd2fd9136eeee39f7.table.json', 'size': 632750, '_type': 'table-file'}",17.873231353059804,,,False,True,dev_r2,False,Yes | Maybe | No,4,CTBase,2da8f134-58db-4f9d-b3b0-8c6b50693ab5,anli,SENTIMENT,False,28,bigscience/T0_3B,0,True,categorize_rating_using_review,prompts/general_fixed_choice.yaml,AppReviews,,3,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,['NLI'],anli,True,False,GeneralFixedChoice,False,False,True,,,prompts,,False,True,categorize_rating_using_review,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.app_reviews.categorize_rating_using_review.LenNorm,ANLI R2,,,,,,,,,,,,,,,,,,,,,46.5,43.0,18
22.60218170020568,46.66117065127784,0.7913775616010726,4.302616686344146,2.0,0.7679753182112885,0.0,0.0,,,,141.051,3.173382576942444,2.76,21.145374449339204,1.1292341094017029,0.6499230723708769,0.8994875233825077,0.6499230723708769,1.24,33.1,"{'size': 652334, '_type': 'table-file', 'ncols': 11, 'nrows': 1000, 'sha256': '684bac330126d1c19b21d85460e13cc1e4af04fe15f29d4ff9a63edcba891985', 'artifact_path': 'wandb-client-artifact://s830msy3q9g5p81zqdy9vddqq2do9pcspfkspur3is1w4nhzrft3efxwpfiwcwg8vjbwdpg51whf5py4fwtsjct1277pckbyq6xk25jkboe6x7sxgwg4h1yigo0uhrd5:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://s830msy3q9g5p81zqdy9vddqq2do9pcspfkspur3is1w4nhzrft3efxwpfiwcwg8vjbwdpg51whf5py4fwtsjct1277pckbyq6xk25jkboe6x7sxgwg4h1yigo0uhrd5:latest/predictions.table.json', 'path': 'media/table/predictions_1_684bac330126d1c19b21.table.json'}",17.873231353059804,,,False,True,dev_r2,False,Yes | Maybe | No,4,CTBase,d34e1413-2699-4701-baa2-05d931d012ba,anli,SENTIMENT,False,28,bigscience/T0_3B,0,True,convert_to_rating,prompts/general_fixed_choice.yaml,AppReviews,,3,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,['NLI'],anli,True,False,GeneralFixedChoice,False,False,False,,,prompts,,False,True,convert_to_rating,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.app_reviews.convert_to_rating.LenNorm,ANLI R2,,,,,,,,,,,,,,,,,,,,,46.5,62.0,28
22.375661375661373,45.66666666666666,0.4617317828026828,1.1490946760177612,1.629,0.4082200142595257,0.4933143014346938,4.571428571428571,,,,124.051,0.5208065290451049,2.751,16.88888888888889,0.6282881469726562,0.647301320869964,0.3947321374335241,0.7011419257183242,1.62,32.0,"{'nrows': 1000, 'sha256': '4089d228e3b45f138c1ee4fe96c7241c6fbcf72b491bbf0c3b72c17261592ee2', 'artifact_path': 'wandb-client-artifact://fr0tyba1vifm06tekzu1adk980h5eivob4xr6eppba9ftkiqla3bx9msgsn5rhpbd8v9dp313y4yfnq0y921vczvi1gb2gmg2jhv9ixjq0cyceq3b76qyycisc2791n0:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://fr0tyba1vifm06tekzu1adk980h5eivob4xr6eppba9ftkiqla3bx9msgsn5rhpbd8v9dp313y4yfnq0y921vczvi1gb2gmg2jhv9ixjq0cyceq3b76qyycisc2791n0:latest/predictions.table.json', 'path': 'media/table/predictions_1_4089d228e3b45f138c1e.table.json', 'size': 593036, '_type': 'table-file', 'ncols': 11}",17.873231353059808,,,False,True,dev_r2,False,Yes | Maybe | No,4,CTBase,96538f30-f2c1-430e-8fc6-936a16966d9c,anli,SENTIMENT,False,28,bigscience/T0_3B,0,True,Writer_Expressed_Sentiment,prompts/general_fixed_choice.yaml,IMDB,,3,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,['NLI'],anli,True,False,GeneralFixedChoice,False,False,False,,,prompts,,False,True,Writer Expressed Sentiment,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.imdb.Writer_Expressed_Sentiment.LenNorm,ANLI R2,,,,,,,,,,,,,,,,,,,,,75.0,65.0,10
16.65416354088522,49.96249062265567,0.5897724055023958,2.8689952087402344,1.76,0.6696712350642863,0.4270831300812524,0.0,,,,123.051,0.7694539966583251,3.0,0.0,2.099541212081909,0.0,0.6077282349827619,0.4270831300812524,1.24,33.300000000000004,"{'_type': 'table-file', 'ncols': 11, 'nrows': 1000, 'sha256': 'cbb5b506c48e840dcaa1c3e8dd6e3ec2b28b70db4066f87e4607a4ed2d634a9f', 'artifact_path': 'wandb-client-artifact://5t25n9wiyjwnc47ce975h6yk0ntg2jyc4pvn47l00m6cmz9sflvlny2bmqik0uwjdrnmgp6csn7dqy8yb41f1jikplbsmohjf40bwovlvp8h2piaakmuao9v0w51g6b9:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://5t25n9wiyjwnc47ce975h6yk0ntg2jyc4pvn47l00m6cmz9sflvlny2bmqik0uwjdrnmgp6csn7dqy8yb41f1jikplbsmohjf40bwovlvp8h2piaakmuao9v0w51g6b9:latest/predictions.table.json', 'path': 'media/table/predictions_1_cbb5b506c48e840dcaa1.table.json', 'size': 581035}",17.873231353059808,,,False,True,dev_r2,False,Yes | Maybe | No,4,CTBase,866474a5-1498-46b7-bfee-ac0c5160707f,anli,SENTIMENT,False,28,bigscience/T0_3B,0,True,Reviewer_Sentiment_Feeling,prompts/general_fixed_choice.yaml,IMDB,,3,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,['NLI'],anli,True,False,GeneralFixedChoice,False,False,False,,,prompts,,False,True,Reviewer Sentiment Feeling,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.imdb.Reviewer_Sentiment_Feeling.LenNorm,ANLI R2,,,,,,,,,,,,,,,,,,,,,34.0,90.0,9
28.125408016712367,38.54289071680376,0.6902490421864887,4.047244785308838,2.0,0.518248240645427,0.0,0.0,,,,130.051,3.392928198814392,2.036,45.83333333333334,0.6543165864944458,0.9993517899118408,0.6536826688384714,0.9993517899118408,1.964,35.099999999999994,"{'artifact_path': 'wandb-client-artifact://mfidaezjdb3dop1p43cih4nqvgpqxo5kbxsa6q7o1uapw7m2w9n5huui68ozrjfzrecbr5626x0mvjwz4htvytfk76epfqvs2vdbnapg3n0k0rv8ptd92zme4mtbmy2y:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://mfidaezjdb3dop1p43cih4nqvgpqxo5kbxsa6q7o1uapw7m2w9n5huui68ozrjfzrecbr5626x0mvjwz4htvytfk76epfqvs2vdbnapg3n0k0rv8ptd92zme4mtbmy2y:latest/predictions.table.json', 'path': 'media/table/predictions_1_0f88dde5a16d2c7ef714.table.json', 'size': 585137, '_type': 'table-file', 'ncols': 11, 'nrows': 1000, 'sha256': '0f88dde5a16d2c7ef714419c0cc7b5889e2939cc81a4682eec4d41a02f695ba1'}",17.873231353059804,,,False,True,dev_r2,False,Yes | Maybe | No,4,CTBase,5f372fb1-795a-47b6-8ddf-c4fd1579e76a,anli,SENTIMENT,False,28,bigscience/T0_3B,0,True,Sentiment_with_choices,prompts/general_fixed_choice.yaml,IMDB,,3,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,['NLI'],anli,True,False,GeneralFixedChoice,False,False,True,,,prompts,,False,True,Sentiment with choices ,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.imdb.Sentiment_with_choices.LenNorm,ANLI R2,,,,,,,,,,,,,,,,,,,,,1.5,2.0,6
20.96813486948016,45.86404586404586,0.5576026142981088,4.325377666473389,2.0,0.6164065805379394,0.0,0.0,,,,133.051,3.3879562039375304,2.776,17.040358744394617,0.937421462535858,0.6307329070216648,0.627176286951668,0.6307329070216647,1.224,31.8,"{'_latest_artifact_path': 'wandb-client-artifact://imd382ktx9rvaditvjuyb0768810xg859gn3nwp1fhivzb4dtg67ksayvy99nq8f778x91irp442zbymgq02g3j354svt288vy20rhbr8x6mh5l8b6ids64ywzekomdr:latest/predictions.table.json', 'path': 'media/table/predictions_1_20ef03a89c8168c86fb9.table.json', 'size': 600755, '_type': 'table-file', 'ncols': 11, 'nrows': 1000, 'sha256': '20ef03a89c8168c86fb94ea2b21e9fe560aef43b62736ea9c016a1e1243ef0d4', 'artifact_path': 'wandb-client-artifact://imd382ktx9rvaditvjuyb0768810xg859gn3nwp1fhivzb4dtg67ksayvy99nq8f778x91irp442zbymgq02g3j354svt288vy20rhbr8x6mh5l8b6ids64ywzekomdr:latest/predictions.table.json'}",17.873231353059804,,,False,True,dev_r2,False,Yes | Maybe | No,4,CTBase,2351d12a-e630-4d19-8b41-e199266e38f7,anli,SENTIMENT,False,28,bigscience/T0_3B,0,True,Reviewer_Opinion_bad_good_choices,prompts/general_fixed_choice.yaml,IMDB,,3,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,['NLI'],anli,True,False,GeneralFixedChoice,False,False,True,,,prompts,,False,True,Reviewer Opinion bad good choices,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.imdb.Reviewer_Opinion_bad_good_choices.LenNorm,ANLI R2,,,,,,,,,,,,,,,,,,,,,78.0,73.0,9
22.841071255386066,44.89795918367347,0.7503710910909748,2.3637217721939088,1.964,0.6383828457082869,0.1915828802372487,0.0,,,,124.051,1.407465615272522,2.686,23.62525458248473,0.9562561569213868,0.7276015393056835,0.7851798549965391,0.7345066371381542,1.35,32.2,"{'sha256': '6a8704a099e79c4b9551482329b1ddfcf9441d79cd59e30b280fcef914165b9d', 'artifact_path': 'wandb-client-artifact://15ee06qr1ax4suk9n929vn6r9bvsoptodqzxp0gfh8p7opzrbgmz2stdcoxmzvds784qo0svr4qr2duf3adhzi5cbmcjhda8q29h0gl5hq31m8ssgxz7ee0y5gsn71e9:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://15ee06qr1ax4suk9n929vn6r9bvsoptodqzxp0gfh8p7opzrbgmz2stdcoxmzvds784qo0svr4qr2duf3adhzi5cbmcjhda8q29h0gl5hq31m8ssgxz7ee0y5gsn71e9:latest/predictions.table.json', 'path': 'media/table/predictions_1_6a8704a099e79c4b9551.table.json', 'size': 591965, '_type': 'table-file', 'ncols': 11, 'nrows': 1000}",17.873231353059808,,,False,True,dev_r2,False,Yes | Maybe | No,4,CTBase,02ff2949-0f45-4d97-941e-6fa4c0afbc2d,anli,SENTIMENT,False,28,bigscience/T0_3B,0,True,Movie_Expressed_Sentiment_2,prompts/general_fixed_choice.yaml,IMDB,,3,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,['NLI'],anli,True,False,GeneralFixedChoice,False,False,False,,,prompts,,False,True,Movie Expressed Sentiment 2,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.imdb.Movie_Expressed_Sentiment_2.LenNorm,ANLI R2,,,,,,,,,,,,,,,,,,,,,72.0,60.0,10
28.135911589476475,38.78504672897197,0.8258026737263632,3.825772946357727,2.0,0.5415146661061733,0.0,0.0,,,,115.434,3.141545082807541,2.046,45.62268803945746,0.6842278635501862,0.9989414397250722,0.8059931743465147,0.9989414397250722,1.954,35.099999999999994,"{'sha256': '773811db998a4be73e1b81327c3c84154bbf04d64c3d6c1a7a64cd79404f1f2f', 'artifact_path': 'wandb-client-artifact://18gjwjlb2143tl12xv8i5pkejohop0mg7pkqfhw3mcksx40uz56j7dh0pambkn71ho81pvdb3ag689anbp3lheiyf0eilsei630gld2xwql4ovnq1ang2a3xoszpl4p6:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://18gjwjlb2143tl12xv8i5pkejohop0mg7pkqfhw3mcksx40uz56j7dh0pambkn71ho81pvdb3ag689anbp3lheiyf0eilsei630gld2xwql4ovnq1ang2a3xoszpl4p6:latest/predictions.table.json', 'path': 'media/table/predictions_1_773811db998a4be73e1b.table.json', 'size': 565621, '_type': 'table-file', 'ncols': 11, 'nrows': 1000}",17.88970776731694,,,False,True,dev_r2,False,Yes | Maybe | No,4,CTBase,f56ffced-9b16-431a-8a17-501e63cddf73,anli,ENTAILMENT,False,28,bigscience/T0_3B,0,True,imply_separated,prompts/general_fixed_choice.yaml,RTE,,3,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,['NLI'],anli,False,False,GeneralFixedChoice,False,False,True,,,prompts,,False,True,imply separated,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.super_glue_rte.imply_separated.LenNorm,ANLI R2,,,,,,,,,,,,,,,,,,,,,1.5,1.0,6
26.29305235560895,41.49043303121853,0.7286829744822898,4.996753982543945,2.0,0.635979755569977,0.0,0.0,,,,121.567,4.225712651014328,2.32,37.38872403560831,0.7710413315296173,0.9474175425861612,0.7747566090828305,0.947417542586161,1.68,33.2,"{'path': 'media/table/predictions_1_8c1b915c6a4445a6de9c.table.json', 'size': 582773, '_type': 'table-file', 'ncols': 11, 'nrows': 1000, 'sha256': '8c1b915c6a4445a6de9c23d32cb56611ad21f8a39f956b85dcf908f0753a198f', 'artifact_path': 'wandb-client-artifact://txzy420fukog5w8zbr5yi74cuiqkcybhw8xvh3r07fgbwmqg2yzvqj1l3fihf8i88uyi9nwah424romd6vczpefw8kcwwyalf5osri5ofkp31q6km09vrzpaf71eiaa7:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://txzy420fukog5w8zbr5yi74cuiqkcybhw8xvh3r07fgbwmqg2yzvqj1l3fihf8i88uyi9nwah424romd6vczpefw8kcwwyalf5osri5ofkp31q6km09vrzpaf71eiaa7:latest/predictions.table.json'}",17.87052072548531,,,False,True,dev_r2,False,Yes | Maybe | No,4,CTBase,c8dfc879-40f2-412d-be1e-4cd70107f6e6,anli,ENTAILMENT,False,28,bigscience/T0_3B,0,True,imply,prompts/general_fixed_choice.yaml,RTE,,3,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,['NLI'],anli,False,False,GeneralFixedChoice,False,False,True,,,prompts,,False,True,imply,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.super_glue_rte.imply.LenNorm,ANLI R2,,,,,,,,,,,,,,,,,,,,,40.5,27.0,14
22.103557631321,44.765957446808514,0.6093202139222227,5.248616942167282,2.0,0.5327207257007539,0.0,0.0,,,,148.434,4.528008621692657,2.684,21.544715447154477,0.7206083204746246,0.7294820080029389,0.602228876524879,0.7294820080029389,1.316,31.6,"{'path': 'media/table/predictions_1_dcc1891b7bb97a03610a.table.json', 'size': 739996, '_type': 'table-file', 'ncols': 11, 'nrows': 1000, 'sha256': 'dcc1891b7bb97a03610a292359ef82dbcf5a11c6d77e79f66da9f1c6eeb2aa45', 'artifact_path': 'wandb-client-artifact://jyfim1ia3xsmoxdhihjuo0hzhobs6dwpnsq68v4csrkolpq2kz7722if41153fjbwcgc79e6ylry5xyusez2hj4qayeca9f1q112cvgbxie6bx7gm2hmac2nxh1knxcd:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://jyfim1ia3xsmoxdhihjuo0hzhobs6dwpnsq68v4csrkolpq2kz7722if41153fjbwcgc79e6ylry5xyusez2hj4qayeca9f1q112cvgbxie6bx7gm2hmac2nxh1knxcd:latest/predictions.table.json'}",17.88970776731694,,,False,True,dev_r2,False,Yes | Maybe | No,4,CTBase,9e2b4267-ec23-44c8-b82a-107e2c890fec,anli,ENTAILMENT,False,28,bigscience/T0_3B,0,True,entailment_explained,prompts/general_fixed_choice.yaml,RTE,,3,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,['NLI'],anli,False,False,GeneralFixedChoice,False,False,True,,,prompts,,False,True,entailment explained,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.super_glue_rte.entailment_explained.LenNorm,ANLI R2,,,,,,,,,,,,,,,,,,,,,80.5,68.0,40
26.011827535226143,41.69960474308301,0.7500019376338881,5.043001556396485,2.0,0.58459329514338,0.0,0.0,,,,125.567,4.335111304998398,2.358,36.335877862595424,0.7078902513980866,0.9337215859130602,0.8006987240346879,0.9337215859130602,1.642,33.0,"{'path': 'media/table/predictions_1_1e3dee505bb5012e591e.table.json', 'size': 607852, '_type': 'table-file', 'ncols': 11, 'nrows': 1000, 'sha256': '1e3dee505bb5012e591e8f7782e1ec7838f7abba9c08b103dad96228e3c4f34a', 'artifact_path': 'wandb-client-artifact://wkf0ec002a7ikyfieuskmiuunsa19c3nx7w1z0zbhqfvxuyyxdzz0t0jufdqo9dxbokcvd7bzulvycjb1qevgizqh2join2ejbiw3e19h8l0okgfjya0p0tvvnqsqbbe:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://wkf0ec002a7ikyfieuskmiuunsa19c3nx7w1z0zbhqfvxuyyxdzz0t0jufdqo9dxbokcvd7bzulvycjb1qevgizqh2join2ejbiw3e19h8l0okgfjya0p0tvvnqsqbbe:latest/predictions.table.json'}",17.87052072548531,,,False,True,dev_r2,False,Yes | Maybe | No,4,CTBase,4ee6ff27-de63-4e7b-a9d4-82a17eba407a,anli,ENTAILMENT,False,28,bigscience/T0_3B,0,True,does_the_claim_follow_the_fact,prompts/general_fixed_choice.yaml,RTE,,3,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,['NLI'],anli,False,False,GeneralFixedChoice,False,False,True,,,prompts,,False,True,does the claim follow the fact,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.super_glue_rte.does_the_claim_follow_the_fact.LenNorm,ANLI R2,,,,,,,,,,,,,,,,,,,,,52.0,31.0,18
27.35319747148683,39.00226757369615,0.876200833960076,4.3197074754238125,2.0,0.5903527124478962,0.0,0.0,,,,118.623,3.5854866242408754,2.098,43.05732484076433,0.7342208511829377,0.9951864146982714,0.8377935152873597,0.9951864146982716,1.902,34.1,"{'ncols': 11, 'nrows': 1000, 'sha256': '2ac1484a34f006b5f971d9e3868f88eeb97065fd2c5f558adff83d8cc1499a39', 'artifact_path': 'wandb-client-artifact://bmt4b7onqw6j0xfjq5cf5qwvj4cgleha42awnn04bsrhnfjqoc6cljmo6l94lwy9jopgqc0aynhrzbh4fi4pxxub3yyt0vtoyqm5zuqu0uxr1ribch8a5xl20zspa01a:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://bmt4b7onqw6j0xfjq5cf5qwvj4cgleha42awnn04bsrhnfjqoc6cljmo6l94lwy9jopgqc0aynhrzbh4fi4pxxub3yyt0vtoyqm5zuqu0uxr1ribch8a5xl20zspa01a:latest/predictions.table.json', 'path': 'media/table/predictions_1_2ac1484a34f006b5f971.table.json', 'size': 568748, '_type': 'table-file'}",17.855443735735047,,,False,True,dev_r2,False,Yes | Maybe | No,4,CTBase,03a7ae07-5ddd-46c4-92f3-2152223d44ec,anli,ENTAILMENT,False,28,bigscience/T0_3B,0,True,mean,prompts/general_fixed_choice.yaml,RTE,,3,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,['NLI'],anli,False,False,GeneralFixedChoice,False,False,True,,,prompts,,False,True,mean,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.super_glue_rte.mean.LenNorm,ANLI R2,,,,,,,,,,,,,,,,,,,,,16.5,10.0,9
24.823478614243623,43.382352941176464,1.441495305158646,11.786663205385208,2.0,1.054403066311436,0.0,0.0,,,,123.051,10.433484402894974,2.51,31.088082901554408,1.3531788024902345,0.8601744009211155,1.509363412578774,0.8601744009211156,1.49,32.6,"{'path': 'media/table/predictions_1_28b2a77e273bac695083.table.json', 'size': 577872, '_type': 'table-file', 'ncols': 11, 'nrows': 1000, 'sha256': '28b2a77e273bac695083d7e0108af0d5bf2f71de33c9182b8c021058f8c1f4e6', 'artifact_path': 'wandb-client-artifact://18ipaexptsba7q8bcqfx3yofybvgghjbifwq5wdvrhurrr4cd6harturhvsjsg5oh4iouk1us5jq95rqy7kfp0g2ed84ogv5rb9jycqe8cy64fih64jz0ozbdmvy6xln:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://18ipaexptsba7q8bcqfx3yofybvgghjbifwq5wdvrhurrr4cd6harturhvsjsg5oh4iouk1us5jq95rqy7kfp0g2ed84ogv5rb9jycqe8cy64fih64jz0ozbdmvy6xln:latest/predictions.table.json'}",17.873231353059808,,,False,True,dev_r2,False,Yes | Maybe | No,4,CTBase,f2004e15-9d9a-4ca1-9830-a341e684e97e,anli,QA,False,28,bigscience/T0_3B,0,True,qa_no_choices_and_answer,prompts/general_fixed_choice.yaml,No Prompt,,3,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,['NLI'],anli,False,False,GeneralFixedChoice,False,False,False,,,prompts,,False,True,qa no choices and answer,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.BAREBONES.qa_no_choices_and_answer.LenNorm,ANLI R2,,,,,,,,,,,,,,,,,,,,,64.5,44.0,0
25.31341120597838,45.057880676758685,1.0565770576986573,4.641073759913445,1.999,0.6629302313779417,0.0316069612585582,0.0,,,,100.434,3.773742235302925,2.58,30.882352941176467,0.8673315246105194,0.814616474176652,1.0162935696966522,0.8147140602690002,1.421,33.7,"{'nrows': 1000, 'sha256': 'f8573d0ab2422cb6bebcfdce603045a9749f417365e4289d4f6e61758497c3d6', 'artifact_path': 'wandb-client-artifact://1kkv9teuhl10t6wm5poiyigi38ho32578kd7w7b7aa8z4nk17s667mplkzx06je8o6qo9xfatqpl63752l2qo1r5cuv0ky6ubsofji8gr0xaqgu0d3kxzfxmei1d3yhg:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://1kkv9teuhl10t6wm5poiyigi38ho32578kd7w7b7aa8z4nk17s667mplkzx06je8o6qo9xfatqpl63752l2qo1r5cuv0ky6ubsofji8gr0xaqgu0d3kxzfxmei1d3yhg:latest/predictions.table.json', 'path': 'media/table/predictions_1_f8573d0ab2422cb6bebc.table.json', 'size': 516668, '_type': 'table-file', 'ncols': 11}",17.88970776731694,,,False,True,dev_r2,False,Yes | Maybe | No,4,CTBase,e5eaa3ee-e537-4d20-9dfa-6084db54f2ef,anli,ENTAILMENT,False,28,bigscience/T0_3B,0,True,entailment_no_choices_and_answer,prompts/general_fixed_choice.yaml,No Prompt,,3,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,['NLI'],anli,False,False,GeneralFixedChoice,False,False,False,,,prompts,,False,True,entailment no choices and answer,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.BAREBONES.entailment_no_choices_and_answer.LenNorm,ANLI R2,,,,,,,,,,,,,,,,,,,,,19.5,40.0,2
26.22693969225753,41.06614017769003,1.081152016439229,5.767987665772438,2.0,0.7578823625176629,0.0,0.0,,,,116.051,4.790379701852799,2.36,37.61467889908257,0.9776079639196396,0.932952303175248,1.0971768990404411,0.932952303175248,1.64,33.1,"{'_type': 'table-file', 'ncols': 11, 'nrows': 1000, 'sha256': '4dc1fe82c63bd1847c1668ca79fdec429cfa75fe81ff49c3f3dd67f5fbaf8102', 'artifact_path': 'wandb-client-artifact://12yea5vbwjp3wg6l69vt5k5qka9s0pf4mkikd40coyxu7pqxbgei5xrpdy9mayh0tjgk3hm66qzy5ezn7jzqwbprhlysqfmpobac8xrrrvi8bytbiqzu51q5muwv6wgs:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://12yea5vbwjp3wg6l69vt5k5qka9s0pf4mkikd40coyxu7pqxbgei5xrpdy9mayh0tjgk3hm66qzy5ezn7jzqwbprhlysqfmpobac8xrrrvi8bytbiqzu51q5muwv6wgs:latest/predictions.table.json', 'path': 'media/table/predictions_1_4dc1fe82c63bd1847c16.table.json', 'size': 547073}",17.873231353059808,,,False,True,dev_r2,False,Yes | Maybe | No,4,CTBase,cf005ddf-8cf2-409d-b884-45d22463f463,anli,CLASSIFICATION,False,28,bigscience/T0_3B,0,True,classification_no_choices_and_answer,prompts/general_fixed_choice.yaml,No Prompt,,3,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,['NLI'],anli,False,False,GeneralFixedChoice,False,False,False,,,prompts,,False,True,classification no choices and answer,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.BAREBONES.classification_no_choices_and_answer.LenNorm,ANLI R2,,,,,,,,,,,,,,,,,,,,,46.5,28.0,2
16.77482748939817,0.5882352941176471,0.8395621731141882,6.25835205629468,2.0,0.7730472807177333,0.0,0.0,,,,240.102,4.004285780668258,1.014,49.73624717407687,2.254066275626421,0.1667453147767576,0.6848231259462266,0.1667453147767576,2.986,33.1,"{'path': 'media/table/predictions_1_c5a1a561f5d571c9a234.table.json', 'size': 1003560, '_type': 'table-file', 'ncols': 11, 'nrows': 1000, 'sha256': 'c5a1a561f5d571c9a23493eaefc1d8edb7c8dcbbdcddcd45e14c9bd33b318f0d', 'artifact_path': 'wandb-client-artifact://7ihpckyh474f28i3cpny9hmxdnmjk9yj5pzrolym5vuxaujy4fjs7261bg4sanu7ieyp0rjem8utwsejgiqs05df8ff7qqfqyjwv0sq71ebkbyj8sq9iprhryn7gl04o:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://7ihpckyh474f28i3cpny9hmxdnmjk9yj5pzrolym5vuxaujy4fjs7261bg4sanu7ieyp0rjem8utwsejgiqs05df8ff7qqfqyjwv0sq71ebkbyj8sq9iprhryn7gl04o:latest/predictions.table.json'}",35.746462706119615,,,False,True,dev_r2,False,Yes | Maybe | No,4,CTBase,2e94d035-3c3d-44cf-98cb-3d11bea7c17b,anli,QA,False,28,bigscience/T0_3B,0,True,qa_choices_and_answer,prompts/general_fixed_choice.yaml,No Prompt,,3,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,['NLI'],anli,False,False,GeneralFixedChoice,False,False,True,,,prompts,,False,True,qa choices and answer,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.BAREBONES.qa_choices_and_answer.LenNorm,ANLI R2,,,,,,,,,,,,,,,,,,,,,46.5,89.0,2
12.054794520547944,,0.739063746924915,1.1577024885853255,,,,12.054794520547944,,,,70.62068965517241,1.1577024885853255,1.072100313479624,64.76399560922064,,0.2586539353571946,0.739063746924915,0.2586539353571946,1.927899686520376,49.68652037617554,"{'sha256': '47af1d6e618a73717784b98d5380457272e2cb19339d919fe21020e9aa919f56', 'artifact_path': 'wandb-client-artifact://krmv68z44zmiwgp93as211zjzu7v9awsq37zy8b58tx3yve2v10z4rqh4pdi9ku8lg49hk2egm6f8jg5nvdzzk910vssomc2e9e229w7x6288zt0svnbgdv07n9c60k0:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://krmv68z44zmiwgp93as211zjzu7v9awsq37zy8b58tx3yve2v10z4rqh4pdi9ku8lg49hk2egm6f8jg5nvdzzk910vssomc2e9e229w7x6288zt0svnbgdv07n9c60k0:latest/predictions.table.json', 'path': 'media/table/predictions_1_47af1d6e618a73717784.table.json', 'size': 237077, '_type': 'table-file', 'ncols': 9, 'nrows': 638}",7.037985482349875,,,False,True,validation,False,No | Yes,4,CTBase,a64d5a15-68e2-4d1c-b30a-ca8250c860f9,wic,QA,False,28,bigscience/T0_3B,0,True,answer_the_following_q,prompts/general_fixed_choice.yaml,AdversarialQA,,2,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,Word Sense Disambiguation,wic,True,False,GeneralFixedChoice,False,False,False,,,prompts,,False,True,answer_the_following_q,,cross_task,wic,,,,False,,,False,,True,,,False,,CTBase.GenFC.adversarial_qa.answer_the_following_q.LenNorm,WiC,55.68513258721223,55.31490453120546,WordsinContext,super_glue,,,,,,,,,,,,,,,,,88.5,23.0,23
26.32253011494528,41.84184184184184,0.7307607674678511,4.4651335157305,2.0,0.4958207759773675,0.0,0.0,,,,111.434,3.857855329692364,2.332,37.12574850299401,0.6072781860381364,0.943279385972152,0.74482396941025,0.943279385972152,1.668,33.300000000000004,"{'nrows': 1000, 'sha256': 'c7235eea24de30b60e438e6dc8b006a1f8beb038e7ef2da7cd6db817a0740f57', 'artifact_path': 'wandb-client-artifact://epz6d2zdjjtrrmkugl1wvneu7sdag9emgeu166z6ldechi0du07hmccaia5zj9veeqrumfp9qw9vzzkct95vnn3g9pb2hv6ickt8we8p0qmy7s91xi4htdhpldcaxwe3:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://epz6d2zdjjtrrmkugl1wvneu7sdag9emgeu166z6ldechi0du07hmccaia5zj9veeqrumfp9qw9vzzkct95vnn3g9pb2hv6ickt8we8p0qmy7s91xi4htdhpldcaxwe3:latest/predictions.table.json', 'path': 'media/table/predictions_1_c7235eea24de30b60e43.table.json', 'size': 547079, '_type': 'table-file', 'ncols': 11}",17.88970776731694,,,False,True,dev_r2,False,Yes | Maybe | No,4,CTBase,c225e598-1efe-4cb6-9f7c-a1b7eb5c7803,anli,ENTAILMENT,False,28,bigscience/T0_3B,0,True,entailment_choices_and_answer,prompts/general_fixed_choice.yaml,No Prompt,,3,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,['NLI'],anli,False,False,GeneralFixedChoice,False,False,True,,,prompts,,False,True,entailment choices and answer,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.BAREBONES.entailment_choices_and_answer.LenNorm,ANLI R2,,,,,,,,,,,,,,,,,,,,,34.0,26.0,2
4.833836858006042,,0.886776637747029,1.8447733798464263,,,,4.833836858006042,,,,63.62068965517241,1.8447733798464263,1.0188087774294672,66.66666666666667,,0.1358492080252066,0.886776637747029,0.1358492080252066,1.9811912225705328,50.626959247648905,"{'path': 'media/table/predictions_1_267985090b096e3526a3.table.json', 'size': 211132, '_type': 'table-file', 'ncols': 9, 'nrows': 638, 'sha256': '267985090b096e3526a31df8f174d6cf4f4be19f9514e8cd33482992bf690d31', 'artifact_path': 'wandb-client-artifact://l6y43ouvmn2i855mnn3qdld0c8vz0l2oa3f59s5e7rjsrr0ezqcdmglnar8a54gqw090mt2ug6sevmpsdmw1c240ysadme5ja9c0elqhkjfulfkiaklywftxd5dwye8o:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://l6y43ouvmn2i855mnn3qdld0c8vz0l2oa3f59s5e7rjsrr0ezqcdmglnar8a54gqw090mt2ug6sevmpsdmw1c240ysadme5ja9c0elqhkjfulfkiaklywftxd5dwye8o:latest/predictions.table.json'}",7.037985482349875,,,False,True,validation,False,No | Yes,4,CTBase,a0872cde-2f19-4ae6-919a-868da47bfbcb,wic,QA,False,28,bigscience/T0_3B,0,True,based_on,prompts/general_fixed_choice.yaml,AdversarialQA,,2,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,Word Sense Disambiguation,wic,True,False,GeneralFixedChoice,False,False,False,,,prompts,,False,True,based_on,,cross_task,wic,,,,False,,,False,,True,,,False,,CTBase.GenFC.adversarial_qa.based_on.LenNorm,WiC,56.52261360565445,56.91473157693026,WordsinContext,super_glue,,,,,,,,,,,,,,,,,36.5,59.0,16
10.285714285714286,,0.8228324081778067,1.4266349327601608,,,,10.285714285714286,,,,58.62068965517241,1.4266349327601608,1.04858934169279,66.09071274298056,,0.2150079476825246,0.8228324081778067,0.2150079476825246,1.95141065830721,50.78369905956113,"{'_latest_artifact_path': 'wandb-client-artifact://tirur4rrs0z4e9lr9dg38a2vfnqyetgp7v9xvhy7qyc34n0ckqw9hfpai14iqvgbd2gc2jsz03njz1ly59fcp4b0abxfooyuazrnhg231m8nkw7w2azeexfgwxpqy4jt:latest/predictions.table.json', 'path': 'media/table/predictions_1_bc429f444dc6facb8c49.table.json', 'size': 180945, '_type': 'table-file', 'ncols': 9, 'nrows': 638, 'sha256': 'bc429f444dc6facb8c4907f53b78aa2a8436e87381ca404b961a274cf04b9e7b', 'artifact_path': 'wandb-client-artifact://tirur4rrs0z4e9lr9dg38a2vfnqyetgp7v9xvhy7qyc34n0ckqw9hfpai14iqvgbd2gc2jsz03njz1ly59fcp4b0abxfooyuazrnhg231m8nkw7w2azeexfgwxpqy4jt:latest/predictions.table.json'}",7.037985482349875,,,False,True,validation,False,No | Yes,4,CTBase,5bdb1815-5c6f-49a3-ad1d-367344420701,wic,QA,False,28,bigscience/T0_3B,0,True,question_context_answer,prompts/general_fixed_choice.yaml,AdversarialQA,,2,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,Word Sense Disambiguation,wic,True,False,GeneralFixedChoice,False,False,False,,,prompts,,False,True,question_context_answer,,cross_task,wic,,,,False,,,False,,True,,,False,,CTBase.GenFC.adversarial_qa.question_context_answer.LenNorm,WiC,55.38130357102895,55.63526301824864,WordsinContext,super_glue,,,,,,,,,,,,,,,,,28.0,32.0,11
7.647058823529411,,0.8729728789245634,1.621219295319345,,,,7.647058823529411,,,,70.62068965517241,1.621219295319345,1.0329153605015673,66.45299145299145,,0.1784150765619858,0.8729728789245634,0.1784150765619858,1.9670846394984327,50.78369905956113,"{'artifact_path': 'wandb-client-artifact://jrggbnaigl9u1vfh8q343dzia24sfvz989kb5rnotsp9387exv1smb43ypo79lo8sedk9zkc6d8bb62qkgelhr6a8iutsa3cgfh0e7bbvl8v172ghv2mj4hkkiu17ogn:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://jrggbnaigl9u1vfh8q343dzia24sfvz989kb5rnotsp9387exv1smb43ypo79lo8sedk9zkc6d8bb62qkgelhr6a8iutsa3cgfh0e7bbvl8v172ghv2mj4hkkiu17ogn:latest/predictions.table.json', 'path': 'media/table/predictions_1_fc838c81484b13beff13.table.json', 'size': 210863, '_type': 'table-file', 'ncols': 9, 'nrows': 638, 'sha256': 'fc838c81484b13beff13c206ef2ce274fe6abf33de0a14086dc784da8021d140'}",7.037985482349875,,,False,True,validation,False,No | Yes,4,CTBase,3b2459cc-6600-443c-abf8-8f60c34cd998,wic,QA,False,28,bigscience/T0_3B,0,True,tell_what_it_is,prompts/general_fixed_choice.yaml,AdversarialQA,,2,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,Word Sense Disambiguation,wic,True,False,GeneralFixedChoice,False,False,False,,,prompts,,False,True,tell_what_it_is,,cross_task,wic,,,,False,,,False,,True,,,False,,CTBase.GenFC.adversarial_qa.tell_what_it_is.LenNorm,WiC,55.21980881825722,55.60381678639165,WordsinContext,super_glue,,,,,,,,,,,,,,,,,28.0,43.5,22
27.8601650842305,41.36413641364136,0.7807923649062001,5.1433437494859096,2.0,0.625156118654258,0.0,0.0,,,,127.051,4.362739895224571,2.152,42.21635883905013,0.7806038542613387,0.988380493534752,0.7807293941218427,0.988380493534752,1.848,34.8,"{'path': 'media/table/predictions_1_fd8ec859e9162789c730.table.json', 'size': 579269, '_type': 'table-file', 'ncols': 11, 'nrows': 1000, 'sha256': 'fd8ec859e9162789c730506068d06099c527dd2fd691179dd16cc4652ca76379', 'artifact_path': 'wandb-client-artifact://6y8h5ire4j5ecewxlu9glsersb4505a6ddl4r9tihpeyaryx83jqhdavy1p6lgq60obs9m4z4v3p0wovusdcynoihs45yuiyos4hfdwjexo0ocmkmp5ay29u6oshqlhp:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://6y8h5ire4j5ecewxlu9glsersb4505a6ddl4r9tihpeyaryx83jqhdavy1p6lgq60obs9m4z4v3p0wovusdcynoihs45yuiyos4hfdwjexo0ocmkmp5ay29u6oshqlhp:latest/predictions.table.json'}",17.873231353059808,,,False,True,dev_r2,False,Yes | Maybe | No,4,CTBase,32a28538-99bc-4c5a-8086-83b885fddb50,anli,CLASSIFICATION,False,28,bigscience/T0_3B,0,True,classification_choices_and_answer,prompts/general_fixed_choice.yaml,No Prompt,,3,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,['NLI'],anli,False,False,GeneralFixedChoice,False,False,True,,,prompts,,False,True,classification choices and answer,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.BAREBONES.classification_choices_and_answer.LenNorm,ANLI R2,,,,,,,,,,,,,,,,,,,,,7.5,6.0,2
26.634382566585955,,0.701732454425744,0.994161143945676,,,,26.634382566585955,,,,58.62068965517241,0.994161143945676,1.1473354231974922,64.88991888760138,,0.3544399755511616,0.701732454425744,0.3544399755511616,1.852664576802508,52.507836990595614,"{'sha256': 'e300d7815e55a0fcd55742c3556893daac107eae603bcb82ee7abe8a9ffb916b', 'artifact_path': 'wandb-client-artifact://13krxudjknc92iujwgjfqtrxo5a0vaz260tqlp2t3w3muiauy8k4xlcve0vb8b8i6kge1tq3ngwa8jtb46evew57ytq6bkbw5dkw6m2or0l4sni9rl4anie4m5yngp6t:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://13krxudjknc92iujwgjfqtrxo5a0vaz260tqlp2t3w3muiauy8k4xlcve0vb8b8i6kge1tq3ngwa8jtb46evew57ytq6bkbw5dkw6m2or0l4sni9rl4anie4m5yngp6t:latest/predictions.table.json', 'path': 'media/table/predictions_1_e300d7815e55a0fcd557.table.json', 'size': 183424, '_type': 'table-file', 'ncols': 9, 'nrows': 638}",7.037985482349875,,,False,True,validation,False,No | Yes,4,CTBase,4dd990b3-7201-4cba-bb9a-baa462d68b1a,wic,SENTIMENT,False,28,bigscience/T0_3B,0,True,format_score,prompts/general_fixed_choice.yaml,Yelp,,2,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,Word Sense Disambiguation,wic,True,False,GeneralFixedChoice,False,False,False,,,prompts,,False,True,format_score,,cross_task,wic,,,,False,,,False,,True,,,False,,CTBase.GenFC.yelp.format_score.LenNorm,WiC,57.04620455056008,57.43064631833414,WordsinContext,super_glue,,,,,,,,,,,,,,,,,2.0,5.0,12
19.94750656167979,,0.7698435847347569,1.1943850053888876,,,,19.94750656167979,,,,52.62068965517241,1.1943850053888876,1.09717868338558,65.92178770949721,,0.2962009231603189,0.7698435847347569,0.2962009231603189,1.90282131661442,52.19435736677116,"{'path': 'media/table/predictions_1_2e53d31e2fe28726c306.table.json', 'size': 167418, '_type': 'table-file', 'ncols': 9, 'nrows': 638, 'sha256': '2e53d31e2fe28726c3062f371d4edcb7e1be3ecc48eb239a54ee874b053af92c', 'artifact_path': 'wandb-client-artifact://8wim0n6luevmhm4ljwour1u56fp98qs1bhejpzxdowmcbsr6qfjl5g8qdu37bxlkqc5ishtkmukljd355uqaprg6zskj0aqbv0jsnylijra6rjpzfln93shfxw1vej6u:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://8wim0n6luevmhm4ljwour1u56fp98qs1bhejpzxdowmcbsr6qfjl5g8qdu37bxlkqc5ishtkmukljd355uqaprg6zskj0aqbv0jsnylijra6rjpzfln93shfxw1vej6u:latest/predictions.table.json'}",7.037985482349875,,,False,True,validation,False,No | Yes,4,CTBase,29fc6386-90b3-4976-b249-26e49fe7c924,wic,SENTIMENT,False,28,bigscience/T0_3B,0,True,format_star,prompts/general_fixed_choice.yaml,Yelp,,2,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,Word Sense Disambiguation,wic,True,False,GeneralFixedChoice,False,False,False,,,prompts,,False,True,format_star,,cross_task,wic,,,,False,,,False,,True,,,False,,CTBase.GenFC.yelp.format_star.LenNorm,WiC,56.67371955371097,56.93831625082301,WordsinContext,super_glue,,,,,,,,,,,,,,,,,3.0,14.0,6
11.331444759206798,,0.7465659477389128,1.2594698574102037,,,,11.331444759206798,,,,56.62068965517241,1.2594698574102037,1.053291536050157,66.08884073672806,,0.2246142209112584,0.7465659477389128,0.2246142209112584,1.946708463949843,50.94043887147336,"{'_latest_artifact_path': 'wandb-client-artifact://6wdhc455z0dxmnfok0039w7vyhelr9mk2pokd3x7p0118o0nhc7yuc45p1teese1xof7sr0fu3lr2zuqcf832slwgm0q38xpq3ndzk4x6d1c93lbb3r1s1c6i0cm6irg:latest/predictions.table.json', 'path': 'media/table/predictions_1_0fadf2bcfb22ecb96abe.table.json', 'size': 175006, '_type': 'table-file', 'ncols': 9, 'nrows': 638, 'sha256': '0fadf2bcfb22ecb96abef358a7c30d097b7d0f597efb40ab75496dd275af855e', 'artifact_path': 'wandb-client-artifact://6wdhc455z0dxmnfok0039w7vyhelr9mk2pokd3x7p0118o0nhc7yuc45p1teese1xof7sr0fu3lr2zuqcf832slwgm0q38xpq3ndzk4x6d1c93lbb3r1s1c6i0cm6irg:latest/predictions.table.json'}",7.037985482349875,,,False,True,validation,False,No | Yes,4,CTBase,27b6bc81-bb1c-467b-91c0-22a4d6a19f44,wic,SENTIMENT,False,28,bigscience/T0_3B,0,True,based_on_that,prompts/general_fixed_choice.yaml,Yelp,,2,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,Word Sense Disambiguation,wic,True,False,GeneralFixedChoice,False,False,False,,,prompts,,False,True,based_on_that,,cross_task,wic,,,,False,,,False,,True,,,False,,CTBase.GenFC.yelp.based_on_that.LenNorm,WiC,56.64072348854327,57.35104804394611,WordsinContext,super_glue,,,,,,,,,,,,,,,,,23.0,28.0,10
19.17570335135951,7.253886010362695,1.33364360285313,6.031385396838188,2.0,1.0340087693306732,0.0,0.0,,,,227.102,4.109741246223449,1.106,50.27322404371584,1.9216441506147384,0.4480669592817572,1.063575422771824,0.4480669592817572,2.894,33.6,"{'_latest_artifact_path': 'wandb-client-artifact://e3wtmyhy189z4psnb94zqxmt96gb52cf6gnt1gfvj4k6k2lnu3f1lt1myfxgjp9ogkot0lyufufl9w2rd2bm3s8oujo8b7ugkoopnat8d9akwb7zdikchubaymdycnf6:latest/predictions.table.json', 'path': 'media/table/predictions_1_fef9ace3db8128b8def7.table.json', 'size': 964976, '_type': 'table-file', 'ncols': 11, 'nrows': 1000, 'sha256': 'fef9ace3db8128b8def7b1dda42e6faeaab59ba5999b5e7818dcf399ae90807d', 'artifact_path': 'wandb-client-artifact://e3wtmyhy189z4psnb94zqxmt96gb52cf6gnt1gfvj4k6k2lnu3f1lt1myfxgjp9ogkot0lyufufl9w2rd2bm3s8oujo8b7ugkoopnat8d9akwb7zdikchubaymdycnf6:latest/predictions.table.json'}",35.746462706119615,,,False,True,dev_r2,False,Yes | Maybe | No,4,CTBase,97030be6-9843-4fc2-98cf-b47b879b5447,anli,QA,False,28,bigscience/T0_3B,0,True,qa_no_choices,prompts/general_fixed_choice.yaml,No Prompt,,3,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,['NLI'],anli,False,False,GeneralFixedChoice,False,False,False,,,prompts,,False,True,qa no choices,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.BAREBONES.qa_no_choices.LenNorm,ANLI R2,,,,,,,,,,,,,,,,,,,,,23.0,79.0,0
11.830985915492958,,0.8297143867360841,1.4068686539850266,,,,11.830985915492958,,,,53.62068965517241,1.4068686539850266,1.056426332288401,66.01520086862106,,0.2307431500887516,0.8297143867360841,0.2307431500887516,1.943573667711599,50.94043887147336,"{'_latest_artifact_path': 'wandb-client-artifact://mcs5kwyq5wh8bdfh5u97bm375n37chy6oii30buqfn25zw994lzwhc8a1w10q3r1cxq49xewgna7w425kmb9n47bdkf2yhf78g88ghd7zr07rynla63nya4kwyr15g47:latest/predictions.table.json', 'path': 'media/table/predictions_1_d05f40cf8e4b89af0943.table.json', 'size': 171848, '_type': 'table-file', 'ncols': 9, 'nrows': 638, 'sha256': 'd05f40cf8e4b89af0943c397ef4cbe6d7f41751c10adf5de0fb0df5dc1c61e41', 'artifact_path': 'wandb-client-artifact://mcs5kwyq5wh8bdfh5u97bm375n37chy6oii30buqfn25zw994lzwhc8a1w10q3r1cxq49xewgna7w425kmb9n47bdkf2yhf78g88ghd7zr07rynla63nya4kwyr15g47:latest/predictions.table.json'}",7.037985482349875,,,False,True,validation,False,No | Yes,4,CTBase,135fcd11-9fcc-4b55-bf1b-9b76290d0f6b,wic,SENTIMENT,False,28,bigscience/T0_3B,0,True,so_i_would,prompts/general_fixed_choice.yaml,Yelp,,2,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,Word Sense Disambiguation,wic,True,False,GeneralFixedChoice,False,False,False,,,prompts,,False,True,so_i_would,,cross_task,wic,,,,False,,,False,,True,,,False,,CTBase.GenFC.yelp.so_i_would.LenNorm,WiC,55.18321554408132,55.62936684977545,WordsinContext,super_glue,,,,,,,,,,,,,,,,,23.0,25.0,7
7.977207977207977,,0.4871526074223086,0.7726810456817053,,,,7.977207977207977,,,,69.62068965517241,0.7726810456817053,1.0501567398119125,65.08108108108108,,0.218268278188454,0.4871526074223086,0.218268278188454,1.9498432601880875,49.3730407523511,"{'path': 'media/table/predictions_1_3d8b3634f109e23e0bf0.table.json', 'size': 208277, '_type': 'table-file', 'ncols': 9, 'nrows': 638, 'sha256': '3d8b3634f109e23e0bf09f5b7ca567f013eded87426b659d25b6cdb3c6ab20ae', 'artifact_path': 'wandb-client-artifact://14z3slwjp6byg217204m6r6n1tfr4n34jbhwan8bua248zd0m2xg08x507zh9xccxopxr9ck6tpp4qyfquji3jalzyzolb9g8xoedg3sqqasup394odcv0isrobt16s1:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://14z3slwjp6byg217204m6r6n1tfr4n34jbhwan8bua248zd0m2xg08x507zh9xccxopxr9ck6tpp4qyfquji3jalzyzolb9g8xoedg3sqqasup394odcv0isrobt16s1:latest/predictions.table.json'}",7.037985482349875,,,False,True,validation,False,No | Yes,4,CTBase,2da8f134-58db-4f9d-b3b0-8c6b50693ab5,wic,SENTIMENT,False,28,bigscience/T0_3B,0,True,categorize_rating_using_review,prompts/general_fixed_choice.yaml,AppReviews,,2,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,Word Sense Disambiguation,wic,True,False,GeneralFixedChoice,False,False,True,,,prompts,,False,True,categorize_rating_using_review,,cross_task,wic,,,,False,,,False,,True,,,False,,CTBase.GenFC.app_reviews.categorize_rating_using_review.LenNorm,WiC,53.99368756170156,56.7899293442478,WordsinContext,super_glue,,,,,,,,,,,,,,,,,90.0,42.0,18
8.259587020648967,,0.7010862328040139,1.2769708842693075,,,,8.259587020648967,,,,73.62068965517241,1.2769708842693075,1.031347962382445,66.80896478121664,,0.174256327394198,0.7010862328040139,0.174256327394198,1.968652037617555,51.2539184952978,"{'path': 'media/table/predictions_1_62c2a6f8031680751cf3.table.json', 'size': 226670, '_type': 'table-file', 'ncols': 9, 'nrows': 638, 'sha256': '62c2a6f8031680751cf3edb57bbc8e333e896567a1227fcbd79cce6ff88354f3', 'artifact_path': 'wandb-client-artifact://14rlidqr4rs3ba5aqqtnfvaca1jke3xaijkzu1fvzy6yid9pl9bgeayhzbb58gcd52m4y5x6tq9oboucoly51ra6fx3rike1nfwrfq9ww2xid2et6yhfvcaiw0suczkx:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://14rlidqr4rs3ba5aqqtnfvaca1jke3xaijkzu1fvzy6yid9pl9bgeayhzbb58gcd52m4y5x6tq9oboucoly51ra6fx3rike1nfwrfq9ww2xid2et6yhfvcaiw0suczkx:latest/predictions.table.json'}",7.037985482349875,,,False,True,validation,False,No | Yes,4,CTBase,d34e1413-2699-4701-baa2-05d931d012ba,wic,SENTIMENT,False,28,bigscience/T0_3B,0,True,convert_to_rating,prompts/general_fixed_choice.yaml,AppReviews,,2,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,Word Sense Disambiguation,wic,True,False,GeneralFixedChoice,False,False,False,,,prompts,,False,True,convert_to_rating,,cross_task,wic,,,,False,,,False,,True,,,False,,CTBase.GenFC.app_reviews.convert_to_rating.LenNorm,WiC,57.75636007968708,58.68358211888641,WordsinContext,super_glue,,,,,,,,,,,,,,,,,12.5,39.0,28
6.470588235294119,,0.5862120200885407,1.0738390082475908,,,,6.470588235294119,,,,56.62068965517241,1.0738390082475908,1.0329153605015673,66.02564102564102,,0.1784150765619858,0.5862120200885407,0.1784150765619858,1.9670846394984327,50.15673981191222,"{'ncols': 9, 'nrows': 638, 'sha256': 'c9e30c872833fa588bb0138b796063c99d1c5c3e1dfa1717a042e4dbcddd2024', 'artifact_path': 'wandb-client-artifact://sdh1v8bue9xrsa5ghpz15j3d7u07osd47hcjc0fk5ycc2ph9dlx36viiuuejf3l0yqsfgrgjpfwgbk6yzezm8kugezwtcy4nz2wedirabk4eiutstbem69s378mfpyy8:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://sdh1v8bue9xrsa5ghpz15j3d7u07osd47hcjc0fk5ycc2ph9dlx36viiuuejf3l0yqsfgrgjpfwgbk6yzezm8kugezwtcy4nz2wedirabk4eiutstbem69s378mfpyy8:latest/predictions.table.json', 'path': 'media/table/predictions_1_c9e30c872833fa588bb0.table.json', 'size': 190031, '_type': 'table-file'}",7.037985482349875,,,False,True,validation,False,No | Yes,4,CTBase,96538f30-f2c1-430e-8fc6-936a16966d9c,wic,SENTIMENT,False,28,bigscience/T0_3B,0,True,Writer_Expressed_Sentiment,prompts/general_fixed_choice.yaml,IMDB,,2,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,Word Sense Disambiguation,wic,True,False,GeneralFixedChoice,False,False,False,,,prompts,,False,True,Writer Expressed Sentiment,,cross_task,wic,,,,False,,,False,,True,,,False,,CTBase.GenFC.imdb.Writer_Expressed_Sentiment.LenNorm,WiC,55.25041324560205,57.32648067530784,WordsinContext,super_glue,,,,,,,,,,,,,,,,,70.5,51.0,10
0.6230529595015576,,0.7731262539267557,2.26621474816134,,,,0.6230529595015576,,,,55.62068965517241,2.26621474816134,1.0031347962382444,66.59685863874346,,0.0559014247652884,0.7731262539267557,0.0559014247652884,1.996865203761756,50.0,"{'_latest_artifact_path': 'wandb-client-artifact://13o25d10t45sto5rlfo8gu323vfgzsjhttlz1y7xs4z8pjpkcehqvyiikj4vxh76cl4v1a6gi88tz41lc9lwfkk07rf9gyy5ljzf47aangspdbnu6ryu0fof240vjsr3:latest/predictions.table.json', 'path': 'media/table/predictions_1_5dfd4cb65ef75480f2c4.table.json', 'size': 181885, '_type': 'table-file', 'ncols': 9, 'nrows': 638, 'sha256': '5dfd4cb65ef75480f2c4fc63831e4f4bba7f545f5297fce8ad71deca9f3b115b', 'artifact_path': 'wandb-client-artifact://13o25d10t45sto5rlfo8gu323vfgzsjhttlz1y7xs4z8pjpkcehqvyiikj4vxh76cl4v1a6gi88tz41lc9lwfkk07rf9gyy5ljzf47aangspdbnu6ryu0fof240vjsr3:latest/predictions.table.json'}",7.037985482349875,,,False,True,validation,False,No | Yes,4,CTBase,866474a5-1498-46b7-bfee-ac0c5160707f,wic,SENTIMENT,False,28,bigscience/T0_3B,0,True,Reviewer_Sentiment_Feeling,prompts/general_fixed_choice.yaml,IMDB,,2,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,Word Sense Disambiguation,wic,True,False,GeneralFixedChoice,False,False,False,,,prompts,,False,True,Reviewer Sentiment Feeling,,cross_task,wic,,,,False,,,False,,True,,,False,,CTBase.GenFC.imdb.Reviewer_Sentiment_Feeling.LenNorm,WiC,55.17252179436633,57.70285276284628,WordsinContext,super_glue,,,,,,,,,,,,,,,,,82.5,90.0,9
10.37463976945245,,0.671634296439977,1.2068685685579306,,,,10.37463976945245,,,,58.62068965517241,1.2068685685579306,1.0438871473354232,66.52314316469322,,0.2048440031687089,0.671634296439977,0.2048440031687089,1.9561128526645768,51.2539184952978,"{'sha256': 'f631c210119c49c6e133dfd42f7f7caef9c71064f6043ec63d35943a3b0c8507', 'artifact_path': 'wandb-client-artifact://l5abgh7wpjmzlz0fvo06xfeb4ptlxuokcsaw8a1fmni50stnoo30pokh7uqr936njd2zmp1cdxxz7xmwq92p9w9u43i6dpckqtl0oacxog3jjucoiz1d09itgcvmprze:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://l5abgh7wpjmzlz0fvo06xfeb4ptlxuokcsaw8a1fmni50stnoo30pokh7uqr936njd2zmp1cdxxz7xmwq92p9w9u43i6dpckqtl0oacxog3jjucoiz1d09itgcvmprze:latest/predictions.table.json', 'path': 'media/table/predictions_1_f631c210119c49c6e133.table.json', 'size': 177534, '_type': 'table-file', 'ncols': 9, 'nrows': 638}",7.037985482349875,,,False,True,validation,False,No | Yes,4,CTBase,5f372fb1-795a-47b6-8ddf-c4fd1579e76a,wic,SENTIMENT,False,28,bigscience/T0_3B,0,True,Sentiment_with_choices,prompts/general_fixed_choice.yaml,IMDB,,2,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,Word Sense Disambiguation,wic,True,False,GeneralFixedChoice,False,False,True,,,prompts,,False,True,Sentiment with choices ,,cross_task,wic,,,,False,,,False,,True,,,False,,CTBase.GenFC.imdb.Sentiment_with_choices.LenNorm,WiC,56.08347911000647,57.10144357858118,WordsinContext,super_glue,,,,,,,,,,,,,,,,,12.5,31.0,6
18.64023692497281,49.235474006116206,1.1387279880358174,4.372209975749255,1.99,0.8532151827888569,0.099498743710662,0.0,,,,98.434,2.625420852184296,2.95,6.685236768802229,1.7467891235649586,0.3122498999199199,1.0565826019971878,0.3261901286060018,1.06,33.4,"{'nrows': 1000, 'sha256': '88ff817707fae7dd0032133528f2d8d33f1c83bf44f2076c5b0868f0dee6a45d', 'artifact_path': 'wandb-client-artifact://24w3gs5wdqfl5cgofr82mtpmnuqfyl5xigjenzmtdvhjvto5h2ltvz6d3n0dl03v6lt32sbv698wgp1ucff1214ywy84tu3z1k7rtmnpxcnm7c9g6qnxslbgcgwae1n8:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://24w3gs5wdqfl5cgofr82mtpmnuqfyl5xigjenzmtdvhjvto5h2ltvz6d3n0dl03v6lt32sbv698wgp1ucff1214ywy84tu3z1k7rtmnpxcnm7c9g6qnxslbgcgwae1n8:latest/predictions.table.json', 'path': 'media/table/predictions_1_88ff817707fae7dd0032.table.json', 'size': 507825, '_type': 'table-file', 'ncols': 11}",17.88970776731694,,,False,True,dev_r2,False,Yes | Maybe | No,4,CTBase,cc2958ca-e826-4fef-96aa-1c4caa188605,anli,ENTAILMENT,False,28,bigscience/T0_3B,0,True,entailment_no_choices,prompts/general_fixed_choice.yaml,No Prompt,,3,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,['NLI'],anli,False,False,GeneralFixedChoice,False,False,False,,,prompts,,False,True,entailment no choices,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.BAREBONES.entailment_no_choices.LenNorm,ANLI R2,,,,,,,,,,,,,,,,,,,,,29.0,82.0,0
1.2422360248447204,,0.6724869686024817,1.7550955954763956,,,,1.2422360248447204,,,,61.62068965517241,1.7550955954763956,1.0047021943573669,66.66666666666667,,0.0684111374382294,0.6724869686024817,0.0684111374382294,1.9952978056426327,50.15673981191222,"{'nrows': 638, 'sha256': '4cce1f7819f3040a4b8a15c5213e81c79f06f5c7f3afc46408a152869794121a', 'artifact_path': 'wandb-client-artifact://37sqyycdewuu7kmkktoopl4730n5n7n0ek8yf0ibdl0bl5i7uctl05iqraje24uqcl0q1mwx2ba4n441vwrxakw9qo29iijht38cwefd7bs26qpzywtzdnjimuj3dbhw:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://37sqyycdewuu7kmkktoopl4730n5n7n0ek8yf0ibdl0bl5i7uctl05iqraje24uqcl0q1mwx2ba4n441vwrxakw9qo29iijht38cwefd7bs26qpzywtzdnjimuj3dbhw:latest/predictions.table.json', 'path': 'media/table/predictions_1_4cce1f7819f3040a4b8a.table.json', 'size': 187758, '_type': 'table-file', 'ncols': 9}",7.037985482349875,,,False,True,validation,False,No | Yes,4,CTBase,2351d12a-e630-4d19-8b41-e199266e38f7,wic,SENTIMENT,False,28,bigscience/T0_3B,0,True,Reviewer_Opinion_bad_good_choices,prompts/general_fixed_choice.yaml,IMDB,,2,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,Word Sense Disambiguation,wic,True,False,GeneralFixedChoice,False,False,True,,,prompts,,False,True,Reviewer Opinion bad good choices,,cross_task,wic,,,,False,,,False,,True,,,False,,CTBase.GenFC.imdb.Reviewer_Opinion_bad_good_choices.LenNorm,WiC,54.71825780133931,56.024410137479,WordsinContext,super_glue,,,,,,,,,,,,,,,,,70.5,84.0,9
22.55639097744361,,0.6182348565145322,0.9246283982614738,,,,22.55639097744361,,,,56.62068965517241,0.9246283982614738,1.1253918495297806,64.76624857468643,,0.3311626995923324,0.6182348565145322,0.3311626995923324,1.8746081504702192,51.56739811912225,"{'path': 'media/table/predictions_1_1a409eee002ef8677a91.table.json', 'size': 189311, '_type': 'table-file', 'ncols': 9, 'nrows': 638, 'sha256': '1a409eee002ef8677a915d396bf46a18417f3e3e1a99bbb6e85e0bd7feb090b4', 'artifact_path': 'wandb-client-artifact://xyzvva4xble74h33pivp7a5jzkjpfq3671269s8kufz5psybtwdyleq5pmbxtpm1nrt57a8cbvh5z5w1ajah7rf4xyrglrwajbcp2j6eg3j3e4oqot8e8poogypr0zqg:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://xyzvva4xble74h33pivp7a5jzkjpfq3671269s8kufz5psybtwdyleq5pmbxtpm1nrt57a8cbvh5z5w1ajah7rf4xyrglrwajbcp2j6eg3j3e4oqot8e8poogypr0zqg:latest/predictions.table.json'}",7.037985482349875,,,False,True,validation,False,No | Yes,4,CTBase,02ff2949-0f45-4d97-941e-6fa4c0afbc2d,wic,SENTIMENT,False,28,bigscience/T0_3B,0,True,Movie_Expressed_Sentiment_2,prompts/general_fixed_choice.yaml,IMDB,,2,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,Word Sense Disambiguation,wic,True,False,GeneralFixedChoice,False,False,False,,,prompts,,False,True,Movie Expressed Sentiment 2,,cross_task,wic,,,,False,,,False,,True,,,False,,CTBase.GenFC.imdb.Movie_Expressed_Sentiment_2.LenNorm,WiC,55.33393386936848,57.49943495052132,WordsinContext,super_glue,,,,,,,,,,,,,,,,,8.0,12.0,10
23.140826028787057,45.622895622895626,1.1810406541842438,5.116103270828724,1.998,0.9450513516828312,0.0446766158073773,0.0,,,,114.051,3.7643626143932334,2.71,23.79958246346555,1.3517406564354897,0.70420167565833,1.2312058113842634,0.7047950056576736,1.292,32.800000000000004,"{'sha256': '2e378c960c9a61064d6dd2cbc059042ed614e7a604265c50174351b315a8369b', 'artifact_path': 'wandb-client-artifact://xx9kjibefody2e9svn64lqeyorakiybumw8gg1d7k55uvl908pcq359a73y5ybjsaukouc30azav9q4g745oihc4ng0tovbfcgy4nieermpv6zvgxsfaia4wik9s8tm9:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://xx9kjibefody2e9svn64lqeyorakiybumw8gg1d7k55uvl908pcq359a73y5ybjsaukouc30azav9q4g745oihc4ng0tovbfcgy4nieermpv6zvgxsfaia4wik9s8tm9:latest/predictions.table.json', 'path': 'media/table/predictions_1_2e378c960c9a61064d6d.table.json', 'size': 537891, '_type': 'table-file', 'ncols': 11, 'nrows': 1000}",17.873231353059808,,,False,True,dev_r2,False,Yes | Maybe | No,4,CTBase,74693ecc-f903-488c-968d-6a2bc8e76611,anli,CLASSIFICATION,False,28,bigscience/T0_3B,0,True,classification_no_choices,prompts/general_fixed_choice.yaml,No Prompt,,3,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,['NLI'],anli,False,False,GeneralFixedChoice,False,False,False,,,prompts,,False,True,classification no choices,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.BAREBONES.classification_no_choices.LenNorm,ANLI R2,,,,,,,,,,,,,,,,,,,,,57.5,56.0,0
2.4767801857585137,,0.6630819578950046,1.669381364012213,,,,2.4767801857585137,,,,59.62068965517241,1.669381364012213,1.006269592476489,66.94648478488982,,0.0789321524264211,0.6630819578950046,0.0789321524264211,1.993730407523511,50.626959247648905,"{'sha256': '3e74fb3fa690a10c7216e7a896b97a4958ab8b1dac15971813ed45e234179984', 'artifact_path': 'wandb-client-artifact://b1lu2wcokcvcd839s1d8vtilogbi8r3s6fwfv8df258ifwh77uqjcxe762pxv45vx6hljsxapifu0fdjjmy9jboskwjygyegztfhx73j4iy00blyoiqlkafvkrg0grcd:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://b1lu2wcokcvcd839s1d8vtilogbi8r3s6fwfv8df258ifwh77uqjcxe762pxv45vx6hljsxapifu0fdjjmy9jboskwjygyegztfhx73j4iy00blyoiqlkafvkrg0grcd:latest/predictions.table.json', 'path': 'media/table/predictions_1_3e74fb3fa690a10c7216.table.json', 'size': 185418, '_type': 'table-file', 'ncols': 9, 'nrows': 638}",7.037985482349875,,,False,True,validation,False,No | Yes,4,CTBase,f56ffced-9b16-431a-8a17-501e63cddf73,wic,ENTAILMENT,False,28,bigscience/T0_3B,0,True,imply_separated,prompts/general_fixed_choice.yaml,RTE,,2,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,Word Sense Disambiguation,wic,False,False,GeneralFixedChoice,False,False,True,,,prompts,,False,True,imply separated,,cross_task,wic,,,,False,,,False,,True,,,False,,CTBase.GenFC.super_glue_rte.imply_separated.LenNorm,WiC,54.93511402853481,55.64803804994055,WordsinContext,super_glue,,,,,,,,,,,,,,,,,36.5,73.0,6
2.469135802469136,,0.6660156247772162,1.6071996139508429,,,,2.469135802469136,,,,63.62068965517241,1.6071996139508429,1.0078369905956113,66.80672268907563,,0.0881792048842332,0.6660156247772162,0.0881792048842332,1.9921630094043887,50.470219435736674,"{'nrows': 638, 'sha256': 'c38ed6ebeaab225066e08b08aa06cebc069d3258c9a804a47f786e1da246e225', 'artifact_path': 'wandb-client-artifact://ijmhzkz6y33zwhyygx79u79bhi1fvmjgijt4ylgw56xqq9debs4ewk0tcy3vtti7e5aa1asnv5taoobl6yz6su6v4qaaazgxo2qjms0qnb2jucrrall0ujq8lt50jed4:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://ijmhzkz6y33zwhyygx79u79bhi1fvmjgijt4ylgw56xqq9debs4ewk0tcy3vtti7e5aa1asnv5taoobl6yz6su6v4qaaazgxo2qjms0qnb2jucrrall0ujq8lt50jed4:latest/predictions.table.json', 'path': 'media/table/predictions_1_c38ed6ebeaab225066e0.table.json', 'size': 196318, '_type': 'table-file', 'ncols': 9}",7.037985482349875,,,False,True,validation,False,No | Yes,4,CTBase,c8dfc879-40f2-412d-be1e-4cd70107f6e6,wic,ENTAILMENT,False,28,bigscience/T0_3B,0,True,imply,prompts/general_fixed_choice.yaml,RTE,,2,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,Word Sense Disambiguation,wic,False,False,GeneralFixedChoice,False,False,True,,,prompts,,False,True,imply,,cross_task,wic,,,,False,,,False,,True,,,False,,CTBase.GenFC.super_glue_rte.imply.LenNorm,WiC,54.14109630187216,54.408859975825706,WordsinContext,super_glue,,,,,,,,,,,,,,,,,47.5,76.0,14
4.790419161676646,,0.5743657576633484,1.0853575621279057,,,,4.790419161676646,,,,92.6206896551724,1.0853575621279057,1.0235109717868338,66.24203821656052,,0.1515196554657928,0.5743657576633484,0.1515196554657928,1.9764890282131664,50.15673981191222,"{'sha256': '4c11c0ac4a609fdf59486786832c2994d219d50fce7c847999a65e3288f065de', 'artifact_path': 'wandb-client-artifact://16jdjcujju6hq1kha3k69gm15wbvxrrvtmq24410fyfrhnkwz45xgzfj5r9d62mxm65rgenj3msr9okkvjm2h88oaol31mjp943fhzs4zk2aq3vl1nyopdzik1ckz739:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://16jdjcujju6hq1kha3k69gm15wbvxrrvtmq24410fyfrhnkwz45xgzfj5r9d62mxm65rgenj3msr9okkvjm2h88oaol31mjp943fhzs4zk2aq3vl1nyopdzik1ckz739:latest/predictions.table.json', 'path': 'media/table/predictions_1_4c11c0ac4a609fdf5948.table.json', 'size': 296282, '_type': 'table-file', 'ncols': 9, 'nrows': 638}",7.037985482349875,,,False,True,validation,False,No | Yes,4,CTBase,9e2b4267-ec23-44c8-b82a-107e2c890fec,wic,ENTAILMENT,False,28,bigscience/T0_3B,0,True,entailment_explained,prompts/general_fixed_choice.yaml,RTE,,2,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,Word Sense Disambiguation,wic,False,False,GeneralFixedChoice,False,False,True,,,prompts,,False,True,entailment explained,,cross_task,wic,,,,False,,,False,,True,,,False,,CTBase.GenFC.super_glue_rte.entailment_explained.LenNorm,WiC,53.878859848474434,54.06688220438085,WordsinContext,super_glue,,,,,,,,,,,,,,,,,70.5,60.0,40
16.915721691841092,0.5970149253731343,0.8912547670349046,5.691800324320793,2.0,0.8385609842434121,0.0,0.0,,,,238.102,2.9665432300567627,1.004,50.15015015015016,2.7252570942640304,0.0893532316147547,0.6828597732589281,0.0893532316147547,2.996,33.5,"{'_latest_artifact_path': 'wandb-client-artifact://wt1grk5t57tk3v3iknovgig3mlds0rlt472ldum8670g0rr7enbx8sj4goe4vn34qk20azokg5r2m4ol0ee0y26yzpx48xmhpe8vd3vay74us1tv6ocb08309vg68d3l:latest/predictions.table.json', 'path': 'media/table/predictions_1_2d66f9527dd5b87c8ec1.table.json', 'size': 994358, '_type': 'table-file', 'ncols': 11, 'nrows': 1000, 'sha256': '2d66f9527dd5b87c8ec1192d048732eb839b8f4dd361ce7181986c61e959a337', 'artifact_path': 'wandb-client-artifact://wt1grk5t57tk3v3iknovgig3mlds0rlt472ldum8670g0rr7enbx8sj4goe4vn34qk20azokg5r2m4ol0ee0y26yzpx48xmhpe8vd3vay74us1tv6ocb08309vg68d3l:latest/predictions.table.json'}",35.746462706119615,,,False,True,dev_r2,False,Yes | Maybe | No,4,CTBase,d92fc0d4-5367-41e1-b35d-1058f22a3c1c,anli,QA,False,28,bigscience/T0_3B,0,True,qa_choices,prompts/general_fixed_choice.yaml,No Prompt,,3,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,['NLI'],anli,False,False,GeneralFixedChoice,False,False,True,,,prompts,,False,True,qa choices,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.BAREBONES.qa_choices.LenNorm,ANLI R2,,,,,,,,,,,,,,,,,,,,,26.0,87.0,0
2.469135802469136,,0.7490713314046317,1.7625684611102257,,,,2.469135802469136,,,,67.62068965517241,1.7625684611102257,1.0078369905956113,66.80672268907563,,0.0881792048842332,0.7490713314046317,0.0881792048842332,1.9921630094043887,50.470219435736674,"{'nrows': 638, 'sha256': 'c9d9a236d5d0720c9bf5ab4b9b1c7e00435e49131264a38382fa840e3fa3447e', 'artifact_path': 'wandb-client-artifact://ih1fohtgs5a1eo8kvjk1q8iywksbxlyk1necjjb849q6pnyyrr2be797yvqubbmq6ti5n741qsbdre8o7brlvl3v0r5gfuutx7e80ykuu06qvcp5nuqf46yz94azeesm:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://ih1fohtgs5a1eo8kvjk1q8iywksbxlyk1necjjb849q6pnyyrr2be797yvqubbmq6ti5n741qsbdre8o7brlvl3v0r5gfuutx7e80ykuu06qvcp5nuqf46yz94azeesm:latest/predictions.table.json', 'path': 'media/table/predictions_1_c9d9a236d5d0720c9bf5.table.json', 'size': 212149, '_type': 'table-file', 'ncols': 9}",7.037985482349875,,,False,True,validation,False,No | Yes,4,CTBase,4ee6ff27-de63-4e7b-a9d4-82a17eba407a,wic,ENTAILMENT,False,28,bigscience/T0_3B,0,True,does_the_claim_follow_the_fact,prompts/general_fixed_choice.yaml,RTE,,2,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,Word Sense Disambiguation,wic,False,False,GeneralFixedChoice,False,False,True,,,prompts,,False,True,does the claim follow the fact,,cross_task,wic,,,,False,,,False,,True,,,False,,CTBase.GenFC.super_glue_rte.does_the_claim_follow_the_fact.LenNorm,WiC,53.63469481629475,53.59813681076246,WordsinContext,super_glue,,,,,,,,,,,,,,,,,47.5,76.0,18
4.242424242424243,,0.6478057929268457,1.2633822950823554,,,,4.242424242424243,,,,61.62068965517241,1.2633822950823554,1.0172413793103448,66.59619450317125,,0.130169559228806,0.6478057929268457,0.130169559228806,1.9827586206896552,50.470219435736674,"{'sha256': '915ec3384968de9ef3ed4ba2bc63e083d303816fa0005af1681645ba948f8fbe', 'artifact_path': 'wandb-client-artifact://441agyw2scc34zkhebsmm40u44do32nq23cd8dts696udwwdkckkj19qkvz2450qlur2mn40s497fe0tkpuw87d8nnd6rqiv8vtlo9dv8w6lrk65xp1ck6s8pftfm6go:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://441agyw2scc34zkhebsmm40u44do32nq23cd8dts696udwwdkckkj19qkvz2450qlur2mn40s497fe0tkpuw87d8nnd6rqiv8vtlo9dv8w6lrk65xp1ck6s8pftfm6go:latest/predictions.table.json', 'path': 'media/table/predictions_1_915ec3384968de9ef3ed.table.json', 'size': 187273, '_type': 'table-file', 'ncols': 9, 'nrows': 638}",7.037985482349875,,,False,True,validation,False,No | Yes,4,CTBase,03a7ae07-5ddd-46c4-92f3-2152223d44ec,wic,ENTAILMENT,False,28,bigscience/T0_3B,0,True,mean,prompts/general_fixed_choice.yaml,RTE,,2,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,Word Sense Disambiguation,wic,False,False,GeneralFixedChoice,False,False,True,,,prompts,,False,True,mean,,cross_task,wic,,,,False,,,False,,True,,,False,,CTBase.GenFC.super_glue_rte.mean.LenNorm,WiC,53.07834876677323,53.1264433329075,WordsinContext,super_glue,,,,,,,,,,,,,,,,,47.5,64.0,9
3.058103975535168,,0.9165361337077148,2.1349472474528706,,,,3.058103975535168,,,,47.62068965517241,2.1349472474528706,1.012539184952978,66.59641728134879,,0.1112742278952906,0.9165361337077148,0.1112742278952906,1.987460815047022,50.313479623824456,"{'path': 'media/table/predictions_1_2e0c9fff0231128efc54.table.json', 'size': 159238, '_type': 'table-file', 'ncols': 9, 'nrows': 638, 'sha256': '2e0c9fff0231128efc5401d8765d5b9f38bf0a4e9fa15cbc5aac47c8b97936e6', 'artifact_path': 'wandb-client-artifact://nv4ycpv3mgdkchuc0s440vslh1ummensm3mtfa86xahia5r0vpazoh01bvw46n46jokn3kd47wnw1p8qbk1ur3pf5rs06c4cv5932gvo9vwpgohkc4ex5gwgplm4u2ej:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://nv4ycpv3mgdkchuc0s440vslh1ummensm3mtfa86xahia5r0vpazoh01bvw46n46jokn3kd47wnw1p8qbk1ur3pf5rs06c4cv5932gvo9vwpgohkc4ex5gwgplm4u2ej:latest/predictions.table.json'}",7.037985482349875,,,False,True,validation,False,No | Yes,4,CTBase,f2004e15-9d9a-4ca1-9830-a341e684e97e,wic,QA,False,28,bigscience/T0_3B,0,True,qa_no_choices_and_answer,prompts/general_fixed_choice.yaml,No Prompt,,2,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,Word Sense Disambiguation,wic,False,False,GeneralFixedChoice,False,False,False,,,prompts,,False,True,qa no choices and answer,,cross_task,wic,,,,False,,,False,,True,,,False,,CTBase.GenFC.BAREBONES.qa_no_choices_and_answer.LenNorm,WiC,56.10309467469279,56.69952142765894,WordsinContext,super_glue,,,,,,,,,,,,,,,,,58.0,71.5,0
17.50663129973475,,0.815627973858833,1.287135959232115,,,,17.50663129973475,,,,48.62068965517241,1.287135959232115,1.0909090909090908,65.40600667408232,,0.2874797872880344,0.815627973858833,0.2874797872880344,1.9090909090909087,51.2539184952978,"{'ncols': 9, 'nrows': 638, 'sha256': '02e80c10e8c16961c6a2d66be8b46c69cff45ceb873543659b3c5f8dc3ce9d4c', 'artifact_path': 'wandb-client-artifact://d8funy4dpwa6u7572tl21xicvowrdh14covhx38ffoz0ivwyzfl1a7j3n550ym9sbphnpfmqolzna7jt20vxmsnobbku4ycwkd0rzzmcruhsm9omb535jy7v7uhwt9in:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://d8funy4dpwa6u7572tl21xicvowrdh14covhx38ffoz0ivwyzfl1a7j3n550ym9sbphnpfmqolzna7jt20vxmsnobbku4ycwkd0rzzmcruhsm9omb535jy7v7uhwt9in:latest/predictions.table.json', 'path': 'media/table/predictions_1_02e80c10e8c16961c6a2.table.json', 'size': 161241, '_type': 'table-file'}",7.037985482349875,,,False,True,validation,False,No | Yes,4,CTBase,e5eaa3ee-e537-4d20-9dfa-6084db54f2ef,wic,ENTAILMENT,False,28,bigscience/T0_3B,0,True,entailment_no_choices_and_answer,prompts/general_fixed_choice.yaml,No Prompt,,2,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,Word Sense Disambiguation,wic,False,False,GeneralFixedChoice,False,False,False,,,prompts,,False,True,entailment no choices and answer,,cross_task,wic,,,,False,,,False,,True,,,False,,CTBase.GenFC.BAREBONES.entailment_no_choices_and_answer.LenNorm,WiC,54.73116493850627,54.97587484399721,WordsinContext,super_glue,,,,,,,,,,,,,,,,,12.5,18.5,2
17.50663129973475,,0.815627973858833,1.287135959232115,,,,17.50663129973475,,,,48.62068965517241,1.287135959232115,1.0909090909090908,65.40600667408232,,0.2874797872880344,0.815627973858833,0.2874797872880344,1.9090909090909087,51.2539184952978,"{'path': 'media/table/predictions_1_93fb05979d771eaf07c9.table.json', 'size': 160603, '_type': 'table-file', 'ncols': 9, 'nrows': 638, 'sha256': '93fb05979d771eaf07c957b0716a8b01efe0d8ae902d65cb3cc1037302b4a665', 'artifact_path': 'wandb-client-artifact://16tsohebv77all59408sztc9fldymt997gu1k1bmsuep28cn57dci12rgmw29suynzeo7wv7okkdtyiniwd27gyjf4gw2alvvgmjex37gnykuul4ssl6t03vkqqs66av:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://16tsohebv77all59408sztc9fldymt997gu1k1bmsuep28cn57dci12rgmw29suynzeo7wv7okkdtyiniwd27gyjf4gw2alvvgmjex37gnykuul4ssl6t03vkqqs66av:latest/predictions.table.json'}",7.037985482349875,,,False,True,validation,False,No | Yes,4,CTBase,cf005ddf-8cf2-409d-b884-45d22463f463,wic,CLASSIFICATION,False,28,bigscience/T0_3B,0,True,classification_no_choices_and_answer,prompts/general_fixed_choice.yaml,No Prompt,,2,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,Word Sense Disambiguation,wic,False,False,GeneralFixedChoice,False,False,False,,,prompts,,False,True,classification no choices and answer,,cross_task,wic,,,,False,,,False,,True,,,False,,CTBase.GenFC.BAREBONES.classification_no_choices_and_answer.LenNorm,WiC,54.73116493850627,54.97587484399721,WordsinContext,super_glue,,,,,,,,,,,,,,,,,12.5,18.5,2
66.59685863874346,,0.6858428786935806,1.946090031450258,,,,66.59685863874346,,,,74.91849529780565,1.946090031450258,1.996865203761756,0.6230529595015576,,0.0559014247652884,0.6858428786935806,0.0559014247652884,1.0031347962382444,50.0,"{'_latest_artifact_path': 'wandb-client-artifact://sxvg7s8epma9x07mhgt76ulw1wkxzl5ylm1vu6gqiv5ndalhpvtzru87eslj8flza1mpkuyz9ewo8k41uyvue03lwok8m1gaft3xhqh3zvjezzgttorwuah2gird7mjp:latest/predictions.table.json', 'path': 'media/table/predictions_1_8246214b75cae320b61b.table.json', 'size': 212321, '_type': 'table-file', 'ncols': 9, 'nrows': 638, 'sha256': '8246214b75cae320b61bcee65644c721d091499b188b9d534ec6593b5a9f7e5b', 'artifact_path': 'wandb-client-artifact://sxvg7s8epma9x07mhgt76ulw1wkxzl5ylm1vu6gqiv5ndalhpvtzru87eslj8flza1mpkuyz9ewo8k41uyvue03lwok8m1gaft3xhqh3zvjezzgttorwuah2gird7mjp:latest/predictions.table.json'}",13.625175030107874,,,False,True,validation,False,No | Yes,4,CTBase,2e94d035-3c3d-44cf-98cb-3d11bea7c17b,wic,QA,False,28,bigscience/T0_3B,0,True,qa_choices_and_answer,prompts/general_fixed_choice.yaml,No Prompt,,2,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,Word Sense Disambiguation,wic,False,False,GeneralFixedChoice,False,False,True,,,prompts,,False,True,qa choices and answer,,cross_task,wic,,,,False,,,False,,True,,,False,,CTBase.GenFC.BAREBONES.qa_choices_and_answer.LenNorm,WiC,53.10238782373303,53.26402059728187,WordsinContext,super_glue,,,,,,,,,,,,,,,,,82.5,3.0,2
25.32187857961054,43.29896907216495,0.8648727589451857,3.68126878041029,1.998,0.5887445773698748,0.0446766158073773,0.0,,,,109.434,2.940713533580303,2.468,32.66666666666666,0.7405552468299865,0.8837284650841569,0.8522560578748052,0.8836537783543961,1.534,32.9,"{'sha256': '1d7a4251f0d40682e8d0979b3fa38bd2d6e0ec461825e3b4fe2695d9320f728a', 'artifact_path': 'wandb-client-artifact://15oeirvv0lxstw6o9firw0min2ntt1b4qfrcj2863apwmuy9s4fejgsuizc4jvfzofnq3w0wkg2ctdnugxoevkf4qsajkb8nf1iyjoga2zgqc38b41j9hp9ha0v1vhh1:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://15oeirvv0lxstw6o9firw0min2ntt1b4qfrcj2863apwmuy9s4fejgsuizc4jvfzofnq3w0wkg2ctdnugxoevkf4qsajkb8nf1iyjoga2zgqc38b41j9hp9ha0v1vhh1:latest/predictions.table.json', 'path': 'media/table/predictions_1_1d7a4251f0d40682e8d0.table.json', 'size': 537626, '_type': 'table-file', 'ncols': 11, 'nrows': 1000}",17.88970776731694,,,False,True,dev_r2,False,Yes | Maybe | No,4,CTBase,bb648cf3-d9ab-45a8-9bd7-6ba4585c4b9a,anli,ENTAILMENT,False,28,bigscience/T0_3B,0,True,entailment_choices,prompts/general_fixed_choice.yaml,No Prompt,,3,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,['NLI'],anli,False,False,GeneralFixedChoice,False,False,True,,,prompts,,False,True,entailment choices,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.BAREBONES.entailment_choices.LenNorm,ANLI R2,,,,,,,,,,,,,,,,,,,,,55.0,39.0,0
4.776119402985074,,0.6974161455383457,1.374879116642064,,,,4.776119402985074,,,,55.62068965517241,1.374879116642064,1.025078369905956,66.09989373007438,,0.1563631838663313,0.6974161455383457,0.1563631838663313,1.974921630094044,50.0,"{'size': 173684, '_type': 'table-file', 'ncols': 9, 'nrows': 638, 'sha256': '56e0b5955dd3d5ea86877fc4614121a2e22ced6efa8d189cfbd5110bfb25195c', 'artifact_path': 'wandb-client-artifact://9lkpnvgn6xo2mv0ia10p6c82xuzjw2i1j719kbg83s4idkt74n6rj9y8iix24yjkgum9tkek24u80mj5sn53tgvfjxwptjqwl8s3ib97eg3p04p2zkpo1ro1sv5i2jrt:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://9lkpnvgn6xo2mv0ia10p6c82xuzjw2i1j719kbg83s4idkt74n6rj9y8iix24yjkgum9tkek24u80mj5sn53tgvfjxwptjqwl8s3ib97eg3p04p2zkpo1ro1sv5i2jrt:latest/predictions.table.json', 'path': 'media/table/predictions_1_56e0b5955dd3d5ea8687.table.json'}",7.037985482349875,,,False,True,validation,False,No | Yes,4,CTBase,c225e598-1efe-4cb6-9f7c-a1b7eb5c7803,wic,ENTAILMENT,False,28,bigscience/T0_3B,0,True,entailment_choices_and_answer,prompts/general_fixed_choice.yaml,No Prompt,,2,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,Word Sense Disambiguation,wic,False,False,GeneralFixedChoice,False,False,True,,,prompts,,False,True,entailment choices and answer,,cross_task,wic,,,,False,,,False,,True,,,False,,CTBase.GenFC.BAREBONES.entailment_choices_and_answer.LenNorm,WiC,53.98880557521856,54.6889279783021,WordsinContext,super_glue,,,,,,,,,,,,,,,,,82.5,61.5,2
4.776119402985074,,0.6974161455383457,1.374879116642064,,,,4.776119402985074,,,,55.62068965517241,1.374879116642064,1.025078369905956,66.09989373007438,,0.1563631838663313,0.6974161455383457,0.1563631838663313,1.974921630094044,50.0,"{'path': 'media/table/predictions_1_6d51ada18b1c51deb3b7.table.json', 'size': 174322, '_type': 'table-file', 'ncols': 9, 'nrows': 638, 'sha256': '6d51ada18b1c51deb3b73d97ba81ef06106b6f434b2aa9b5c1af9f826524e0d9', 'artifact_path': 'wandb-client-artifact://134btz48vfxkubla05fd38xei51thymo08yw5dzlp9wizbzzlzghy5uie9ewr6nuifixqjhzya4s7ux99j1uqcte2hbr7ghzdvqrxu36c8lopoos1wuefhaf32mxpyfa:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://134btz48vfxkubla05fd38xei51thymo08yw5dzlp9wizbzzlzghy5uie9ewr6nuifixqjhzya4s7ux99j1uqcte2hbr7ghzdvqrxu36c8lopoos1wuefhaf32mxpyfa:latest/predictions.table.json'}",7.037985482349875,,,False,True,validation,False,No | Yes,4,CTBase,32a28538-99bc-4c5a-8086-83b885fddb50,wic,CLASSIFICATION,False,28,bigscience/T0_3B,0,True,classification_choices_and_answer,prompts/general_fixed_choice.yaml,No Prompt,,2,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,Word Sense Disambiguation,wic,False,False,GeneralFixedChoice,False,False,True,,,prompts,,False,True,classification choices and answer,,cross_task,wic,,,,False,,,False,,True,,,False,,CTBase.GenFC.BAREBONES.classification_choices_and_answer.LenNorm,WiC,53.98880557521856,54.6889279783021,WordsinContext,super_glue,,,,,,,,,,,,,,,,,82.5,61.5,2
66.66666666666667,,0.9114597823468146,2.1683569586949663,,,,66.66666666666667,,,,65.91849529780565,2.1683569586949663,1.9952978056426327,1.2422360248447204,,0.0684111374382294,0.9114597823468146,0.0684111374382294,1.0047021943573669,50.15673981191222,"{'sha256': '7a54a0ef6fc3b47f01018ea56052f73bebfbdb764ae337fe9dc3f033e1c9b985', 'artifact_path': 'wandb-client-artifact://uzvg18nenbimwsi10ogg85zvf3psozwp74iy4aettbm9fvihwv64iqct1436zb3fn84j0p9780holuqp9vgirdi8cbvblenri2t0s3c9p2l77s0ch2s2w05icv2ru9yg:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://uzvg18nenbimwsi10ogg85zvf3psozwp74iy4aettbm9fvihwv64iqct1436zb3fn84j0p9780holuqp9vgirdi8cbvblenri2t0s3c9p2l77s0ch2s2w05icv2ru9yg:latest/predictions.table.json', 'path': 'media/table/predictions_1_7a54a0ef6fc3b47f0101.table.json', 'size': 193985, '_type': 'table-file', 'ncols': 9, 'nrows': 638}",13.625175030107874,,,False,True,validation,False,No | Yes,4,CTBase,97030be6-9843-4fc2-98cf-b47b879b5447,wic,QA,False,28,bigscience/T0_3B,0,True,qa_no_choices,prompts/general_fixed_choice.yaml,No Prompt,,2,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,Word Sense Disambiguation,wic,False,False,GeneralFixedChoice,False,False,False,,,prompts,,False,True,qa no choices,,cross_task,wic,,,,False,,,False,,True,,,False,,CTBase.GenFC.BAREBONES.qa_no_choices.LenNorm,WiC,53.99768047829427,54.526783345289466,WordsinContext,super_glue,,,,,,,,,,,,,,,,,70.5,2.0,0
27.626181868743043,35.9375,0.8156666885386789,4.367215701520443,2.0,0.6264073575239759,0.0,0.0,,,,125.051,3.5421974201202397,1.87,46.941045606229146,0.8250182814002037,0.9915139938498094,0.7636519147077174,0.9915139938498094,2.13,34.9,"{'artifact_path': 'wandb-client-artifact://13dg4y5puuiwuu7db2zfcsz11n6afqgbomsopvx08pra8z8kfnki92p34zqt2v3uk67fg9hweeurvqorm4ytpkyysi9e4rm0mgs25o5a5c40bujbk45u1qr2iyj1i8aq:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://13dg4y5puuiwuu7db2zfcsz11n6afqgbomsopvx08pra8z8kfnki92p34zqt2v3uk67fg9hweeurvqorm4ytpkyysi9e4rm0mgs25o5a5c40bujbk45u1qr2iyj1i8aq:latest/predictions.table.json', 'path': 'media/table/predictions_1_bdabc84d9655e26e4239.table.json', 'size': 568889, '_type': 'table-file', 'ncols': 11, 'nrows': 1000, 'sha256': 'bdabc84d9655e26e42393bc8194f02a9d658e20496ec698f750c080edc828179'}",17.873231353059808,,,False,True,dev_r2,False,Yes | Maybe | No,4,CTBase,88bdb026-e9c9-445b-96ef-0cdb986b7fbd,anli,CLASSIFICATION,False,28,bigscience/T0_3B,0,True,classification_choices,prompts/general_fixed_choice.yaml,No Prompt,,3,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,['NLI'],anli,False,False,GeneralFixedChoice,False,False,True,,,prompts,,False,True,classification choices,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.BAREBONES.classification_choices.LenNorm,ANLI R2,,,,,,,,,,,,,,,,,,,,,5.5,8.0,0
11.699164345403895,,0.8183461907385782,1.3971047834916548,,,,11.699164345403895,,,,46.62068965517241,1.3971047834916548,1.0626959247648904,65.43075245365321,,0.2424152342217078,0.8183461907385782,0.2424152342217078,1.9373040752351096,50.313479623824456,"{'path': 'media/table/predictions_1_28d655e367e28ae8c2b3.table.json', 'size': 155394, '_type': 'table-file', 'ncols': 9, 'nrows': 638, 'sha256': '28d655e367e28ae8c2b3c845a4baa997fd31b9507cf3f0a2447b5486973575a1', 'artifact_path': 'wandb-client-artifact://12y6ihitq2k2a0ag7dj3iexzrtlb82vmdy45xvummossj2ktiuoatk96by4o5danlroo08cjwu91nevq0c9ejegqlrp8idgaenfxs45ltvk64yox5lcawwaduonhrgxp:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://12y6ihitq2k2a0ag7dj3iexzrtlb82vmdy45xvummossj2ktiuoatk96by4o5danlroo08cjwu91nevq0c9ejegqlrp8idgaenfxs45ltvk64yox5lcawwaduonhrgxp:latest/predictions.table.json'}",7.037985482349875,,,False,True,validation,False,No | Yes,4,CTBase,cc2958ca-e826-4fef-96aa-1c4caa188605,wic,ENTAILMENT,False,28,bigscience/T0_3B,0,True,entailment_no_choices,prompts/general_fixed_choice.yaml,No Prompt,,2,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,Word Sense Disambiguation,wic,False,False,GeneralFixedChoice,False,False,False,,,prompts,,False,True,entailment no choices,,cross_task,wic,,,,False,,,False,,True,,,False,,CTBase.GenFC.BAREBONES.entailment_no_choices.LenNorm,WiC,55.42654908916672,55.65196882892267,WordsinContext,super_glue,,,,,,,,,,,,,,,,,58.0,26.5,0
11.699164345403895,,0.8183461907385782,1.3971047834916548,,,,11.699164345403895,,,,46.62068965517241,1.3971047834916548,1.0626959247648904,65.43075245365321,,0.2424152342217078,0.8183461907385782,0.2424152342217078,1.9373040752351096,50.313479623824456,"{'_latest_artifact_path': 'wandb-client-artifact://azdkzak5luqmdcwj3rt4u9q1gq36ktuzu7wr8yxiwd1m0avvcsmno7dlnqevwlb6yfyckn4pnlb392157tm9zi7j1zmg0wbvdun5pu93vbe92bl9cg4qf7pniqo1i22p:latest/predictions.table.json', 'path': 'media/table/predictions_1_5de9966a3e37affc4db5.table.json', 'size': 154756, '_type': 'table-file', 'ncols': 9, 'nrows': 638, 'sha256': '5de9966a3e37affc4db599fe3c78c94f206ea2ebd4a917bb5f0f8be4f6e43cc6', 'artifact_path': 'wandb-client-artifact://azdkzak5luqmdcwj3rt4u9q1gq36ktuzu7wr8yxiwd1m0avvcsmno7dlnqevwlb6yfyckn4pnlb392157tm9zi7j1zmg0wbvdun5pu93vbe92bl9cg4qf7pniqo1i22p:latest/predictions.table.json'}",7.037985482349875,,,False,True,validation,False,No | Yes,4,CTBase,74693ecc-f903-488c-968d-6a2bc8e76611,wic,CLASSIFICATION,False,28,bigscience/T0_3B,0,True,classification_no_choices,prompts/general_fixed_choice.yaml,No Prompt,,2,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,Word Sense Disambiguation,wic,False,False,GeneralFixedChoice,False,False,False,,,prompts,,False,True,classification no choices,,cross_task,wic,,,,False,,,False,,True,,,False,,CTBase.GenFC.BAREBONES.classification_no_choices.LenNorm,WiC,55.42654908916672,55.65196882892267,WordsinContext,super_glue,,,,,,,,,,,,,,,,,58.0,26.5,0
66.87631027253668,,0.7013570714363594,1.95334048607156,,,,66.87631027253668,,,,72.91849529780565,1.95334048607156,1.9952978056426327,1.8633540372670807,,0.0684111374382294,0.7013570714363594,0.0684111374382294,1.0047021943573669,50.470219435736674,"{'ncols': 9, 'nrows': 638, 'sha256': 'b2c9e75f96b31edc8430ffcf51425080f1e5c197c8faf667661bc37f09f60eb2', 'artifact_path': 'wandb-client-artifact://700zmobo2g82vu9i40wq3u452l5gjbpolu41562twmao2xxb9lesetmxsvvmmnchjeyzn4cap2eph9m2xeltytdbsioof2xdd7aajc9q65w4xdq9skvdsirti1ffjeuw:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://700zmobo2g82vu9i40wq3u452l5gjbpolu41562twmao2xxb9lesetmxsvvmmnchjeyzn4cap2eph9m2xeltytdbsioof2xdd7aajc9q65w4xdq9skvdsirti1ffjeuw:latest/predictions.table.json', 'path': 'media/table/predictions_1_b2c9e75f96b31edc8430.table.json', 'size': 206479, '_type': 'table-file'}",13.625175030107874,,,False,True,validation,False,No | Yes,4,CTBase,d92fc0d4-5367-41e1-b35d-1058f22a3c1c,wic,QA,False,28,bigscience/T0_3B,0,True,qa_choices,prompts/general_fixed_choice.yaml,No Prompt,,2,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,Word Sense Disambiguation,wic,False,False,GeneralFixedChoice,False,False,True,,,prompts,,False,True,qa choices,,cross_task,wic,,,,False,,,False,,True,,,False,,CTBase.GenFC.BAREBONES.qa_choices.LenNorm,WiC,53.15151845877401,53.87034325527461,WordsinContext,super_glue,,,,,,,,,,,,,,,,,47.5,1.0,0
5.357142857142857,,0.7056483034932444,1.4338311374561166,,,,5.357142857142857,,,,53.62068965517241,1.4338311374561166,1.0266457680250785,66.17021276595744,,0.1610458663593452,0.7056483034932444,0.1610458663593452,1.973354231974921,50.15673981191222,"{'artifact_path': 'wandb-client-artifact://vy8havmwput463ikokgdncesjsbliirg6jaml1svhr74k95qz2n0st9lz4mr5tvqd64yl8jdp420poe9zxi20q6fdx7l9t3byeuap03jb6to799tj8kdx62acolb03uw:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://vy8havmwput463ikokgdncesjsbliirg6jaml1svhr74k95qz2n0st9lz4mr5tvqd64yl8jdp420poe9zxi20q6fdx7l9t3byeuap03jb6to799tj8kdx62acolb03uw:latest/predictions.table.json', 'path': 'media/table/predictions_1_8ab135d81e8f28a9b156.table.json', 'size': 167936, '_type': 'table-file', 'ncols': 9, 'nrows': 638, 'sha256': '8ab135d81e8f28a9b156ccd809ee4d57bf3a81205bfac541b7e59ddba7f70ad0'}",7.037985482349875,,,False,True,validation,False,No | Yes,4,CTBase,bb648cf3-d9ab-45a8-9bd7-6ba4585c4b9a,wic,ENTAILMENT,False,28,bigscience/T0_3B,0,True,entailment_choices,prompts/general_fixed_choice.yaml,No Prompt,,2,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,Word Sense Disambiguation,wic,False,False,GeneralFixedChoice,False,False,True,,,prompts,,False,True,entailment choices,,cross_task,wic,,,,False,,,False,,True,,,False,,CTBase.GenFC.BAREBONES.entailment_choices.LenNorm,WiC,54.75501270327917,56.29268580300901,WordsinContext,super_glue,,,,,,,,,,,,,,,,,70.5,57.5,0
5.357142857142857,,0.7056483034932444,1.4338311374561166,,,,5.357142857142857,,,,53.62068965517241,1.4338311374561166,1.0266457680250785,66.17021276595744,,0.1610458663593452,0.7056483034932444,0.1610458663593452,1.973354231974921,50.15673981191222,"{'path': 'media/table/predictions_1_696c0225aa8d2a600450.table.json', 'size': 167936, '_type': 'table-file', 'ncols': 9, 'nrows': 638, 'sha256': '696c0225aa8d2a600450465ea9a29bc0d2bc26d4f7bdb4ab2432b8fdfddfc23c', 'artifact_path': 'wandb-client-artifact://n8ryiokp2xf9tks49l6gri51o9nf90qmvm4dtlw2iqte50i0xjgh67hwzs5bglhz4l394cw5gn3149odfdn80ovrvkwqhr7r3dug5o7pqu2uz79ek30kfeqrx0z4mtzl:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://n8ryiokp2xf9tks49l6gri51o9nf90qmvm4dtlw2iqte50i0xjgh67hwzs5bglhz4l394cw5gn3149odfdn80ovrvkwqhr7r3dug5o7pqu2uz79ek30kfeqrx0z4mtzl:latest/predictions.table.json'}",7.037985482349875,,,False,True,validation,False,No | Yes,4,CTBase,88bdb026-e9c9-445b-96ef-0cdb986b7fbd,wic,CLASSIFICATION,False,28,bigscience/T0_3B,0,True,classification_choices,prompts/general_fixed_choice.yaml,No Prompt,,2,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,Word Sense Disambiguation,wic,False,False,GeneralFixedChoice,False,False,True,,,prompts,,False,True,classification choices,,cross_task,wic,,,,False,,,False,,True,,,False,,CTBase.GenFC.BAREBONES.classification_choices.LenNorm,WiC,54.75501270327917,56.29268580300901,WordsinContext,super_glue,,,,,,,,,,,,,,,,,70.5,57.5,0
2.469135802469136,,0.5718525775611859,1.3101077221777746,,,,2.469135802469136,,,,79.62068965517241,1.3101077221777746,1.0078369905956113,66.80672268907563,,0.0881792048842332,0.5718525775611859,0.0881792048842332,1.9921630094043887,50.470219435736674,"{'ncols': 9, 'nrows': 638, 'sha256': '3927e24d8e5682e874180733853361451c3f3f25285164afbd968f5c92dde0e3', 'artifact_path': 'wandb-client-artifact://4z0yj2v350bbeh49jevykcwdrn9sdyfq7b06khyuzfilducfe27veipdy8k3ohljvdtzu9j35vh7c6hsxca1jno1y1q49nqh02clg6ugwsxzrnfvk7vi3bko99yc1txc:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://4z0yj2v350bbeh49jevykcwdrn9sdyfq7b06khyuzfilducfe27veipdy8k3ohljvdtzu9j35vh7c6hsxca1jno1y1q49nqh02clg6ugwsxzrnfvk7vi3bko99yc1txc:latest/predictions.table.json', 'path': 'media/table/predictions_1_3927e24d8e5682e87418.table.json', 'size': 220161, '_type': 'table-file'}",7.037985482349875,,,False,True,validation,False,No | Yes,4,CTBase,725b5ed0-7728-4890-95a4-a74cb7ae1bb4,wic,ENTAILMENT,False,28,bigscience/T0_3B,0,True,affirmation_true_or_false,prompts/general_fixed_choice.yaml,WiC,,2,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",True,Word Sense Disambiguation,wic,False,False,GeneralFixedChoice,False,False,True,,,prompts,,False,True,affirmation_true_or_false,,cross_task,wic,,,,False,,,False,,True,,,False,,CTBase.GenFC.super_glue_wic.affirmation_true_or_false.LenNorm,WiC,53.8229197259811,54.47863130275843,WordsinContext,super_glue,,,,,,,,,,,,,,,,,47.5,76.0,25
2.469135802469136,,0.6656778957387539,1.7564041506160388,,,,2.469135802469136,,,,78.62068965517241,1.7564041506160388,1.0078369905956113,66.80672268907563,,0.0881792048842332,0.6656778957387539,0.0881792048842332,1.9921630094043887,50.470219435736674,"{'_latest_artifact_path': 'wandb-client-artifact://10vyllhld7ke6235cuu9rt936x6dna512lhjii4fkx463fnhr7reia0k0mf4oiflupwk9e0e9s7tivgi8om31pzhyhfcrqcmwsd9em39768u7ufdwkcz5glgwtb6r4gz:latest/predictions.table.json', 'path': 'media/table/predictions_1_9252c93f5e3f98505a3d.table.json', 'size': 243800, '_type': 'table-file', 'ncols': 9, 'nrows': 638, 'sha256': '9252c93f5e3f98505a3d507a0a9ab00464d097511bc326b9e37c5cc3c8677e9a', 'artifact_path': 'wandb-client-artifact://10vyllhld7ke6235cuu9rt936x6dna512lhjii4fkx463fnhr7reia0k0mf4oiflupwk9e0e9s7tivgi8om31pzhyhfcrqcmwsd9em39768u7ufdwkcz5glgwtb6r4gz:latest/predictions.table.json'}",7.037985482349875,,,False,True,validation,False,No | Yes,4,CTBase,611d13dc-d414-4b9b-9204-e4f325e859e7,wic,ENTAILMENT,False,28,bigscience/T0_3B,0,True,grammar_homework,prompts/general_fixed_choice.yaml,WiC,,2,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",True,Word Sense Disambiguation,wic,False,False,GeneralFixedChoice,False,False,True,,,prompts,,False,True,grammar_homework,,cross_task,wic,,,,False,,,False,,True,,,False,,CTBase.GenFC.super_glue_wic.grammar_homework.LenNorm,WiC,54.37469286234909,54.4275311759908,WordsinContext,super_glue,,,,,,,,,,,,,,,,,47.5,76.0,25
3.0769230769230766,,0.7917507441152418,1.888232360065544,,,,3.0769230769230766,,,,62.62068965517241,1.888232360065544,1.0094043887147337,66.8769716088328,,0.0965191493312893,0.7917507441152418,0.0965191493312893,1.9905956112852663,50.626959247648905,"{'artifact_path': 'wandb-client-artifact://a86ebjuc42th4px0rc1q6y0xskjeuz2f5s378azuac64eiya3n1h2sp8nfpxu5k1ayhn6mtki6dl9m0ftnmtwe7yi1dkup4q8pu17u222jswn47qft172om6r8uvs90o:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://a86ebjuc42th4px0rc1q6y0xskjeuz2f5s378azuac64eiya3n1h2sp8nfpxu5k1ayhn6mtki6dl9m0ftnmtwe7yi1dkup4q8pu17u222jswn47qft172om6r8uvs90o:latest/predictions.table.json', 'path': 'media/table/predictions_1_e1592713605ba216137f.table.json', 'size': 202425, '_type': 'table-file', 'ncols': 9, 'nrows': 638, 'sha256': 'e1592713605ba216137f352f524f0124e668f5fdc46fc5d4fec231de32a1789a'}",7.037985482349875,,,False,True,validation,False,No | Yes,4,CTBase,3503ead5-4fa5-4f77-95dc-f0c2ed3eecdc,wic,ENTAILMENT,False,28,bigscience/T0_3B,0,True,question_context_meaning,prompts/general_fixed_choice.yaml,WiC,,2,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",True,Word Sense Disambiguation,wic,False,False,GeneralFixedChoice,False,False,False,,,prompts,,False,True,question-context-meaning,,cross_task,wic,,,,False,,,False,,True,,,False,,CTBase.GenFC.super_glue_wic.question_context_meaning.LenNorm,WiC,55.73874209919626,55.28149290985742,WordsinContext,super_glue,,,,,,,,,,,,,,,,,36.5,69.0,14
2.469135802469136,,0.6412698484421148,1.686163821190502,,,,2.469135802469136,,,,70.62068965517241,1.686163821190502,1.0078369905956113,66.80672268907563,,0.0881792048842332,0.6412698484421148,0.0881792048842332,1.9921630094043887,50.470219435736674,"{'path': 'media/table/predictions_1_04baeef38a3dd7d115c9.table.json', 'size': 214669, '_type': 'table-file', 'ncols': 9, 'nrows': 638, 'sha256': '04baeef38a3dd7d115c93ffabaa7766c12d26f867ee23586223b47244ca6c847', 'artifact_path': 'wandb-client-artifact://19dozh0q1zkx94mxokn5uwwgko81lzu01rt9z4xknck3k73l5ryndiz1yqch2tg5ztl2gmbkfu5jgoiys7c51wacmlubulitz0caec97d6o0nm6u6nqtdeuf0g5josz2:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://19dozh0q1zkx94mxokn5uwwgko81lzu01rt9z4xknck3k73l5ryndiz1yqch2tg5ztl2gmbkfu5jgoiys7c51wacmlubulitz0caec97d6o0nm6u6nqtdeuf0g5josz2:latest/predictions.table.json'}",7.037985482349875,,,False,True,validation,False,No | Yes,4,CTBase,14e73f39-a0d1-44c2-b9a4-4e48f9f1608e,wic,ENTAILMENT,False,28,bigscience/T0_3B,0,True,question_context_meaning_with_label,prompts/general_fixed_choice.yaml,WiC,,2,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",True,Word Sense Disambiguation,wic,False,False,GeneralFixedChoice,False,False,True,,,prompts,,False,True,question-context-meaning-with-label,,cross_task,wic,,,,False,,,False,,True,,,False,,CTBase.GenFC.super_glue_wic.question_context_meaning_with_label.LenNorm,WiC,54.2581247092196,54.4874755554682,WordsinContext,super_glue,,,,,,,,,,,,,,,,,47.5,76.0,16
3.0769230769230766,,0.9004465308754926,2.306693855451192,,,,3.0769230769230766,,,,74.62068965517241,2.306693855451192,1.0094043887147337,66.8769716088328,,0.0965191493312893,0.9004465308754926,0.0965191493312893,1.9905956112852663,50.626959247648905,"{'ncols': 9, 'nrows': 638, 'sha256': '72a39a196bce39b2aa70c83d99d05564f61a404dd1cdfc259df85a2ea185820e', 'artifact_path': 'wandb-client-artifact://4igup4fu1or7fcq9uxalknkbt4048uk2uy5j9db32xfow1yw5spbbttl2lsf6lduvkb82pxubc1ul22icaqxlm6cggdgvo8wflt2yhkf821jwy6z0o5eu6x97mda8hhu:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://4igup4fu1or7fcq9uxalknkbt4048uk2uy5j9db32xfow1yw5spbbttl2lsf6lduvkb82pxubc1ul22icaqxlm6cggdgvo8wflt2yhkf821jwy6z0o5eu6x97mda8hhu:latest/predictions.table.json', 'path': 'media/table/predictions_1_72a39a196bce39b2aa70.table.json', 'size': 236115, '_type': 'table-file'}",7.037985482349875,,,False,True,validation,False,No | Yes,4,CTBase,cd563834-49ee-495d-ac46-99f0264e58d5,wic,QA,False,28,bigscience/T0_3B,0,True,ask_question_as_teacher,prompts/general_fixed_choice.yaml,ZEST,,2,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,Word Sense Disambiguation,wic,False,False,GeneralFixedChoice,False,False,False,,,prompts,,False,True,ask_question_as_teacher,,cross_task,wic,,,,False,,,False,,True,,,False,,CTBase.GenFC.zest.ask_question_as_teacher.LenNorm,WiC,56.68878448855459,56.91866235591239,WordsinContext,super_glue,,,,,,,,,,,,,,,,,36.5,69.0,24
14.207650273224044,,0.7276436150257344,1.1752123920521391,,,,14.207650273224044,,,,75.62068965517241,1.1752123920521391,1.073667711598746,65.49450549450549,,0.2612293625658303,0.7276436150257344,0.2612293625658303,1.926332288401254,50.78369905956113,"{'_type': 'table-file', 'ncols': 9, 'nrows': 638, 'sha256': '205518a57c810a66ed14b662c02fd435ef4e86b78dff0bd743f7bc300cea4410', 'artifact_path': 'wandb-client-artifact://toizgcvmjbv0qw9xxgajoihnry4trel1ia4yc58n52cue96hhbdwnlday9goc3gokwb60m2hf73l1jrdihqqpu13xcf6hr1984209dh74m5vgqfzoxomq4bddloz0x4q:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://toizgcvmjbv0qw9xxgajoihnry4trel1ia4yc58n52cue96hhbdwnlday9goc3gokwb60m2hf73l1jrdihqqpu13xcf6hr1984209dh74m5vgqfzoxomq4bddloz0x4q:latest/predictions.table.json', 'path': 'media/table/predictions_1_205518a57c810a66ed14.table.json', 'size': 236532}",7.037985482349875,,,False,True,validation,False,No | Yes,4,CTBase,7425232a-9880-428c-9ddc-4070e50e22cc,wic,QA,False,28,bigscience/T0_3B,0,True,gpt3_instruct_format,prompts/general_fixed_choice.yaml,ZEST,,2,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,Word Sense Disambiguation,wic,False,False,GeneralFixedChoice,False,False,False,,,prompts,,False,True,gpt3_instruct_format,,cross_task,wic,,,,False,,,False,,True,,,False,,CTBase.GenFC.zest.gpt3_instruct_format.LenNorm,WiC,55.70908020928418,56.065191969418535,WordsinContext,super_glue,,,,,,,,,,,,,,,,,28.0,22.0,28
8.16326530612245,,0.8182022616611798,1.4963899639239506,,,,8.16326530612245,,,,80.62068965517241,1.4963899639239506,1.037617554858934,66.23794212218648,,0.1902694784387902,0.8182022616611798,0.1902694784387902,1.962382445141066,50.626959247648905,"{'_latest_artifact_path': 'wandb-client-artifact://ewrvwvg93mf5v4z8znwj7jkdvqxjiikorwpdtl51lcnay1rixqassd6no42q71mer7kt1b8nz98c3nrq6umq926k0gj5cjv8rx0u6qttulxkrmajbjmi1cbr0cbv33zk:latest/predictions.table.json', 'path': 'media/table/predictions_1_8b71157abf8a0ace6611.table.json', 'size': 236888, '_type': 'table-file', 'ncols': 9, 'nrows': 638, 'sha256': '8b71157abf8a0ace66118ed3ffe69ad1a6a505de988639d97526f38790bb0127', 'artifact_path': 'wandb-client-artifact://ewrvwvg93mf5v4z8znwj7jkdvqxjiikorwpdtl51lcnay1rixqassd6no42q71mer7kt1b8nz98c3nrq6umq926k0gj5cjv8rx0u6qttulxkrmajbjmi1cbr0cbv33zk:latest/predictions.table.json'}",7.037985482349875,,,False,True,validation,False,No | Yes,4,CTBase,6f694e45-1d17-4067-a1f6-7dae89c148db,wic,QA,False,28,bigscience/T0_3B,0,True,ask_question_as_kid,prompts/general_fixed_choice.yaml,ZEST,,2,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,Word Sense Disambiguation,wic,False,False,GeneralFixedChoice,False,False,False,,,prompts,,False,True,ask_question_as_kid,,cross_task,wic,,,,False,,,False,,True,,,False,,CTBase.GenFC.zest.ask_question_as_kid.LenNorm,WiC,54.21267828836556,54.642741325262136,WordsinContext,super_glue,,,,,,,,,,,,,,,,,36.5,40.0,31
5.438066465256798,,0.837764747722353,1.6830279183191563,,,,5.438066465256798,,,,68.62068965517241,1.6830279183191563,1.0188087774294672,66.87830687830689,,0.1358492080252066,0.837764747722353,0.1358492080252066,1.9811912225705328,50.94043887147336,"{'_latest_artifact_path': 'wandb-client-artifact://17edun9mjt8loxjwfpas8ft0n3q1g37zymf7yqdojaz4e40g2i9sqnlh47tyl52mbivl9vr6cu761za3nxrxger1qahh66g72gyh2wyy8ukpihyjzmm4gdr24mrbju0h:latest/predictions.table.json', 'path': 'media/table/predictions_1_8bb833d60a35b59b7868.table.json', 'size': 212519, '_type': 'table-file', 'ncols': 9, 'nrows': 638, 'sha256': '8bb833d60a35b59b7868c5cf117a66541fe3a7e67b3d04d64a4c546390722513', 'artifact_path': 'wandb-client-artifact://17edun9mjt8loxjwfpas8ft0n3q1g37zymf7yqdojaz4e40g2i9sqnlh47tyl52mbivl9vr6cu761za3nxrxger1qahh66g72gyh2wyy8ukpihyjzmm4gdr24mrbju0h:latest/predictions.table.json'}",7.037985482349875,,,False,True,validation,False,No | Yes,4,CTBase,2283cebf-988e-4bff-96bf-982a09963e49,wic,QA,False,28,bigscience/T0_3B,0,True,answerable_or_not,prompts/general_fixed_choice.yaml,ZEST,,2,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,Word Sense Disambiguation,wic,False,False,GeneralFixedChoice,False,False,False,,,prompts,,False,True,answerable_or_not,,cross_task,wic,,,,False,,,False,,True,,,False,,CTBase.GenFC.zest.answerable_or_not.LenNorm,WiC,55.49438455638753,55.623470681302265,WordsinContext,super_glue,,,,,,,,,,,,,,,,,23.0,56.0,20
28.21339822763267,41.47665580890337,1.0350019636154149,12.477169042378664,2.0,0.8334178936972816,0.0,0.0,,,,148.056,11.501767780542371,2.176,43.16353887399464,0.9754012618362904,0.984390166549829,1.0028485319529097,0.984390166549829,1.824,35.2,"{'sha256': '46b0adf2be8c3cb16f12f9b657ff8dbeccf8e8b9f94af6663eb5aba42367e2c7', 'artifact_path': 'wandb-client-artifact://kzj1ya8xhgozspgitjpg3pfw1tk959n7nuj95gpdcq5g07sarpxzmxwxrinjtmiq2di5czxhj1syqrbbg6dsw8wc8inqt8d5n5f9ztoobv3bcqw5i14z8t23rkobglwb:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://kzj1ya8xhgozspgitjpg3pfw1tk959n7nuj95gpdcq5g07sarpxzmxwxrinjtmiq2di5czxhj1syqrbbg6dsw8wc8inqt8d5n5f9ztoobv3bcqw5i14z8t23rkobglwb:latest/predictions.table.json', 'path': 'media/table/predictions_1_46b0adf2be8c3cb16f12.table.json', 'size': 705490, '_type': 'table-file', 'ncols': 11, 'nrows': 1000}",18.09101611297718,,,False,True,dev_r1,False,Yes | Maybe | No,4,CTBase,a64d5a15-68e2-4d1c-b30a-ca8250c860f9,anli,QA,False,28,bigscience/T0_3B,0,True,answer_the_following_q,prompts/general_fixed_choice.yaml,AdversarialQA,,3,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,['NLI'],anli,True,False,GeneralFixedChoice,False,False,False,,,prompts,,False,True,answer_the_following_q,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.adversarial_qa.answer_the_following_q.LenNorm,ANLI R1,,,,,,,,,,,,,,,,,,,,,36.5,30.0,23
21.220524039736453,46.95512820512821,0.7411806437294282,5.840234925746918,2.0,0.8386016618741499,0.0,0.0,,,,136.434,4.50737800192833,2.83,16.706443914081145,1.3328569238185883,0.5577633906953737,0.8129278223139083,0.5577633906953737,1.17,32.800000000000004,"{'_latest_artifact_path': 'wandb-client-artifact://ktkiozk39nep0vrs36dy5kb5ipq3j5tiv4xor2sq78n2kxykadh5bspl56f4xl5t63emswxgnxp19z7ahodbo0fzzykgtujnhxgby7i9anlzqifz41eq8zxgur0ryth7:latest/predictions.table.json', 'path': 'media/table/predictions_1_a8d1478763733fea99fb.table.json', 'size': 619667, '_type': 'table-file', 'ncols': 11, 'nrows': 1000, 'sha256': 'a8d1478763733fea99fb5f16376ccd6177f3bd012c6793e22b0cd1aa3a2862c7', 'artifact_path': 'wandb-client-artifact://ktkiozk39nep0vrs36dy5kb5ipq3j5tiv4xor2sq78n2kxykadh5bspl56f4xl5t63emswxgnxp19z7ahodbo0fzzykgtujnhxgby7i9anlzqifz41eq8zxgur0ryth7:latest/predictions.table.json'}",17.88970776731694,,,False,True,dev_r2,False,Yes | Maybe | No,4,CTBase,725b5ed0-7728-4890-95a4-a74cb7ae1bb4,anli,ENTAILMENT,False,28,bigscience/T0_3B,0,True,affirmation_true_or_false,prompts/general_fixed_choice.yaml,WiC,,3,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,['NLI'],anli,False,False,GeneralFixedChoice,False,False,True,,,prompts,,False,True,affirmation_true_or_false,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.super_glue_wic.affirmation_true_or_false.LenNorm,ANLI R2,,,,,,,,,,,,,,,,,,,,,57.5,71.0,25
19.037637647688857,48.9607390300231,0.8026069878857117,5.2328153314739465,2.0,0.696626975417713,0.0,0.0,,,,135.434,3.869963019251823,2.932,8.152173913043478,1.3628523122221232,0.3624582734605461,0.8643320114372258,0.3624582734605461,1.068,33.300000000000004,"{'size': 656524, '_type': 'table-file', 'ncols': 11, 'nrows': 1000, 'sha256': '4dd2195c27e594866e001bb16c2a092229dadeea9bf0b4a9d6e39a683ed4c9cb', 'artifact_path': 'wandb-client-artifact://f92hk78v5mp82rvk3jwcw856vr4xcoga3j7rayy0zt98pgmk2mjcsvwnic37dc49oveu7bdp0zek58ovbyteiyxpscj8o0xx7wdsbk58182cve2v11ks5zvi01mzqhti:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://f92hk78v5mp82rvk3jwcw856vr4xcoga3j7rayy0zt98pgmk2mjcsvwnic37dc49oveu7bdp0zek58ovbyteiyxpscj8o0xx7wdsbk58182cve2v11ks5zvi01mzqhti:latest/predictions.table.json', 'path': 'media/table/predictions_1_4dd2195c27e594866e00.table.json'}",17.88970776731694,,,False,True,dev_r2,False,Yes | Maybe | No,4,CTBase,611d13dc-d414-4b9b-9204-e4f325e859e7,anli,ENTAILMENT,False,28,bigscience/T0_3B,0,True,grammar_homework,prompts/general_fixed_choice.yaml,WiC,,3,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,['NLI'],anli,False,False,GeneralFixedChoice,False,False,True,,,prompts,,False,True,grammar_homework,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.super_glue_wic.grammar_homework.LenNorm,ANLI R2,,,,,,,,,,,,,,,,,,,,,34.0,80.0,25
28.412879570800797,43.08617234468938,1.2539841164779877,13.040586131989956,2.0,1.084657087558466,0.0,0.0,,,,141.056,11.737676197767255,2.33,42.15246636771301,1.3029099342226982,0.9439809320108112,1.2223559265889876,0.9439809320108112,1.67,35.6,"{'ncols': 11, 'nrows': 1000, 'sha256': 'e3e3e647216dd5a190ec5da64abf78bfd3073bd6d58ee861e62ddf814b0a4b18', 'artifact_path': 'wandb-client-artifact://10w9afl4s3hgrgl46pcdtk50l76dmjfzvfcwblfzbbs9ao17hjxryozn6tnxlruix7ozfcwolvdzbooh9wrph6kbu0tjjmutha5ivjat18pw88nq04520h8xnf4k81jn:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://10w9afl4s3hgrgl46pcdtk50l76dmjfzvfcwblfzbbs9ao17hjxryozn6tnxlruix7ozfcwolvdzbooh9wrph6kbu0tjjmutha5ivjat18pw88nq04520h8xnf4k81jn:latest/predictions.table.json', 'path': 'media/table/predictions_1_e3e3e647216dd5a190ec.table.json', 'size': 664241, '_type': 'table-file'}",18.09101611297718,,,False,True,dev_r1,False,Yes | Maybe | No,4,CTBase,a0872cde-2f19-4ae6-919a-868da47bfbcb,anli,QA,False,28,bigscience/T0_3B,0,True,based_on,prompts/general_fixed_choice.yaml,AdversarialQA,,3,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,['NLI'],anli,True,False,GeneralFixedChoice,False,False,False,,,prompts,,False,True,based_on,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.adversarial_qa.based_on.LenNorm,ANLI R1,,,,,,,,,,,,,,,,,,,,,31.5,29.0,16
21.70169947760441,48.358686949559655,1.227681777725645,8.98201603937149,2.0,0.7680148665727192,0.0,0.0,,,,115.434,7.748258555412293,2.832,16.74641148325359,1.233757483959198,0.5547756303227459,1.2119148247982674,0.5547756303227458,1.168,33.7,"{'nrows': 1000, 'sha256': '4669af024161dff933cecc836d2dc08731b03fda05c16a8ee1d22ff63a452757', 'artifact_path': 'wandb-client-artifact://udncoa6zxr7pmlfi427fshsaa18ijpgn89riio1oxkl4u39a89r44nk9c3hsvy6itj38wy0rgyr8ye8t2k6awjnr3bvzsv3yep71zr4cd6a9c99v713r2ffh0w7ojrpj:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://udncoa6zxr7pmlfi427fshsaa18ijpgn89riio1oxkl4u39a89r44nk9c3hsvy6itj38wy0rgyr8ye8t2k6awjnr3bvzsv3yep71zr4cd6a9c99v713r2ffh0w7ojrpj:latest/predictions.table.json', 'path': 'media/table/predictions_1_4669af024161dff933ce.table.json', 'size': 582165, '_type': 'table-file', 'ncols': 11}",17.88970776731694,,,False,True,dev_r2,False,Yes | Maybe | No,4,CTBase,3503ead5-4fa5-4f77-95dc-f0c2ed3eecdc,anli,ENTAILMENT,False,28,bigscience/T0_3B,0,True,question_context_meaning,prompts/general_fixed_choice.yaml,WiC,,3,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,['NLI'],anli,False,False,GeneralFixedChoice,False,False,False,,,prompts,,False,True,question-context-meaning,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.super_glue_wic.question_context_meaning.LenNorm,ANLI R2,,,,,,,,,,,,,,,,,,,,,19.5,69.0,14
28.172049347791923,42.083333333333336,1.223746226111695,12.646424253702165,2.0,0.999762134243244,0.0,0.0,,,,136.056,11.430832522153857,2.254,42.43281471004243,1.2155917315483094,0.967204218353084,1.1782893237681014,0.967204218353084,1.746,35.2,"{'_type': 'table-file', 'ncols': 11, 'nrows': 1000, 'sha256': '5a0bed551d1c2bbf93c4079c2511cf4fb9c5013d3591c1a990e114bff38e6732', 'artifact_path': 'wandb-client-artifact://12gzn06c58vamjlpj32rycwnki8j7kttx9z4rzb1e9ppg71gq4vzr21dx59blz4t1val67yiwll3mxjnik0w6ann721ci90g86tlqkfyw4uuxv471wvjxo5dfnpnzlte:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://12gzn06c58vamjlpj32rycwnki8j7kttx9z4rzb1e9ppg71gq4vzr21dx59blz4t1val67yiwll3mxjnik0w6ann721ci90g86tlqkfyw4uuxv471wvjxo5dfnpnzlte:latest/predictions.table.json', 'path': 'media/table/predictions_1_5a0bed551d1c2bbf93c4.table.json', 'size': 617192}",18.09101611297718,,,False,True,dev_r1,False,Yes | Maybe | No,4,CTBase,5bdb1815-5c6f-49a3-ad1d-367344420701,anli,QA,False,28,bigscience/T0_3B,0,True,question_context_answer,prompts/general_fixed_choice.yaml,AdversarialQA,,3,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,['NLI'],anli,True,False,GeneralFixedChoice,False,False,False,,,prompts,,False,True,question_context_answer,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.adversarial_qa.question_context_answer.LenNorm,ANLI R1,,,,,,,,,,,,,,,,,,,,,36.5,31.0,11
18.729445976864024,49.46564885496183,0.7684587171977647,5.389834298849106,2.0,0.6736025258547893,0.0,0.0,,,,127.434,4.022576706886292,2.954,6.722689075630253,1.3672575919628145,0.2998066043301915,0.8160148056628139,0.2998066043301915,1.046,33.6,"{'artifact_path': 'wandb-client-artifact://art61ezf546reolgoxvkdd1wb7rbs889me1j40aljotq73x42y9uzy0bmpr6sqilccqipzg5a7uqxwjkgnzqdd8s86c1rr1fehc9tnwzforr9wwtoj54ka02lzz9lkhe:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://art61ezf546reolgoxvkdd1wb7rbs889me1j40aljotq73x42y9uzy0bmpr6sqilccqipzg5a7uqxwjkgnzqdd8s86c1rr1fehc9tnwzforr9wwtoj54ka02lzz9lkhe:latest/predictions.table.json', 'path': 'media/table/predictions_1_86359c2389b81423818e.table.json', 'size': 611507, '_type': 'table-file', 'ncols': 11, 'nrows': 1000, 'sha256': '86359c2389b81423818ec3032cd3ad8a099a7dffe3b59024080836a66ed94fad'}",17.88970776731694,,,False,True,dev_r2,False,Yes | Maybe | No,4,CTBase,14e73f39-a0d1-44c2-b9a4-4e48f9f1608e,anli,ENTAILMENT,False,28,bigscience/T0_3B,0,True,question_context_meaning_with_label,prompts/general_fixed_choice.yaml,WiC,,3,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,['NLI'],anli,False,False,GeneralFixedChoice,False,False,True,,,prompts,,False,True,question-context-meaning-with-label,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.super_glue_wic.question_context_meaning_with_label.LenNorm,ANLI R2,,,,,,,,,,,,,,,,,,,,,23.0,81.0,16
27.40279788031628,41.41519250780436,1.2202063547728366,12.35473322892189,2.0,0.996064295418476,0.0,0.0,,,,148.056,11.156022884607316,2.256,40.79320113314448,1.1987103443145752,0.966676781556276,1.1979063808549404,0.966676781556276,1.744,34.300000000000004,"{'size': 664167, '_type': 'table-file', 'ncols': 11, 'nrows': 1000, 'sha256': 'c608c11eebc2e20d326413722438c63ab2a883f4f8d4d152c4aacc27e5b9bdc8', 'artifact_path': 'wandb-client-artifact://19r44cimfqdb4u999tyo9odf8omykzp8srl4gbrfpj1uvl31qqycquyqso8k5bnlvniy0h1yy2m9y62kopgyvg57f6cfn145q9350szr6jegmpzr7o12au2mxb14w3vo:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://19r44cimfqdb4u999tyo9odf8omykzp8srl4gbrfpj1uvl31qqycquyqso8k5bnlvniy0h1yy2m9y62kopgyvg57f6cfn145q9350szr6jegmpzr7o12au2mxb14w3vo:latest/predictions.table.json', 'path': 'media/table/predictions_1_c608c11eebc2e20d3264.table.json'}",18.09101611297718,,,False,True,dev_r1,False,Yes | Maybe | No,4,CTBase,3b2459cc-6600-443c-abf8-8f60c34cd998,anli,QA,False,28,bigscience/T0_3B,0,True,tell_what_it_is,prompts/general_fixed_choice.yaml,AdversarialQA,,3,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,['NLI'],anli,True,False,GeneralFixedChoice,False,False,False,,,prompts,,False,True,tell_what_it_is,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.adversarial_qa.tell_what_it_is.LenNorm,ANLI R1,,,,,,,,,,,,,,,,,,,,,46.5,39.0,22
24.267021960662973,43.108233117483806,1.1615217571050078,11.98154886507988,2.0,0.966757530336142,0.0,0.0,,,,152.051,10.767165635585783,2.496,29.69283276450512,1.2143832294940948,0.8683225207260261,1.278206303423375,0.8683225207260261,1.504,32.0,"{'_latest_artifact_path': 'wandb-client-artifact://16r4x78sdantkl0b34fnvti2wadkku16wa7gibf9hbj385zxmgk82ttc2ftqzew0y5htir4czjta1hhcgdmw4qk83dygm0je55mbjbnb82dd6ibo4tizj286ahfglrfn:latest/predictions.table.json', 'path': 'media/table/predictions_1_606a5193d15a000ef364.table.json', 'size': 697891, '_type': 'table-file', 'ncols': 11, 'nrows': 1000, 'sha256': '606a5193d15a000ef364bd1f7e985bf532ea8273ed74a8be199d21bdf6ece17f', 'artifact_path': 'wandb-client-artifact://16r4x78sdantkl0b34fnvti2wadkku16wa7gibf9hbj385zxmgk82ttc2ftqzew0y5htir4czjta1hhcgdmw4qk83dygm0je55mbjbnb82dd6ibo4tizj286ahfglrfn:latest/predictions.table.json'}",17.873231353059804,,,False,True,dev_r2,False,Yes | Maybe | No,4,CTBase,cd563834-49ee-495d-ac46-99f0264e58d5,anli,QA,False,28,bigscience/T0_3B,0,True,ask_question_as_teacher,prompts/general_fixed_choice.yaml,ZEST,,3,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,['NLI'],anli,False,False,GeneralFixedChoice,False,False,False,,,prompts,,False,True,ask_question_as_teacher,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.zest.ask_question_as_teacher.LenNorm,ANLI R2,,,,,,,,,,,,,,,,,,,,,75.0,48.0,24
26.097623210507557,41.58215010141988,0.9903797958503066,10.08649110174179,2.0,0.7605863188020868,0.0,0.0,,,,151.051,9.128595942020416,2.306,36.71071953010279,0.9578951597213744,0.9520315120835025,1.037306220202024,0.9520315120835025,1.694,33.0,"{'ncols': 11, 'nrows': 1000, 'sha256': '0149769247a8c78556e62cf83c9a3593ade0b7bb1531022be27f1f76affc43ec', 'artifact_path': 'wandb-client-artifact://b6ovfdx3vpp19kews4dry86x4iuees5vno3ziwqq9xmyo3m300zv613kui6zbvktitteveec0sg1qrtstu2derv4xlz68zqongjdyeswg8s86ekhdpd4cw8gzo9zts94:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://b6ovfdx3vpp19kews4dry86x4iuees5vno3ziwqq9xmyo3m300zv613kui6zbvktitteveec0sg1qrtstu2derv4xlz68zqongjdyeswg8s86ekhdpd4cw8gzo9zts94:latest/predictions.table.json', 'path': 'media/table/predictions_1_0149769247a8c78556e6.table.json', 'size': 699366, '_type': 'table-file'}",17.873231353059804,,,False,True,dev_r2,False,Yes | Maybe | No,4,CTBase,7425232a-9880-428c-9ddc-4070e50e22cc,anli,QA,False,28,bigscience/T0_3B,0,True,gpt3_instruct_format,prompts/general_fixed_choice.yaml,ZEST,,3,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,['NLI'],anli,False,False,GeneralFixedChoice,False,False,False,,,prompts,,False,True,gpt3_instruct_format,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.zest.gpt3_instruct_format.LenNorm,ANLI R2,,,,,,,,,,,,,,,,,,,,,52.0,29.0,28
27.14937655104736,41.2262156448203,0.8798879499430584,4.518627660751343,2.0,0.7556175086978315,0.0,0.0,,,,128.056,3.5747286520004278,2.226,40.221914008321775,0.9438990087509156,0.9741273017424366,0.8667882956447449,0.9741273017424366,1.774,34.0,"{'_latest_artifact_path': 'wandb-client-artifact://bqnkuxfsh29eg12bb05k31ap0d0skq63g8cuorhhgi67n65cwm3lvh66oktzc78xnjpq1xv4ja8tqh7fdhnkfd9aypc3b3se1f8qujmdnjn1eaxny786toryxejob7wc:latest/predictions.table.json', 'path': 'media/table/predictions_1_f24e322649fc03fbc8ad.table.json', 'size': 589302, '_type': 'table-file', 'ncols': 11, 'nrows': 1000, 'sha256': 'f24e322649fc03fbc8ad4aa6160bfd7e5f8b48c2e96366148a288b99418a703a', 'artifact_path': 'wandb-client-artifact://bqnkuxfsh29eg12bb05k31ap0d0skq63g8cuorhhgi67n65cwm3lvh66oktzc78xnjpq1xv4ja8tqh7fdhnkfd9aypc3b3se1f8qujmdnjn1eaxny786toryxejob7wc:latest/predictions.table.json'}",18.09101611297718,,,False,True,dev_r1,False,Yes | Maybe | No,4,CTBase,4dd990b3-7201-4cba-bb9a-baa462d68b1a,anli,SENTIMENT,False,28,bigscience/T0_3B,0,True,format_score,prompts/general_fixed_choice.yaml,Yelp,,3,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,['NLI'],anli,True,False,GeneralFixedChoice,False,False,False,,,prompts,,False,True,format_score,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.yelp.format_score.LenNorm,ANLI R1,,,,,,,,,,,,,,,,,,,,,53.0,42.0,12
26.58351441402289,39.33333333333333,1.0672545244977814,10.99115543782711,2.0,0.7638469887138502,0.0,0.0,,,,158.051,10.01154882287979,2.134,40.41720990873534,0.979606614947319,0.990981331812058,1.0742754259100318,0.990981331812058,1.866,33.2,"{'_type': 'table-file', 'ncols': 11, 'nrows': 1000, 'sha256': '3c82a7c8fb6fce666beb2acd5afe7fee3d110951fa1d6cc8bb6f979404cddd6c', 'artifact_path': 'wandb-client-artifact://on1ozb3fkeqb7mcf72m7gtlwm3f08mtwn9j9i5iq8tfoh4qa1mu5b1946smf7pe0oya85sd0djuk0y837ahmn0k262dtusk46kcc8htyejptuy40q9umiuqx19s1fwfa:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://on1ozb3fkeqb7mcf72m7gtlwm3f08mtwn9j9i5iq8tfoh4qa1mu5b1946smf7pe0oya85sd0djuk0y837ahmn0k262dtusk46kcc8htyejptuy40q9umiuqx19s1fwfa:latest/predictions.table.json', 'path': 'media/table/predictions_1_3c82a7c8fb6fce666beb.table.json', 'size': 699163}",17.873231353059804,,,False,True,dev_r2,False,Yes | Maybe | No,4,CTBase,6f694e45-1d17-4067-a1f6-7dae89c148db,anli,QA,False,28,bigscience/T0_3B,0,True,ask_question_as_kid,prompts/general_fixed_choice.yaml,ZEST,,3,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,['NLI'],anli,False,False,GeneralFixedChoice,False,False,False,,,prompts,,False,True,ask_question_as_kid,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.zest.ask_question_as_kid.LenNorm,ANLI R2,,,,,,,,,,,,,,,,,,,,,40.5,22.0,31
25.515226611059067,41.57635467980296,0.9687334141377388,4.267566568851471,2.0,0.766906740536088,0.0,0.0,,,,122.056,3.2795666885375976,2.364,34.96932515337423,0.9879998803138732,0.931398947819891,0.9081531041655732,0.9313989478198912,1.636,32.5,"{'nrows': 1000, 'sha256': '47d1050708e63a7fb571741bef101fa0c32ad0f399f4e28973161c1e6958d0cf', 'artifact_path': 'wandb-client-artifact://2bxen6r5q9v88nwep1z2ibbj6u5td5i9y8rl43d5n4x3awep43fek1mz5qbgesigiky9phrdo8ntyrbyiiahkxie0g3otucysb6dr79ltew428ib042gxjiyoz791kj0:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://2bxen6r5q9v88nwep1z2ibbj6u5td5i9y8rl43d5n4x3awep43fek1mz5qbgesigiky9phrdo8ntyrbyiiahkxie0g3otucysb6dr79ltew428ib042gxjiyoz791kj0:latest/predictions.table.json', 'path': 'media/table/predictions_1_47d1050708e63a7fb571.table.json', 'size': 563592, '_type': 'table-file', 'ncols': 11}",18.09101611297718,,,False,True,dev_r1,False,Yes | Maybe | No,4,CTBase,29fc6386-90b3-4976-b249-26e49fe7c924,anli,SENTIMENT,False,28,bigscience/T0_3B,0,True,format_star,prompts/general_fixed_choice.yaml,Yelp,,3,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,['NLI'],anli,True,False,GeneralFixedChoice,False,False,False,,,prompts,,False,True,format_star,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.yelp.format_star.LenNorm,ANLI R1,,,,,,,,,,,,,,,,,,,,,78.5,55.0,6
23.802870028700287,43.73333333333333,0.8636702542602981,3.975403688907624,2.0,0.8490894923943861,0.0,0.0,,,,126.056,2.8398627614974976,2.584,27.675276752767523,1.1355409274101258,0.8117536572138128,0.8498729765491877,0.8117536572138128,1.416,32.1,"{'size': 576511, '_type': 'table-file', 'ncols': 11, 'nrows': 1000, 'sha256': 'df403497385d66dd86150c3eaeebcd54cbc1a7a16318736f62c0f251b3a02d49', 'artifact_path': 'wandb-client-artifact://130mhsl24mdb4jp611x7zd2lraqpnv0ty53o9egnxklode2litgiqloy28ku1xipfm7l13y623jz7ec8rwpjrc9wa3399cvcxqrczj4iu6ot4elmqztmqd6cxy7sq7en:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://130mhsl24mdb4jp611x7zd2lraqpnv0ty53o9egnxklode2litgiqloy28ku1xipfm7l13y623jz7ec8rwpjrc9wa3399cvcxqrczj4iu6ot4elmqztmqd6cxy7sq7en:latest/predictions.table.json', 'path': 'media/table/predictions_1_df403497385d66dd8615.table.json'}",18.09101611297718,,,False,True,dev_r1,False,Yes | Maybe | No,4,CTBase,27b6bc81-bb1c-467b-91c0-22a4d6a19f44,anli,SENTIMENT,False,28,bigscience/T0_3B,0,True,based_on_that,prompts/general_fixed_choice.yaml,Yelp,,3,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,['NLI'],anli,True,False,GeneralFixedChoice,False,False,False,,,prompts,,False,True,based_on_that,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.yelp.based_on_that.LenNorm,ANLI R1,,,,,,,,,,,,,,,,,,,,,81.5,68.0,10
25.477768001963145,40.963855421686745,1.1031956399388978,11.912628348708152,2.0,0.8690318827753186,0.0,0.0,,,,144.051,10.835371579170229,2.326,35.46944858420268,1.0772567695379258,0.945369768926424,1.1755006061128987,0.945369768926424,1.674,32.300000000000004,"{'ncols': 11, 'nrows': 1000, 'sha256': 'f65f75e1ed4964a0376feb6d265e4625263e8d3d3a1bce91631547827163a87e', 'artifact_path': 'wandb-client-artifact://w6moi1ldnhkytou5lr8h9p4dxxws3uwrw1in0o65g9k5s8zvx92c39vclcvvba1eupyqbi2uh0zzeb9emfmq50nof2ero5q4j7j3xv07opmf54706rwdzsdbbwt70sq2:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://w6moi1ldnhkytou5lr8h9p4dxxws3uwrw1in0o65g9k5s8zvx92c39vclcvvba1eupyqbi2uh0zzeb9emfmq50nof2ero5q4j7j3xv07opmf54706rwdzsdbbwt70sq2:latest/predictions.table.json', 'path': 'media/table/predictions_1_f65f75e1ed4964a0376f.table.json', 'size': 661105, '_type': 'table-file'}",17.873231353059804,,,False,True,dev_r2,False,Yes | Maybe | No,4,CTBase,2283cebf-988e-4bff-96bf-982a09963e49,anli,QA,False,28,bigscience/T0_3B,0,True,answerable_or_not,prompts/general_fixed_choice.yaml,ZEST,,3,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,['NLI'],anli,False,False,GeneralFixedChoice,False,False,False,,,prompts,,False,True,answerable_or_not,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.zest.answerable_or_not.LenNorm,ANLI R2,,,,,,,,,,,,,,,,,,,,,69.5,37.0,20
27.654459823144943,37.75,1.137893932303585,3.408462312221527,1.995,0.7287647267976542,0.0705336798983294,0.0,,,,123.056,2.496025260448456,1.934,45.213379469434834,0.9124370517730712,0.9978196229780208,1.026166353272706,0.9949668336180858,2.071,34.7,"{'size': 571354, '_type': 'table-file', 'ncols': 11, 'nrows': 1000, 'sha256': 'e164e1c1a42f95341def6a273311c0623fe80a74c51d5d260974391b9a1aad39', 'artifact_path': 'wandb-client-artifact://5aeku65zgjsrrkjds5tysbj38aj9mmmey1h0g66hpzvt6igk3nzu9lyxehlxj3sqin9imw4iz4dmu017x1018lkb9mhv2octw2wap7g53okrgyvouk3471ow425t87ya:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://5aeku65zgjsrrkjds5tysbj38aj9mmmey1h0g66hpzvt6igk3nzu9lyxehlxj3sqin9imw4iz4dmu017x1018lkb9mhv2octw2wap7g53okrgyvouk3471ow425t87ya:latest/predictions.table.json', 'path': 'media/table/predictions_1_e164e1c1a42f95341def.table.json'}",18.09101611297718,,,False,True,dev_r1,False,Yes | Maybe | No,4,CTBase,135fcd11-9fcc-4b55-bf1b-9b76290d0f6b,anli,SENTIMENT,False,28,bigscience/T0_3B,0,True,so_i_would,prompts/general_fixed_choice.yaml,Yelp,,3,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,['NLI'],anli,True,False,GeneralFixedChoice,False,False,False,,,prompts,,False,True,so_i_would,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.yelp.so_i_would.LenNorm,ANLI R1,,,,,,,,,,,,,,,,,,,,,42.5,37.0,7
23.95140930102084,43.69747899159664,1.1351981100241166,11.235713041722777,2.0,0.7876356701359941,0.0,0.0,,,,140.23583333333335,10.194601775010426,2.5216666666666665,28.156748911465897,1.0411112667123477,0.8531493942381305,1.192781962211711,0.8531493942381305,1.4783333333333333,31.916666666666664,"{'ncols': 11, 'nrows': 1200, 'sha256': '40a4a656597464f4446012ad0e68d5e0f2bd666994b43bdd12d754f83426227c', 'artifact_path': 'wandb-client-artifact://vgu0ht3eg4ildquw4zjqthg5yz0hprwuenryfpk8i68jqplecoz5dx2tdgj4r1xuhvfda83elm562zet1f651r7bc7btla92aqgi6ctgmquz8utb2k0cdcqgadqo88cb:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://vgu0ht3eg4ildquw4zjqthg5yz0hprwuenryfpk8i68jqplecoz5dx2tdgj4r1xuhvfda83elm562zet1f651r7bc7btla92aqgi6ctgmquz8utb2k0cdcqgadqo88cb:latest/predictions.table.json', 'path': 'media/table/predictions_1_40a4a656597464f44460.table.json', 'size': 824512, '_type': 'table-file'}",32.01257902719214,,,False,True,dev_r3,False,Yes | Maybe | No,4,CTBase,a64d5a15-68e2-4d1c-b30a-ca8250c860f9,anli,QA,False,28,bigscience/T0_3B,0,True,answer_the_following_q,prompts/general_fixed_choice.yaml,AdversarialQA,,3,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,['NLI'],anli,True,False,GeneralFixedChoice,False,False,False,,,prompts,,False,True,answer_the_following_q,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.adversarial_qa.answer_the_following_q.LenNorm,ANLI R3,,,,,,,,,,,,,,,,,,,,,89.5,42.0,23
26.866096597695226,30.691399662731868,0.4499922341378914,1.2002937517166137,2.013,0.426427557185851,0.1970558296524109,0.0,,,,143.056,0.6541504917144776,1.52,49.90689013035382,0.5461432600021362,0.8772684879784525,0.3636157376912855,0.8619228503758326,2.467,35.9,"{'_latest_artifact_path': 'wandb-client-artifact://cwhceejr4raam5e2kp214t8400x1wvlixgkj7zh6fm8ktqxfndw15abeeza9a02q3z0xg9tqai8ttru52or68ckv3sd4cden31d9jrngcbgqm90bh2u0anlhj8yqt465:latest/predictions.table.json', 'path': 'media/table/predictions_1_cd236ab140b83dc802c1.table.json', 'size': 637935, '_type': 'table-file', 'ncols': 11, 'nrows': 1000, 'sha256': 'cd236ab140b83dc802c1497f400bd7ddaed0bafac766ff4876cd7ed841dca531', 'artifact_path': 'wandb-client-artifact://cwhceejr4raam5e2kp214t8400x1wvlixgkj7zh6fm8ktqxfndw15abeeza9a02q3z0xg9tqai8ttru52or68ckv3sd4cden31d9jrngcbgqm90bh2u0anlhj8yqt465:latest/predictions.table.json'}",18.09101611297718,,,False,True,dev_r1,False,Yes | Maybe | No,4,CTBase,2da8f134-58db-4f9d-b3b0-8c6b50693ab5,anli,SENTIMENT,False,28,bigscience/T0_3B,0,True,categorize_rating_using_review,prompts/general_fixed_choice.yaml,AppReviews,,3,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,['NLI'],anli,True,False,GeneralFixedChoice,False,False,True,,,prompts,,False,True,categorize_rating_using_review,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.app_reviews.categorize_rating_using_review.LenNorm,ANLI R1,,,,,,,,,,,,,,,,,,,,,29.5,46.0,18
24.16021774591252,46.40804597701149,1.4844195598439467,11.369541998604934,2.0,1.0032708901540586,0.0,0.0,,,,133.23583333333335,9.916439414421715,2.66,26.072607260726077,1.453102584183216,0.751265598839718,1.517699303627083,0.751265598839718,1.34,33.5,"{'nrows': 1200, 'sha256': '319455b08612fa98ad77f2c3a9d6fb9025472e9537ddccd121da8a1ac7d8a7bd', 'artifact_path': 'wandb-client-artifact://e20rzi9wjyqbs91fs9h75zte53p5ct67imhgz8b1s7vrzs4ssx8molpzym70tv8s261hfzipr2a6ze6dimmelsllqswa6c2lq3fq62hk9ablcrzpjkhdniele9zzwngk:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://e20rzi9wjyqbs91fs9h75zte53p5ct67imhgz8b1s7vrzs4ssx8molpzym70tv8s261hfzipr2a6ze6dimmelsllqswa6c2lq3fq62hk9ablcrzpjkhdniele9zzwngk:latest/predictions.table.json', 'path': 'media/table/predictions_1_319455b08612fa98ad77.table.json', 'size': 775034, '_type': 'table-file', 'ncols': 11}",32.01257902719214,,,False,True,dev_r3,False,Yes | Maybe | No,4,CTBase,a0872cde-2f19-4ae6-919a-868da47bfbcb,anli,QA,False,28,bigscience/T0_3B,0,True,based_on,prompts/general_fixed_choice.yaml,AdversarialQA,,3,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,['NLI'],anli,True,False,GeneralFixedChoice,False,False,False,,,prompts,,False,True,based_on,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.adversarial_qa.based_on.LenNorm,ANLI R3,,,,,,,,,,,,,,,,,,,,,33.0,38.0,16
22.986118251928023,45.75835475578406,0.8329610635131969,4.394860779762268,2.0,0.7831956018048549,0.0,0.0,,,,143.056,3.347116967201233,2.668,23.200000000000003,1.0477438125610352,0.744161272843461,0.8204132642401265,0.744161272843461,1.332,32.5,"{'artifact_path': 'wandb-client-artifact://d1bsobyrhubgknz4b8es5ffm1loodtidvhnh3t31ygqplcgbmxqn5dpcjm6idfxpbpia5f2bbtoopz5ign95jle5z2s1l54d14uf131q8z5pozsgs7gl4nvh9p5jn94u:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://d1bsobyrhubgknz4b8es5ffm1loodtidvhnh3t31ygqplcgbmxqn5dpcjm6idfxpbpia5f2bbtoopz5ign95jle5z2s1l54d14uf131q8z5pozsgs7gl4nvh9p5jn94u:latest/predictions.table.json', 'path': 'media/table/predictions_1_a1daccbbb10629c4c317.table.json', 'size': 657629, '_type': 'table-file', 'ncols': 11, 'nrows': 1000, 'sha256': 'a1daccbbb10629c4c3176435b860d749fc41c3b0810ceedc6de930cb5aeb652e'}",18.09101611297718,,,False,True,dev_r1,False,Yes | Maybe | No,4,CTBase,d34e1413-2699-4701-baa2-05d931d012ba,anli,SENTIMENT,False,28,bigscience/T0_3B,0,True,convert_to_rating,prompts/general_fixed_choice.yaml,AppReviews,,3,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,['NLI'],anli,True,False,GeneralFixedChoice,False,False,False,,,prompts,,False,True,convert_to_rating,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.app_reviews.convert_to_rating.LenNorm,ANLI R1,,,,,,,,,,,,,,,,,,,,,78.5,70.0,28
23.80986573989858,46.93295292439373,1.383684268489299,11.016017269889511,2.0,0.9557311280469692,0.0,0.0,,,,128.23583333333335,9.62364895562331,2.6766666666666667,24.496644295302016,1.3923683142662049,0.7362894962052782,1.4395688071624964,0.7362894962052782,1.3233333333333333,33.5,"{'nrows': 1200, 'sha256': '18a96de2c44de72b89e2f52f4b38d0a165dfc0ee7775c47a5b509a62bab4c693', 'artifact_path': 'wandb-client-artifact://ksia5waw2fskesnk3tnommbjbi1d0o365z4utbra8nfjpq8md90gepjw0rulldvrskzlywvtnlwbdpty5e3cmqbpuqgy32e5fgfzwbqqz4uwaz6itwytkpuj819a3lrw:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://ksia5waw2fskesnk3tnommbjbi1d0o365z4utbra8nfjpq8md90gepjw0rulldvrskzlywvtnlwbdpty5e3cmqbpuqgy32e5fgfzwbqqz4uwaz6itwytkpuj819a3lrw:latest/predictions.table.json', 'path': 'media/table/predictions_1_18a96de2c44de72b89e2.table.json', 'size': 718468, '_type': 'table-file', 'ncols': 11}",32.01257902719214,,,False,True,dev_r3,False,Yes | Maybe | No,4,CTBase,5bdb1815-5c6f-49a3-ad1d-367344420701,anli,QA,False,28,bigscience/T0_3B,0,True,question_context_answer,prompts/general_fixed_choice.yaml,AdversarialQA,,3,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,['NLI'],anli,True,False,GeneralFixedChoice,False,False,False,,,prompts,,False,True,question_context_answer,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.adversarial_qa.question_context_answer.LenNorm,ANLI R3,,,,,,,,,,,,,,,,,,,,,33.0,43.0,11
22.194611341201785,45.23206751054852,0.490053368026032,1.1911183166503907,1.712,0.4240092505386876,0.4680341867855381,2.857142857142857,,,,126.056,0.564990270614624,2.721,18.494623655913976,0.6261280460357666,0.6805578594065312,0.4480052073323018,0.7262995249895183,1.567,31.6,"{'artifact_path': 'wandb-client-artifact://v5zhh9rtmrqd2ev9lh31fn6nes43aqxrwmel617onq3hm8ja2i003cy0mv167k2ffjo5orxroua1tblqxdhxgje67lr0mj9x2evigbo3wci46bxfti3qisydgjnm9v11:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://v5zhh9rtmrqd2ev9lh31fn6nes43aqxrwmel617onq3hm8ja2i003cy0mv167k2ffjo5orxroua1tblqxdhxgje67lr0mj9x2evigbo3wci46bxfti3qisydgjnm9v11:latest/predictions.table.json', 'path': 'media/table/predictions_1_7c290c862118083e6987.table.json', 'size': 598223, '_type': 'table-file', 'ncols': 11, 'nrows': 1000, 'sha256': '7c290c862118083e6987f27370864452c7e61f5037f1fc6c086c19c6dd1ceae0'}",18.09101611297718,,,False,True,dev_r1,False,Yes | Maybe | No,4,CTBase,96538f30-f2c1-430e-8fc6-936a16966d9c,anli,SENTIMENT,False,28,bigscience/T0_3B,0,True,Writer_Expressed_Sentiment,prompts/general_fixed_choice.yaml,IMDB,,3,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,['NLI'],anli,True,False,GeneralFixedChoice,False,False,False,,,prompts,,False,True,Writer Expressed Sentiment,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.imdb.Writer_Expressed_Sentiment.LenNorm,ANLI R1,,,,,,,,,,,,,,,,,,,,,86.5,72.0,10
23.38931178681967,46.461758398856325,1.360214979107505,10.987561554710071,2.0,0.9602355469215076,0.0,0.0,,,,140.23583333333335,9.571828735868136,2.671666666666667,23.706176961602672,1.4157328188419342,0.7408534867899921,1.4303357480380086,0.740853486789992,1.3283333333333334,33.0,"{'_type': 'table-file', 'ncols': 11, 'nrows': 1200, 'sha256': '3bfcb22b74baaf1da1e708c82310ad69f6d6b3e279eab999ec02684d9e6bd39b', 'artifact_path': 'wandb-client-artifact://v1rugqxvdh02xranmpjs9jhkg3tgi8lnpqtjziptw1pfqs74nbf5w0h7radzs9b1z7vvic8psb8ngymrdcl6f6eeuojbp35nc5v2drtpqht2zqzw1z98zk0qoc4va01n:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://v1rugqxvdh02xranmpjs9jhkg3tgi8lnpqtjziptw1pfqs74nbf5w0h7radzs9b1z7vvic8psb8ngymrdcl6f6eeuojbp35nc5v2drtpqht2zqzw1z98zk0qoc4va01n:latest/predictions.table.json', 'path': 'media/table/predictions_1_3bfcb22b74baaf1da1e7.table.json', 'size': 774896}",32.01257902719214,,,False,True,dev_r3,False,Yes | Maybe | No,4,CTBase,3b2459cc-6600-443c-abf8-8f60c34cd998,anli,QA,False,28,bigscience/T0_3B,0,True,tell_what_it_is,prompts/general_fixed_choice.yaml,AdversarialQA,,3,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,['NLI'],anli,True,False,GeneralFixedChoice,False,False,False,,,prompts,,False,True,tell_what_it_is,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.adversarial_qa.tell_what_it_is.LenNorm,ANLI R3,,,,,,,,,,,,,,,,,,,,,54.0,49.0,22
16.553799849510913,49.66139954853273,0.6171758414109018,2.9141144742965697,1.842,0.6817815387931693,0.3647410040014694,0.0,,,,125.056,0.9010922241210938,2.992,0.0,2.013022250175476,0.126237870704476,0.6511296370020273,0.3826800229957137,1.166,33.0,"{'_latest_artifact_path': 'wandb-client-artifact://xn7jdikswz3s8hbs6v4d8jonew9t3olyqt787t4gq885z7zl3175v3rqb95qu50a36hj8d2x1ne54dwkg6782t8ydqhxn88kupd9xapkp9mrz627jjm5ruyevhfkbnx8:latest/predictions.table.json', 'path': 'media/table/predictions_1_1e885a89dc947a53508b.table.json', 'size': 586251, '_type': 'table-file', 'ncols': 11, 'nrows': 1000, 'sha256': '1e885a89dc947a53508b7849fedf279d5103a06cb0ed2dcab824ec0b60c20f6e', 'artifact_path': 'wandb-client-artifact://xn7jdikswz3s8hbs6v4d8jonew9t3olyqt787t4gq885z7zl3175v3rqb95qu50a36hj8d2x1ne54dwkg6782t8ydqhxn88kupd9xapkp9mrz627jjm5ruyevhfkbnx8:latest/predictions.table.json'}",18.09101611297718,,,False,True,dev_r1,False,Yes | Maybe | No,4,CTBase,866474a5-1498-46b7-bfee-ac0c5160707f,anli,SENTIMENT,False,28,bigscience/T0_3B,0,True,Reviewer_Sentiment_Feeling,prompts/general_fixed_choice.yaml,IMDB,,3,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,['NLI'],anli,True,False,GeneralFixedChoice,False,False,False,,,prompts,,False,True,Reviewer Sentiment Feeling,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.imdb.Reviewer_Sentiment_Feeling.LenNorm,ANLI R1,,,,,,,,,,,,,,,,,,,,,72.0,90.0,9
23.724013734930768,45.85152838427947,1.1540037274435564,3.451766995390256,1.9916666666666667,0.893506226645293,0.0909059342886309,0.0,,,,120.23583333333332,2.2324865718682605,2.63,25.320512820512818,1.2192804235219956,0.7765951326141569,1.073055678316769,0.7779442282209068,1.3783333333333334,32.83333333333333,"{'path': 'media/table/predictions_1_b1c7a4850d465d13bc46.table.json', 'size': 684537, '_type': 'table-file', 'ncols': 11, 'nrows': 1200, 'sha256': 'b1c7a4850d465d13bc466c228fc81553c489836474bc0025acb3de441c12c6ab', 'artifact_path': 'wandb-client-artifact://11gyz1xlklh1y6j0qg2a2wfchfp0mh4oar4t4pyanb6hjobe6g2dbvqm515p8xq2obatf60ig5vbdbld2orpmmdu4cxyrn3d3zqll5a4cv46dya3pp3yn6setysluwv9:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://11gyz1xlklh1y6j0qg2a2wfchfp0mh4oar4t4pyanb6hjobe6g2dbvqm515p8xq2obatf60ig5vbdbld2orpmmdu4cxyrn3d3zqll5a4cv46dya3pp3yn6setysluwv9:latest/predictions.table.json'}",32.01257902719214,,,False,True,dev_r3,False,Yes | Maybe | No,4,CTBase,4dd990b3-7201-4cba-bb9a-baa462d68b1a,anli,SENTIMENT,False,28,bigscience/T0_3B,0,True,format_score,prompts/general_fixed_choice.yaml,Yelp,,3,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,['NLI'],anli,True,False,GeneralFixedChoice,False,False,False,,,prompts,,False,True,format_score,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.yelp.format_score.LenNorm,ANLI R3,,,,,,,,,,,,,,,,,,,,,63.0,44.0,12
29.63433317206902,41.02564102564102,0.7356769292496527,4.1691873140335085,2.0,0.6016862200388156,0.0,0.0,,,,132.056,3.46251446056366,1.972,47.87735849056604,0.7066728534698486,0.9996079231378672,0.6270423345003029,0.9996079231378672,2.028,37.1,"{'size': 590285, '_type': 'table-file', 'ncols': 11, 'nrows': 1000, 'sha256': 'e8e3bd73970a21bfb5f6ae7bb4f43b08fb54d96cb3de7f1016f5af81b57d2a27', 'artifact_path': 'wandb-client-artifact://l8mmu98hotluk5qp2d3cr207isei1jn0cdfge2n0rjlcbkxzrxxaqcnj7bvykbp8fnhbow2g389s7idf8mc55bnqkpl73irzdo6wbig9g7r5l9mi42i0f150a2t4fgrs:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://l8mmu98hotluk5qp2d3cr207isei1jn0cdfge2n0rjlcbkxzrxxaqcnj7bvykbp8fnhbow2g389s7idf8mc55bnqkpl73irzdo6wbig9g7r5l9mi42i0f150a2t4fgrs:latest/predictions.table.json', 'path': 'media/table/predictions_1_e8e3bd73970a21bfb5f6.table.json'}",18.09101611297718,,,False,True,dev_r1,False,Yes | Maybe | No,4,CTBase,5f372fb1-795a-47b6-8ddf-c4fd1579e76a,anli,SENTIMENT,False,28,bigscience/T0_3B,0,True,Sentiment_with_choices,prompts/general_fixed_choice.yaml,IMDB,,3,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,['NLI'],anli,True,False,GeneralFixedChoice,False,False,True,,,prompts,,False,True,Sentiment with choices ,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.imdb.Sentiment_with_choices.LenNorm,ANLI R1,,,,,,,,,,,,,,,,,,,,,19.5,16.0,6
23.50813260360596,46.53818700927908,1.232953846270269,3.217611048022906,1.9583333333333333,0.9181091780145504,0.2196904387744011,0.4962779156327544,,,,114.23583333333332,1.893202863931656,2.6758333333333333,23.48993288590604,1.32440818409125,0.7364889491514603,1.098411291746386,0.7407199013272305,1.3658333333333332,33.08333333333333,"{'_latest_artifact_path': 'wandb-client-artifact://sej803d1p3iwr2lg1el3drtd7azb5ak2qsyh26fqqexwopjxl32ji2j58589exxyihsaxxait7tijhb43htvqo4b9qm9zngwkv6dqvqxjd73zm6314x6pni5ux2cde5i:latest/predictions.table.json', 'path': 'media/table/predictions_1_955aa59bd6da88620483.table.json', 'size': 653913, '_type': 'table-file', 'ncols': 11, 'nrows': 1200, 'sha256': '955aa59bd6da886204836799f6f94777424bc4455b17da8c449eb45701c0ec6a', 'artifact_path': 'wandb-client-artifact://sej803d1p3iwr2lg1el3drtd7azb5ak2qsyh26fqqexwopjxl32ji2j58589exxyihsaxxait7tijhb43htvqo4b9qm9zngwkv6dqvqxjd73zm6314x6pni5ux2cde5i:latest/predictions.table.json'}",32.01257902719214,,,False,True,dev_r3,False,Yes | Maybe | No,4,CTBase,29fc6386-90b3-4976-b249-26e49fe7c924,anli,SENTIMENT,False,28,bigscience/T0_3B,0,True,format_star,prompts/general_fixed_choice.yaml,Yelp,,3,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,['NLI'],anli,True,False,GeneralFixedChoice,False,False,False,,,prompts,,False,True,format_star,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.yelp.format_star.LenNorm,ANLI R3,,,,,,,,,,,,,,,,,,,,,48.5,46.0,6
22.616035209891866,45.22184300341296,0.5877005014448509,4.360858579874039,2.0,0.6516580002443758,0.0,0.0,,,,135.056,3.47532927942276,2.678,22.626262626262623,0.8855293004512786,0.7350619021551857,0.6262053774907068,0.7350619021551857,1.322,32.1,"{'artifact_path': 'wandb-client-artifact://11s8vyimytgm22gdga82cqpolhpjp8vuze5vudot8ir06nofwfijpxtn2oybqdass32aka6ty2e8xn8zni935bpcmbwevv8vrboldlenv1g3qpa7i24jvpryxz1akql6:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://11s8vyimytgm22gdga82cqpolhpjp8vuze5vudot8ir06nofwfijpxtn2oybqdass32aka6ty2e8xn8zni935bpcmbwevv8vrboldlenv1g3qpa7i24jvpryxz1akql6:latest/predictions.table.json', 'path': 'media/table/predictions_1_80b146b055e6679ee879.table.json', 'size': 606055, '_type': 'table-file', 'ncols': 11, 'nrows': 1000, 'sha256': '80b146b055e6679ee879675edb09ac51a56eb2e111c103c7598015323e697c56'}",18.09101611297718,,,False,True,dev_r1,False,Yes | Maybe | No,4,CTBase,2351d12a-e630-4d19-8b41-e199266e38f7,anli,SENTIMENT,False,28,bigscience/T0_3B,0,True,Reviewer_Opinion_bad_good_choices,prompts/general_fixed_choice.yaml,IMDB,,3,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,['NLI'],anli,True,False,GeneralFixedChoice,False,False,True,,,prompts,,False,True,Reviewer Opinion bad good choices,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.imdb.Reviewer_Opinion_bad_good_choices.LenNorm,ANLI R1,,,,,,,,,,,,,,,,,,,,,81.5,71.0,9
21.232795562090885,48.17320703653586,1.029106494408674,3.029950020313263,1.955833333333333,0.8800321066112106,0.2094818342694394,0.4962779156327544,,,,118.23583333333332,1.5833056894938151,2.8041666666666667,15.028901734104046,1.446644330819448,0.5937024834787951,0.9467639514120793,0.6143289021363068,1.24,33.0,"{'artifact_path': 'wandb-client-artifact://7lcx5j7nm6u6ya10l3w25oljnfrnjpz11u8cd0gillzia0qh0tlrvtdnz4b4977i99ddwrtsejzupjcxj3f2o92ow5k1ueippqlcsvpk8mjxo258t1rjby7h8pjotik2:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://7lcx5j7nm6u6ya10l3w25oljnfrnjpz11u8cd0gillzia0qh0tlrvtdnz4b4977i99ddwrtsejzupjcxj3f2o92ow5k1ueippqlcsvpk8mjxo258t1rjby7h8pjotik2:latest/predictions.table.json', 'path': 'media/table/predictions_1_faf01f5aac5a03abe9a4.table.json', 'size': 669675, '_type': 'table-file', 'ncols': 11, 'nrows': 1200, 'sha256': 'faf01f5aac5a03abe9a4fc79595e6b9350aaa65812ad2f684652af64d3cdd676'}",32.01257902719214,,,False,True,dev_r3,False,Yes | Maybe | No,4,CTBase,27b6bc81-bb1c-467b-91c0-22a4d6a19f44,anli,SENTIMENT,False,28,bigscience/T0_3B,0,True,based_on_that,prompts/general_fixed_choice.yaml,Yelp,,3,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,['NLI'],anli,True,False,GeneralFixedChoice,False,False,False,,,prompts,,False,True,based_on_that,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.yelp.based_on_that.LenNorm,ANLI R3,,,,,,,,,,,,,,,,,,,,,54.0,68.0,10
25.003843071840915,44.91978609625668,0.7918148039908057,2.46445685005188,1.976,0.6559761786870053,0.1530490117576719,0.0,,,,126.056,1.559725806236267,2.578,30.091743119266056,0.9047310438156128,0.8160367638777067,0.7760597172364013,0.8179755497568372,1.446,33.4,"{'nrows': 1000, 'sha256': 'ae41b04cd5d564e1eafdfef68d90f98f1f7e080cacb3d80cfe1ba28240a76880', 'artifact_path': 'wandb-client-artifact://101l1s217edjkb91ycn6bocfvh5dsqzw29srhgwbv6rxlvjndrnxcyuve2zv1543bgiw8y8dz9y96fp729h162cpbpce2jk8fkyi6vvv41wli5w6n07isgisnm7p7hgw:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://101l1s217edjkb91ycn6bocfvh5dsqzw29srhgwbv6rxlvjndrnxcyuve2zv1543bgiw8y8dz9y96fp729h162cpbpce2jk8fkyi6vvv41wli5w6n07isgisnm7p7hgw:latest/predictions.table.json', 'path': 'media/table/predictions_1_ae41b04cd5d564e1eafd.table.json', 'size': 597279, '_type': 'table-file', 'ncols': 11}",18.09101611297718,,,False,True,dev_r1,False,Yes | Maybe | No,4,CTBase,02ff2949-0f45-4d97-941e-6fa4c0afbc2d,anli,SENTIMENT,False,28,bigscience/T0_3B,0,True,Movie_Expressed_Sentiment_2,prompts/general_fixed_choice.yaml,IMDB,,3,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,['NLI'],anli,True,False,GeneralFixedChoice,False,False,False,,,prompts,,False,True,Movie Expressed Sentiment 2,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.imdb.Movie_Expressed_Sentiment_2.LenNorm,ANLI R1,,,,,,,,,,,,,,,,,,,,,64.5,61.0,10
28.36652517777542,44.628099173553714,1.217676989187419,2.6226938247680662,1.9483333333333333,0.802830152931305,0.3276134239550565,3.800475059382422,,,,115.23583333333332,1.5611341687043507,2.3725,36.67100130039012,1.0615596560637155,0.9194620256795094,1.0330796126264346,0.8960464862692983,1.6791666666666667,34.91666666666667,"{'size': 663137, '_type': 'table-file', 'ncols': 11, 'nrows': 1200, 'sha256': 'bed5e25d320e88feba9ae57d26c6f507d3e54450a2617f41cac70228b5ee48d2', 'artifact_path': 'wandb-client-artifact://x3q8pkh6ontqbhk73kapyf6knfv3d25mmjww8c3ei8crihk3hichs4zudh493rxyd1k025o64utmoavou3ghugvi0yerctln03s86w456u30qhhzsasa7ko1nx4beyix:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://x3q8pkh6ontqbhk73kapyf6knfv3d25mmjww8c3ei8crihk3hichs4zudh493rxyd1k025o64utmoavou3ghugvi0yerctln03s86w456u30qhhzsasa7ko1nx4beyix:latest/predictions.table.json', 'path': 'media/table/predictions_1_bed5e25d320e88feba9a.table.json'}",32.01257902719214,,,False,True,dev_r3,False,Yes | Maybe | No,4,CTBase,135fcd11-9fcc-4b55-bf1b-9b76290d0f6b,anli,SENTIMENT,False,28,bigscience/T0_3B,0,True,so_i_would,prompts/general_fixed_choice.yaml,Yelp,,3,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,['NLI'],anli,True,False,GeneralFixedChoice,False,False,False,,,prompts,,False,True,so_i_would,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.yelp.so_i_would.LenNorm,ANLI R3,,,,,,,,,,,,,,,,,,,,,7.0,2.0,7
29.669256215493498,40.34653465346535,0.8729494431174918,3.9484211013317103,2.0,0.6226102766008582,0.0,0.0,,,,117.428,3.209259573936462,1.95,48.66123399301514,0.7391615273952484,0.9987492177719088,0.769522916661865,0.9987492177719088,2.05,37.2,"{'_latest_artifact_path': 'wandb-client-artifact://15wrtzskq6jz3uzpm6m3omvig13tuqxda4286ch4rbb5r9srnrgd8339l4ca89er8c2vhp4fcd3o2yw08nc5pcqvus7rd840cd4a5ku61eew1ellex9i4mqedf3axy2k:latest/predictions.table.json', 'path': 'media/table/predictions_1_05d2df8d84c955e2c904.table.json', 'size': 570934, '_type': 'table-file', 'ncols': 11, 'nrows': 1000, 'sha256': '05d2df8d84c955e2c904998b5a022002bec10ca308182b5f62e6aa669c614a84', 'artifact_path': 'wandb-client-artifact://15wrtzskq6jz3uzpm6m3omvig13tuqxda4286ch4rbb5r9srnrgd8339l4ca89er8c2vhp4fcd3o2yw08nc5pcqvus7rd840cd4a5ku61eew1ellex9i4mqedf3axy2k:latest/predictions.table.json'}",18.13314137153295,,,False,True,dev_r1,False,Yes | Maybe | No,4,CTBase,f56ffced-9b16-431a-8a17-501e63cddf73,anli,ENTAILMENT,False,28,bigscience/T0_3B,0,True,imply_separated,prompts/general_fixed_choice.yaml,RTE,,3,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,['NLI'],anli,False,False,GeneralFixedChoice,False,False,True,,,prompts,,False,True,imply separated,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.super_glue_rte.imply_separated.LenNorm,ANLI R1,,,,,,,,,,,,,,,,,,,,,17.0,14.0,6
27.9436092881888,40.63373718546132,0.5499737508660678,0.9798249226808547,1.9008333333333336,0.4582777664578001,0.5043140280508652,1.4388489208633093,,,,135.23583333333335,0.4300388737519582,2.140833333333333,41.75824175824176,0.5497860489288966,0.9837001434493248,0.3341843817239266,0.8640585756893002,1.9583333333333333,34.25,"{'size': 743283, '_type': 'table-file', 'ncols': 11, 'nrows': 1200, 'sha256': 'e0047ab277d3d68a1be7ce9c33ebb7bc024e5687880867ab551bfb0b94680ac0', 'artifact_path': 'wandb-client-artifact://17uun8k0ok00hne4hxainoo9npv00sk6ntw6dh96r4w63ijgemmjlbapwipdeepp7b0r1xsh5ubjdfqyxbetz08fad42ujs3hhfti76ajkrj8oi1jbbx50n7cmyr0scp:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://17uun8k0ok00hne4hxainoo9npv00sk6ntw6dh96r4w63ijgemmjlbapwipdeepp7b0r1xsh5ubjdfqyxbetz08fad42ujs3hhfti76ajkrj8oi1jbbx50n7cmyr0scp:latest/predictions.table.json', 'path': 'media/table/predictions_1_e0047ab277d3d68a1be7.table.json'}",32.01257902719214,,,False,True,dev_r3,False,Yes | Maybe | No,4,CTBase,2da8f134-58db-4f9d-b3b0-8c6b50693ab5,anli,SENTIMENT,False,28,bigscience/T0_3B,0,True,categorize_rating_using_review,prompts/general_fixed_choice.yaml,AppReviews,,3,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,['NLI'],anli,True,False,GeneralFixedChoice,False,False,True,,,prompts,,False,True,categorize_rating_using_review,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.app_reviews.categorize_rating_using_review.LenNorm,ANLI R3,,,,,,,,,,,,,,,,,,,,,13.0,5.0,18
28.919430459067936,42.946058091286304,0.7553869033231329,5.104838838219643,2.0,0.7047991448295586,0.0,0.0,,,,123.533,4.285934949159622,2.262,43.81223328591749,0.8189038890600204,0.965067873260736,0.7304829327101983,0.965067873260736,1.738,36.1,"{'nrows': 1000, 'sha256': '2a0be5e5e4b4eaccec0e208f7731274108307e90dae5a9177795f3fa17963069', 'artifact_path': 'wandb-client-artifact://1tu5k8oatqb2ivttic34w7e5hlqxrf1wt4bo3psvcortxi0pfoit8doy3v2ahpp328t9ijwbvi9uhys00vv12yowxm8g36bdv2gyus8ghrg267fs797dz01g1sxxtdur:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://1tu5k8oatqb2ivttic34w7e5hlqxrf1wt4bo3psvcortxi0pfoit8doy3v2ahpp328t9ijwbvi9uhys00vv12yowxm8g36bdv2gyus8ghrg267fs797dz01g1sxxtdur:latest/predictions.table.json', 'path': 'media/table/predictions_1_2a0be5e5e4b4eaccec0e.table.json', 'size': 587993, '_type': 'table-file', 'ncols': 11}",18.09720727073656,,,False,True,dev_r1,False,Yes | Maybe | No,4,CTBase,c8dfc879-40f2-412d-be1e-4cd70107f6e6,anli,ENTAILMENT,False,28,bigscience/T0_3B,0,True,imply,prompts/general_fixed_choice.yaml,RTE,,3,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,['NLI'],anli,False,False,GeneralFixedChoice,False,False,True,,,prompts,,False,True,imply,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.super_glue_rte.imply.LenNorm,ANLI R1,,,,,,,,,,,,,,,,,,,,,26.5,25.0,14
20.549144299507905,48.36775483011325,1.0377544281527409,3.304238916635513,1.9791666666666667,0.8796400942550018,0.1428261375083551,0.0,,,,135.23583333333335,1.9068452588717144,2.841666666666667,13.279678068410464,1.397393657763799,0.5399974279774139,1.0143043286318938,0.5526294468769788,1.1791666666666667,33.0,"{'size': 767016, '_type': 'table-file', 'ncols': 11, 'nrows': 1200, 'sha256': '126c13eca568b84dabd715c2e1ba0c81ba7291894270aadb8195fbfda898a3f2', 'artifact_path': 'wandb-client-artifact://y6ob9dawj9rnzsw02418miutwhd90w5ihqvmsy0f0934wnrtgxc2jtcqke21cif0pceihxg5rix6ozoo696swb5eh0so5p7722y05ajzp0c8rz9v8vufu399u1vtve3y:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://y6ob9dawj9rnzsw02418miutwhd90w5ihqvmsy0f0934wnrtgxc2jtcqke21cif0pceihxg5rix6ozoo696swb5eh0so5p7722y05ajzp0c8rz9v8vufu399u1vtve3y:latest/predictions.table.json', 'path': 'media/table/predictions_1_126c13eca568b84dabd7.table.json'}",32.01257902719214,,,False,True,dev_r3,False,Yes | Maybe | No,4,CTBase,d34e1413-2699-4701-baa2-05d931d012ba,anli,SENTIMENT,False,28,bigscience/T0_3B,0,True,convert_to_rating,prompts/general_fixed_choice.yaml,AppReviews,,3,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,['NLI'],anli,True,False,GeneralFixedChoice,False,False,False,,,prompts,,False,True,convert_to_rating,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.app_reviews.convert_to_rating.LenNorm,ANLI R3,,,,,,,,,,,,,,,,,,,,,54.0,73.0,28
23.88272067449235,42.767295597484285,0.6283038776211508,5.34070817399025,2.0,0.545504064353086,0.0,0.0,,,,150.428,4.646911228656768,2.56,28.88086642599277,0.6937969453334808,0.8284926070883192,0.6006505444402742,0.8284926070883192,1.44,31.8,"{'path': 'media/table/predictions_1_8839f368b6f9ef4379e8.table.json', 'size': 745166, '_type': 'table-file', 'ncols': 11, 'nrows': 1000, 'sha256': '8839f368b6f9ef4379e8aad8b9acad9edceb4d2512a5c21abc1b65517e93f385', 'artifact_path': 'wandb-client-artifact://mg7okwr9chvq99zg7wldbcsu6s5qkvv6rsuuhk9fzzx2gead0m072do0d87jfgnsh4g8ukq0b3wjzjbokyt5b0mz5xk5bmt0mgidpj0koge8kk325re0j18l236z0p3c:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://mg7okwr9chvq99zg7wldbcsu6s5qkvv6rsuuhk9fzzx2gead0m072do0d87jfgnsh4g8ukq0b3wjzjbokyt5b0mz5xk5bmt0mgidpj0koge8kk325re0j18l236z0p3c:latest/predictions.table.json'}",18.13314137153295,,,False,True,dev_r1,False,Yes | Maybe | No,4,CTBase,9e2b4267-ec23-44c8-b82a-107e2c890fec,anli,ENTAILMENT,False,28,bigscience/T0_3B,0,True,entailment_explained,prompts/general_fixed_choice.yaml,RTE,,3,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,['NLI'],anli,False,False,GeneralFixedChoice,False,False,True,,,prompts,,False,True,entailment explained,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.super_glue_rte.entailment_explained.LenNorm,ANLI R1,,,,,,,,,,,,,,,,,,,,,84.5,67.0,40
25.012672640347997,46.08567208271787,0.5732922170994431,1.234485058784485,1.4008333333333334,0.488153709976055,0.5432917928905444,17.16287215411559,,,,118.23583333333332,0.5589656217892964,2.7375,11.789473684210526,0.6755194369951883,0.5614805576924874,0.3985850417990265,0.6837620606289556,1.8616666666666664,32.416666666666664,"{'_latest_artifact_path': 'wandb-client-artifact://68whg1q02mxbz7wsq0wjy16w1oiec23sp4rk1gqmbd8fxy0eikdx6c9qy0h0u6pomtq3opiig2unk31y2yyz47dnzjnvxhq6fkeqy1z8fvpuo0yldxcgeulg95pw4usy:latest/predictions.table.json', 'path': 'media/table/predictions_1_a4c7b35594dd1c7be88e.table.json', 'size': 696363, '_type': 'table-file', 'ncols': 11, 'nrows': 1200, 'sha256': 'a4c7b35594dd1c7be88e6aa317b2cfe5f54f39ce1902a51e1404ea87ff12b247', 'artifact_path': 'wandb-client-artifact://68whg1q02mxbz7wsq0wjy16w1oiec23sp4rk1gqmbd8fxy0eikdx6c9qy0h0u6pomtq3opiig2unk31y2yyz47dnzjnvxhq6fkeqy1z8fvpuo0yldxcgeulg95pw4usy:latest/predictions.table.json'}",32.01257902719214,,,False,True,dev_r3,False,Yes | Maybe | No,4,CTBase,96538f30-f2c1-430e-8fc6-936a16966d9c,anli,SENTIMENT,False,28,bigscience/T0_3B,0,True,Writer_Expressed_Sentiment,prompts/general_fixed_choice.yaml,IMDB,,3,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,['NLI'],anli,True,False,GeneralFixedChoice,False,False,False,,,prompts,,False,True,Writer Expressed Sentiment,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.imdb.Writer_Expressed_Sentiment.LenNorm,ANLI R3,,,,,,,,,,,,,,,,,,,,,80.5,31.0,10
27.608637464900298,42.71047227926078,0.7356515170441534,5.183969462156296,2.0,0.6257886408126019,0.0,0.0,,,,127.533,4.436018173456192,2.282,40.11544011544012,0.7479512887001037,0.9594144047282174,0.7320034302519968,0.9594144047282174,1.718,34.7,"{'_latest_artifact_path': 'wandb-client-artifact://kb7obii77m8rq57g782dz2f1xdoliubom28v501rp3de55kmi84i1565pr8ggy0mxrqc56utgic0z583t0tfnm3a0h15kf73muveot9clucvh8yg37rtl3mpi98l8lxp:latest/predictions.table.json', 'path': 'media/table/predictions_1_8586e04d24a9abfb1ee2.table.json', 'size': 613125, '_type': 'table-file', 'ncols': 11, 'nrows': 1000, 'sha256': '8586e04d24a9abfb1ee2981b9d68769f5c269b0ce3b04a814898fb3c1a775f16', 'artifact_path': 'wandb-client-artifact://kb7obii77m8rq57g782dz2f1xdoliubom28v501rp3de55kmi84i1565pr8ggy0mxrqc56utgic0z583t0tfnm3a0h15kf73muveot9clucvh8yg37rtl3mpi98l8lxp:latest/predictions.table.json'}",18.09720727073656,,,False,True,dev_r1,False,Yes | Maybe | No,4,CTBase,4ee6ff27-de63-4e7b-a9d4-82a17eba407a,anli,ENTAILMENT,False,28,bigscience/T0_3B,0,True,does_the_claim_follow_the_fact,prompts/general_fixed_choice.yaml,RTE,,3,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,['NLI'],anli,False,False,GeneralFixedChoice,False,False,True,,,prompts,,False,True,does the claim follow the fact,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.super_glue_rte.does_the_claim_follow_the_fact.LenNorm,ANLI R1,,,,,,,,,,,,,,,,,,,,,42.5,38.0,18
17.00336598543909,49.52859836580767,0.8014014810551161,2.7291958963871004,1.4391666666666667,0.7869525584679289,0.4962855081055214,0.4962779156327544,,,,117.23583333333332,0.6908157714207968,2.9925,0.9852216748768472,2.038380124966304,0.1187872748515878,0.5200565287240695,0.5036505622839003,1.5683333333333334,33.08333333333333,"{'nrows': 1200, 'sha256': 'b6280cb9a8d22cbc013a198e3dd252b00f7c4c0f485be136cea60dc60e3150ad', 'artifact_path': 'wandb-client-artifact://sgts4fy1dgk7959tl6ujowk2cbeeuxijr15nq2yocqjzwnmzc85wp24rpvsx4d3urzbw3442tu9b9i3xo2pj2utpbvrg1rm9m6w0lzolr56cwnjpxyw2mzypuyqmivae:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://sgts4fy1dgk7959tl6ujowk2cbeeuxijr15nq2yocqjzwnmzc85wp24rpvsx4d3urzbw3442tu9b9i3xo2pj2utpbvrg1rm9m6w0lzolr56cwnjpxyw2mzypuyqmivae:latest/predictions.table.json', 'path': 'media/table/predictions_1_b6280cb9a8d22cbc013a.table.json', 'size': 681617, '_type': 'table-file', 'ncols': 11}",32.01257902719214,,,False,True,dev_r3,False,Yes | Maybe | No,4,CTBase,866474a5-1498-46b7-bfee-ac0c5160707f,anli,SENTIMENT,False,28,bigscience/T0_3B,0,True,Reviewer_Sentiment_Feeling,prompts/general_fixed_choice.yaml,IMDB,,3,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,['NLI'],anli,True,False,GeneralFixedChoice,False,False,False,,,prompts,,False,True,Reviewer Sentiment Feeling,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.imdb.Reviewer_Sentiment_Feeling.LenNorm,ANLI R3,,,,,,,,,,,,,,,,,,,,,48.5,90.0,9
29.51836711192999,40.7185628742515,0.8747594450238813,4.490866346359253,2.0,0.6930030949877115,0.0,0.0,,,,120.549,3.6706106476783753,2.004,47.83653846153847,0.8202556986808777,0.9999919999679996,0.7868148808457456,0.9999919999679996,1.996,36.9,"{'_type': 'table-file', 'ncols': 11, 'nrows': 1000, 'sha256': '281dc60ecd121b817fce2ce303daddb9b4b40122e8fd26ea41a2277498cf5d0a', 'artifact_path': 'wandb-client-artifact://1ey0966ik7w74lxkh1czxopxkbfe6yezrr77r1cmwpnd8upszxnddso4dulw0bjyu05kmqwfntxhggmie9kz69hsbq4xmq622hguy5fdhqns2fuwn5a4mrti762lzkz4:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://1ey0966ik7w74lxkh1czxopxkbfe6yezrr77r1cmwpnd8upszxnddso4dulw0bjyu05kmqwfntxhggmie9kz69hsbq4xmq622hguy5fdhqns2fuwn5a4mrti762lzkz4:latest/predictions.table.json', 'path': 'media/table/predictions_1_281dc60ecd121b817fce.table.json', 'size': 574075}",18.070517397130608,,,False,True,dev_r1,False,Yes | Maybe | No,4,CTBase,03a7ae07-5ddd-46c4-92f3-2152223d44ec,anli,ENTAILMENT,False,28,bigscience/T0_3B,0,True,mean,prompts/general_fixed_choice.yaml,RTE,,3,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,['NLI'],anli,False,False,GeneralFixedChoice,False,False,True,,,prompts,,False,True,mean,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.super_glue_rte.mean.LenNorm,ANLI R1,,,,,,,,,,,,,,,,,,,,,22.0,19.0,9
27.3459685671254,45.25316455696203,0.7957029749316984,3.438702662388484,2.0,0.5983423837980594,0.0,0.0,,,,124.23583333333332,2.6620638597011568,2.4466666666666668,36.78474114441418,0.7766388026873271,0.8947004464561806,0.734534086631865,0.8947004464561806,1.5533333333333332,35.083333333333336,"{'_type': 'table-file', 'ncols': 11, 'nrows': 1200, 'sha256': '56b92a0e8705c4a4823a4846e75daa4a402235582afed42af964fd768744152c', 'artifact_path': 'wandb-client-artifact://breem6ecm4xp3hm17i0u19hkrbydz84illlezhxwz85ezlp8vu4anp1itryvtetcxdmlz3b2mktr53s9s9o8ysmde5w566izfgvyokg2w1hu6cxnmjvd2jc7fenuzk65:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://breem6ecm4xp3hm17i0u19hkrbydz84illlezhxwz85ezlp8vu4anp1itryvtetcxdmlz3b2mktr53s9s9o8ysmde5w566izfgvyokg2w1hu6cxnmjvd2jc7fenuzk65:latest/predictions.table.json', 'path': 'media/table/predictions_1_56b92a0e8705c4a4823a.table.json', 'size': 686196}",32.01257902719214,,,False,True,dev_r3,False,Yes | Maybe | No,4,CTBase,5f372fb1-795a-47b6-8ddf-c4fd1579e76a,anli,SENTIMENT,False,28,bigscience/T0_3B,0,True,Sentiment_with_choices,prompts/general_fixed_choice.yaml,IMDB,,3,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,['NLI'],anli,True,False,GeneralFixedChoice,False,False,True,,,prompts,,False,True,Sentiment with choices ,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.imdb.Sentiment_with_choices.LenNorm,ANLI R3,,,,,,,,,,,,,,,,,,,,,5.5,12.0,6
26.99925358884897,43.15992292870906,1.4249560454179038,11.927009740054608,2.0,1.1538679058979049,0.0,0.0,,,,125.056,10.53282933974266,2.41,37.83783783783783,1.394180400311947,0.9120855223058856,1.3757459994918404,0.9120855223058856,1.59,34.300000000000004,"{'size': 583152, '_type': 'table-file', 'ncols': 11, 'nrows': 1000, 'sha256': '65118cc764483f61bdb5a84def147831fef6e89ad1ac3f247343bc4c4c46da77', 'artifact_path': 'wandb-client-artifact://iqhdmt6httft90clfain748rps6udrwyqcxwrtk9f8omscta1pfcy1rjlbf7k96gpkrfiqoi1byxglxq9lq1hhdjf8nw9gtk74wvdoar9x7w171sjp82r2lmaa55xkmn:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://iqhdmt6httft90clfain748rps6udrwyqcxwrtk9f8omscta1pfcy1rjlbf7k96gpkrfiqoi1byxglxq9lq1hhdjf8nw9gtk74wvdoar9x7w171sjp82r2lmaa55xkmn:latest/predictions.table.json', 'path': 'media/table/predictions_1_65118cc764483f61bdb5.table.json'}",18.09101611297718,,,False,True,dev_r1,False,Yes | Maybe | No,4,CTBase,f2004e15-9d9a-4ca1-9830-a341e684e97e,anli,QA,False,28,bigscience/T0_3B,0,True,qa_no_choices_and_answer,prompts/general_fixed_choice.yaml,No Prompt,,3,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,['NLI'],anli,False,False,GeneralFixedChoice,False,False,False,,,prompts,,False,True,qa no choices and answer,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.BAREBONES.qa_no_choices_and_answer.LenNorm,ANLI R1,,,,,,,,,,,,,,,,,,,,,46.5,44.0,0
19.5825874601145,47.80039395929088,0.7095780664382646,4.08707309226195,2.0,0.7562834349801023,0.0,0.0,,,,127.23583333333332,2.8591846585273744,2.8783333333333334,10.947368421052632,1.227888433734576,0.4780486957994506,0.6603527155496192,0.4780486957994506,1.1216666666666666,32.5,"{'sha256': '5742d81aaf1c736b8558fe3793a5f2ba74a283ee5990af76ed659037170ee55d', 'artifact_path': 'wandb-client-artifact://13arhlak4qmop5sew41y8e5r4gx4jtc4awe7prdud9if6ejexr4lhmlb1qlq8iadbyg55zsu09xbkmysq27bljvsgdnx42uply9ha1epvlpwssirgjqh5pbvz3h0x3vb:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://13arhlak4qmop5sew41y8e5r4gx4jtc4awe7prdud9if6ejexr4lhmlb1qlq8iadbyg55zsu09xbkmysq27bljvsgdnx42uply9ha1epvlpwssirgjqh5pbvz3h0x3vb:latest/predictions.table.json', 'path': 'media/table/predictions_1_5742d81aaf1c736b8558.table.json', 'size': 705164, '_type': 'table-file', 'ncols': 11, 'nrows': 1200}",32.01257902719214,,,False,True,dev_r3,False,Yes | Maybe | No,4,CTBase,2351d12a-e630-4d19-8b41-e199266e38f7,anli,SENTIMENT,False,28,bigscience/T0_3B,0,True,Reviewer_Opinion_bad_good_choices,prompts/general_fixed_choice.yaml,IMDB,,3,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,['NLI'],anli,True,False,GeneralFixedChoice,False,False,True,,,prompts,,False,True,Reviewer Opinion bad good choices,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.imdb.Reviewer_Opinion_bad_good_choices.LenNorm,ANLI R3,,,,,,,,,,,,,,,,,,,,,76.5,77.0,9
25.06586091308248,44.01114206128134,1.0476257562279798,4.687062952816486,2.0,0.6425239520816038,0.0,0.0,,,,102.428,3.8529100620746615,2.488,31.186440677966104,0.8341528907418251,0.8728436286070947,0.97924946754829,0.8728436286070947,1.512,32.9,"{'sha256': '0514bf8333467751b2be5f730ad250c07cd9828c636230b559036d1f16d1bf7b', 'artifact_path': 'wandb-client-artifact://9bf0xhgy4ker362iufmo6uuth0wj42j192k71lv4y7vqgy6og95kjiumzbsynrnwa9alxy40urg4kql8e1k9p2retp56c4qerjlmnssarjn75icaoq2bw3yt4jdoju4q:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://9bf0xhgy4ker362iufmo6uuth0wj42j192k71lv4y7vqgy6og95kjiumzbsynrnwa9alxy40urg4kql8e1k9p2retp56c4qerjlmnssarjn75icaoq2bw3yt4jdoju4q:latest/predictions.table.json', 'path': 'media/table/predictions_1_0514bf8333467751b2be.table.json', 'size': 521932, '_type': 'table-file', 'ncols': 11, 'nrows': 1000}",18.13314137153295,,,False,True,dev_r1,False,Yes | Maybe | No,4,CTBase,e5eaa3ee-e537-4d20-9dfa-6084db54f2ef,anli,ENTAILMENT,False,28,bigscience/T0_3B,0,True,entailment_no_choices_and_answer,prompts/general_fixed_choice.yaml,No Prompt,,3,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,['NLI'],anli,False,False,GeneralFixedChoice,False,False,False,,,prompts,,False,True,entailment no choices and answer,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.BAREBONES.entailment_no_choices_and_answer.LenNorm,ANLI R1,,,,,,,,,,,,,,,,,,,,,74.5,60.0,2
24.15507539729964,46.67143879742305,0.8866541544048947,2.0474393804868063,1.8616666666666664,0.6824283037318626,0.3730914394920128,0.9638554216867468,,,,118.23583333333332,1.0258039569854736,2.6791666666666667,24.829931972789115,1.0216354235013323,0.7265667935954377,0.7621638693871814,0.7483310133594328,1.4591666666666667,33.416666666666664,"{'_latest_artifact_path': 'wandb-client-artifact://170uwcv9lp9cjtovd012zexvlw1k7atrdts7ooc7iowvs8kva5wteonnq304x3mbqlmj3zy9xf1862xmrhe33akiupqaaasyky9xsv88c6hwmjdj4vozvj37bluvdn64:latest/predictions.table.json', 'path': 'media/table/predictions_1_4e913f5ff84e35c1ec2c.table.json', 'size': 694814, '_type': 'table-file', 'ncols': 11, 'nrows': 1200, 'sha256': '4e913f5ff84e35c1ec2c4cde55275ff1b9538adc0e8b0f5d5cb04bab22f5cc90', 'artifact_path': 'wandb-client-artifact://170uwcv9lp9cjtovd012zexvlw1k7atrdts7ooc7iowvs8kva5wteonnq304x3mbqlmj3zy9xf1862xmrhe33akiupqaaasyky9xsv88c6hwmjdj4vozvj37bluvdn64:latest/predictions.table.json'}",32.01257902719214,,,False,True,dev_r3,False,Yes | Maybe | No,4,CTBase,02ff2949-0f45-4d97-941e-6fa4c0afbc2d,anli,SENTIMENT,False,28,bigscience/T0_3B,0,True,Movie_Expressed_Sentiment_2,prompts/general_fixed_choice.yaml,IMDB,,3,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,['NLI'],anli,True,False,GeneralFixedChoice,False,False,False,,,prompts,,False,True,Movie Expressed Sentiment 2,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.imdb.Movie_Expressed_Sentiment_2.LenNorm,ANLI R3,,,,,,,,,,,,,,,,,,,,,37.0,39.0,10
28.011699003701544,41.84100418410041,1.0987095994341336,5.838172527730465,2.0,0.8183357465639016,0.0,0.0,,,,118.056,4.809303945541382,2.246,42.19409282700421,1.028868582189083,0.9692698282728088,1.037492723511786,0.9692698282728088,1.754,35.0,"{'nrows': 1000, 'sha256': '31534d142d5185493b4c665ce304bc4d41b71be7cc11aabeb3d6ece7b16ff578', 'artifact_path': 'wandb-client-artifact://17e1mlmmygm8t7qwn4743ex1731t05o1ll8v2alh2sj8rbmxvlfbg49bhn4u52pkwqj5iz2ipyd618r9kh19l7xhuuhyb16aqpckj42o9jqlcfroyxejbzipu1np5sli:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://17e1mlmmygm8t7qwn4743ex1731t05o1ll8v2alh2sj8rbmxvlfbg49bhn4u52pkwqj5iz2ipyd618r9kh19l7xhuuhyb16aqpckj42o9jqlcfroyxejbzipu1np5sli:latest/predictions.table.json', 'path': 'media/table/predictions_1_31534d142d5185493b4c.table.json', 'size': 552356, '_type': 'table-file', 'ncols': 11}",18.09101611297718,,,False,True,dev_r1,False,Yes | Maybe | No,4,CTBase,cf005ddf-8cf2-409d-b884-45d22463f463,anli,CLASSIFICATION,False,28,bigscience/T0_3B,0,True,classification_no_choices_and_answer,prompts/general_fixed_choice.yaml,No Prompt,,3,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,['NLI'],anli,False,False,GeneralFixedChoice,False,False,False,,,prompts,,False,True,classification no choices and answer,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.BAREBONES.classification_no_choices_and_answer.LenNorm,ANLI R1,,,,,,,,,,,,,,,,,,,,,39.0,32.0,2
25.656005924929257,45.176110260336905,0.9565698404672528,3.102176273365816,1.995833333333333,0.7123718204534067,0.076262521740513,0.0,,,,110.10583333333334,2.167500446438789,2.5166666666666666,31.791907514450862,0.934675826927026,0.8561866359360881,0.9501073920552768,0.8552838222874712,1.4875,33.75,"{'sha256': '3bd209b1b35cda899fa5e9a07f19ae336a0592ae6fd3218008fbc8905ca2a65a', 'artifact_path': 'wandb-client-artifact://i9i63x27t5120f24tcgjv9x1ai1m270ye8n53yfarzo8m987r19158pt1zz4s7xpc73oxeurg4w2d8a1le57uwbi0ubmp8iwkgiuf5x99h1do98irdx1kf6mvlfwupwl:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://i9i63x27t5120f24tcgjv9x1ai1m270ye8n53yfarzo8m987r19158pt1zz4s7xpc73oxeurg4w2d8a1le57uwbi0ubmp8iwkgiuf5x99h1do98irdx1kf6mvlfwupwl:latest/predictions.table.json', 'path': 'media/table/predictions_1_3bd209b1b35cda899fa5.table.json', 'size': 662696, '_type': 'table-file', 'ncols': 11, 'nrows': 1200}",31.96711277712699,,,False,True,dev_r3,False,Yes | Maybe | No,4,CTBase,f56ffced-9b16-431a-8a17-501e63cddf73,anli,ENTAILMENT,False,28,bigscience/T0_3B,0,True,imply_separated,prompts/general_fixed_choice.yaml,RTE,,3,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,['NLI'],anli,False,False,GeneralFixedChoice,False,False,True,,,prompts,,False,True,imply separated,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.super_glue_rte.imply_separated.LenNorm,ANLI R3,,,,,,,,,,,,,,,,,,,,,26.0,25.0,6
18.539554462594023,5.202312138728325,0.8019742385871882,6.309769195720554,2.0,0.8315290917447598,0.0,0.0,,,,244.112,4.028342417478561,1.026,50.41635124905375,2.281426778241992,0.2265480081572115,0.6871196372508203,0.2265480081572115,2.974,34.2,"{'sha256': '62f40a5fac20ee37f75a20d12100e2b802032b2bdec8093250bbbb093411b41a', 'artifact_path': 'wandb-client-artifact://8lme3zewt5e0ta96rkkklaxpzgo5e9k3vvri4wdh1f5e7i9eujh8yr6sbisdty7yazyb36wicnhp7rbjsa7vncvugyur1elwo67bwxb9alni06t2hbc7nxgj2kituqto:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://8lme3zewt5e0ta96rkkklaxpzgo5e9k3vvri4wdh1f5e7i9eujh8yr6sbisdty7yazyb36wicnhp7rbjsa7vncvugyur1elwo67bwxb9alni06t2hbc7nxgj2kituqto:latest/predictions.table.json', 'path': 'media/table/predictions_1_62f40a5fac20ee37f75a.table.json', 'size': 1013918, '_type': 'table-file', 'ncols': 11, 'nrows': 1000}",36.18203222595436,,,False,True,dev_r1,False,Yes | Maybe | No,4,CTBase,2e94d035-3c3d-44cf-98cb-3d11bea7c17b,anli,QA,False,28,bigscience/T0_3B,0,True,qa_choices_and_answer,prompts/general_fixed_choice.yaml,No Prompt,,3,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,['NLI'],anli,False,False,GeneralFixedChoice,False,False,True,,,prompts,,False,True,qa choices and answer,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.BAREBONES.qa_choices_and_answer.LenNorm,ANLI R1,,,,,,,,,,,,,,,,,,,,,48.5,86.0,2
23.426427475877063,47.59887005649717,0.8613173308104777,4.264629101157189,2.0,0.7815985022727167,0.0,0.0,,,,115.7075,3.137726334730784,2.7,22.68041237113402,1.1269027664264044,0.714142842854285,0.9396613037449244,0.714142842854285,1.3,33.58333333333333,"{'_latest_artifact_path': 'wandb-client-artifact://octm9x0k6th6ggekqopbzmknaoin6lc42nl6vo3j926fxrw6xyjqtzqafofao5nu2zqh04sh39a3f52i5fh6o246n1yox44nv4bd4xjlntags64m7506wyosy9i4397g:latest/predictions.table.json', 'path': 'media/table/predictions_1_c31f3ca01c6968f295cd.table.json', 'size': 683109, '_type': 'table-file', 'ncols': 11, 'nrows': 1200, 'sha256': 'c31f3ca01c6968f295cd731020904836edb0f98ee54191513f51944a46f04c25', 'artifact_path': 'wandb-client-artifact://octm9x0k6th6ggekqopbzmknaoin6lc42nl6vo3j926fxrw6xyjqtzqafofao5nu2zqh04sh39a3f52i5fh6o246n1yox44nv4bd4xjlntags64m7506wyosy9i4397g:latest/predictions.table.json'}",32.112359153706954,,,False,True,dev_r3,False,Yes | Maybe | No,4,CTBase,c8dfc879-40f2-412d-be1e-4cd70107f6e6,anli,ENTAILMENT,False,28,bigscience/T0_3B,0,True,imply,prompts/general_fixed_choice.yaml,RTE,,3,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,['NLI'],anli,False,False,GeneralFixedChoice,False,False,True,,,prompts,,False,True,imply,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.super_glue_rte.imply.LenNorm,ANLI R3,,,,,,,,,,,,,,,,,,,,,29.0,48.0,14
21.30470450359953,46.82320441988951,0.7401351259492708,4.768585868875186,2.0,0.6394586158649562,0.0,0.0,,,,143.10583333333332,3.828014128605525,2.7533333333333334,17.09090909090909,0.940571740269661,0.6576388742226914,0.7633643549442325,0.6576388742226914,1.2466666666666666,32.166666666666664,"{'artifact_path': 'wandb-client-artifact://k4ehe9w7d4gpmwpkwbybw180g2s5othaxnouulnyuiqca61cuwuxuyu77654kij56x1at859njsf9qdg7urr5gsttj0p4ct2on7m5a1jj63oqffodzkti2umhykh5qdi:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://k4ehe9w7d4gpmwpkwbybw180g2s5othaxnouulnyuiqca61cuwuxuyu77654kij56x1at859njsf9qdg7urr5gsttj0p4ct2on7m5a1jj63oqffodzkti2umhykh5qdi:latest/predictions.table.json', 'path': 'media/table/predictions_1_b5f44fb0f3bc3ca31481.table.json', 'size': 872025, '_type': 'table-file', 'ncols': 11, 'nrows': 1200, 'sha256': 'b5f44fb0f3bc3ca31481beb6f8fcbf02ee426518e8edb09ce42b2bb39c0593db'}",31.96711277712699,,,False,True,dev_r3,False,Yes | Maybe | No,4,CTBase,9e2b4267-ec23-44c8-b82a-107e2c890fec,anli,ENTAILMENT,False,28,bigscience/T0_3B,0,True,entailment_explained,prompts/general_fixed_choice.yaml,RTE,,3,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,['NLI'],anli,False,False,GeneralFixedChoice,False,False,True,,,prompts,,False,True,entailment explained,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.super_glue_rte.entailment_explained.LenNorm,ANLI R3,,,,,,,,,,,,,,,,,,,,,85.5,67.0,40
27.14762977026212,42.00626959247649,0.7578702026457728,4.5129092122018335,2.0,0.5081553192923441,0.0,0.0,,,,113.428,3.9083892426490783,2.248,39.436619718309856,0.6045199695527553,0.9687600322061184,0.728387489965145,0.9687600322061188,1.752,34.1,"{'_latest_artifact_path': 'wandb-client-artifact://13yxoma1w843iocr1gjv313emon4me3992z0b879w89ob2vr31blgtmnsx46lsl468i1b2nj504c5o0jqc6cdrv470qwnb7mnq4kqi4yptgf2ym3csk8gb8w1psakmlo:latest/predictions.table.json', 'path': 'media/table/predictions_1_25996d06786a41582d53.table.json', 'size': 552307, '_type': 'table-file', 'ncols': 11, 'nrows': 1000, 'sha256': '25996d06786a41582d53687fa33bd1aadebf9fc888cf6952274ccd649fb3b627', 'artifact_path': 'wandb-client-artifact://13yxoma1w843iocr1gjv313emon4me3992z0b879w89ob2vr31blgtmnsx46lsl468i1b2nj504c5o0jqc6cdrv470qwnb7mnq4kqi4yptgf2ym3csk8gb8w1psakmlo:latest/predictions.table.json'}",18.13314137153295,,,False,True,dev_r1,False,Yes | Maybe | No,4,CTBase,c225e598-1efe-4cb6-9f7c-a1b7eb5c7803,anli,ENTAILMENT,False,28,bigscience/T0_3B,0,True,entailment_choices_and_answer,prompts/general_fixed_choice.yaml,No Prompt,,3,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,['NLI'],anli,False,False,GeneralFixedChoice,False,False,True,,,prompts,,False,True,entailment choices and answer,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.BAREBONES.entailment_choices_and_answer.LenNorm,ANLI R1,,,,,,,,,,,,,,,,,,,,,50.5,43.0,2
21.806385642896743,48.04392587508579,0.8001704331065931,4.415570692916711,2.0,0.711262472332062,0.0,0.0,,,,119.7075,3.302745685974757,2.768333333333333,17.375231053604438,1.1128250069419543,0.6400499112482471,0.921680148162184,0.6400499112482471,1.231666666666667,33.08333333333333,"{'nrows': 1200, 'sha256': 'd49d1a0a18e562578212bd4df561eb10566bbcb73f92620e4bb61b09fb8ad929', 'artifact_path': 'wandb-client-artifact://wj8dzjlztloeqdys28i8pdsqh7307kg2g89dfcpvvdjgq8fgtmh57ileg8q731mra5xmh0ct59zhh5qds3xtfqtnnfa3obm96weywat37qhcvz199188vggaixkypf8g:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://wj8dzjlztloeqdys28i8pdsqh7307kg2g89dfcpvvdjgq8fgtmh57ileg8q731mra5xmh0ct59zhh5qds3xtfqtnnfa3obm96weywat37qhcvz199188vggaixkypf8g:latest/predictions.table.json', 'path': 'media/table/predictions_1_d49d1a0a18e562578212.table.json', 'size': 713239, '_type': 'table-file', 'ncols': 11}",32.112359153706954,,,False,True,dev_r3,False,Yes | Maybe | No,4,CTBase,4ee6ff27-de63-4e7b-a9d4-82a17eba407a,anli,ENTAILMENT,False,28,bigscience/T0_3B,0,True,does_the_claim_follow_the_fact,prompts/general_fixed_choice.yaml,RTE,,3,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,['NLI'],anli,False,False,GeneralFixedChoice,False,False,True,,,prompts,,False,True,does the claim follow the fact,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.super_glue_rte.does_the_claim_follow_the_fact.LenNorm,ANLI R3,,,,,,,,,,,,,,,,,,,,,48.5,59.0,18
28.85580751254977,41.28440366972477,0.7857539486536156,5.269500723779202,2.0,0.7080240246419136,0.0,0.0,,,,129.056,4.405486975967884,2.078,45.28301886792453,0.8640137478113175,0.996953358989276,0.7196840347000403,0.9969533589892756,1.922,36.0,"{'ncols': 11, 'nrows': 1000, 'sha256': '82dbbb6fe0155cb2569f52075ceae4c14b9d34066736b7dfd46ab8d45451b928', 'artifact_path': 'wandb-client-artifact://j23z0bzfj8sm4iv9a3xbvh50adjnyg3ckem2saxkeo3hgytzssn9j4ltf7utdzcqfa3gwvl70y52x93jv61wv1h4z1hi3fnu1tk8y9s90cli06lrdt7u6dczz8j99x77:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://j23z0bzfj8sm4iv9a3xbvh50adjnyg3ckem2saxkeo3hgytzssn9j4ltf7utdzcqfa3gwvl70y52x93jv61wv1h4z1hi3fnu1tk8y9s90cli06lrdt7u6dczz8j99x77:latest/predictions.table.json', 'path': 'media/table/predictions_1_82dbbb6fe0155cb2569f.table.json', 'size': 584444, '_type': 'table-file'}",18.09101611297718,,,False,True,dev_r1,False,Yes | Maybe | No,4,CTBase,32a28538-99bc-4c5a-8086-83b885fddb50,anli,CLASSIFICATION,False,28,bigscience/T0_3B,0,True,classification_choices_and_answer,prompts/general_fixed_choice.yaml,No Prompt,,3,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,['NLI'],anli,False,False,GeneralFixedChoice,False,False,True,,,prompts,,False,True,classification choices and answer,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.BAREBONES.classification_choices_and_answer.LenNorm,ANLI R1,,,,,,,,,,,,,,,,,,,,,28.0,26.0,2
26.49107644440603,44.95268138801261,0.9996232675580742,3.4017295175790787,2.0,0.692932154430013,0.0408248290463863,0.0,,,,113.1,2.51827404042085,2.453333333333333,34.52054794520548,0.8834554771582286,0.8913410620457743,0.9832902623657844,0.8904056503764013,1.5466666666666666,34.25,"{'size': 666342, '_type': 'table-file', 'ncols': 11, 'nrows': 1200, 'sha256': '6a590b0d2e4977cd4ae85db429345ae29ca93a6fcaebbbe506d3090c71859d6d', 'artifact_path': 'wandb-client-artifact://o5balk2ux79hzm3tuh8pozftwjxn5j7w8htbd2wzfgboy2u9ne5vft723s0972kr9feylqjojxhc1d8hjlhnrwdweihg309lw60y8coc3113f1gb3kzs2lt6so67fj6z:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://o5balk2ux79hzm3tuh8pozftwjxn5j7w8htbd2wzfgboy2u9ne5vft723s0972kr9feylqjojxhc1d8hjlhnrwdweihg309lw60y8coc3113f1gb3kzs2lt6so67fj6z:latest/predictions.table.json', 'path': 'media/table/predictions_1_6a590b0d2e4977cd4ae8.table.json'}",32.020462207782074,,,False,True,dev_r3,False,Yes | Maybe | No,4,CTBase,03a7ae07-5ddd-46c4-92f3-2152223d44ec,anli,ENTAILMENT,False,28,bigscience/T0_3B,0,True,mean,prompts/general_fixed_choice.yaml,RTE,,3,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,['NLI'],anli,False,False,GeneralFixedChoice,False,False,True,,,prompts,,False,True,mean,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.super_glue_rte.mean.LenNorm,ANLI R3,,,,,,,,,,,,,,,,,,,,,13.0,20.0,9
19.434834171676275,8.421052631578947,1.297491648235768,6.117861344575882,2.0,1.075967863506971,0.0,0.0,,,,231.112,4.068293431282044,1.094,49.88344988344988,2.0495679132938385,0.4232776866313649,1.0877939447552467,0.423277686631365,2.906,33.7,"{'path': 'media/table/predictions_1_9f75fc221c95a4f6f1c5.table.json', 'size': 975437, '_type': 'table-file', 'ncols': 11, 'nrows': 1000, 'sha256': '9f75fc221c95a4f6f1c5914e6ffc6a70f4be1046b16180ae1434168ad51c9ce3', 'artifact_path': 'wandb-client-artifact://l6lhpmz2d57l4oputk02s291zl0jhmpx2mf91x2h338t0ci0tcrwcp11tqixsqptmdgx1fbwgjyz8n5mf904yuf5thf756vn8tp4gb2j7v9xv0dmenes71b35887tve1:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://l6lhpmz2d57l4oputk02s291zl0jhmpx2mf91x2h338t0ci0tcrwcp11tqixsqptmdgx1fbwgjyz8n5mf904yuf5thf756vn8tp4gb2j7v9xv0dmenes71b35887tve1:latest/predictions.table.json'}",36.18203222595436,,,False,True,dev_r1,False,Yes | Maybe | No,4,CTBase,97030be6-9843-4fc2-98cf-b47b879b5447,anli,QA,False,28,bigscience/T0_3B,0,True,qa_no_choices,prompts/general_fixed_choice.yaml,No Prompt,,3,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,['NLI'],anli,False,False,GeneralFixedChoice,False,False,False,,,prompts,,False,True,qa no choices,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.BAREBONES.qa_no_choices.LenNorm,ANLI R1,,,,,,,,,,,,,,,,,,,,,60.0,81.0,0
22.790816792598104,46.76966292134831,1.71127993372671,9.885104646235703,2.0,1.0865647823400155,0.0,0.0,,,,117.23583333333332,8.247478048900764,2.713333333333334,21.602787456445995,1.637626597334941,0.700824910769841,1.7546098658272014,0.700824910769841,1.2866666666666666,32.916666666666664,"{'_latest_artifact_path': 'wandb-client-artifact://13qwa05qhg3q3jkqv4x5r9vtwttqkoskh3ybma62xtuy8ojcgbtbx24w6aarwfz8aahto2p2fd9u55le10ec5qg177qwag0xuow3z5qkje8rw6ai8eabxz0wqi5dn9sw:latest/predictions.table.json', 'path': 'media/table/predictions_1_1db1e355fddc6589c422.table.json', 'size': 677841, '_type': 'table-file', 'ncols': 11, 'nrows': 1200, 'sha256': '1db1e355fddc6589c422979d531464e16a90dd82ba6e7fe8af501720e0d59c4d', 'artifact_path': 'wandb-client-artifact://13qwa05qhg3q3jkqv4x5r9vtwttqkoskh3ybma62xtuy8ojcgbtbx24w6aarwfz8aahto2p2fd9u55le10ec5qg177qwag0xuow3z5qkje8rw6ai8eabxz0wqi5dn9sw:latest/predictions.table.json'}",32.01257902719214,,,False,True,dev_r3,False,Yes | Maybe | No,4,CTBase,f2004e15-9d9a-4ca1-9830-a341e684e97e,anli,QA,False,28,bigscience/T0_3B,0,True,qa_no_choices_and_answer,prompts/general_fixed_choice.yaml,No Prompt,,3,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,['NLI'],anli,False,False,GeneralFixedChoice,False,False,False,,,prompts,,False,True,qa no choices and answer,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.BAREBONES.qa_no_choices_and_answer.LenNorm,ANLI R3,,,,,,,,,,,,,,,,,,,,,58.5,52.0,0
24.82301147593419,45.73991031390135,1.5107837012489722,3.753456544280052,1.9833333333333336,0.969331318122857,0.1674979270186815,0.9852216748768472,,,,95.10583333333334,2.434397748510043,2.5733333333333333,27.743902439024392,1.3190587957700093,0.8172854798389334,1.3510388530718862,0.8155502573246006,1.4433333333333334,33.25,"{'path': 'media/table/predictions_1_41b66f2ff9ffa9a3cbad.table.json', 'size': 604220, '_type': 'table-file', 'ncols': 11, 'nrows': 1200, 'sha256': '41b66f2ff9ffa9a3cbadcf4e31b913a753c44ed40fee8bad2b0889c900d2360c', 'artifact_path': 'wandb-client-artifact://125ar3cemsmawi0wtzk1uop2fs3i856uwnm11k3hz64e3tek656bbl2fih41mzoxgmt12j6nllht6y87ey1ucbgyh5u9s1n6g0d6o697ejdedypiz3ytrb4z0m9r1121:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://125ar3cemsmawi0wtzk1uop2fs3i856uwnm11k3hz64e3tek656bbl2fih41mzoxgmt12j6nllht6y87ey1ucbgyh5u9s1n6g0d6o697ejdedypiz3ytrb4z0m9r1121:latest/predictions.table.json'}",31.96711277712699,,,False,True,dev_r3,False,Yes | Maybe | No,4,CTBase,e5eaa3ee-e537-4d20-9dfa-6084db54f2ef,anli,ENTAILMENT,False,28,bigscience/T0_3B,0,True,entailment_no_choices_and_answer,prompts/general_fixed_choice.yaml,No Prompt,,3,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,['NLI'],anli,False,False,GeneralFixedChoice,False,False,False,,,prompts,,False,True,entailment no choices and answer,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.BAREBONES.entailment_no_choices_and_answer.LenNorm,ANLI R3,,,,,,,,,,,,,,,,,,,,,42.0,33.0,2
18.993329545693665,49.30875576036866,1.1537519456295289,4.434490712881089,1.996,0.8809558420746971,0.063118935352238,0.0,,,,100.428,2.7414762563705444,2.938,7.671232876712328,1.6930144565105438,0.3466352549871406,1.0553956736504555,0.3516304878704348,1.066,33.5,"{'nrows': 1000, 'sha256': 'fce18e5032f1f9c47b1e27b3f20facc1f2c2640ebaf44b11b8229d7d157287c3', 'artifact_path': 'wandb-client-artifact://19x5aq6e86a5gr5zemhguyxuij6ouco42d7cp2p3npz7uw3droiyh2yrkruevqjqwd1morreddaic6mlkzyawmek7whplmudnbeaxs0vfmvia1kmxpfmgjh30k02xeyx:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://19x5aq6e86a5gr5zemhguyxuij6ouco42d7cp2p3npz7uw3droiyh2yrkruevqjqwd1morreddaic6mlkzyawmek7whplmudnbeaxs0vfmvia1kmxpfmgjh30k02xeyx:latest/predictions.table.json', 'path': 'media/table/predictions_1_fce18e5032f1f9c47b1e.table.json', 'size': 512983, '_type': 'table-file', 'ncols': 11}",18.13314137153295,,,False,True,dev_r1,False,Yes | Maybe | No,4,CTBase,cc2958ca-e826-4fef-96aa-1c4caa188605,anli,ENTAILMENT,False,28,bigscience/T0_3B,0,True,entailment_no_choices,prompts/general_fixed_choice.yaml,No Prompt,,3,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,['NLI'],anli,False,False,GeneralFixedChoice,False,False,False,,,prompts,,False,True,entailment no choices,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.BAREBONES.entailment_no_choices.LenNorm,ANLI R1,,,,,,,,,,,,,,,,,,,,,62.5,84.0,0
24.711492662784103,45.65055762081784,1.4118526474523845,4.664977361783385,1.9975,0.9156583301508086,0.0499374608885954,0.0,,,,110.23583333333332,3.40933944940567,2.5816666666666666,28.48392036753446,1.255637912377715,0.8134272486761732,1.3314437217866535,0.8136743649779205,1.4208333333333334,33.33333333333333,"{'path': 'media/table/predictions_1_39173a3be920d761f5e0.table.json', 'size': 640323, '_type': 'table-file', 'ncols': 11, 'nrows': 1200, 'sha256': '39173a3be920d761f5e027f71f61fab64303dca7535ecaea6197f55c50f8b599', 'artifact_path': 'wandb-client-artifact://ufe6pb9cf1vk1hg2w6mfkbim5bw8k8naqh8snqyn2ref7mwgu45xqc2qjta18d58ru7ud2fnc91sxpf175zl1xnt2rza99u4det0q9rz3bpnfx2spgcnp5gcb4irmgrh:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://ufe6pb9cf1vk1hg2w6mfkbim5bw8k8naqh8snqyn2ref7mwgu45xqc2qjta18d58ru7ud2fnc91sxpf175zl1xnt2rza99u4det0q9rz3bpnfx2spgcnp5gcb4irmgrh:latest/predictions.table.json'}",32.01257902719214,,,False,True,dev_r3,False,Yes | Maybe | No,4,CTBase,cf005ddf-8cf2-409d-b884-45d22463f463,anli,CLASSIFICATION,False,28,bigscience/T0_3B,0,True,classification_no_choices_and_answer,prompts/general_fixed_choice.yaml,No Prompt,,3,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,['NLI'],anli,False,False,GeneralFixedChoice,False,False,False,,,prompts,,False,True,classification no choices and answer,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.BAREBONES.classification_no_choices_and_answer.LenNorm,ANLI R3,,,,,,,,,,,,,,,,,,,,,39.5,35.0,2
26.29974033073664,45.68888888888889,1.2178919466817333,5.173827517747879,1.999,0.9961745389155656,0.0316069612585582,0.0,,,,116.056,3.863326423883438,2.584,33.21033210332104,1.310501093864441,0.8117536572138128,1.1754776212648337,0.8118565144161868,1.417,34.7,"{'ncols': 11, 'nrows': 1000, 'sha256': '51d2f052bf0bfc5c983a04ae0d9567a630122a461402845cd84994cd6f116536', 'artifact_path': 'wandb-client-artifact://10dp6d30ncnf4gwabmki7iacen2ktnkyy73flrnvjoaj64ke7ge2fyco47ergp4vc0jeq9v2jibh1jtz9kultt5xfgbh6m7js2t4llgg0udb19guei9azvrofqmdlt43:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://10dp6d30ncnf4gwabmki7iacen2ktnkyy73flrnvjoaj64ke7ge2fyco47ergp4vc0jeq9v2jibh1jtz9kultt5xfgbh6m7js2t4llgg0udb19guei9azvrofqmdlt43:latest/predictions.table.json', 'path': 'media/table/predictions_1_51d2f052bf0bfc5c983a.table.json', 'size': 543166, '_type': 'table-file'}",18.09101611297718,,,False,True,dev_r1,False,Yes | Maybe | No,4,CTBase,74693ecc-f903-488c-968d-6a2bc8e76611,anli,CLASSIFICATION,False,28,bigscience/T0_3B,0,True,classification_no_choices,prompts/general_fixed_choice.yaml,No Prompt,,3,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,['NLI'],anli,False,False,GeneralFixedChoice,False,False,False,,,prompts,,False,True,classification no choices,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.BAREBONES.classification_no_choices.LenNorm,ANLI R1,,,,,,,,,,,,,,,,,,,,,42.5,49.0,0
18.275092039350596,4.761904761904763,0.9156962106148924,5.206696826641759,2.0,0.7913756204037623,0.0,0.0,,,,228.47166666666664,3.4303076107303303,1.04,50.063371356147016,1.776389215911428,0.2799999999999999,0.8088511473242318,0.2799999999999999,2.96,33.75,"{'nrows': 1200, 'sha256': '603250c5c7e15ec35fbc2ad93747ed9a906f8b267b542f8d14b855a769de89a9', 'artifact_path': 'wandb-client-artifact://hxors62ptlt1hw8qpbvu0xt9522h8qpbn88e8zpb7xemp0mwie0kvz9tx53724yeojut3b4kb77ljq3l0qdxj23iat3xz5tlw60cko07bddjy1ucobemg4m4ijnk5okg:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://hxors62ptlt1hw8qpbvu0xt9522h8qpbn88e8zpb7xemp0mwie0kvz9tx53724yeojut3b4kb77ljq3l0qdxj23iat3xz5tlw60cko07bddjy1ucobemg4m4ijnk5okg:latest/predictions.table.json', 'path': 'media/table/predictions_1_603250c5c7e15ec35fbc.table.json', 'size': 1172450, '_type': 'table-file', 'ncols': 11}",64.02515805438428,,,False,True,dev_r3,False,Yes | Maybe | No,4,CTBase,2e94d035-3c3d-44cf-98cb-3d11bea7c17b,anli,QA,False,28,bigscience/T0_3B,0,True,qa_choices_and_answer,prompts/general_fixed_choice.yaml,No Prompt,,3,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,['NLI'],anli,False,False,GeneralFixedChoice,False,False,True,,,prompts,,False,True,qa choices and answer,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.BAREBONES.qa_choices_and_answer.LenNorm,ANLI R3,,,,,,,,,,,,,,,,,,,,,26.0,83.0,2
17.92430762440693,3.508771929824561,0.868262545569626,5.765215249478817,2.0,0.903400392594882,0.0,0.0,,,,242.112,3.003453053474426,1.018,50.264150943396224,2.7617621960043905,0.1888809148643663,0.7103044813714674,0.1888809148643663,2.982,33.900000000000006,"{'ncols': 11, 'nrows': 1000, 'sha256': '918bf828214447d30e2d1a3723643f10224f6a394a7f48ef0df334cb99750d52', 'artifact_path': 'wandb-client-artifact://ndrfy7imfebkekwiiph4a67c973bs06z0x4bb8tcyg731q10p9gxf6s658a53l6fk32em85jz74soar7h16c3gwl3lsz1x09ent00ymj7vmzw101ll6kw0v5c636w2y4:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://ndrfy7imfebkekwiiph4a67c973bs06z0x4bb8tcyg731q10p9gxf6s658a53l6fk32em85jz74soar7h16c3gwl3lsz1x09ent00ymj7vmzw101ll6kw0v5c636w2y4:latest/predictions.table.json', 'path': 'media/table/predictions_1_918bf828214447d30e2d.table.json', 'size': 1004782, '_type': 'table-file'}",36.18203222595436,,,False,True,dev_r1,False,Yes | Maybe | No,4,CTBase,d92fc0d4-5367-41e1-b35d-1058f22a3c1c,anli,QA,False,28,bigscience/T0_3B,0,True,qa_choices,prompts/general_fixed_choice.yaml,No Prompt,,3,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,['NLI'],anli,False,False,GeneralFixedChoice,False,False,True,,,prompts,,False,True,qa choices,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.BAREBONES.qa_choices.LenNorm,ANLI R1,,,,,,,,,,,,,,,,,,,,,56.5,87.0,0
25.149607035053776,45.43396226415094,1.008972913771281,3.723254882519444,1.9991666666666668,0.7551368242895067,0.0499930550732354,0.0,,,,106.10583333333334,2.731097887518505,2.5483333333333333,30.0148588410104,0.9921569950009386,0.8362598612605746,0.9835588896645516,0.8353105709854269,1.4525,33.5,"{'_type': 'table-file', 'ncols': 11, 'nrows': 1200, 'sha256': 'd2b3c1b5216d55a921b33e370b8bd0758b81009dd9784f3b74059c235b87f77f', 'artifact_path': 'wandb-client-artifact://89mlg29tvoads25rxspe9dqdbuxvi7inj850jb0xg2p5hnay6hphupwivrdny2na1i0uixrzngi5xj1og6f6tnonvydl9k97ti289ofy19z8pduvk15ylw579t87zavc:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://89mlg29tvoads25rxspe9dqdbuxvi7inj850jb0xg2p5hnay6hphupwivrdny2na1i0uixrzngi5xj1og6f6tnonvydl9k97ti289ofy19z8pduvk15ylw579t87zavc:latest/predictions.table.json', 'path': 'media/table/predictions_1_d2b3c1b5216d55a921b3.table.json', 'size': 640440}",31.96711277712699,,,False,True,dev_r3,False,Yes | Maybe | No,4,CTBase,c225e598-1efe-4cb6-9f7c-a1b7eb5c7803,anli,ENTAILMENT,False,28,bigscience/T0_3B,0,True,entailment_choices_and_answer,prompts/general_fixed_choice.yaml,No Prompt,,3,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,['NLI'],anli,False,False,GeneralFixedChoice,False,False,True,,,prompts,,False,True,entailment choices and answer,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.BAREBONES.entailment_choices_and_answer.LenNorm,ANLI R3,,,,,,,,,,,,,,,,,,,,,33.0,30.0,2
25.404331492827065,42.67453294001967,0.8931544559947131,3.697656750023365,2.0,0.5720407487609588,0.0,0.0,,,,111.428,2.987591020464897,2.368,33.53846153846154,0.7100657295584679,0.9298257901349046,0.8143092397168229,0.9298257901349049,1.632,32.6,"{'_latest_artifact_path': 'wandb-client-artifact://1n92qj2v7iz2vsi98hr4bxz6wcpr3kt4fvlt8ftbqtq8pcopnk7u5xxpn15pvn12i2rsnqqv3ys0w89cuis5au9tgu5dpo56r4zhq0zmt7s9548qugtcbyvek7kos0lq:latest/predictions.table.json', 'path': 'media/table/predictions_1_15281f2ba3996d2b613c.table.json', 'size': 542863, '_type': 'table-file', 'ncols': 11, 'nrows': 1000, 'sha256': '15281f2ba3996d2b613c3924860afdfeab0582235152c682ceaa01f6958bd3e4', 'artifact_path': 'wandb-client-artifact://1n92qj2v7iz2vsi98hr4bxz6wcpr3kt4fvlt8ftbqtq8pcopnk7u5xxpn15pvn12i2rsnqqv3ys0w89cuis5au9tgu5dpo56r4zhq0zmt7s9548qugtcbyvek7kos0lq:latest/predictions.table.json'}",18.13314137153295,,,False,True,dev_r1,False,Yes | Maybe | No,4,CTBase,bb648cf3-d9ab-45a8-9bd7-6ba4585c4b9a,anli,ENTAILMENT,False,28,bigscience/T0_3B,0,True,entailment_choices,prompts/general_fixed_choice.yaml,No Prompt,,3,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,['NLI'],anli,False,False,GeneralFixedChoice,False,False,True,,,prompts,,False,True,entailment choices,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.BAREBONES.entailment_choices.LenNorm,ANLI R1,,,,,,,,,,,,,,,,,,,,,76.5,56.0,0
25.685695393431786,45.53846153846155,0.9257897968701534,4.189503617485364,2.0,0.709476617335845,0.0,0.0,,,,121.23583333333332,3.248697322035829,2.506666666666667,31.51862464183381,0.9408062954495352,0.8621420352174511,0.918321505777422,0.8621420352174513,1.4933333333333334,33.83333333333333,"{'ncols': 11, 'nrows': 1200, 'sha256': '08778a26ee7464fd8d3e76d34f68341e352020bdf49c4cf5ea74f3289309f5a3', 'artifact_path': 'wandb-client-artifact://553v51ncmblgtsovxyv7atv1xue12r6ndj2f2m08dqezv7mi5ht744aocsxsp83523zighavo016csbuqklaj00mhy175efmm230732rdt6uxgrysw79rjbeju0h5wpj:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://553v51ncmblgtsovxyv7atv1xue12r6ndj2f2m08dqezv7mi5ht744aocsxsp83523zighavo016csbuqklaj00mhy175efmm230732rdt6uxgrysw79rjbeju0h5wpj:latest/predictions.table.json', 'path': 'media/table/predictions_1_08778a26ee7464fd8d3e.table.json', 'size': 678918, '_type': 'table-file'}",32.01257902719214,,,False,True,dev_r3,False,Yes | Maybe | No,4,CTBase,32a28538-99bc-4c5a-8086-83b885fddb50,anli,CLASSIFICATION,False,28,bigscience/T0_3B,0,True,classification_choices_and_answer,prompts/general_fixed_choice.yaml,No Prompt,,3,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,['NLI'],anli,False,False,GeneralFixedChoice,False,False,True,,,prompts,,False,True,classification choices and answer,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.BAREBONES.classification_choices_and_answer.LenNorm,ANLI R3,,,,,,,,,,,,,,,,,,,,,23.5,24.0,2
29.92525497564896,40.32042723631508,0.8455340256849806,4.521317930132151,2.0,0.7318142724611816,0.0,0.0,,,,127.056,3.591980748295784,1.832,49.45533769063181,0.9293371818363666,0.9857869952479592,0.7457850258113116,0.9857869952479592,2.168,37.8,"{'path': 'media/table/predictions_1_5aba06994e0daae9075d.table.json', 'size': 574101, '_type': 'table-file', 'ncols': 11, 'nrows': 1000, 'sha256': '5aba06994e0daae9075daf5fbeb8b62f491f5d249d3d8a57dc8e136d9c26a43e', 'artifact_path': 'wandb-client-artifact://xdjapbjhgzdwkekeij20z3ddt9m95wgs71h9xp1ytakx7sl9teqpv65s2qyb7pc5wu3aestymuo3ddmd85uaxqlk1628mwk58c1pofybcvpxsu74av1l6c7kqoyc3xe9:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://xdjapbjhgzdwkekeij20z3ddt9m95wgs71h9xp1ytakx7sl9teqpv65s2qyb7pc5wu3aestymuo3ddmd85uaxqlk1628mwk58c1pofybcvpxsu74av1l6c7kqoyc3xe9:latest/predictions.table.json'}",18.09101611297718,,,False,True,dev_r1,False,Yes | Maybe | No,4,CTBase,88bdb026-e9c9-445b-96ef-0cdb986b7fbd,anli,CLASSIFICATION,False,28,bigscience/T0_3B,0,True,classification_choices,prompts/general_fixed_choice.yaml,No Prompt,,3,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,['NLI'],anli,False,False,GeneralFixedChoice,False,False,True,,,prompts,,False,True,classification choices,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.BAREBONES.classification_choices.LenNorm,ANLI R1,,,,,,,,,,,,,,,,,,,,,8.0,13.0,0
23.086046809599377,20.71307300509338,1.4514864998825343,4.622606485287348,2.006666666666667,1.028585097570951,0.0813770374382246,0.0,,,,215.47166666666664,3.015376567840576,1.3216666666666668,48.54506742370475,1.6072299174467723,0.7347543051176283,1.3364708943636578,0.73634042549776,2.671666666666667,33.58333333333333,"{'_type': 'table-file', 'ncols': 11, 'nrows': 1200, 'sha256': '6655cdb13efb33230ef6dfc269801cd52c564ec8abcf8650e3f5cda4f9cc387e', 'artifact_path': 'wandb-client-artifact://ny2pabm9unwgyil2urqxyiorsraj1psm2gwzl5rcrv39bhwnxi1n7f7gwwiamxokr6tyxyey1dkpnb891ewzitd32gl1d7reun3by24z0d27fz6zoiohb78j42xtpzij:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://ny2pabm9unwgyil2urqxyiorsraj1psm2gwzl5rcrv39bhwnxi1n7f7gwwiamxokr6tyxyey1dkpnb891ewzitd32gl1d7reun3by24z0d27fz6zoiohb78j42xtpzij:latest/predictions.table.json', 'path': 'media/table/predictions_1_6655cdb13efb33230ef6.table.json', 'size': 1126064}",64.02515805438428,,,False,True,dev_r3,False,Yes | Maybe | No,4,CTBase,97030be6-9843-4fc2-98cf-b47b879b5447,anli,QA,False,28,bigscience/T0_3B,0,True,qa_no_choices,prompts/general_fixed_choice.yaml,No Prompt,,3,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,['NLI'],anli,False,False,GeneralFixedChoice,False,False,False,,,prompts,,False,True,qa no choices,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.BAREBONES.qa_no_choices.LenNorm,ANLI R3,,,,,,,,,,,,,,,,,,,,,29.0,50.0,0
23.48961965892319,47.65897973445144,1.6662887502087569,3.118087793638309,1.7891666666666666,1.2208234109523652,0.4597636772178604,8.242950108459869,,,,93.10583333333334,1.3728505651156109,2.7741666666666664,14.566929133858263,1.745237228522698,0.5928737686519412,1.1109425449886725,0.689919480003927,1.4366666666666668,33.08333333333333,"{'sha256': '7033ba5d8fc3c472a4bf0c12ed01f55f5b34e18dd93947983c3b2cd816500557', 'artifact_path': 'wandb-client-artifact://8fk4vl9muiibtshe9mv2h3fgwznhdd2gok9b27ughuieypfafzd23jndmm8h9p34fkrq98asxvwx72smeccgmdufmnd0xdcbku95didmgrl0c8xua06nityhvyp6kze6:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://8fk4vl9muiibtshe9mv2h3fgwznhdd2gok9b27ughuieypfafzd23jndmm8h9p34fkrq98asxvwx72smeccgmdufmnd0xdcbku95didmgrl0c8xua06nityhvyp6kze6:latest/predictions.table.json', 'path': 'media/table/predictions_1_7033ba5d8fc3c472a4bf.table.json', 'size': 593671, '_type': 'table-file', 'ncols': 11, 'nrows': 1200}",31.96711277712699,,,False,True,dev_r3,False,Yes | Maybe | No,4,CTBase,cc2958ca-e826-4fef-96aa-1c4caa188605,anli,ENTAILMENT,False,28,bigscience/T0_3B,0,True,entailment_no_choices,prompts/general_fixed_choice.yaml,No Prompt,,3,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,['NLI'],anli,False,False,GeneralFixedChoice,False,False,False,,,prompts,,False,True,entailment no choices,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.BAREBONES.entailment_no_choices.LenNorm,ANLI R3,,,,,,,,,,,,,,,,,,,,,48.5,47.0,0
21.99487362292271,47.397260273972606,1.4607669371632368,3.935541251301766,1.9483333333333333,1.085549083944836,0.2213531617624249,0.0,,,,108.23583333333332,2.2225688765446345,2.773333333333333,18.58736059479554,1.712972374757131,0.6339996494916661,1.333850100758935,0.653858207530926,1.278333333333333,33.0,"{'artifact_path': 'wandb-client-artifact://iynw5x5pw29t7fofwbdw7mjd082snmyz10tivlduwflniyxuo9nj6ogqjrh034hjgjmyyifvs2abnh8c8olf0jrexgxol0gk5s9m1r9kqry0mg29v1eklaon3qqbgi7m:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://iynw5x5pw29t7fofwbdw7mjd082snmyz10tivlduwflniyxuo9nj6ogqjrh034hjgjmyyifvs2abnh8c8olf0jrexgxol0gk5s9m1r9kqry0mg29v1eklaon3qqbgi7m:latest/predictions.table.json', 'path': 'media/table/predictions_1_7b90af9e4835faacac25.table.json', 'size': 629453, '_type': 'table-file', 'ncols': 11, 'nrows': 1200, 'sha256': '7b90af9e4835faacac25fccb883a8b9a8441c3b4d12ef6ea8fb97bd7ae8eff0b'}",32.01257902719214,,,False,True,dev_r3,False,Yes | Maybe | No,4,CTBase,74693ecc-f903-488c-968d-6a2bc8e76611,anli,CLASSIFICATION,False,28,bigscience/T0_3B,0,True,classification_no_choices,prompts/general_fixed_choice.yaml,No Prompt,,3,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,['NLI'],anli,False,False,GeneralFixedChoice,False,False,False,,,prompts,,False,True,classification no choices,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.BAREBONES.classification_no_choices.LenNorm,ANLI R3,,,,,,,,,,,,,,,,,,,,,54.0,58.0,0
17.846859576908113,3.414634146341464,0.972594293600075,4.603874451865752,2.0016666666666665,0.8724983755623993,0.0407907941684013,0.0,,,,226.47166666666664,2.531084263920784,1.0233333333333334,50.12594458438288,2.0727901879449684,0.2147608489045948,0.8212096317057582,0.2184223737013526,2.975,33.75,"{'ncols': 11, 'nrows': 1200, 'sha256': 'afc9a0e9ee324d9f1f2048081cd92cc43763b355bba4f125fe165e1bb7cfd0cb', 'artifact_path': 'wandb-client-artifact://19i5fponwy6kpwhvppmx162hsifybg6yr43nq7gducwdpcnnr0ug6bx1blajm4wod8b1pna8yhf4zs4xvaaypgckntlwbiqsy82safrd7g59ipl4u0rvtxnsaiv3vv4n:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://19i5fponwy6kpwhvppmx162hsifybg6yr43nq7gducwdpcnnr0ug6bx1blajm4wod8b1pna8yhf4zs4xvaaypgckntlwbiqsy82safrd7g59ipl4u0rvtxnsaiv3vv4n:latest/predictions.table.json', 'path': 'media/table/predictions_1_afc9a0e9ee324d9f1f20.table.json', 'size': 1161363, '_type': 'table-file'}",64.02515805438428,,,False,True,dev_r3,False,Yes | Maybe | No,4,CTBase,d92fc0d4-5367-41e1-b35d-1058f22a3c1c,anli,QA,False,28,bigscience/T0_3B,0,True,qa_choices,prompts/general_fixed_choice.yaml,No Prompt,,3,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,['NLI'],anli,False,False,GeneralFixedChoice,False,False,True,,,prompts,,False,True,qa choices,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.BAREBONES.qa_choices.LenNorm,ANLI R3,,,,,,,,,,,,,,,,,,,,,26.0,85.0,0
23.95912825230741,45.12285927029039,1.173584590793534,2.850398671825727,1.9666666666666663,0.8533109354087637,0.2134374745810949,0.9876543209876544,,,,104.10583333333334,1.709821159640948,2.580833333333333,25.76687116564417,1.1405775121847788,0.8124854699555487,1.0391120401875014,0.809985853785937,1.4525,32.416666666666664,"{'artifact_path': 'wandb-client-artifact://36ukdrbexd10di7nreab1kkhpwo18ynrjp4oszxd3oqtdznmrc4w4ejo3nk53pr0feuqwdhzhijls4i2v85dtxr1yf6wkom1togqyk5lbavgc0j7k8m1rkzclpsgo52r:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://36ukdrbexd10di7nreab1kkhpwo18ynrjp4oszxd3oqtdznmrc4w4ejo3nk53pr0feuqwdhzhijls4i2v85dtxr1yf6wkom1togqyk5lbavgc0j7k8m1rkzclpsgo52r:latest/predictions.table.json', 'path': 'media/table/predictions_1_e292ec036620819f427e.table.json', 'size': 629182, '_type': 'table-file', 'ncols': 11, 'nrows': 1200, 'sha256': 'e292ec036620819f427eb3256fb7f993e4f2797d64ab0d544439995ad502822d'}",31.96711277712699,,,False,True,dev_r3,False,Yes | Maybe | No,4,CTBase,bb648cf3-d9ab-45a8-9bd7-6ba4585c4b9a,anli,ENTAILMENT,False,28,bigscience/T0_3B,0,True,entailment_choices,prompts/general_fixed_choice.yaml,No Prompt,,3,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,['NLI'],anli,False,False,GeneralFixedChoice,False,False,True,,,prompts,,False,True,entailment choices,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.BAREBONES.entailment_choices.LenNorm,ANLI R3,,,,,,,,,,,,,,,,,,,,,80.5,41.0,0
26.466835369100632,43.970467596390485,0.9568263860598952,3.4830030761038264,1.9983333333333333,0.6906305772566802,0.0407907941684013,0.0,,,,119.23583333333332,2.5807421983281773,2.3716666666666666,35.43003851091142,0.9022608777756492,0.9283662471723586,0.9167275299283988,0.9281343293582742,1.63,33.83333333333333,"{'_latest_artifact_path': 'wandb-client-artifact://bmcuz09mkcjgc9k9pw76lqn5fkud8mzgvfawe132v7vb72qsc0e504ze5k4n80fgk4287s4fnaf3d0brncugsu1zrrvg75dg9vf0ub91ad3a9ea6mi95zt13h7snvm1y:latest/predictions.table.json', 'path': 'media/table/predictions_1_42326b467f7414c2bea3.table.json', 'size': 666582, '_type': 'table-file', 'ncols': 11, 'nrows': 1200, 'sha256': '42326b467f7414c2bea323e3e646c19ddc71d946d2a07005b16a12e6212f102c', 'artifact_path': 'wandb-client-artifact://bmcuz09mkcjgc9k9pw76lqn5fkud8mzgvfawe132v7vb72qsc0e504ze5k4n80fgk4287s4fnaf3d0brncugsu1zrrvg75dg9vf0ub91ad3a9ea6mi95zt13h7snvm1y:latest/predictions.table.json'}",32.01257902719214,,,False,True,dev_r3,False,Yes | Maybe | No,4,CTBase,88bdb026-e9c9-445b-96ef-0cdb986b7fbd,anli,CLASSIFICATION,False,28,bigscience/T0_3B,0,True,classification_choices,prompts/general_fixed_choice.yaml,No Prompt,,3,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,['NLI'],anli,False,False,GeneralFixedChoice,False,False,True,,,prompts,,False,True,classification choices,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.BAREBONES.classification_choices.LenNorm,ANLI R3,,,,,,,,,,,,,,,,,,,,,23.5,22.0,0
21.39323572749938,45.29558701082432,0.746700817650352,5.947653413578868,2.0,0.9065666413621574,0.0,0.0,,,,138.428,4.618173240184784,2.736,18.88412017167382,1.329480173394084,0.676981535937281,0.8326917103253276,0.676981535937281,1.264,31.6,"{'artifact_path': 'wandb-client-artifact://19h4f0mamc64v3to8w31wyhrzctkw2tohenifl2u8aatd6blp6jb6p43crexq7nzdwixo7kswq0d4vglteby1gm0o4pmocc042juf17ibheqw6twguujdf9gesicchel:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://19h4f0mamc64v3to8w31wyhrzctkw2tohenifl2u8aatd6blp6jb6p43crexq7nzdwixo7kswq0d4vglteby1gm0o4pmocc042juf17ibheqw6twguujdf9gesicchel:latest/predictions.table.json', 'path': 'media/table/predictions_1_fb4f8583b23098f2c5f2.table.json', 'size': 624951, '_type': 'table-file', 'ncols': 11, 'nrows': 1000, 'sha256': 'fb4f8583b23098f2c5f2ecb18205cec8ee9f615cc96e0220485d4c447aa30899'}",18.13314137153295,,,False,True,dev_r1,False,Yes | Maybe | No,4,CTBase,725b5ed0-7728-4890-95a4-a74cb7ae1bb4,anli,ENTAILMENT,False,28,bigscience/T0_3B,0,True,affirmation_true_or_false,prompts/general_fixed_choice.yaml,WiC,,3,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,['NLI'],anli,False,False,GeneralFixedChoice,False,False,True,,,prompts,,False,True,affirmation_true_or_false,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.super_glue_wic.affirmation_true_or_false.LenNorm,ANLI R1,,,,,,,,,,,,,,,,,,,,,86.5,76.0,25
19.191153575115948,48.60248447204969,0.8023677403588302,5.294550249174237,2.0,0.7316660777359708,0.0,0.0,,,,137.428,3.976864651918411,2.91,8.970976253298153,1.317685597255826,0.4146082488325575,0.8270566215847234,0.4146082488325577,1.09,33.0,"{'nrows': 1000, 'sha256': 'a294bf51e03623c6304f87882bf75783c28f1c7862a4ddffa28f0b6226e9e003', 'artifact_path': 'wandb-client-artifact://12lzbhmznvf4fkysbqdggxaw84qszewd37ge48f9ab7glywy6lt2db2zlvauam0alsisrll9kg4a7lmlkz8yn8cbfra2htpdp9r9dsy0jzpm79dsshr9ml6hjcolcy2g:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://12lzbhmznvf4fkysbqdggxaw84qszewd37ge48f9ab7glywy6lt2db2zlvauam0alsisrll9kg4a7lmlkz8yn8cbfra2htpdp9r9dsy0jzpm79dsshr9ml6hjcolcy2g:latest/predictions.table.json', 'path': 'media/table/predictions_1_a294bf51e03623c6304f.table.json', 'size': 661774, '_type': 'table-file', 'ncols': 11}",18.13314137153295,,,False,True,dev_r1,False,Yes | Maybe | No,4,CTBase,611d13dc-d414-4b9b-9204-e4f325e859e7,anli,ENTAILMENT,False,28,bigscience/T0_3B,0,True,grammar_homework,prompts/general_fixed_choice.yaml,WiC,,3,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,['NLI'],anli,False,False,GeneralFixedChoice,False,False,True,,,prompts,,False,True,grammar_homework,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.super_glue_wic.grammar_homework.LenNorm,ANLI R1,,,,,,,,,,,,,,,,,,,,,72.0,83.0,25
22.030369338903256,47.27272727272727,1.217272385559058,9.112677621603012,2.0,0.8099422809272567,0.0,0.0,,,,117.428,7.925499757289886,2.754,18.81838074398249,1.1871778643131257,0.656874417221435,1.170735968443372,0.656874417221435,1.246,32.9,"{'path': 'media/table/predictions_1_ee6248466309cb42da4b.table.json', 'size': 587311, '_type': 'table-file', 'ncols': 11, 'nrows': 1000, 'sha256': 'ee6248466309cb42da4ba31408ed770aaec38e10edb02f3c2c2f580ad91c550e', 'artifact_path': 'wandb-client-artifact://161u320mu04rdtkfxwmc0m2xfqd7kturs8yokb88an9xitvlfcm0b1e0011z0qhj06key15n3b0wfks4woc4lqt4w2thjb4ylu0qlqzsqv55znjsdodo64yzw9bnbhbp:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://161u320mu04rdtkfxwmc0m2xfqd7kturs8yokb88an9xitvlfcm0b1e0011z0qhj06key15n3b0wfks4woc4lqt4w2thjb4ylu0qlqzsqv55znjsdodo64yzw9bnbhbp:latest/predictions.table.json'}",18.13314137153295,,,False,True,dev_r1,False,Yes | Maybe | No,4,CTBase,3503ead5-4fa5-4f77-95dc-f0c2ed3eecdc,anli,ENTAILMENT,False,28,bigscience/T0_3B,0,True,question_context_meaning,prompts/general_fixed_choice.yaml,WiC,,3,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,['NLI'],anli,False,False,GeneralFixedChoice,False,False,False,,,prompts,,False,True,question-context-meaning,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.super_glue_wic.question_context_meaning.LenNorm,ANLI R1,,,,,,,,,,,,,,,,,,,,,74.5,73.0,14
17.90747491450261,48.84437596302003,0.7479368329450278,5.486220445156097,2.0,0.7345611390712988,0.0,0.0,,,,129.428,4.151152189016342,2.93,4.878048780487805,1.335068256139755,0.3675595189897822,0.7722578960909237,0.3675595189897822,1.07,32.6,"{'ncols': 11, 'nrows': 1000, 'sha256': '842c79e73b197d080ccea4abf69b4a5467d38d39343188f216ee774a882ee42c', 'artifact_path': 'wandb-client-artifact://s3uqy1suj2g0khcgys2wvo5llx6r1b168g2ie68py2zfkhbnp1mkkkadxhn2gz7jjfz7xrpofg39t3r3iix3e9oa81p3638mi8b58tsyu0z0zl0f2ewrzh4tp5424z2t:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://s3uqy1suj2g0khcgys2wvo5llx6r1b168g2ie68py2zfkhbnp1mkkkadxhn2gz7jjfz7xrpofg39t3r3iix3e9oa81p3638mi8b58tsyu0z0zl0f2ewrzh4tp5424z2t:latest/predictions.table.json', 'path': 'media/table/predictions_1_842c79e73b197d080cce.table.json', 'size': 616744, '_type': 'table-file'}",18.13314137153295,,,False,True,dev_r1,False,Yes | Maybe | No,4,CTBase,14e73f39-a0d1-44c2-b9a4-4e48f9f1608e,anli,ENTAILMENT,False,28,bigscience/T0_3B,0,True,question_context_meaning_with_label,prompts/general_fixed_choice.yaml,WiC,,3,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,['NLI'],anli,False,False,GeneralFixedChoice,False,False,True,,,prompts,,False,True,question-context-meaning-with-label,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.super_glue_wic.question_context_meaning_with_label.LenNorm,ANLI R1,,,,,,,,,,,,,,,,,,,,,76.5,88.0,16
26.78107757221681,42.843232716650434,1.1444462151928956,12.099773456811905,2.0,1.0473463955687077,0.0,0.0,,,,154.056,10.837799072504044,2.388,37.5,1.2619743843078612,0.9216593730874764,1.165963711626927,0.9216593730874764,1.612,34.0,"{'_latest_artifact_path': 'wandb-client-artifact://aqdp1xqn4e4ep70janbc9sisma285l1mj0hxb9mh6r4flz994l3ytk1lacpv0xltm5tnts5onisd3b1vztvd3inwnio47n0jlxnd47gx07gwp1y59w3umleyquvzfjhm:latest/predictions.table.json', 'path': 'media/table/predictions_1_272e2f44f2b78f89251b.table.json', 'size': 703085, '_type': 'table-file', 'ncols': 11, 'nrows': 1000, 'sha256': '272e2f44f2b78f89251bd7792fbfa077e65e6d13092c0e927c008f99a0be6797', 'artifact_path': 'wandb-client-artifact://aqdp1xqn4e4ep70janbc9sisma285l1mj0hxb9mh6r4flz994l3ytk1lacpv0xltm5tnts5onisd3b1vztvd3inwnio47n0jlxnd47gx07gwp1y59w3umleyquvzfjhm:latest/predictions.table.json'}",18.09101611297718,,,False,True,dev_r1,False,Yes | Maybe | No,4,CTBase,cd563834-49ee-495d-ac46-99f0264e58d5,anli,QA,False,28,bigscience/T0_3B,0,True,ask_question_as_teacher,prompts/general_fixed_choice.yaml,ZEST,,3,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,['NLI'],anli,False,False,GeneralFixedChoice,False,False,False,,,prompts,,False,True,ask_question_as_teacher,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.zest.ask_question_as_teacher.LenNorm,ANLI R1,,,,,,,,,,,,,,,,,,,,,53.0,47.0,24
27.961344168679997,41.40127388535032,1.0180270712738826,10.23328329576552,2.0,0.8538088158593491,0.0,0.0,,,,153.056,9.221559281110764,2.218,42.48275862068965,1.0117240146547557,0.9759487691472332,0.9519723236927844,0.9759487691472332,1.782,34.9,"{'ncols': 11, 'nrows': 1000, 'sha256': '87d584b5d4c19e549ab33e92ed72fffca0127e146a5ba96d703822949d4a360e', 'artifact_path': 'wandb-client-artifact://120pbgccj266wei5rcrybnhpi4f5hsea7na7emo0upos0fcsqjtw55a7x4h0znkrecyopa80jows2cg1x34ebixq2dkj46w9rluk10le5v41ddgyqcmwdjtxexjrdksc:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://120pbgccj266wei5rcrybnhpi4f5hsea7na7emo0upos0fcsqjtw55a7x4h0znkrecyopa80jows2cg1x34ebixq2dkj46w9rluk10le5v41ddgyqcmwdjtxexjrdksc:latest/predictions.table.json', 'path': 'media/table/predictions_1_87d584b5d4c19e549ab3.table.json', 'size': 704464, '_type': 'table-file'}",18.09101611297718,,,False,True,dev_r1,False,Yes | Maybe | No,4,CTBase,7425232a-9880-428c-9ddc-4070e50e22cc,anli,QA,False,28,bigscience/T0_3B,0,True,gpt3_instruct_format,prompts/general_fixed_choice.yaml,ZEST,,3,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,['NLI'],anli,False,False,GeneralFixedChoice,False,False,False,,,prompts,,False,True,gpt3_instruct_format,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.zest.gpt3_instruct_format.LenNorm,ANLI R1,,,,,,,,,,,,,,,,,,,,,40.0,33.0,28
19.7187443898482,47.625418060200666,0.8755295925401351,5.2672106975317,2.0,0.8571354016640395,0.0,0.0,,,,131.10583333333332,3.853448048979044,2.8316666666666666,11.530815109343935,1.4137626485526562,0.5552752070420177,0.870608450966349,0.5552752070420175,1.1683333333333332,32.083333333333336,"{'size': 727874, '_type': 'table-file', 'ncols': 11, 'nrows': 1200, 'sha256': '781cadfda7f7f2a298cb192512f075c6805a5812f76968ade174f3974f71ef53', 'artifact_path': 'wandb-client-artifact://16zk3mbr1qtb1ok60h1zaljc3w5rfy942gd918v24nbq5du6erbpxcl8fpozo8zmg9eg0ejjcnz56gsodacokxw4lh2kcq5rege87okythcuvm5no9x5xoeybr64z89w:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://16zk3mbr1qtb1ok60h1zaljc3w5rfy942gd918v24nbq5du6erbpxcl8fpozo8zmg9eg0ejjcnz56gsodacokxw4lh2kcq5rege87okythcuvm5no9x5xoeybr64z89w:latest/predictions.table.json', 'path': 'media/table/predictions_1_781cadfda7f7f2a298cb.table.json'}",31.96711277712699,,,False,True,dev_r3,False,Yes | Maybe | No,4,CTBase,725b5ed0-7728-4890-95a4-a74cb7ae1bb4,anli,ENTAILMENT,False,28,bigscience/T0_3B,0,True,affirmation_true_or_false,prompts/general_fixed_choice.yaml,WiC,,3,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,['NLI'],anli,False,False,GeneralFixedChoice,False,False,True,,,prompts,,False,True,affirmation_true_or_false,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.super_glue_wic.affirmation_true_or_false.LenNorm,ANLI R3,,,,,,,,,,,,,,,,,,,,,87.5,76.0,25
28.49028978276147,39.35558112773303,1.045377813122614,11.098536708116532,2.0,0.866610325368517,0.0,0.0,,,,160.056,10.040495031118391,2.072,46.115288220551385,1.0580416769981384,0.9974046320325568,0.96640146528399,0.9974046320325568,1.928,35.5,"{'ncols': 11, 'nrows': 1000, 'sha256': '6b168d44d8adbbb607462ff91bd4516b5f582588d27087e9ba861dc948762426', 'artifact_path': 'wandb-client-artifact://u4zo6i8st03ym3jeo8617mtmpruo7xgbxk6dtou7wotf862dd5idku41zghxoo51vewbiudx48kuk05efwpmai0ugnfzbydt9kew2t54g4oadoqu7gtzpncbxxx8qopo:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://u4zo6i8st03ym3jeo8617mtmpruo7xgbxk6dtou7wotf862dd5idku41zghxoo51vewbiudx48kuk05efwpmai0ugnfzbydt9kew2t54g4oadoqu7gtzpncbxxx8qopo:latest/predictions.table.json', 'path': 'media/table/predictions_1_6b168d44d8adbbb60746.table.json', 'size': 704401, '_type': 'table-file'}",18.09101611297718,,,False,True,dev_r1,False,Yes | Maybe | No,4,CTBase,6f694e45-1d17-4067-a1f6-7dae89c148db,anli,QA,False,28,bigscience/T0_3B,0,True,ask_question_as_kid,prompts/general_fixed_choice.yaml,ZEST,,3,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,['NLI'],anli,False,False,GeneralFixedChoice,False,False,False,,,prompts,,False,True,ask_question_as_kid,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.zest.ask_question_as_kid.LenNorm,ANLI R1,,,,,,,,,,,,,,,,,,,,,33.5,27.0,31
18.278609831029183,49.03225806451613,1.0349882266948909,4.464251545245449,1.995,0.8995279409012277,0.0705336798983294,0.0,,,,130.10583333333332,2.7605864838759104,2.9233333333333333,5.803571428571427,1.7036650613695383,0.3839994212958602,1.0716314141430667,0.3894404818311637,1.0816666666666668,32.75,"{'ncols': 11, 'nrows': 1200, 'sha256': '34714d1c05c973c6b7af7e27a328f0811ce60b9707ff6d8302aa562c62d20439', 'artifact_path': 'wandb-client-artifact://cvdbcha9zxqqddzqveuo83yy1aty8eh076su2iy26dbcn0ainh2uhyuijtyhgr236p835d19l9wj65tref5qryw0daxkum5o806tpg04uakj4aw20nuq85inilzdkg2m:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://cvdbcha9zxqqddzqveuo83yy1aty8eh076su2iy26dbcn0ainh2uhyuijtyhgr236p835d19l9wj65tref5qryw0daxkum5o806tpg04uakj4aw20nuq85inilzdkg2m:latest/predictions.table.json', 'path': 'media/table/predictions_1_34714d1c05c973c6b7af.table.json', 'size': 771999, '_type': 'table-file'}",31.96711277712699,,,False,True,dev_r3,False,Yes | Maybe | No,4,CTBase,611d13dc-d414-4b9b-9204-e4f325e859e7,anli,ENTAILMENT,False,28,bigscience/T0_3B,0,True,grammar_homework,prompts/general_fixed_choice.yaml,WiC,,3,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,['NLI'],anli,False,False,GeneralFixedChoice,False,False,True,,,prompts,,False,True,grammar_homework,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.super_glue_wic.grammar_homework.LenNorm,ANLI R3,,,,,,,,,,,,,,,,,,,,,67.5,82.0,25
28.447245036030083,42.15991692627207,1.0872328705825254,12.0288950920552,2.0,0.9593187053594362,0.0,0.0,,,,146.056,10.876520302772525,2.26,43.18181818181818,1.1523747892826797,0.965608616365865,1.0606556949490022,0.9656086163658648,1.74,35.5,"{'_type': 'table-file', 'ncols': 11, 'nrows': 1000, 'sha256': '836c3e70e5256590261df275786d212363472fae1f38103233a8113b0de77ad5', 'artifact_path': 'wandb-client-artifact://xoa95zikybrjq967c5lb7gj6yeyysspx6zs5totkr955fe9z3etcc3wlk4k2rvzljpqgwnqql6ikfs7a4ih89pucl00an31of7356psan17l61jbupjjq0mzds91gfya:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://xoa95zikybrjq967c5lb7gj6yeyysspx6zs5totkr955fe9z3etcc3wlk4k2rvzljpqgwnqql6ikfs7a4ih89pucl00an31of7356psan17l61jbupjjq0mzds91gfya:latest/predictions.table.json', 'path': 'media/table/predictions_1_836c3e70e5256590261d.table.json', 'size': 666196}",18.09101611297718,,,False,True,dev_r1,False,Yes | Maybe | No,4,CTBase,2283cebf-988e-4bff-96bf-982a09963e49,anli,QA,False,28,bigscience/T0_3B,0,True,answerable_or_not,prompts/general_fixed_choice.yaml,ZEST,,3,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,['NLI'],anli,False,False,GeneralFixedChoice,False,False,False,,,prompts,,False,True,answerable_or_not,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.zest.answerable_or_not.LenNorm,ANLI R1,,,,,,,,,,,,,,,,,,,,,33.5,28.0,20
21.745255288232222,46.54088050314465,1.610708129949134,7.584013037681579,2.0,0.9879904554223206,0.0,0.0,,,,110.10583333333334,6.105645436048508,2.725,18.69488536155203,1.4783676016330718,0.6887488656977956,1.619363662350289,0.6887488656977956,1.275,32.166666666666664,"{'ncols': 11, 'nrows': 1200, 'sha256': '139ba5ba8312231fecfc0b69ac6d48255641eaf306d8d37c72bfad2a1cc3199d', 'artifact_path': 'wandb-client-artifact://hb6wd8yaptzrxt9f2ni8hil81sgxh74vz84tcf5cmuxeaj69mnngw5ew74na6jkd1bov5svcfu406md5468t610ow7ir42o2vxw33n59a4a7fer5qax313wfs6s1qvp7:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://hb6wd8yaptzrxt9f2ni8hil81sgxh74vz84tcf5cmuxeaj69mnngw5ew74na6jkd1bov5svcfu406md5468t610ow7ir42o2vxw33n59a4a7fer5qax313wfs6s1qvp7:latest/predictions.table.json', 'path': 'media/table/predictions_1_139ba5ba8312231fecfc.table.json', 'size': 682996, '_type': 'table-file'}",31.96711277712699,,,False,True,dev_r3,False,Yes | Maybe | No,4,CTBase,3503ead5-4fa5-4f77-95dc-f0c2ed3eecdc,anli,ENTAILMENT,False,28,bigscience/T0_3B,0,True,question_context_meaning,prompts/general_fixed_choice.yaml,WiC,,3,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,['NLI'],anli,False,False,GeneralFixedChoice,False,False,False,,,prompts,,False,True,question-context-meaning,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.super_glue_wic.question_context_meaning.LenNorm,ANLI R3,,,,,,,,,,,,,,,,,,,,,85.5,61.0,14
18.60663423852018,48.347375243033056,0.9699615502706086,4.514420050382614,1.9991666666666668,0.828148379097698,0.0288554828219679,0.0,,,,122.10583333333334,2.9964573885997137,2.911666666666666,7.472527472527473,1.5179626617829003,0.4109305158891085,0.9712019175324248,0.4117636525430038,1.0891666666666666,32.5,"{'_type': 'table-file', 'ncols': 11, 'nrows': 1200, 'sha256': '3aa393580a6e86d29f2b10700f0c6c8de63c0aec7a12dba56bc4f17c3424a9de', 'artifact_path': 'wandb-client-artifact://c3m0f7smm9hqh64q2a2h24cw9ovzxus1wlw5bwo3lmn6ydnwnirythsdew5f7h9we0spg105qractosk5sm8ag2vypjaujomthgtidlfdq57fq9l4i5pcbuki6pcrcsm:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://c3m0f7smm9hqh64q2a2h24cw9ovzxus1wlw5bwo3lmn6ydnwnirythsdew5f7h9we0spg105qractosk5sm8ag2vypjaujomthgtidlfdq57fq9l4i5pcbuki6pcrcsm:latest/predictions.table.json', 'path': 'media/table/predictions_1_3aa393580a6e86d29f2b.table.json', 'size': 717799}",31.96711277712699,,,False,True,dev_r3,False,Yes | Maybe | No,4,CTBase,14e73f39-a0d1-44c2-b9a4-4e48f9f1608e,anli,ENTAILMENT,False,28,bigscience/T0_3B,0,True,question_context_meaning_with_label,prompts/general_fixed_choice.yaml,WiC,,3,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,['NLI'],anli,False,False,GeneralFixedChoice,False,False,True,,,prompts,,False,True,question-context-meaning-with-label,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.super_glue_wic.question_context_meaning_with_label.LenNorm,ANLI R3,,,,,,,,,,,,,,,,,,,,,76.5,79.0,16
19.726678550207964,12.12121212121212,0.7908227836116791,10.12925786631448,2.0,0.519988305286298,0.0,0.0,,,,145.78571428571428,9.39417062486921,2.0,47.05882352941176,0.7350872414452689,1.0,0.7303692126076705,1.0,2.0,25.0,"{'sha256': 'b361947ebbc7849b9ec77520f598865043fdc8381aae18a85b32cf8f9dfbb168', 'artifact_path': 'wandb-client-artifact://102xejhqi50v25xwp4dhnylhgqu8fl6xdlww6cdipwivc5e19f9s8eooqf7l08aqtlol72asvlblt0o07eplvwk1uvlax3wcbux3jv8t94l210dlvac8cfs905t9mmu2:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://102xejhqi50v25xwp4dhnylhgqu8fl6xdlww6cdipwivc5e19f9s8eooqf7l08aqtlol72asvlblt0o07eplvwk1uvlax3wcbux3jv8t94l210dlvac8cfs905t9mmu2:latest/predictions.table.json', 'path': 'media/table/predictions_1_b361947ebbc7849b9ec7.table.json', 'size': 38131, '_type': 'table-file', 'ncols': 11, 'nrows': 56}",55.06285832888571,,,False,True,validation,False,Yes | Maybe | No,4,CTBase,a64d5a15-68e2-4d1c-b30a-ca8250c860f9,cb,QA,False,28,bigscience/T0_3B,0,True,answer_the_following_q,prompts/general_fixed_choice.yaml,AdversarialQA,,3,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,['NLI'],cb,True,False,GeneralFixedChoice,False,False,False,,,prompts,,False,True,answer_the_following_q,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.adversarial_qa.answer_the_following_q.LenNorm,CB,,,CommitmentBank,super_glue,,,,,,,,,,,,,,,,,35.5,49.0,23
20.151515151515152,15.0,0.9318107681505228,9.72679072192737,2.0,0.587874792530193,0.0,0.0,,,,138.78571428571428,8.821933439799718,2.25,45.454545454545446,0.9048572821276528,0.9682458365518544,0.9113465257372034,0.9682458365518544,1.75,23.214285714285715,"{'artifact_path': 'wandb-client-artifact://1cwpvzgt8it8xsy4r9qxhmr5p1hy49mczhsljhbcjq34xi1qnbz4vjprks6ad2hob5gzsc0pct7a81hxudr56cgwd8i5i4ldxh1t5j7ufc0cfaijqv4kk3vpd2qqnh38:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://1cwpvzgt8it8xsy4r9qxhmr5p1hy49mczhsljhbcjq34xi1qnbz4vjprks6ad2hob5gzsc0pct7a81hxudr56cgwd8i5i4ldxh1t5j7ufc0cfaijqv4kk3vpd2qqnh38:latest/predictions.table.json', 'path': 'media/table/predictions_1_284c870192f0196d9e94.table.json', 'size': 35837, '_type': 'table-file', 'ncols': 11, 'nrows': 56, 'sha256': '284c870192f0196d9e941060eaeb76def8d2b14e44f7a1bffc1be9437c3447f0'}",55.06285832888571,,,False,True,validation,False,Yes | Maybe | No,4,CTBase,a0872cde-2f19-4ae6-919a-868da47bfbcb,cb,QA,False,28,bigscience/T0_3B,0,True,based_on,prompts/general_fixed_choice.yaml,AdversarialQA,,3,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,['NLI'],cb,True,False,GeneralFixedChoice,False,False,False,,,prompts,,False,True,based_on,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.adversarial_qa.based_on.LenNorm,CB,,,CommitmentBank,super_glue,,,,,,,,,,,,,,,,,44.0,44.0,16
22.22222222222222,19.047619047619047,0.9043234368582366,9.713611364364624,2.0,0.66424090703893,0.0,0.0,,,,133.78571428571428,8.800429701805115,2.321428571428572,47.61904761904761,0.9131816625595092,0.9469338273973468,0.9062641063805998,0.9469338273973468,1.6785714285714286,25.0,"{'nrows': 56, 'sha256': '373fa0b11f2658fcb11c74e4450113397d4c8211c3a0d26da8428fe92e33a99b', 'artifact_path': 'wandb-client-artifact://y1u4b28u73eeipaddxp3ms3mw8i1cshelnabjw9nstm6tfpisq087ax5665bg1pen4g2aim238hz5l1fyqetalvvx1k6rrts4eqsyife6n482h9hcmbjajej84spjr71:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://y1u4b28u73eeipaddxp3ms3mw8i1cshelnabjw9nstm6tfpisq087ax5665bg1pen4g2aim238hz5l1fyqetalvvx1k6rrts4eqsyife6n482h9hcmbjajej84spjr71:latest/predictions.table.json', 'path': 'media/table/predictions_1_373fa0b11f2658fcb11c.table.json', 'size': 33190, '_type': 'table-file', 'ncols': 11}",55.06285832888571,,,False,True,validation,False,Yes | Maybe | No,4,CTBase,5bdb1815-5c6f-49a3-ad1d-367344420701,cb,QA,False,28,bigscience/T0_3B,0,True,question_context_answer,prompts/general_fixed_choice.yaml,AdversarialQA,,3,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,['NLI'],cb,True,False,GeneralFixedChoice,False,False,False,,,prompts,,False,True,question_context_answer,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.adversarial_qa.question_context_answer.LenNorm,CB,,,CommitmentBank,super_glue,,,,,,,,,,,,,,,,,35.5,24.0,11
20.91132539232369,13.95348837209302,0.95584014835542,9.783779578549522,2.0,0.6782002963089532,0.0,0.0,,,,145.78571428571428,8.872535611901965,2.357142857142857,48.78048780487805,0.9112439666475568,0.9340497736158586,0.9828670659030389,0.9340497736158586,1.6428571428571428,23.214285714285715,"{'_latest_artifact_path': 'wandb-client-artifact://2jay1bdykxi0p2fy2q451e1hficz6jlj2lm4m56nu1lilc1568g3lit420sm1e1fcnvso7xdgsi43rvbm833xq1o56846diiosaelmxv0bs6kv7l0sz9ho53xwguqwdo:latest/predictions.table.json', 'path': 'media/table/predictions_1_c8cf08827c749e00f16e.table.json', 'size': 35816, '_type': 'table-file', 'ncols': 11, 'nrows': 56, 'sha256': 'c8cf08827c749e00f16e39959216b123bcb8d901b112463b677b7896df2d9baf', 'artifact_path': 'wandb-client-artifact://2jay1bdykxi0p2fy2q451e1hficz6jlj2lm4m56nu1lilc1568g3lit420sm1e1fcnvso7xdgsi43rvbm833xq1o56846diiosaelmxv0bs6kv7l0sz9ho53xwguqwdo:latest/predictions.table.json'}",55.06285832888571,,,False,True,validation,False,Yes | Maybe | No,4,CTBase,3b2459cc-6600-443c-abf8-8f60c34cd998,cb,QA,False,28,bigscience/T0_3B,0,True,tell_what_it_is,prompts/general_fixed_choice.yaml,AdversarialQA,,3,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,['NLI'],cb,True,False,GeneralFixedChoice,False,False,False,,,prompts,,False,True,tell_what_it_is,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.adversarial_qa.tell_what_it_is.LenNorm,CB,,,CommitmentBank,super_glue,,,,,,,,,,,,,,,,,44.0,36.0,22
14.285714285714285,14.285714285714285,0.6766999030166148,3.00499621459416,1.9821428571428568,0.6954013528047618,0.132432115840994,0.0,,,,125.78571428571428,1.977651161806924,2.821428571428572,28.57142857142857,1.027345052787236,0.5703114079525468,0.6762935125782323,0.5800136346039898,1.1964285714285714,14.285714285714285,"{'_type': 'table-file', 'ncols': 11, 'nrows': 56, 'sha256': 'e9e3fb06b52da34273e2bd71a0fb8b3cce711a0797035060bce6bb3a08806865', 'artifact_path': 'wandb-client-artifact://z20ukf5vmv1mkfmpufwro4s5ck0uncdgejjmvty7jh9t65pl0fw2uzwondf70636x74hs5awleiy7h055y9la2mf5qac3narrw662bj826axdcf9vnnp28sy01913vwx:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://z20ukf5vmv1mkfmpufwro4s5ck0uncdgejjmvty7jh9t65pl0fw2uzwondf70636x74hs5awleiy7h055y9la2mf5qac3narrw662bj826axdcf9vnnp28sy01913vwx:latest/predictions.table.json', 'path': 'media/table/predictions_1_e9e3fb06b52da34273e2.table.json', 'size': 31581}",55.06285832888572,,,False,True,validation,False,Yes | Maybe | No,4,CTBase,4dd990b3-7201-4cba-bb9a-baa462d68b1a,cb,SENTIMENT,False,28,bigscience/T0_3B,0,True,format_score,prompts/general_fixed_choice.yaml,Yelp,,3,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,['NLI'],cb,True,False,GeneralFixedChoice,False,False,False,,,prompts,,False,True,format_score,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.yelp.format_score.LenNorm,CB,,,CommitmentBank,super_glue,,,,,,,,,,,,,,,,,67.5,65.0,12
9.725906277630417,13.79310344827586,0.7135627842728467,2.9889838099479675,1.9821428571428568,0.6725956730868621,0.132432115840994,0.0,,,,119.78571428571428,1.8858581696237835,2.892857142857143,15.384615384615383,1.1031256403241838,0.4503400076042319,0.7011781252972789,0.4653147935998351,1.125,10.714285714285714,"{'_type': 'table-file', 'ncols': 11, 'nrows': 56, 'sha256': '73cb9e8be64ab06ef6d8cbacdb58be908b321ef8c85fd22c797bde7ee67c77bf', 'artifact_path': 'wandb-client-artifact://14j6dwdzefsln2motjlr0pxireysb827joa1miyvq1h3nwof42awv7m0j5jd8tk142hyahsxyf7w4ceffewctax6o13tcxs80f7erg8j9xr4118igpcaew3ub0vbatqh:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://14j6dwdzefsln2motjlr0pxireysb827joa1miyvq1h3nwof42awv7m0j5jd8tk142hyahsxyf7w4ceffewctax6o13tcxs80f7erg8j9xr4118igpcaew3ub0vbatqh:latest/predictions.table.json', 'path': 'media/table/predictions_1_73cb9e8be64ab06ef6d8.table.json', 'size': 30160}",55.06285832888572,,,False,True,validation,False,Yes | Maybe | No,4,CTBase,29fc6386-90b3-4976-b249-26e49fe7c924,cb,SENTIMENT,False,28,bigscience/T0_3B,0,True,format_star,prompts/general_fixed_choice.yaml,Yelp,,3,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,['NLI'],cb,True,False,GeneralFixedChoice,False,False,False,,,prompts,,False,True,format_star,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.yelp.format_star.LenNorm,CB,,,CommitmentBank,super_glue,,,,,,,,,,,,,,,,,80.5,79.0,6
22.965403258904303,47.37945492662474,1.3344874120331047,10.538986850778262,2.0,1.0102233370571458,0.0,0.0,,,,146.23583333333335,9.021659336686136,2.725,21.516754850088184,1.5173275140921274,0.6887488656977956,1.407807899593977,0.6887488656977956,1.275,33.33333333333333,"{'path': 'media/table/predictions_1_61469a7d9efaa970ffc9.table.json', 'size': 821712, '_type': 'table-file', 'ncols': 11, 'nrows': 1200, 'sha256': '61469a7d9efaa970ffc9550f97128ed25764f865943cc524d1caff34347c7c43', 'artifact_path': 'wandb-client-artifact://nzl3e6pztn7rwv34yicvvkakz0u424fh67ck6fxj5b5w761i9z1xh78260rphuijohft0zcu21ftislg0skt4ji4ks8p6hha9aekxn26scj3vik82kde32e0qeoaz7yk:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://nzl3e6pztn7rwv34yicvvkakz0u424fh67ck6fxj5b5w761i9z1xh78260rphuijohft0zcu21ftislg0skt4ji4ks8p6hha9aekxn26scj3vik82kde32e0qeoaz7yk:latest/predictions.table.json'}",32.01257902719214,,,False,True,dev_r3,False,Yes | Maybe | No,4,CTBase,cd563834-49ee-495d-ac46-99f0264e58d5,anli,QA,False,28,bigscience/T0_3B,0,True,ask_question_as_teacher,prompts/general_fixed_choice.yaml,ZEST,,3,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,['NLI'],anli,False,False,GeneralFixedChoice,False,False,False,,,prompts,,False,True,ask_question_as_teacher,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.zest.ask_question_as_teacher.LenNorm,ANLI R3,,,,,,,,,,,,,,,,,,,,,39.5,51.0,24
8.333333333333332,16.666666666666668,0.6403543542172345,2.8379980666296825,2.0,0.674300373676209,0.0,0.0,,,,123.78571428571428,1.3755604028701782,2.9642857142857144,8.333333333333332,1.462437663759504,0.264864231681988,0.5968158152166638,0.264864231681988,1.0357142857142858,10.714285714285714,"{'artifact_path': 'wandb-client-artifact://i2sdb0tx77axth0vv1418negafmxullg35e6d5pxv17to8c0a2cj5egg88pe6wmposm8hdmzjh2sz9kbzkl9hyzm4xf012fklor9ag0fkrk4h7oxpm950gjpleav7uy7:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://i2sdb0tx77axth0vv1418negafmxullg35e6d5pxv17to8c0a2cj5egg88pe6wmposm8hdmzjh2sz9kbzkl9hyzm4xf012fklor9ag0fkrk4h7oxpm950gjpleav7uy7:latest/predictions.table.json', 'path': 'media/table/predictions_1_493f7e8ece4c977332ae.table.json', 'size': 30894, '_type': 'table-file', 'ncols': 11, 'nrows': 56, 'sha256': '493f7e8ece4c977332ae0fe0866a031b01cd77d023b71756544da457919d5648'}",55.06285832888572,,,False,True,validation,False,Yes | Maybe | No,4,CTBase,27b6bc81-bb1c-467b-91c0-22a4d6a19f44,cb,SENTIMENT,False,28,bigscience/T0_3B,0,True,based_on_that,prompts/general_fixed_choice.yaml,Yelp,,3,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,['NLI'],cb,True,False,GeneralFixedChoice,False,False,False,,,prompts,,False,True,based_on_that,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.yelp.based_on_that.LenNorm,CB,,,CommitmentBank,super_glue,,,,,,,,,,,,,,,,,80.5,82.5,10
20.083184789067143,11.76470588235294,0.8541791420557936,2.543209195137024,1.9642857142857144,0.630716095208573,0.1855768722395225,0.0,,,,120.78571428571428,1.6048272933278764,2.642857142857143,48.48484848484848,0.9383819018091474,0.7659860924831148,0.8682348194100468,0.7717922423205111,1.3928571428571428,19.642857142857142,"{'size': 30602, '_type': 'table-file', 'ncols': 11, 'nrows': 56, 'sha256': '38133b98e2b931678da1c1c78dc652abdacc50c9b4059310df32d77c7074dcd4', 'artifact_path': 'wandb-client-artifact://124i4ve4u4774d3gjeg7cxgqdto6ptea1o23dcul82hfp7y67h4j2l3ev0g2x021tj8320xrjl27unvc1brla14lp9w1xuktxbmqnuzjhzz33jrfjeuug8jw7grshjo6:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://124i4ve4u4774d3gjeg7cxgqdto6ptea1o23dcul82hfp7y67h4j2l3ev0g2x021tj8320xrjl27unvc1brla14lp9w1xuktxbmqnuzjhzz33jrfjeuug8jw7grshjo6:latest/predictions.table.json', 'path': 'media/table/predictions_1_38133b98e2b931678da1.table.json'}",55.06285832888572,,,False,True,validation,False,Yes | Maybe | No,4,CTBase,135fcd11-9fcc-4b55-bf1b-9b76290d0f6b,cb,SENTIMENT,False,28,bigscience/T0_3B,0,True,so_i_would,prompts/general_fixed_choice.yaml,Yelp,,3,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,['NLI'],cb,True,False,GeneralFixedChoice,False,False,False,,,prompts,,False,True,so_i_would,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.yelp.so_i_would.LenNorm,CB,,,CommitmentBank,super_glue,,,,,,,,,,,,,,,,,54.5,46.0,7
24.02402402402402,5.405405405405405,0.289210085937008,0.7029904297419957,1.7678571428571428,0.2790482271290852,0.5342241179161283,13.333333333333334,,,,140.78571428571428,0.2843395641871861,2.1785714285714284,53.33333333333332,0.4186508655548096,0.9656075596139838,0.2104033145149565,0.8328017011686443,2.0535714285714284,26.785714285714285,"{'size': 34330, '_type': 'table-file', 'ncols': 11, 'nrows': 56, 'sha256': '9c1925ab1fa047299ecf398b81a93537a286f3e58551165d0f9a2f56ea1118da', 'artifact_path': 'wandb-client-artifact://f9wct5dda83mauvgrindw0upk9l5vfvdbgedj81i77sddxd9m72n399y75pyudo4xlzo34uujwinoy0sglkb795nmgtsxh3dbjgip7ylb4pg8n9pbje8b19x9yrb7a46:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://f9wct5dda83mauvgrindw0upk9l5vfvdbgedj81i77sddxd9m72n399y75pyudo4xlzo34uujwinoy0sglkb795nmgtsxh3dbjgip7ylb4pg8n9pbje8b19x9yrb7a46:latest/predictions.table.json', 'path': 'media/table/predictions_1_9c1925ab1fa047299ecf.table.json'}",55.06285832888571,,,False,True,validation,False,Yes | Maybe | No,4,CTBase,2da8f134-58db-4f9d-b3b0-8c6b50693ab5,cb,SENTIMENT,False,28,bigscience/T0_3B,0,True,categorize_rating_using_review,prompts/general_fixed_choice.yaml,AppReviews,,3,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,['NLI'],cb,True,False,GeneralFixedChoice,False,False,True,,,prompts,,False,True,categorize_rating_using_review,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.app_reviews.categorize_rating_using_review.LenNorm,CB,,,CommitmentBank,super_glue,,,,,,,,,,,,,,,,,27.5,14.0,18
10.983050847457628,16.94915254237288,0.6296990337997749,2.990651266915457,2.0,0.6692932074616866,0.0,0.0,,,,140.78571428571428,1.6942290578569683,2.9285714285714284,16.0,1.2964222090584892,0.3711537444790451,0.5974700928633677,0.3711537444790451,1.0714285714285714,12.5,"{'ncols': 11, 'nrows': 56, 'sha256': 'b75f1a78dcc37d4bca649cdb0eb8a4f5ced4e567e88728034afd1574bf55eeda', 'artifact_path': 'wandb-client-artifact://5r5dqizjr72vi97sznifdioy19myyu4auc2k0vpn3bszq40b8qypufm2dixwtlya56zbmvvex0nikay5vgy4dea2idd8xb4zgb2lo0ipwdwp3uo2l0udq7ym0vhir4nr:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://5r5dqizjr72vi97sznifdioy19myyu4auc2k0vpn3bszq40b8qypufm2dixwtlya56zbmvvex0nikay5vgy4dea2idd8xb4zgb2lo0ipwdwp3uo2l0udq7ym0vhir4nr:latest/predictions.table.json', 'path': 'media/table/predictions_1_b75f1a78dcc37d4bca64.table.json', 'size': 35444, '_type': 'table-file'}",55.06285832888571,,,False,True,validation,False,Yes | Maybe | No,4,CTBase,d34e1413-2699-4701-baa2-05d931d012ba,cb,SENTIMENT,False,28,bigscience/T0_3B,0,True,convert_to_rating,prompts/general_fixed_choice.yaml,AppReviews,,3,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,['NLI'],cb,True,False,GeneralFixedChoice,False,False,False,,,prompts,,False,True,convert_to_rating,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.app_reviews.convert_to_rating.LenNorm,CB,,,CommitmentBank,super_glue,,,,,,,,,,,,,,,,,74.0,75.5,28
10.726345866614713,16.94915254237288,0.4054623612103145,1.1714667422430856,1.4464285714285714,0.3898069523763802,0.4971218181098234,6.89655172413793,,,,123.78571428571428,0.4591679232461112,2.946428571428572,8.333333333333332,0.7122988189969744,0.293965672020613,0.3002784687767821,0.5567306167185677,1.6071428571428572,12.5,"{'ncols': 11, 'nrows': 56, 'sha256': '12b2251ce12ca686b0ca73d8d139c4759c62021c4ed206a546ee7c8282593cf3', 'artifact_path': 'wandb-client-artifact://v7yqmtl5itdk8g4vcq29blp1snoimdlijzo9u9gb03y21vr9k7z5453gqhiu7k4lo8klj2mjq3rix6dcatirnbc7hgircue9hh4y1cjgzpopma8ogwbe6bkh2j3hywpv:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://v7yqmtl5itdk8g4vcq29blp1snoimdlijzo9u9gb03y21vr9k7z5453gqhiu7k4lo8klj2mjq3rix6dcatirnbc7hgircue9hh4y1cjgzpopma8ogwbe6bkh2j3hywpv:latest/predictions.table.json', 'path': 'media/table/predictions_1_12b2251ce12ca686b0ca.table.json', 'size': 32121, '_type': 'table-file'}",55.06285832888572,,,False,True,validation,False,Yes | Maybe | No,4,CTBase,96538f30-f2c1-430e-8fc6-936a16966d9c,cb,SENTIMENT,False,28,bigscience/T0_3B,0,True,Writer_Expressed_Sentiment,prompts/general_fixed_choice.yaml,IMDB,,3,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,['NLI'],cb,True,False,GeneralFixedChoice,False,False,False,,,prompts,,False,True,Writer Expressed Sentiment,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.imdb.Writer_Expressed_Sentiment.LenNorm,CB,,,CommitmentBank,super_glue,,,,,,,,,,,,,,,,,74.0,77.0,10
5.464480874316941,16.393442622950822,0.4479696566505066,2.6584524427141463,1.5892857142857142,0.5289277706368325,0.4919634754984253,0.0,,,,122.78571428571428,0.5129306146076748,3.0,0.0,2.1455218281064714,0.0,0.3913453441455369,0.4919634754984253,1.4107142857142858,8.928571428571429,"{'_type': 'table-file', 'ncols': 11, 'nrows': 56, 'sha256': 'c1ba7f0c2b110109a336d78ca7ed1ba3a35977a96f031623967bcb5f5141ad48', 'artifact_path': 'wandb-client-artifact://lubql4fa1vtjqw2abh8ons57x1hkiu5s5twdb0w6vy7pvsixunhmxpv93ohgoq682fnt8jsnd7wj98wrsb9zdrddfnnvoxm6p3pydaveknwtwwzk2x31a305dvtw8smy:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://lubql4fa1vtjqw2abh8ons57x1hkiu5s5twdb0w6vy7pvsixunhmxpv93ohgoq682fnt8jsnd7wj98wrsb9zdrddfnnvoxm6p3pydaveknwtwwzk2x31a305dvtw8smy:latest/predictions.table.json', 'path': 'media/table/predictions_1_c1ba7f0c2b110109a336.table.json', 'size': 31468}",55.06285832888572,,,False,True,validation,False,Yes | Maybe | No,4,CTBase,866474a5-1498-46b7-bfee-ac0c5160707f,cb,SENTIMENT,False,28,bigscience/T0_3B,0,True,Reviewer_Sentiment_Feeling,prompts/general_fixed_choice.yaml,IMDB,,3,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,['NLI'],cb,True,False,GeneralFixedChoice,False,False,False,,,prompts,,False,True,Reviewer Sentiment Feeling,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.imdb.Reviewer_Sentiment_Feeling.LenNorm,CB,,,CommitmentBank,super_glue,,,,,,,,,,,,,,,,,86.0,87.5,9
18.82307839754648,5.405405405405405,0.5055313687550592,3.155662400381906,2.0,0.3770374713501869,0.0,0.0,,,,129.78571428571428,2.5781462022236417,2.142857142857143,51.06382978723404,0.5775161981582642,0.989743318610787,0.4052312522560978,0.989743318610787,1.8571428571428568,23.214285714285715,"{'_type': 'table-file', 'ncols': 11, 'nrows': 56, 'sha256': '3a383b517baecbdf80765390c7281df64120a13373def4f92aead19d52d7e6c8', 'artifact_path': 'wandb-client-artifact://fa6f4451syfa0mm5patk8yhey2u2688gucjf4hv5dtzu9a77n8xivks48jwxzi6q06ddwch82ago92iozfrtp11t7ee0ehtpm9bix30a1jdni1c74wyehjf2v0kkwpz2:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://fa6f4451syfa0mm5patk8yhey2u2688gucjf4hv5dtzu9a77n8xivks48jwxzi6q06ddwch82ago92iozfrtp11t7ee0ehtpm9bix30a1jdni1c74wyehjf2v0kkwpz2:latest/predictions.table.json', 'path': 'media/table/predictions_1_3a383b517baecbdf8076.table.json', 'size': 31677}",55.06285832888571,,,False,True,validation,False,Yes | Maybe | No,4,CTBase,5f372fb1-795a-47b6-8ddf-c4fd1579e76a,cb,SENTIMENT,False,28,bigscience/T0_3B,0,True,Sentiment_with_choices,prompts/general_fixed_choice.yaml,IMDB,,3,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,['NLI'],cb,True,False,GeneralFixedChoice,False,False,True,,,prompts,,False,True,Sentiment with choices ,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.imdb.Sentiment_with_choices.LenNorm,CB,,,CommitmentBank,super_glue,,,,,,,,,,,,,,,,,44.0,54.0,6
12.08576998050682,14.035087719298248,0.4861117590967071,3.869434075696128,2.0,0.5422529803189416,0.0,0.0,,,,132.78571428571428,2.9814369763646806,2.857142857142857,22.22222222222221,0.8879970993314471,0.5150787536377127,0.4794937173396706,0.5150787536377127,1.1428571428571428,12.5,"{'ncols': 11, 'nrows': 56, 'sha256': 'b2f36d0c8353e5e2f0d840d273ee2703b96eb91f759b64d47770d5c3fad6801f', 'artifact_path': 'wandb-client-artifact://5g9thrqtw4quoif64dw959l86mvmvlsa7xjh1dx6tz8kx6viwv823d6h4eoufe8uwhpqfx89a1p20qyqqgy2zxckb0h3ghud4gjksd1iwqmx56sya9qem7pttrz147ue:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://5g9thrqtw4quoif64dw959l86mvmvlsa7xjh1dx6tz8kx6viwv823d6h4eoufe8uwhpqfx89a1p20qyqqgy2zxckb0h3ghud4gjksd1iwqmx56sya9qem7pttrz147ue:latest/predictions.table.json', 'path': 'media/table/predictions_1_b2f36d0c8353e5e2f0d8.table.json', 'size': 32564, '_type': 'table-file'}",55.06285832888571,,,False,True,validation,False,Yes | Maybe | No,4,CTBase,2351d12a-e630-4d19-8b41-e199266e38f7,cb,SENTIMENT,False,28,bigscience/T0_3B,0,True,Reviewer_Opinion_bad_good_choices,prompts/general_fixed_choice.yaml,IMDB,,3,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,['NLI'],cb,True,False,GeneralFixedChoice,False,False,True,,,prompts,,False,True,Reviewer Opinion bad good choices,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.imdb.Reviewer_Opinion_bad_good_choices.LenNorm,CB,,,CommitmentBank,super_glue,,,,,,,,,,,,,,,,,74.0,72.0,9
25.868945868945875,15.384615384615383,0.6659597763678224,2.130637986319406,2.0357142857142856,0.3957832248153053,0.1855768722395225,0.0,,,,123.78571428571428,1.485549943787711,2.2142857142857144,62.22222222222224,0.6450880425316947,0.9767710236555244,0.6403770254500638,0.9496239857363094,1.75,30.357142857142858,"{'path': 'media/table/predictions_1_3dac4af863008fe400aa.table.json', 'size': 32105, '_type': 'table-file', 'ncols': 11, 'nrows': 56, 'sha256': '3dac4af863008fe400aae36c6eeb7b9f73798581762d4fe3e1266a937f7491cc', 'artifact_path': 'wandb-client-artifact://12n1hbfujrkxa5xunoeg8u4tn0mm5bzkcw1kurxzebmbp26ioi863g3hxtc43af64zdg7i3bgc9luea4d5ugaaqwmh89esg9fp4tsbz9x201z6rhirvp3w6hjvan2kcu:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://12n1hbfujrkxa5xunoeg8u4tn0mm5bzkcw1kurxzebmbp26ioi863g3hxtc43af64zdg7i3bgc9luea4d5ugaaqwmh89esg9fp4tsbz9x201z6rhirvp3w6hjvan2kcu:latest/predictions.table.json'}",55.06285832888572,,,False,True,validation,False,Yes | Maybe | No,4,CTBase,02ff2949-0f45-4d97-941e-6fa4c0afbc2d,cb,SENTIMENT,False,28,bigscience/T0_3B,0,True,Movie_Expressed_Sentiment_2,prompts/general_fixed_choice.yaml,IMDB,,3,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,['NLI'],cb,True,False,GeneralFixedChoice,False,False,False,,,prompts,,False,True,Movie Expressed Sentiment 2,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.imdb.Movie_Expressed_Sentiment_2.LenNorm,CB,,,CommitmentBank,super_glue,,,,,,,,,,,,,,,,,16.5,6.0,10
24.41019664967225,46.03058994901675,1.1060020951037517,8.856676736176015,2.0,0.783528631303934,0.0,0.0,,,,145.23583333333335,7.748669919272264,2.6283333333333334,27.200000000000003,1.10800681690375,0.7779442282209068,1.1358734368849086,0.7779442282209068,1.3716666666666666,33.416666666666664,"{'path': 'media/table/predictions_1_3c8ce93fdb32f9e1a3c7.table.json', 'size': 823226, '_type': 'table-file', 'ncols': 11, 'nrows': 1200, 'sha256': '3c8ce93fdb32f9e1a3c7c29efdf15b74108bdca3a7f5499581ccdae8e4784398', 'artifact_path': 'wandb-client-artifact://13f0eabh7vzi2qnw75qxun6cq6u1zqvmfsb4io7g900xoivyezi5shyke6f1aytriwhk3gyew6tbawooogavllf3q0na4ln0g664xg0b86pwfss4g99qt2umulrj99x1:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://13f0eabh7vzi2qnw75qxun6cq6u1zqvmfsb4io7g900xoivyezi5shyke6f1aytriwhk3gyew6tbawooogavllf3q0na4ln0g664xg0b86pwfss4g99qt2umulrj99x1:latest/predictions.table.json'}",32.01257902719214,,,False,True,dev_r3,False,Yes | Maybe | No,4,CTBase,7425232a-9880-428c-9ddc-4070e50e22cc,anli,QA,False,28,bigscience/T0_3B,0,True,gpt3_instruct_format,prompts/general_fixed_choice.yaml,ZEST,,3,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,['NLI'],anli,False,False,GeneralFixedChoice,False,False,False,,,prompts,,False,True,gpt3_instruct_format,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.zest.gpt3_instruct_format.LenNorm,ANLI R3,,,,,,,,,,,,,,,,,,,,,37.0,37.0,28
26.438746438746435,17.777777777777782,0.6399581206837849,2.603924879005977,2.0,0.5771039423426306,0.0,0.0,,,,116.73214285714286,1.824329001562936,2.4285714285714284,61.53846153846153,0.7795958774430412,0.9035079029052512,0.5700116269836282,0.9035079029052512,1.5714285714285714,28.57142857142857,"{'sha256': 'b25088dfadac9c931194234dcc92dd621884b7026ee345c84b50446a25c36722', 'artifact_path': 'wandb-client-artifact://3o52fyz4qu4q9nmp221yw9w0j2hkx0qnb9zmgghx08x0ze4wlvhbtp2vv6zv0jc1307vwpu9tjibj61jko1mush77x015uzeuohb8p9qdnacr9nxljqeq4wchmnatwxv:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://3o52fyz4qu4q9nmp221yw9w0j2hkx0qnb9zmgghx08x0ze4wlvhbtp2vv6zv0jc1307vwpu9tjibj61jko1mush77x015uzeuohb8p9qdnacr9nxljqeq4wchmnatwxv:latest/predictions.table.json', 'path': 'media/table/predictions_1_b25088dfadac9c931194.table.json', 'size': 30572, '_type': 'table-file', 'ncols': 11, 'nrows': 56}",55.07997142837876,,,False,True,validation,False,Yes | Maybe | No,4,CTBase,f56ffced-9b16-431a-8a17-501e63cddf73,cb,ENTAILMENT,False,28,bigscience/T0_3B,0,True,imply_separated,prompts/general_fixed_choice.yaml,RTE,,3,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,['NLI'],cb,False,False,GeneralFixedChoice,False,False,True,,,prompts,,False,True,imply separated,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.super_glue_rte.imply_separated.LenNorm,CB,,,CommitmentBank,super_glue,,,,,,,,,,,,,,,,,21.0,3.0,6
20.91132539232369,13.95348837209302,0.6041579267440833,3.466497902359281,2.0,0.6039814946497183,0.0,0.0,,,,121.89285714285714,2.6449854373931885,2.357142857142857,48.78048780487805,0.8215124649660928,0.9340497736158586,0.547433386426409,0.9340497736158586,1.6428571428571428,23.214285714285715,"{'size': 31531, '_type': 'table-file', 'ncols': 11, 'nrows': 56, 'sha256': '01d178b03a502b68887f68917791f1f0a24c9835efe8831bdc6da7c4260d71f6', 'artifact_path': 'wandb-client-artifact://8kt0gixhcyyf0x54oweivscglu91px93134inzvinuxutg0vnjgr31ky0l0p3t4hn4htwaqhnaii8wur8ciyt19xuirogc59t37gu2eflh8s454rnk3umllfuerh7sa5:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://8kt0gixhcyyf0x54oweivscglu91px93134inzvinuxutg0vnjgr31ky0l0p3t4hn4htwaqhnaii8wur8ciyt19xuirogc59t37gu2eflh8s454rnk3umllfuerh7sa5:latest/predictions.table.json', 'path': 'media/table/predictions_1_01d178b03a502b68887f.table.json'}",55.1040180578735,,,False,True,validation,False,Yes | Maybe | No,4,CTBase,c8dfc879-40f2-412d-be1e-4cd70107f6e6,cb,ENTAILMENT,False,28,bigscience/T0_3B,0,True,imply,prompts/general_fixed_choice.yaml,RTE,,3,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,['NLI'],cb,False,False,GeneralFixedChoice,False,False,True,,,prompts,,False,True,imply,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.super_glue_rte.imply.LenNorm,CB,,,CommitmentBank,super_glue,,,,,,,,,,,,,,,,,44.0,36.0,14
17.87878787878788,13.636363636363637,0.6219689055994765,4.256021210125515,2.0,0.5219124812990262,0.0,0.0,,,,149.73214285714286,3.533187883240836,2.392857142857143,40.0,0.7228333268846784,0.9195995135416952,0.4784953879726215,0.9195995135416952,1.6071428571428572,19.642857142857142,"{'_type': 'table-file', 'ncols': 11, 'nrows': 56, 'sha256': '71aad40761665ace234e3ed9e8678ad3cc8732c5640e3386f06f332f19c7aeb4', 'artifact_path': 'wandb-client-artifact://c8o94he13s143ijkb3zz40tlk9fi7j4p1igvd1f93dj4q84kremiyet702volwqg3jum7hoz8ikj7uj37t7mdl7o5u3g0868l6l91ujsi3bmgbq4d84lws89ut5pcufc:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://c8o94he13s143ijkb3zz40tlk9fi7j4p1igvd1f93dj4q84kremiyet702volwqg3jum7hoz8ikj7uj37t7mdl7o5u3g0868l6l91ujsi3bmgbq4d84lws89ut5pcufc:latest/predictions.table.json', 'path': 'media/table/predictions_1_71aad40761665ace234e.table.json', 'size': 40336}",55.07997142837876,,,False,True,validation,False,Yes | Maybe | No,4,CTBase,9e2b4267-ec23-44c8-b82a-107e2c890fec,cb,ENTAILMENT,False,28,bigscience/T0_3B,0,True,entailment_explained,prompts/general_fixed_choice.yaml,RTE,,3,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,['NLI'],cb,False,False,GeneralFixedChoice,False,False,True,,,prompts,,False,True,entailment explained,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.super_glue_rte.entailment_explained.LenNorm,CB,,,CommitmentBank,super_glue,,,,,,,,,,,,,,,,,54.5,59.0,40
10.532915360501567,10.90909090909091,0.5882936146207112,3.5760060293333877,2.0,0.7291237068036902,0.0,0.0,,,,125.89285714285714,2.494647903101785,2.7857142857142856,20.689655172413797,1.0813581262316023,0.618589574131742,0.4820130496544621,0.6185895741317419,1.2142857142857142,10.714285714285714,"{'ncols': 11, 'nrows': 56, 'sha256': 'f0d9911047337db8e19957bde07897ee2fc5e88d6882fbf51c54aa45ee9b71ae', 'artifact_path': 'wandb-client-artifact://12jl5xfbmhuncz73cgtyt8bm1y5ptpy7fkeng6rjqxp8w7lxji5c0m7rakism105mykdeg6468d68vec4hyt77l9ri7q5t3jwyzbk4qpvk41rybhep001ino4dc7tu8w:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://12jl5xfbmhuncz73cgtyt8bm1y5ptpy7fkeng6rjqxp8w7lxji5c0m7rakism105mykdeg6468d68vec4hyt77l9ri7q5t3jwyzbk4qpvk41rybhep001ino4dc7tu8w:latest/predictions.table.json', 'path': 'media/table/predictions_1_f0d9911047337db8e199.table.json', 'size': 32920, '_type': 'table-file'}",55.1040180578735,,,False,True,validation,False,Yes | Maybe | No,4,CTBase,4ee6ff27-de63-4e7b-a9d4-82a17eba407a,cb,ENTAILMENT,False,28,bigscience/T0_3B,0,True,does_the_claim_follow_the_fact,prompts/general_fixed_choice.yaml,RTE,,3,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,['NLI'],cb,False,False,GeneralFixedChoice,False,False,True,,,prompts,,False,True,does the claim follow the fact,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.super_glue_rte.does_the_claim_follow_the_fact.LenNorm,CB,,,CommitmentBank,super_glue,,,,,,,,,,,,,,,,,80.5,78.0,18
23.92156862745098,11.76470588235294,0.5756124385151556,2.7489082132067,2.0,0.4541961377711695,0.0,0.0,,,,119.85714285714286,2.1121214543070117,2.0357142857142856,60.0,0.6367867588996887,0.9993620414023732,0.5589702460004728,0.9993620414023732,1.9642857142857144,30.357142857142858,"{'artifact_path': 'wandb-client-artifact://86qmh00zbntvip80nuy4re5fiso3v2hqn2iypwyatfkmnikcv1ofbgof64qxijachrdczqgyc1b2pmponerl5ijct35hb0xck5vuvqj2v44a6zwslx1hb3nlnapq1asz:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://86qmh00zbntvip80nuy4re5fiso3v2hqn2iypwyatfkmnikcv1ofbgof64qxijachrdczqgyc1b2pmponerl5ijct35hb0xck5vuvqj2v44a6zwslx1hb3nlnapq1asz:latest/predictions.table.json', 'path': 'media/table/predictions_1_b3cc498d3a8fc6604dda.table.json', 'size': 30743, '_type': 'table-file', 'ncols': 11, 'nrows': 56, 'sha256': 'b3cc498d3a8fc6604dda8ecaa597cca90f9321740221f68c8f28bb54f10fe709'}",55.07216971893354,,,False,True,validation,False,Yes | Maybe | No,4,CTBase,03a7ae07-5ddd-46c4-92f3-2152223d44ec,cb,ENTAILMENT,False,28,bigscience/T0_3B,0,True,mean,prompts/general_fixed_choice.yaml,RTE,,3,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,['NLI'],cb,False,False,GeneralFixedChoice,False,False,True,,,prompts,,False,True,mean,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.super_glue_rte.mean.LenNorm,CB,,,CommitmentBank,super_glue,,,,,,,,,,,,,,,,,16.5,15.0,9
21.88997508146445,17.02127659574468,0.9937942350673764,8.22603395155498,2.0,0.7488413685032277,0.0,0.0,,,,122.78571428571428,7.165715779576983,2.5,48.64864864864865,1.0603181719779968,0.8660254037844386,1.042129430689155,0.8660254037844386,1.5,23.214285714285715,"{'nrows': 56, 'sha256': 'd50c7a11a6b362d13cd2596d44cfa558798a7a0a2402264161db3d865327b7b8', 'artifact_path': 'wandb-client-artifact://onra4j57w1mq5b6a9mshxd2fx46ltkwnkvqd2ido6ncoizdhb1r9pxgdqbxxfk989ybix28wi57tlsczk2jtnmxkxlfis4k3pl9f2sd3kqumjsu01ofcmd60wqliqbri:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://onra4j57w1mq5b6a9mshxd2fx46ltkwnkvqd2ido6ncoizdhb1r9pxgdqbxxfk989ybix28wi57tlsczk2jtnmxkxlfis4k3pl9f2sd3kqumjsu01ofcmd60wqliqbri:latest/predictions.table.json', 'path': 'media/table/predictions_1_d50c7a11a6b362d13cd2.table.json', 'size': 31276, '_type': 'table-file', 'ncols': 11}",55.06285832888572,,,False,True,validation,False,Yes | Maybe | No,4,CTBase,f2004e15-9d9a-4ca1-9830-a341e684e97e,cb,QA,False,28,bigscience/T0_3B,0,True,qa_no_choices_and_answer,prompts/general_fixed_choice.yaml,No Prompt,,3,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,['NLI'],cb,False,False,GeneralFixedChoice,False,False,False,,,prompts,,False,True,qa no choices and answer,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.BAREBONES.qa_no_choices_and_answer.LenNorm,CB,,,CommitmentBank,super_glue,,,,,,,,,,,,,,,,,44.0,25.0,0
18.11965811965812,13.333333333333334,1.2100509126079015,3.425127148628235,1.9821428571428568,0.6112510616539912,0.132432115840994,0.0,,,,101.73214285714286,2.5684950820037296,2.4285714285714284,41.02564102564102,0.8566320666245052,0.9035079029052512,1.1546663580867549,0.9019183070838852,1.5892857142857142,19.642857142857142,"{'nrows': 56, 'sha256': '985c9d49cfc9ea885f0075faba23b66ea08ebc6f7d0ad2a904e2b2acb3a361c2', 'artifact_path': 'wandb-client-artifact://e6zo1bqyhkn7xc50acljvriw0ijldx832eyvp34h4f1dzbea1cxhhpc3vshbs6kfd65neemv0wtf58axe4zm8p5io3frlffsx0ak02u0cguzgo59fpd09oyeyvuatodp:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://e6zo1bqyhkn7xc50acljvriw0ijldx832eyvp34h4f1dzbea1cxhhpc3vshbs6kfd65neemv0wtf58axe4zm8p5io3frlffsx0ak02u0cguzgo59fpd09oyeyvuatodp:latest/predictions.table.json', 'path': 'media/table/predictions_1_985c9d49cfc9ea885f00.table.json', 'size': 27839, '_type': 'table-file', 'ncols': 11}",55.07997142837876,,,False,True,validation,False,Yes | Maybe | No,4,CTBase,e5eaa3ee-e537-4d20-9dfa-6084db54f2ef,cb,ENTAILMENT,False,28,bigscience/T0_3B,0,True,entailment_no_choices_and_answer,prompts/general_fixed_choice.yaml,No Prompt,,3,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,['NLI'],cb,False,False,GeneralFixedChoice,False,False,False,,,prompts,,False,True,entailment no choices and answer,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.BAREBONES.entailment_no_choices_and_answer.LenNorm,CB,,,CommitmentBank,super_glue,,,,,,,,,,,,,,,,,54.5,57.0,2
23.691776883266243,17.02127659574468,1.062357033283827,4.412325433322361,2.0,0.6489219402910803,0.0,0.0,,,,115.78571428571428,3.353611946105957,2.5,54.05405405405405,1.0587134872164046,0.8660254037844386,1.0141960737450346,0.8660254037844386,1.5,25.0,"{'size': 29534, '_type': 'table-file', 'ncols': 11, 'nrows': 56, 'sha256': '95a44506db639643565f98ee7989015bf5df0da561b5898bb15246b86172c4e8', 'artifact_path': 'wandb-client-artifact://73ogeglegm5z91ylo8o1s70q494n5nxixuamcvaylle09a6mlxxpd9jhl29g62clp54l6d074zgpv7xv6lkn2af9afmvyk862yasdyvebfawm01scun94dfpranad1u8:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://73ogeglegm5z91ylo8o1s70q494n5nxixuamcvaylle09a6mlxxpd9jhl29g62clp54l6d074zgpv7xv6lkn2af9afmvyk862yasdyvebfawm01scun94dfpranad1u8:latest/predictions.table.json', 'path': 'media/table/predictions_1_95a44506db639643565f.table.json'}",55.06285832888572,,,False,True,validation,False,Yes | Maybe | No,4,CTBase,cf005ddf-8cf2-409d-b884-45d22463f463,cb,CLASSIFICATION,False,28,bigscience/T0_3B,0,True,classification_no_choices_and_answer,prompts/general_fixed_choice.yaml,No Prompt,,3,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,['NLI'],cb,False,False,GeneralFixedChoice,False,False,False,,,prompts,,False,True,classification no choices and answer,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.BAREBONES.classification_no_choices_and_answer.LenNorm,CB,,,CommitmentBank,super_glue,,,,,,,,,,,,,,,,,35.5,16.0,2
18.803418803418804,0.0,0.6330074622229245,4.833435360874448,2.0,0.7364164986444031,0.0,0.0,,,,239.57142857142856,3.183941006660461,1.0357142857142858,56.41025641025641,1.649494354213987,0.2648642316819879,0.6034927212809175,0.2648642316819879,2.9642857142857144,39.285714285714285,"{'_latest_artifact_path': 'wandb-client-artifact://179vvdm5oq97ef1aokqftkjl79zzwg9330lt49hfuqa6633ub8179jh6k4onemq0ertuq5wv0i7en2r28ens4dvl0t380ferrofyudfjatg651s23lm40bbzxmojsuk3:latest/predictions.table.json', 'path': 'media/table/predictions_1_522d637b9348275a9fb2.table.json', 'size': 53869, '_type': 'table-file', 'ncols': 11, 'nrows': 56, 'sha256': '522d637b9348275a9fb276d6ed56f99e8d966cfacf66bf0549a246059bac56b0', 'artifact_path': 'wandb-client-artifact://179vvdm5oq97ef1aokqftkjl79zzwg9330lt49hfuqa6633ub8179jh6k4onemq0ertuq5wv0i7en2r28ens4dvl0t380ferrofyudfjatg651s23lm40bbzxmojsuk3:latest/predictions.table.json'}",110.12571665777143,,,False,True,validation,False,Yes | Maybe | No,4,CTBase,2e94d035-3c3d-44cf-98cb-3d11bea7c17b,cb,QA,False,28,bigscience/T0_3B,0,True,qa_choices_and_answer,prompts/general_fixed_choice.yaml,No Prompt,,3,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,['NLI'],cb,False,False,GeneralFixedChoice,False,False,True,,,prompts,,False,True,qa choices and answer,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.BAREBONES.qa_choices_and_answer.LenNorm,CB,,,CommitmentBank,super_glue,,,,,,,,,,,,,,,,,2.5,55.0,2
24.51812509668437,46.267553584626754,1.1383298703250273,9.883994159003098,2.0,0.8454658685135098,0.0,0.0,,,,152.23583333333335,8.692716011703014,2.595,27.286821705426355,1.1912781473000844,0.8037256994771288,1.1835850206644551,0.8037256994771288,1.405,33.416666666666664,"{'size': 823003, '_type': 'table-file', 'ncols': 11, 'nrows': 1200, 'sha256': '896f096cd74018703828fe4323e0ac1dfa9facd930cd86953d45eceb2863cb49', 'artifact_path': 'wandb-client-artifact://zu82ak3ql96zpvqc5vxe0vzo6ii92avj0ise7mq3it3q7oq2i2emf5xey1bzi41mhpw1k6evayzve1r1hc88o8r7u1ziilfpkuijbwv8tid3nut7ms0a5q0uirh2hf6q:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://zu82ak3ql96zpvqc5vxe0vzo6ii92avj0ise7mq3it3q7oq2i2emf5xey1bzi41mhpw1k6evayzve1r1hc88o8r7u1ziilfpkuijbwv8tid3nut7ms0a5q0uirh2hf6q:latest/predictions.table.json', 'path': 'media/table/predictions_1_896f096cd74018703828.table.json'}",32.01257902719214,,,False,True,dev_r3,False,Yes | Maybe | No,4,CTBase,6f694e45-1d17-4067-a1f6-7dae89c148db,anli,QA,False,28,bigscience/T0_3B,0,True,ask_question_as_kid,prompts/general_fixed_choice.yaml,ZEST,,3,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,['NLI'],anli,False,False,GeneralFixedChoice,False,False,False,,,prompts,,False,True,ask_question_as_kid,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.zest.ask_question_as_kid.LenNorm,ANLI R3,,,,,,,,,,,,,,,,,,,,,37.0,36.0,31
24.6969696969697,15.0,0.6433281837765594,3.0559788335646902,2.0,0.532422593240836,0.0,0.0,,,,112.73214285714286,2.303829544356891,2.25,59.09090909090909,0.7521492892077991,0.9682458365518544,0.6310429936881254,0.9682458365518544,1.75,28.57142857142857,"{'nrows': 56, 'sha256': '804b960d0f2dc745f55af6ba46a8ceea3cfd211698ac87e5627a57d4181fd012', 'artifact_path': 'wandb-client-artifact://jx9498wjjdylv5aq27oleasg9ckt1fq01kb4y3q03e0ghmdl1x8fev1995753df1hmxrwtrfhcis3i0cuy8c9rf9u3cyaepywz5ylotqihzqc7mwhjj6bzvvugi5tbx1:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://jx9498wjjdylv5aq27oleasg9ckt1fq01kb4y3q03e0ghmdl1x8fev1995753df1hmxrwtrfhcis3i0cuy8c9rf9u3cyaepywz5ylotqihzqc7mwhjj6bzvvugi5tbx1:latest/predictions.table.json', 'path': 'media/table/predictions_1_804b960d0f2dc745f55a.table.json', 'size': 29549, '_type': 'table-file', 'ncols': 11}",55.07997142837876,,,False,True,validation,False,Yes | Maybe | No,4,CTBase,c225e598-1efe-4cb6-9f7c-a1b7eb5c7803,cb,ENTAILMENT,False,28,bigscience/T0_3B,0,True,entailment_choices_and_answer,prompts/general_fixed_choice.yaml,No Prompt,,3,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,['NLI'],cb,False,False,GeneralFixedChoice,False,False,True,,,prompts,,False,True,entailment choices and answer,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.BAREBONES.entailment_choices_and_answer.LenNorm,CB,,,CommitmentBank,super_glue,,,,,,,,,,,,,,,,,21.0,9.0,2
20.63492063492064,9.523809523809524,0.6661509068546417,3.5583566278219223,2.0,0.5085714068758042,0.0,0.0,,,,126.78571428571428,2.773940767560686,2.321428571428572,52.38095238095239,0.7844158602612359,0.9469338273973468,0.5136234699864677,0.9469338273973468,1.6785714285714286,23.214285714285715,"{'sha256': 'cc7035cf998fda83806cec7ce817760946281eeed544c8676476c151356ad2bf', 'artifact_path': 'wandb-client-artifact://vig4q41ngqb061jsrhn5temvxkhpm95wd7qc4ogvapf7d2xxvbk0h31tf3aj1bhfavi58ou5kzolyttfm0xeyt8qg5lbriegwjl3vogmf78eadmiksxuegi18vcoqfw7:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://vig4q41ngqb061jsrhn5temvxkhpm95wd7qc4ogvapf7d2xxvbk0h31tf3aj1bhfavi58ou5kzolyttfm0xeyt8qg5lbriegwjl3vogmf78eadmiksxuegi18vcoqfw7:latest/predictions.table.json', 'path': 'media/table/predictions_1_cc7035cf998fda83806c.table.json', 'size': 31342, '_type': 'table-file', 'ncols': 11, 'nrows': 56}",55.06285832888572,,,False,True,validation,False,Yes | Maybe | No,4,CTBase,32a28538-99bc-4c5a-8086-83b885fddb50,cb,CLASSIFICATION,False,28,bigscience/T0_3B,0,True,classification_choices_and_answer,prompts/general_fixed_choice.yaml,No Prompt,,3,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,['NLI'],cb,False,False,GeneralFixedChoice,False,False,True,,,prompts,,False,True,classification choices and answer,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.BAREBONES.classification_choices_and_answer.LenNorm,CB,,,CommitmentBank,super_glue,,,,,,,,,,,,,,,,,44.0,40.0,2
19.55555555555556,0.0,1.1025725837530984,4.675109910113471,2.0,0.9101489600426016,0.0,0.0,,,,226.57142857142856,3.0653641309056963,1.1428571428571428,58.66666666666666,1.6097457792077745,0.5150787536377127,0.9752048250704812,0.5150787536377127,2.857142857142857,39.285714285714285,"{'path': 'media/table/predictions_1_fa97f998eedadc2d8741.table.json', 'size': 51707, '_type': 'table-file', 'ncols': 11, 'nrows': 56, 'sha256': 'fa97f998eedadc2d87418e13f4eb839d76014c8cd075bef7798e4343c3a272f6', 'artifact_path': 'wandb-client-artifact://6mwgj0xeqd050lz0vd63oc69hi7vg3r5svxtqjft7xv88v9bm62unh1ojd7wqgs1q5mmzn7uynerc8axggxmit9uiioauohkvxl2e70a778oqq6xbrn5g4cmxqodt194:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://6mwgj0xeqd050lz0vd63oc69hi7vg3r5svxtqjft7xv88v9bm62unh1ojd7wqgs1q5mmzn7uynerc8axggxmit9uiioauohkvxl2e70a778oqq6xbrn5g4cmxqodt194:latest/predictions.table.json'}",110.12571665777143,,,False,True,validation,False,Yes | Maybe | No,4,CTBase,97030be6-9843-4fc2-98cf-b47b879b5447,cb,QA,False,28,bigscience/T0_3B,0,True,qa_no_choices,prompts/general_fixed_choice.yaml,No Prompt,,3,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,['NLI'],cb,False,False,GeneralFixedChoice,False,False,False,,,prompts,,False,True,qa no choices,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.BAREBONES.qa_no_choices.LenNorm,CB,,,CommitmentBank,super_glue,,,,,,,,,,,,,,,,,2.5,51.0,0
12.364460935889506,12.244897959183673,1.114332978211944,2.3530997037887573,1.875,0.7147001137074874,0.3307189138830738,6.666666666666667,,,,99.73214285714286,1.379800796508789,2.607142857142857,18.181818181818183,0.9732989072799684,0.7717922423205111,1.045363750193816,0.8235608969714433,1.5178571428571428,12.5,"{'nrows': 56, 'sha256': 'b6f2f88dd8827791fcaa39078648d96e05ae8f5e7d7c95e1d6a23b250a26bc2b', 'artifact_path': 'wandb-client-artifact://10pcl6ejjhkqwli3gjxkg7jjv431o28wdu11mzwgbvzmi0qe8ojf388k2959irkkg8ne1hor2y5wbk022vi4z87xvb6b4re8nxf2cg3perb8scq5at7unicz6flg5lvt:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://10pcl6ejjhkqwli3gjxkg7jjv431o28wdu11mzwgbvzmi0qe8ojf388k2959irkkg8ne1hor2y5wbk022vi4z87xvb6b4re8nxf2cg3perb8scq5at7unicz6flg5lvt:latest/predictions.table.json', 'path': 'media/table/predictions_1_b6f2f88dd8827791fcaa.table.json', 'size': 27398, '_type': 'table-file', 'ncols': 11}",55.07997142837876,,,False,True,validation,False,Yes | Maybe | No,4,CTBase,cc2958ca-e826-4fef-96aa-1c4caa188605,cb,ENTAILMENT,False,28,bigscience/T0_3B,0,True,entailment_no_choices,prompts/general_fixed_choice.yaml,No Prompt,,3,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,['NLI'],cb,False,False,GeneralFixedChoice,False,False,False,,,prompts,,False,True,entailment no choices,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.BAREBONES.entailment_no_choices.LenNorm,CB,,,CommitmentBank,super_glue,,,,,,,,,,,,,,,,,74.0,71.0,0
23.07692307692308,19.23076923076923,1.0066382767645694,3.6654311759131297,1.9821428571428568,0.7714675035411354,0.132432115840994,0.0,,,,113.78571428571428,2.383733340672084,2.6785714285714284,50.0,1.2816978352410453,0.7345344214715405,0.998229604972626,0.7386470671409442,1.3392857142857142,23.214285714285715,"{'path': 'media/table/predictions_1_0168a1ca8a7a16b7f372.table.json', 'size': 29026, '_type': 'table-file', 'ncols': 11, 'nrows': 56, 'sha256': '0168a1ca8a7a16b7f372f133d9f71f19dc9af16992fd20ad445acf66e639dc24', 'artifact_path': 'wandb-client-artifact://1315pbxarabq2zn9eacrdrs9ypqsuxy9jrmzzzlp9p79jxpdxzub1l2fus8suw4siwnhp1i7hdl7ucnm2pez8jvzcmb27vjj7ur7t6hp5ar9tl19y4tgz3j487x7b2d2:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://1315pbxarabq2zn9eacrdrs9ypqsuxy9jrmzzzlp9p79jxpdxzub1l2fus8suw4siwnhp1i7hdl7ucnm2pez8jvzcmb27vjj7ur7t6hp5ar9tl19y4tgz3j487x7b2d2:latest/predictions.table.json'}",55.06285832888572,,,False,True,validation,False,Yes | Maybe | No,4,CTBase,74693ecc-f903-488c-968d-6a2bc8e76611,cb,CLASSIFICATION,False,28,bigscience/T0_3B,0,True,classification_no_choices,prompts/general_fixed_choice.yaml,No Prompt,,3,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,['NLI'],cb,False,False,GeneralFixedChoice,False,False,False,,,prompts,,False,True,classification no choices,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.BAREBONES.classification_no_choices.LenNorm,CB,,,CommitmentBank,super_glue,,,,,,,,,,,,,,,,,44.0,21.0,0
19.40928270042194,0.0,0.570446549970391,4.286449006625584,2.0,0.7370485247520934,0.0,0.0,,,,237.57142857142856,2.4100651826177324,1.0,58.22784810126582,1.876383824007852,0.0,0.6061854287248125,0.0,3.0,41.07142857142857,"{'sha256': '053f195b1cd3ae2bb35d4480c33e787bce87dd3bef74de3d73045daa63593cc0', 'artifact_path': 'wandb-client-artifact://5qlyk0pvnkycsfisevfgrp9i8k1xf1awej0avm16elmbb4injug1lpfsz9s1f9gh4ygt2zne8a7yy1clg3vp1edgzfm28dx8br1iqer9i8q9uucooqg6ffmygyy7wkrt:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://5qlyk0pvnkycsfisevfgrp9i8k1xf1awej0avm16elmbb4injug1lpfsz9s1f9gh4ygt2zne8a7yy1clg3vp1edgzfm28dx8br1iqer9i8q9uucooqg6ffmygyy7wkrt:latest/predictions.table.json', 'path': 'media/table/predictions_1_053f195b1cd3ae2bb35d.table.json', 'size': 53359, '_type': 'table-file', 'ncols': 11, 'nrows': 56}",110.12571665777143,,,False,True,validation,False,Yes | Maybe | No,4,CTBase,d92fc0d4-5367-41e1-b35d-1058f22a3c1c,cb,QA,False,28,bigscience/T0_3B,0,True,qa_choices,prompts/general_fixed_choice.yaml,No Prompt,,3,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,['NLI'],cb,False,False,GeneralFixedChoice,False,False,True,,,prompts,,False,True,qa choices,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.BAREBONES.qa_choices.LenNorm,CB,,,CommitmentBank,super_glue,,,,,,,,,,,,,,,,,1.0,53.0,0
16.41025641025641,13.333333333333334,0.7279582563294938,2.350816024201257,1.9642857142857144,0.6683420436949347,0.1855768722395225,0.0,,,,110.73214285714286,1.434765283550535,2.4285714285714284,35.8974358974359,0.916050740650722,0.9035079029052512,0.629095167205004,0.8999716548824395,1.6071428571428572,17.857142857142858,"{'nrows': 56, 'sha256': '18151e32767963e0b7fe00aa9482d8b6dc46f9c2cccbd3b4de54c94ff0a2f88a', 'artifact_path': 'wandb-client-artifact://jpiiynl23ow98x0o7iaqjd8rih9r5ru4ce37ww34th1sceqpnaf9dct21exu3gxxjybdysw1sq0bpgz2yau8m7qho692v3e5cths66p6x7ka1wcm6mbqf44qghju82tp:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://jpiiynl23ow98x0o7iaqjd8rih9r5ru4ce37ww34th1sceqpnaf9dct21exu3gxxjybdysw1sq0bpgz2yau8m7qho692v3e5cths66p6x7ka1wcm6mbqf44qghju82tp:latest/predictions.table.json', 'path': 'media/table/predictions_1_18151e32767963e0b7fe.table.json', 'size': 29005, '_type': 'table-file', 'ncols': 11}",55.07997142837876,,,False,True,validation,False,Yes | Maybe | No,4,CTBase,bb648cf3-d9ab-45a8-9bd7-6ba4585c4b9a,cb,ENTAILMENT,False,28,bigscience/T0_3B,0,True,entailment_choices,prompts/general_fixed_choice.yaml,No Prompt,,3,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,['NLI'],cb,False,False,GeneralFixedChoice,False,False,True,,,prompts,,False,True,entailment choices,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.BAREBONES.entailment_choices.LenNorm,CB,,,CommitmentBank,super_glue,,,,,,,,,,,,,,,,,59.0,60.0,0
20.900076277650648,10.526315789473683,0.5692656361132703,3.065558529325894,2.0,0.4724380436608053,0.0,0.0,,,,124.78571428571428,2.3324821846825734,2.1785714285714284,52.17391304347826,0.7330763446433204,0.9839269509968508,0.451353767150352,0.9839269509968508,1.8214285714285712,25.0,"{'sha256': '8c192115d46128ec6114e8ebf78cb492eb437ed643c59aee6c8ca10314d78879', 'artifact_path': 'wandb-client-artifact://751ir3uonimq72naf0joe5i6d1zzmgii43y3zocto5ywyiaugry6wkirt69cbpbeqtgheaslzenvrpjk1cx78am9fp60jljfsda0lzhg7qcfoqaejrq7334eg0nk6hno:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://751ir3uonimq72naf0joe5i6d1zzmgii43y3zocto5ywyiaugry6wkirt69cbpbeqtgheaslzenvrpjk1cx78am9fp60jljfsda0lzhg7qcfoqaejrq7334eg0nk6hno:latest/predictions.table.json', 'path': 'media/table/predictions_1_8c192115d46128ec6114.table.json', 'size': 30750, '_type': 'table-file', 'ncols': 11, 'nrows': 56}",55.06285832888572,,,False,True,validation,False,Yes | Maybe | No,4,CTBase,88bdb026-e9c9-445b-96ef-0cdb986b7fbd,cb,CLASSIFICATION,False,28,bigscience/T0_3B,0,True,classification_choices,prompts/general_fixed_choice.yaml,No Prompt,,3,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,['NLI'],cb,False,False,GeneralFixedChoice,False,False,True,,,prompts,,False,True,classification choices,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.BAREBONES.classification_choices.LenNorm,CB,,,CommitmentBank,super_glue,,,,,,,,,,,,,,,,,35.5,38.5,0
22.76830573281655,47.050561797752806,1.2324053035286038,10.629907710850238,2.0,0.9260572011090032,0.0,0.0,,,,138.23583333333335,9.264475744962692,2.713333333333334,21.254355400696863,1.3654319658875465,0.700824910769841,1.3005905002614222,0.700824910769841,1.2866666666666666,33.0,"{'artifact_path': 'wandb-client-artifact://17ce7pjb0vu1dq5ccirpa3e3z2w7l660dxlnjoyqy8d6j2fzlam0zx1fe148nwiglj7e5loqk28kz2o4b1y8kkddhotg9tyn1yy0n1yx9ygirra1nflmngrzp23fhhr6:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://17ce7pjb0vu1dq5ccirpa3e3z2w7l660dxlnjoyqy8d6j2fzlam0zx1fe148nwiglj7e5loqk28kz2o4b1y8kkddhotg9tyn1yy0n1yx9ygirra1nflmngrzp23fhhr6:latest/predictions.table.json', 'path': 'media/table/predictions_1_e5a038c0b03208a0a821.table.json', 'size': 777452, '_type': 'table-file', 'ncols': 11, 'nrows': 1200, 'sha256': 'e5a038c0b03208a0a821751f78c40d55db76779c4bb1c4608cd06d0674425021'}",32.01257902719214,,,False,True,dev_r3,False,Yes | Maybe | No,4,CTBase,2283cebf-988e-4bff-96bf-982a09963e49,anli,QA,False,28,bigscience/T0_3B,0,True,answerable_or_not,prompts/general_fixed_choice.yaml,ZEST,,3,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,['NLI'],anli,False,False,GeneralFixedChoice,False,False,False,,,prompts,,False,True,answerable_or_not,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.zest.answerable_or_not.LenNorm,ANLI R3,,,,,,,,,,,,,,,,,,,,,54.0,53.0,20
16.0427807486631,11.76470588235294,0.6718157206574138,4.5069821115051,2.0,0.6251776479012875,0.0,0.0,,,,137.73214285714286,3.545386038720608,2.642857142857143,36.36363636363637,0.961596072784492,0.7659860924831148,0.6476341518619704,0.7659860924831148,1.3571428571428572,16.071428571428573,"{'sha256': '4172f4fed586b1b5d633dbfa43b5cd20372f9ff4b7ff5508cfe4cf86ae3b5f98', 'artifact_path': 'wandb-client-artifact://12xw17kw9uu5aihg3hk1uzo3zy2udir6q15ixrob06bsqr1ptfbsashgvm6w51nsv87aubwz517jvg52fl2i65hy9qhbcrifquy9bpziqxmnurkcrkr6s3c3i7r6t37f:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://12xw17kw9uu5aihg3hk1uzo3zy2udir6q15ixrob06bsqr1ptfbsashgvm6w51nsv87aubwz517jvg52fl2i65hy9qhbcrifquy9bpziqxmnurkcrkr6s3c3i7r6t37f:latest/predictions.table.json', 'path': 'media/table/predictions_1_4172f4fed586b1b5d633.table.json', 'size': 33638, '_type': 'table-file', 'ncols': 11, 'nrows': 56}",55.07997142837876,,,False,True,validation,False,Yes | Maybe | No,4,CTBase,725b5ed0-7728-4890-95a4-a74cb7ae1bb4,cb,ENTAILMENT,False,28,bigscience/T0_3B,0,True,affirmation_true_or_false,prompts/general_fixed_choice.yaml,WiC,,3,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,['NLI'],cb,False,False,GeneralFixedChoice,False,False,True,,,prompts,,False,True,affirmation_true_or_false,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.super_glue_wic.affirmation_true_or_false.LenNorm,CB,,,CommitmentBank,super_glue,,,,,,,,,,,,,,,,,62.5,62.0,25
7.161803713527852,13.79310344827586,0.6766805185635127,4.003684808100973,2.0,0.7223045559717486,0.0,0.0,,,,136.73214285714286,2.800919873373849,2.892857142857143,7.692307692307692,1.202764934727124,0.4503400076042319,0.6744482818925851,0.4503400076042319,1.1071428571428572,8.928571428571429,"{'size': 35666, '_type': 'table-file', 'ncols': 11, 'nrows': 56, 'sha256': 'df8f5e9ec481953fae7b6e3665a22d60b11fbc5302347c505659e7980adb7959', 'artifact_path': 'wandb-client-artifact://r9igshduadfgxr8w4v6eisfbizuzbj5n50wgo2ll483exe30ey1uhke4hxb2n047f0vpi0xw2spo4p83bct4zj9d9vi4ib33fche7ivzvg7cdwbnyp1sm731jvw7o9si:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://r9igshduadfgxr8w4v6eisfbizuzbj5n50wgo2ll483exe30ey1uhke4hxb2n047f0vpi0xw2spo4p83bct4zj9d9vi4ib33fche7ivzvg7cdwbnyp1sm731jvw7o9si:latest/predictions.table.json', 'path': 'media/table/predictions_1_df8f5e9ec481953fae7b.table.json'}",55.07997142837876,,,False,True,validation,False,Yes | Maybe | No,4,CTBase,611d13dc-d414-4b9b-9204-e4f325e859e7,cb,ENTAILMENT,False,28,bigscience/T0_3B,0,True,grammar_homework,prompts/general_fixed_choice.yaml,WiC,,3,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,['NLI'],cb,False,False,GeneralFixedChoice,False,False,True,,,prompts,,False,True,grammar_homework,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.super_glue_wic.grammar_homework.LenNorm,CB,,,CommitmentBank,super_glue,,,,,,,,,,,,,,,,,86.0,86.0,25
11.574074074074074,12.5,1.022708918325297,6.770529585225241,2.0,0.6870506344206811,0.0,0.0,,,,116.73214285714286,5.799382609980447,2.5357142857142856,22.22222222222222,0.9711469752447944,0.8443993155383492,0.8769693811203757,0.8443993155383491,1.4642857142857142,12.5,"{'_type': 'table-file', 'ncols': 11, 'nrows': 56, 'sha256': '789ed60185ed48de489383f7c06905f04e7bcce4da7f0135f8e979404a62d496', 'artifact_path': 'wandb-client-artifact://2qe0sk087v3t3vpkysu283ku6gu7pfo7plauabs1hkj0x6lz05vg8ldeppxfangvnlli9rlvldqyq3z3in98lgr6l36z3jkgqqza4jmsc0k4c8ea91mreq1xktyuuh88:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://2qe0sk087v3t3vpkysu283ku6gu7pfo7plauabs1hkj0x6lz05vg8ldeppxfangvnlli9rlvldqyq3z3in98lgr6l36z3jkgqqza4jmsc0k4c8ea91mreq1xktyuuh88:latest/predictions.table.json', 'path': 'media/table/predictions_1_789ed60185ed48de4893.table.json', 'size': 31550}",55.07997142837876,,,False,True,validation,False,Yes | Maybe | No,4,CTBase,3503ead5-4fa5-4f77-95dc-f0c2ed3eecdc,cb,ENTAILMENT,False,28,bigscience/T0_3B,0,True,question_context_meaning,prompts/general_fixed_choice.yaml,WiC,,3,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,['NLI'],cb,False,False,GeneralFixedChoice,False,False,False,,,prompts,,False,True,question-context-meaning,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.super_glue_wic.question_context_meaning.LenNorm,CB,,,CommitmentBank,super_glue,,,,,,,,,,,,,,,,,74.0,74.0,14
13.80392156862745,12.000000000000002,0.6648935200573037,3.9337185876710072,2.0,0.6683891198262896,0.0,0.0,,,,128.73214285714286,2.9531716278621127,2.607142857142857,29.411764705882355,0.9805469598088946,0.794592695045964,0.5953989469250467,0.794592695045964,1.3928571428571428,14.285714285714285,"{'artifact_path': 'wandb-client-artifact://6p703ig8wkdd3igk2ckp91hay53sdzmrnpdgabc0of7d8srsd52o1o1e5ssjwebh8jbk8iroy7g9xpikhraqjwoiph1ydwdy8gmi00qa8utz36d0mfgu1m8cz9le4dlq:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://6p703ig8wkdd3igk2ckp91hay53sdzmrnpdgabc0of7d8srsd52o1o1e5ssjwebh8jbk8iroy7g9xpikhraqjwoiph1ydwdy8gmi00qa8utz36d0mfgu1m8cz9le4dlq:latest/predictions.table.json', 'path': 'media/table/predictions_1_b195716430e462be1963.table.json', 'size': 33167, '_type': 'table-file', 'ncols': 11, 'nrows': 56, 'sha256': 'b195716430e462be19636cc8fc1589daa52f076015e3dbc0c4557d3a8017ce26'}",55.07997142837876,,,False,True,validation,False,Yes | Maybe | No,4,CTBase,14e73f39-a0d1-44c2-b9a4-4e48f9f1608e,cb,ENTAILMENT,False,28,bigscience/T0_3B,0,True,question_context_meaning_with_label,prompts/general_fixed_choice.yaml,WiC,,3,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,['NLI'],cb,False,False,GeneralFixedChoice,False,False,True,,,prompts,,False,True,question-context-meaning-with-label,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.super_glue_wic.question_context_meaning_with_label.LenNorm,CB,,,CommitmentBank,super_glue,,,,,,,,,,,,,,,,,67.5,68.0,16
19.545454545454547,13.636363636363637,0.9616536516253046,9.045507946184705,2.0,0.7397441105536152,0.0,0.0,,,,151.78571428571428,8.142738699913025,2.392857142857143,45.0,0.9027692462716784,0.9195995135416952,0.9348329404807676,0.9195995135416952,1.6071428571428572,21.428571428571427,"{'_latest_artifact_path': 'wandb-client-artifact://a7x6s6b7lhl89v7t4ptzr7x0048l05l5xm64pp89q78wqw9luwq76ku3opbf9d77z1lmhcaqf3tzvkdxxnc1eeeg8hpdqo04y7ccln5pslhzt5dd4uxjp8agy3569on0:latest/predictions.table.json', 'path': 'media/table/predictions_1_bf5864ba2555ae5eb881.table.json', 'size': 38006, '_type': 'table-file', 'ncols': 11, 'nrows': 56, 'sha256': 'bf5864ba2555ae5eb88155df86682e4bc6e3e96f2a6b8ba8bf7a0c00b6c3ad0e', 'artifact_path': 'wandb-client-artifact://a7x6s6b7lhl89v7t4ptzr7x0048l05l5xm64pp89q78wqw9luwq76ku3opbf9d77z1lmhcaqf3tzvkdxxnc1eeeg8hpdqo04y7ccln5pslhzt5dd4uxjp8agy3569on0:latest/predictions.table.json'}",55.06285832888571,,,False,True,validation,False,Yes | Maybe | No,4,CTBase,cd563834-49ee-495d-ac46-99f0264e58d5,cb,QA,False,28,bigscience/T0_3B,0,True,ask_question_as_teacher,prompts/general_fixed_choice.yaml,ZEST,,3,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,['NLI'],cb,False,False,GeneralFixedChoice,False,False,False,,,prompts,,False,True,ask_question_as_teacher,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.zest.ask_question_as_teacher.LenNorm,CB,,,CommitmentBank,super_glue,,,,,,,,,,,,,,,,,50.0,52.0,24
21.06060606060606,18.181818181818183,0.6759668460141882,7.739570626190731,2.0,0.5690592440422131,0.0,0.0,,,,150.78571428571428,6.970627141850335,2.392857142857143,45.0,0.7689434843403953,0.9195995135416952,0.6622100075003375,0.9195995135416952,1.6071428571428572,23.214285714285715,"{'_type': 'table-file', 'ncols': 11, 'nrows': 56, 'sha256': '74fd57c960535d0b1dec9fba3e81cbafd25c6a11b804e77023719fdd422571e9', 'artifact_path': 'wandb-client-artifact://p9vt96ik4a19qs9systawvqg88ul240n8rkeo6nqggdzfcay2jy795lgvpgg4wo7fsu20gs2ezdqukgnv0xzp6u9bfwuaj8wa7ytx54w6npib9zmgvrwn1sz6lmaapev:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://p9vt96ik4a19qs9systawvqg88ul240n8rkeo6nqggdzfcay2jy795lgvpgg4wo7fsu20gs2ezdqukgnv0xzp6u9bfwuaj8wa7ytx54w6npib9zmgvrwn1sz6lmaapev:latest/predictions.table.json', 'path': 'media/table/predictions_1_74fd57c960535d0b1dec.table.json', 'size': 38056}",55.06285832888571,,,False,True,validation,False,Yes | Maybe | No,4,CTBase,7425232a-9880-428c-9ddc-4070e50e22cc,cb,QA,False,28,bigscience/T0_3B,0,True,gpt3_instruct_format,prompts/general_fixed_choice.yaml,ZEST,,3,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,['NLI'],cb,False,False,GeneralFixedChoice,False,False,False,,,prompts,,False,True,gpt3_instruct_format,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.zest.gpt3_instruct_format.LenNorm,CB,,,CommitmentBank,super_glue,,,,,,,,,,,,,,,,,44.0,32.0,28
24.3939393939394,18.181818181818183,0.7574961525559482,8.894265800714493,2.0,0.6480713579554699,0.0,0.0,,,,157.78571428571428,8.013004916054863,2.392857142857143,55.00000000000001,0.8812608846596309,0.9195995135416952,0.8491152139754243,0.9195995135416952,1.6071428571428572,26.785714285714285,"{'_type': 'table-file', 'ncols': 11, 'nrows': 56, 'sha256': '46e3e4043eff84aabed4090c15d65aa4d712820293529436f708de264d56bfa5', 'artifact_path': 'wandb-client-artifact://szqc7y3rmakf1jlo83blb0ujhzld14dnqua50eve1dk29pxvc2l048fr7ey9hv8q634jza6iemd3a32kgi9mw3lblet85am60c7cbix6mr6rzs6qgzh0g66knvlpjg3l:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://szqc7y3rmakf1jlo83blb0ujhzld14dnqua50eve1dk29pxvc2l048fr7ey9hv8q634jza6iemd3a32kgi9mw3lblet85am60c7cbix6mr6rzs6qgzh0g66knvlpjg3l:latest/predictions.table.json', 'path': 'media/table/predictions_1_46e3e4043eff84aabed4.table.json', 'size': 38061}",55.06285832888571,,,False,True,validation,False,Yes | Maybe | No,4,CTBase,6f694e45-1d17-4067-a1f6-7dae89c148db,cb,QA,False,28,bigscience/T0_3B,0,True,ask_question_as_kid,prompts/general_fixed_choice.yaml,ZEST,,3,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,['NLI'],cb,False,False,GeneralFixedChoice,False,False,False,,,prompts,,False,True,ask_question_as_kid,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.zest.ask_question_as_kid.LenNorm,CB,,,CommitmentBank,super_glue,,,,,,,,,,,,,,,,,27.5,10.0,31
20.91132539232369,13.95348837209302,0.906787864153215,9.334818720817566,2.0,0.667939276470524,0.0,0.0,,,,143.78571428571428,8.427664680140358,2.357142857142857,48.78048780487805,0.9071540406772068,0.9340497736158586,1.014467969466965,0.9340497736158586,1.6428571428571428,23.214285714285715,"{'_latest_artifact_path': 'wandb-client-artifact://ob4oe67mpi41dn13i5ar2152x2cqltddpq5ql6bzurz0x24n9zldnygbwc0btdwznat0mv27tie4o5rqjruj3azqlgme82oj9fjxnz04kecng2a683y3ospv5sdq5veu:latest/predictions.table.json', 'path': 'media/table/predictions_1_e2eb8301ae4620b6489d.table.json', 'size': 35937, '_type': 'table-file', 'ncols': 11, 'nrows': 56, 'sha256': 'e2eb8301ae4620b6489dc820a90f744fe35c9171e7ff251cfbaf9af5c603ef61', 'artifact_path': 'wandb-client-artifact://ob4oe67mpi41dn13i5ar2152x2cqltddpq5ql6bzurz0x24n9zldnygbwc0btdwznat0mv27tie4o5rqjruj3azqlgme82oj9fjxnz04kecng2a683y3ospv5sdq5veu:latest/predictions.table.json'}",55.06285832888571,,,False,True,validation,False,Yes | Maybe | No,4,CTBase,2283cebf-988e-4bff-96bf-982a09963e49,cb,QA,False,28,bigscience/T0_3B,0,True,answerable_or_not,prompts/general_fixed_choice.yaml,ZEST,,3,,,GenFC,"['BAREBONES', 'super_glue/wic', 'BIG-BENCH', 'zest', 'super_glue/rte', 'imdb', 'app_reviews', 'yelp', 'adversarial_qa']",False,['NLI'],cb,False,False,GeneralFixedChoice,False,False,False,,,prompts,,False,True,answerable_or_not,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.zest.answerable_or_not.LenNorm,CB,,,CommitmentBank,super_glue,,,,,,,,,,,,,,,,,44.0,36.0,20
70.37037037037037,,0.5154075030069343,0.661626931131962,,,,70.37037037037037,,,,114.5956678700361,0.661626931131962,1.5018050541516246,71.83098591549297,,0.4999967417688936,0.5154075030069343,0.4999967417688936,1.4981949458483754,71.11913357400722,"{'artifact_path': 'wandb-client-artifact://193c6w7kno1b4c0fgyp78bu64xxjrzih8j5c8krffr0o0oghd2ma33jnzxm2k6uolhkqcdlu7w3ep6ahnkigv9vyfslvk9aog59537xv0vowiupext6udrhhlpgv21ez:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://193c6w7kno1b4c0fgyp78bu64xxjrzih8j5c8krffr0o0oghd2ma33jnzxm2k6uolhkqcdlu7w3ep6ahnkigv9vyfslvk9aog59537xv0vowiupext6udrhhlpgv21ez:latest/predictions.table.json', 'path': 'media/table/predictions_1_6e96405a6e28c14e5bee.table.json', 'size': 140556, '_type': 'table-file', 'ncols': 9, 'nrows': 277, 'sha256': '6e96405a6e28c14e5bee0bea2d40d581c20f4dd2afe6c9bf8c5d59bc8516e29d'}",46.467282647943954,,,False,True,validation,True,Yes | No,4,CTBase,c0403841-68b0-4c08-8c3b-a00a81272d05,rte,MCQ,False,28,bigscience/T0_3B,0,True,Answer_questions_from_options,prompts/general_fixed_choice.yaml,AQuA,,2,,,GenFC,"['aqua_rat/raw', 'math_qa', 'craigslist_bargains']",False,NLI,rte,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,Answer questions from options,,cross_task,two_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.aqua_rat_raw.Answer_questions_from_options.LenNorm,RTE,78.72892363989973,81.71076022168776,RecognizingTextualEntailment,super_glue,,,,,,,,,,,,,,,,,11.5,44.0,11
69.23076923076924,,0.4866912774661456,0.5933936890281926,,,,69.23076923076924,,,,126.5956678700361,0.5933936890281926,1.4657039711191335,72.78911564625851,,0.498822395651,0.4866912774661456,0.498822395651,1.5342960288808665,71.11913357400722,"{'nrows': 277, 'sha256': 'b3fc3e8853dc0c32de58b26edad4666d0d1dccf5326177b59c44e11dd2e86e5c', 'artifact_path': 'wandb-client-artifact://qvsopau1biu9numjxunccmem6619ovxe3294b5mtoxe6dit9hucbz212r0lodrag5vkke3em3p4yam7ptyadqfenjc68z147gyq5za4yca01gg59l4sr3oxakm06i6vb:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://qvsopau1biu9numjxunccmem6619ovxe3294b5mtoxe6dit9hucbz212r0lodrag5vkke3em3p4yam7ptyadqfenjc68z147gyq5za4yca01gg59l4sr3oxakm06i6vb:latest/predictions.table.json', 'path': 'media/table/predictions_1_b3fc3e8853dc0c32de58.table.json', 'size': 152753, '_type': 'table-file', 'ncols': 9}",46.467282647943954,,,False,True,validation,True,Yes | No,4,CTBase,815acaf5-2e59-4f81-8190-ae75dc237cf1,rte,MCQ,False,28,bigscience/T0_3B,0,True,answer_quiz,prompts/general_fixed_choice.yaml,AQuA,,2,,,GenFC,"['aqua_rat/raw', 'math_qa', 'craigslist_bargains']",False,NLI,rte,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,answer_quiz,,cross_task,two_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.aqua_rat_raw.answer_quiz.LenNorm,RTE,78.11755878362096,80.81668932343406,RecognizingTextualEntailment,super_glue,,,,,,,,,,,,,,,,,11.5,50.0,23
76.47058823529412,,0.6140876338299738,0.851589093569814,,,,76.47058823529412,,,,114.5956678700361,0.851589093569814,1.6317689530685922,70.96774193548387,,0.4823245204291475,0.6140876338299738,0.4823245204291475,1.3682310469314078,74.0072202166065,"{'_type': 'table-file', 'ncols': 9, 'nrows': 277, 'sha256': 'eb58ad621355334efd88b3b28696119da9310181cf8e3badf5f90798094b6699', 'artifact_path': 'wandb-client-artifact://zpk91lg5bd2fmvpu0s3erf9qi8cksq8891jgc376zksk1ydz26ki3jjhctkf9qwortwn8x0mqll9ehm2283c94l84qjpx0nwo1bq362qwnipttl15f4cpgnb118hnudp:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://zpk91lg5bd2fmvpu0s3erf9qi8cksq8891jgc376zksk1ydz26ki3jjhctkf9qwortwn8x0mqll9ehm2283c94l84qjpx0nwo1bq362qwnipttl15f4cpgnb118hnudp:latest/predictions.table.json', 'path': 'media/table/predictions_1_eb58ad621355334efd88.table.json', 'size': 140933}",46.467282647943954,,,False,True,validation,True,Yes | No,4,CTBase,5acfaa48-e1b6-44df-8e92-c58b94bff595,rte,MCQ,False,28,bigscience/T0_3B,0,True,generate_rationale,prompts/general_fixed_choice.yaml,AQuA,,2,,,GenFC,"['aqua_rat/raw', 'math_qa', 'craigslist_bargains']",False,NLI,rte,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,generate_rationale,,cross_task,two_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.aqua_rat_raw.generate_rationale.LenNorm,RTE,79.60946386926227,82.2388371849838,RecognizingTextualEntailment,super_glue,,,,,,,,,,,,,,,,,4.0,5.0,17
62.00873362445415,,0.501782876974634,0.6296704753641618,,,,62.00873362445415,,,,136.5956678700361,0.6296704753641618,1.3537906137184117,73.23076923076924,,0.4781451823067563,0.501782876974634,0.4781451823067563,1.6462093862815883,68.59205776173285,"{'size': 161613, '_type': 'table-file', 'ncols': 9, 'nrows': 277, 'sha256': 'cc60d61f2d4fa53be0905c9de33fab8ac50d779e3bf40e5c5e47a1422aef75e1', 'artifact_path': 'wandb-client-artifact://wle22jic933xdsk6qiieb1klwo8xip83p84ivv6m803irw23g1p1oln1cpy1ytxdt25i0cczppcwu47711f35kk53vx6kxuatb5cuo7a0vdin386wo3np75kf1y40417:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://wle22jic933xdsk6qiieb1klwo8xip83p84ivv6m803irw23g1p1oln1cpy1ytxdt25i0cczppcwu47711f35kk53vx6kxuatb5cuo7a0vdin386wo3np75kf1y40417:latest/predictions.table.json', 'path': 'media/table/predictions_1_cc60d61f2d4fa53be090.table.json'}",46.467282647943954,,,False,True,validation,True,Yes | No,4,CTBase,58a6aa2b-ca26-473d-9bf8-385dd1a743cd,rte,MCQ,False,28,bigscience/T0_3B,0,True,generate_rational_and_correct_choice,prompts/general_fixed_choice.yaml,AQuA,,2,,,GenFC,"['aqua_rat/raw', 'math_qa', 'craigslist_bargains']",False,NLI,rte,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,generate_rational_and_correct_choice,,cross_task,two_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.aqua_rat_raw.generate_rational_and_correct_choice.LenNorm,RTE,76.25389927080043,79.93830387953571,RecognizingTextualEntailment,super_glue,,,,,,,,,,,,,,,,,21.0,87.0,33
72.91666666666666,,0.5089083182732074,0.6907535270663375,,,,72.91666666666666,,,,115.5956678700361,0.6907535270663375,1.5667870036101084,70.67669172932331,,0.495519420556635,0.5089083182732074,0.495519420556635,1.4332129963898916,71.84115523465704,"{'sha256': '310917a5452f052a8adaebf99d83901a15ac8bfe9ed18e971b900435cf3e6993', 'artifact_path': 'wandb-client-artifact://pmxdsst3bwj4k7c65qhrkgucfssqo73id821kch4qvmr367kp2mwzukulle5td0rjipbphqwgd9vtcyv4535vkf97ws1np2ckbeeyi8s05smdjq3utnoxrnc2s50b1bx:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://pmxdsst3bwj4k7c65qhrkgucfssqo73id821kch4qvmr367kp2mwzukulle5td0rjipbphqwgd9vtcyv4535vkf97ws1np2ckbeeyi8s05smdjq3utnoxrnc2s50b1bx:latest/predictions.table.json', 'path': 'media/table/predictions_1_310917a5452f052a8ada.table.json', 'size': 141190, '_type': 'table-file', 'ncols': 9, 'nrows': 277}",46.467282647943954,,,False,True,validation,True,Yes | No,4,CTBase,13bd5099-33fa-4383-a441-33a7d2e1746f,rte,MCQ,False,28,bigscience/T0_3B,0,True,select_the_best_option,prompts/general_fixed_choice.yaml,AQuA,,2,,,GenFC,"['aqua_rat/raw', 'math_qa', 'craigslist_bargains']",False,NLI,rte,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,select_the_best_option,,cross_task,two_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.aqua_rat_raw.select_the_best_option.LenNorm,RTE,77.65700600172671,81.44933598243229,RecognizingTextualEntailment,super_glue,,,,,,,,,,,,,,,,,8.5,23.0,12
76.51006711409396,,0.672152690363473,0.9265785245258455,,,,76.51006711409396,,,,105.5956678700361,0.9265785245258455,1.6028880866425992,72.65625000000001,,0.4892995418218016,0.672152690363473,0.4892995418218016,1.3971119133574008,74.72924187725631,"{'size': 131933, '_type': 'table-file', 'ncols': 9, 'nrows': 277, 'sha256': '1fef42d235d1fa0375e8dce5a84e010a78daafa7c7d228427d478cd9734c09c9', 'artifact_path': 'wandb-client-artifact://165damskuc7u105wm1vbv2q4pfum7dfe869dhwqddzh0mz8o2adg3jc3lkhx55lodufs5mxtjzl8srp5tgpc47e50ed1te6lxojc92wkjthpq1ndcl71cp4ae8yloj8f:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://165damskuc7u105wm1vbv2q4pfum7dfe869dhwqddzh0mz8o2adg3jc3lkhx55lodufs5mxtjzl8srp5tgpc47e50ed1te6lxojc92wkjthpq1ndcl71cp4ae8yloj8f:latest/predictions.table.json', 'path': 'media/table/predictions_1_1fef42d235d1fa0375e8.table.json'}",46.467282647943954,,,False,True,validation,True,Yes | No,4,CTBase,eb89c860-5849-461a-9081-3bd466f5642c,rte,MCQ,False,28,bigscience/T0_3B,0,True,gre_problem,prompts/general_fixed_choice.yaml,MathQA,,2,,,GenFC,"['aqua_rat/raw', 'math_qa', 'craigslist_bargains']",False,NLI,rte,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,gre_problem,,cross_task,two_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.math_qa.gre_problem.LenNorm,RTE,80.54902606388964,83.3106765659312,RecognizingTextualEntailment,super_glue,,,,,,,,,,,,,,,,,2.0,4.0,8
74.40476190476191,,0.8332940542954694,1.240676683639361,,,,74.40476190476191,,,,118.5956678700361,1.240676683639361,1.740072202166065,60.55045871559632,,0.4385947306422366,0.8332940542954694,0.4385947306422366,1.259927797833935,68.95306859205776,"{'artifact_path': 'wandb-client-artifact://5bg2qeshkoiexz2sdnmk479cwj5tkf8q5k4me81eccgl3ubu788n6kbuyth0mvt38uh13rpfild3qfpcdqa9u1o8swa0tf79sij7qt19u6as08i3y8r0sju4aqz568ro:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://5bg2qeshkoiexz2sdnmk479cwj5tkf8q5k4me81eccgl3ubu788n6kbuyth0mvt38uh13rpfild3qfpcdqa9u1o8swa0tf79sij7qt19u6as08i3y8r0sju4aqz568ro:latest/predictions.table.json', 'path': 'media/table/predictions_1_78c8b653e871f3d773b3.table.json', 'size': 152373, '_type': 'table-file', 'ncols': 9, 'nrows': 277, 'sha256': '78c8b653e871f3d773b34018227dba7a1db07fc86cd753a1e53caad34165d264'}",46.467282647943954,,,False,True,validation,True,Yes | No,4,CTBase,a313a5f8-53cd-4b76-abb6-fea2ac4e9ef4,rte,MCQ,False,28,bigscience/T0_3B,0,True,first_choice_then_problem,prompts/general_fixed_choice.yaml,MathQA,,2,,,GenFC,"['aqua_rat/raw', 'math_qa', 'craigslist_bargains']",False,NLI,rte,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,first_choice_then_problem,,cross_task,two_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.math_qa.first_choice_then_problem.LenNorm,RTE,78.11122043591423,81.70553173690264,RecognizingTextualEntailment,super_glue,,,,,,,,,,,,,,,,,19.0,14.0,21
76.72131147540983,,0.6300073041474281,0.8819744246961407,,,,76.72131147540983,,,,107.5956678700361,0.8819744246961407,1.628158844765343,71.4859437751004,,0.4832962968080894,0.6300073041474281,0.4832962968080894,1.371841155234657,74.36823104693141,"{'nrows': 277, 'sha256': '7ea00f358cb81c017df7570bd8ba0c2a06939ad8223f3a04a93f5dfcb43ec143', 'artifact_path': 'wandb-client-artifact://d0uoxe7d65tsjlm8iicyzb2x2hxmgowh4fnsqdwgp8my2bo80huecdjwxtxvlauakom90mai8d4grtv0rggmoatdkvfoquceb3aatwoj03o2e2vwujvcd2y5kj0wxn7t:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://d0uoxe7d65tsjlm8iicyzb2x2hxmgowh4fnsqdwgp8my2bo80huecdjwxtxvlauakom90mai8d4grtv0rggmoatdkvfoquceb3aatwoj03o2e2vwujvcd2y5kj0wxn7t:latest/predictions.table.json', 'path': 'media/table/predictions_1_7ea00f358cb81c017df7.table.json', 'size': 136598, '_type': 'table-file', 'ncols': 9}",46.467282647943954,,,False,True,validation,True,Yes | No,4,CTBase,8c4c81cc-ca54-45fc-a69a-4b97a5f2b465,rte,MCQ,False,28,bigscience/T0_3B,0,True,pick_the_correct,prompts/general_fixed_choice.yaml,MathQA,,2,,,GenFC,"['aqua_rat/raw', 'math_qa', 'craigslist_bargains']",False,NLI,rte,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,pick_the_correct,,cross_task,two_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.math_qa.pick_the_correct.LenNorm,RTE,80.23104481800239,82.88716929833734,RecognizingTextualEntailment,super_glue,,,,,,,,,,,,,,,,,3.0,3.0,10
74.67532467532466,,0.5366945693090472,0.753522655163431,,,,74.67532467532466,,,,114.5956678700361,0.753522655163431,1.6389891696750902,68.29268292682927,,0.4802936713231072,0.5366945693090472,0.4802936713231072,1.3610108303249098,71.84115523465704,"{'_type': 'table-file', 'ncols': 9, 'nrows': 277, 'sha256': '31a8929a283d97557f97671a0f2a627ac98f5c33ac436b52cfca4b0bb77c1be6', 'artifact_path': 'wandb-client-artifact://8e45j0wl2ptvuyg11j1dv6tqcug8ucoyuflg1jpv2ednhe0oedzsg3hi69qdhmat4b763jahiahn1lrv0ghxedc2roka1vbj5d99fgjaoi54anm7jqdbe4y7mlkj1r7x:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://8e45j0wl2ptvuyg11j1dv6tqcug8ucoyuflg1jpv2ednhe0oedzsg3hi69qdhmat4b763jahiahn1lrv0ghxedc2roka1vbj5d99fgjaoi54anm7jqdbe4y7mlkj1r7x:latest/predictions.table.json', 'path': 'media/table/predictions_1_31a8929a283d97557f97.table.json', 'size': 145033}",46.467282647943954,,,False,True,validation,True,Yes | No,4,CTBase,6312d599-8ca4-4bc8-a76f-81f2e36727bd,rte,MCQ,False,28,bigscience/T0_3B,0,True,choose_correct_og,prompts/general_fixed_choice.yaml,MathQA,,2,,,GenFC,"['aqua_rat/raw', 'math_qa', 'craigslist_bargains']",False,NLI,rte,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,choose_correct_og,,cross_task,two_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.math_qa.choose_correct_og.LenNorm,RTE,77.90732068574579,80.74871902122766,RecognizingTextualEntailment,super_glue,,,,,,,,,,,,,,,,,8.5,11.0,17
75.49668874172185,,0.6703027488314814,0.8978588060351486,,,,75.49668874172185,,,,111.5956678700361,0.8978588060351486,1.6173285198555956,70.63492063492063,,0.4860391120357445,0.6703027488314814,0.4860391120357445,1.3826714801444044,73.28519855595668,"{'path': 'media/table/predictions_1_65769bacf74e608d6fab.table.json', 'size': 140769, '_type': 'table-file', 'ncols': 9, 'nrows': 277, 'sha256': '65769bacf74e608d6fabd257720715a4a37fb83d32ce8ad901d217844ce40ec3', 'artifact_path': 'wandb-client-artifact://19e4f6iqru22n208mr3bztftnhz6sr2nrrnbhvxshcdkb68q2av6pkpk81zrdynfdeds1a4mlipqcg9wy3qqbpanv9bhrwv2xfu3as7gzpolmt401j2402jw6bnvsfch:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://19e4f6iqru22n208mr3bztftnhz6sr2nrrnbhvxshcdkb68q2av6pkpk81zrdynfdeds1a4mlipqcg9wy3qqbpanv9bhrwv2xfu3as7gzpolmt401j2402jw6bnvsfch:latest/predictions.table.json'}",46.467282647943954,,,False,True,validation,True,Yes | No,4,CTBase,091ba88e-d208-4a3a-ada7-d9698aeb5568,rte,MCQ,False,28,bigscience/T0_3B,0,True,choose_correct_variant,prompts/general_fixed_choice.yaml,MathQA,,2,,,GenFC,"['aqua_rat/raw', 'math_qa', 'craigslist_bargains']",False,NLI,rte,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,choose_correct_variant,,cross_task,two_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.math_qa.choose_correct_variant.LenNorm,RTE,78.71395783408133,81.95649900658789,RecognizingTextualEntailment,super_glue,,,,,,,,,,,,,,,,,5.0,7.0,14
65.48223350253807,,0.4667731078994168,0.8130546773814122,,,,65.48223350253807,,,,150.5956678700361,0.8130546773814122,1.9494584837545128,15.0,,0.2190595156141236,0.4667731078994168,0.2190595156141236,1.0505415162454874,50.90252707581227,"{'ncols': 9, 'nrows': 277, 'sha256': 'd06fc08fe75e5fb04bd937a8c42cd40670463d7f269da15cb6b41d19d9fda2cc', 'artifact_path': 'wandb-client-artifact://32mp3hm8rrfvktnxreo9lkhrgmld2awumkkmk67xpl6z2am44h52g9keukrllz8tvxti9q5rebxo6yqxfm8eyu2w4w4ipqloovg1pf3vbryz8rjw2e2wjcy0jthqcpma:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://32mp3hm8rrfvktnxreo9lkhrgmld2awumkkmk67xpl6z2am44h52g9keukrllz8tvxti9q5rebxo6yqxfm8eyu2w4w4ipqloovg1pf3vbryz8rjw2e2wjcy0jthqcpma:latest/predictions.table.json', 'path': 'media/table/predictions_1_d06fc08fe75e5fb04bd9.table.json', 'size': 182863, '_type': 'table-file'}",46.467282647943954,,,False,True,validation,True,Yes | No,4,CTBase,a1dbb258-2e5c-4160-986b-46fc03546965,rte,MCQ,False,28,bigscience/T0_3B,0,True,best_deal,prompts/general_fixed_choice.yaml,Craigslist,,2,,,GenFC,"['aqua_rat/raw', 'math_qa', 'craigslist_bargains']",False,NLI,rte,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,best deal,,cross_task,two_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.craigslist_bargains.best_deal.LenNorm,RTE,69.3008060596653,75.10195545330964,RecognizingTextualEntailment,super_glue,,,,,,,,,,,,,,,,,82.5,78.0,53
65.17412935323384,,0.6816477114996937,1.5965510877891569,,,,65.17412935323384,,,,146.5956678700361,1.5965510877891569,1.978339350180505,7.894736842105263,,0.1455728891960718,0.6816477114996937,0.1455728891960718,1.021660649819495,49.45848375451264,"{'artifact_path': 'wandb-client-artifact://4d0wntsrcx190p66s0bu9ib3cexmjqrc8adbobvpcaqb7p4deko5bgsupq7qep5ypslfxsq81itxqsq80ku36ky8mdvaqv5h7jb1l257arzp571efx9z6ruefvanoaeu:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://4d0wntsrcx190p66s0bu9ib3cexmjqrc8adbobvpcaqb7p4deko5bgsupq7qep5ypslfxsq81itxqsq80ku36ky8mdvaqv5h7jb1l257arzp571efx9z6ruefvanoaeu:latest/predictions.table.json', 'path': 'media/table/predictions_1_0b9ace91dcf5c9f784bd.table.json', 'size': 177919, '_type': 'table-file', 'ncols': 9, 'nrows': 277, 'sha256': '0b9ace91dcf5c9f784bd5d50e017d6ef39e2e6de55811683670a976b2e639063'}",46.467282647943954,,,False,True,validation,False,Yes | No,4,CTBase,78d1b487-c535-4a0d-ae49-055d321db3fd,rte,CLASSIFICATION,False,28,bigscience/T0_3B,0,True,good_deal_for_seller,prompts/general_fixed_choice.yaml,Craigslist,,2,,,GenFC,"['aqua_rat/raw', 'math_qa', 'craigslist_bargains']",False,NLI,rte,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,good deal for seller,,cross_task,two_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.craigslist_bargains.good_deal_for_seller.LenNorm,RTE,73.19022780133191,79.13834570741399,RecognizingTextualEntailment,super_glue,,,,,,,,,,,,,,,,,88.0,83.0,52
65.32663316582915,,0.716222980522275,1.519727426315473,,,,65.32663316582915,,,,137.5956678700361,1.519727426315473,1.963898916967509,11.538461538461538,,0.1865416705092247,0.716222980522275,0.1865416705092247,1.036101083032491,50.18050541516246,"{'_type': 'table-file', 'ncols': 9, 'nrows': 277, 'sha256': '4463e92443058d6eec4617bfc593eae0a5d689319b35f6e0ea5725796126eb65', 'artifact_path': 'wandb-client-artifact://syx2urvc4znw3xgbpln5xnch6ckrfji3akl8c37eo5wqa8ui0jtjtbpj86p3xq5jkobm978cp7k64qmajswai7645iiwo87o20mi8cz3ix1jlfkr5w6updadi8l9l2pm:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://syx2urvc4znw3xgbpln5xnch6ckrfji3akl8c37eo5wqa8ui0jtjtbpj86p3xq5jkobm978cp7k64qmajswai7645iiwo87o20mi8cz3ix1jlfkr5w6updadi8l9l2pm:latest/predictions.table.json', 'path': 'media/table/predictions_1_4463e92443058d6eec46.table.json', 'size': 170435}",46.467282647943954,,,False,True,validation,False,Yes | No,4,CTBase,27010b55-dd5b-4ee9-9e14-a4b809aa6cdb,rte,CLASSIFICATION,False,28,bigscience/T0_3B,0,True,good_deal_for_seller_no_list_price,prompts/general_fixed_choice.yaml,Craigslist,,2,,,GenFC,"['aqua_rat/raw', 'math_qa', 'craigslist_bargains']",False,NLI,rte,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,good deal for seller no list price,,cross_task,two_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.craigslist_bargains.good_deal_for_seller_no_list_price.LenNorm,RTE,73.05245170405816,79.27951479661195,RecognizingTextualEntailment,super_glue,,,,,,,,,,,,,,,,,85.0,81.0,43
64.21568627450979,,0.8207160427905774,2.3010458842942,,,,64.21568627450979,,,,131.5956678700361,2.3010458842942,2.0,0.0,,0.0,0.8207160427905774,0.0,1.0,47.29241877256317,"{'nrows': 277, 'sha256': 'bbde19fa1aadb33aa195ce203e972e3acfeb218deac43795a8e542c111afc2f1', 'artifact_path': 'wandb-client-artifact://3fs5de49aqjtgsndcax67d4jj13pk1gh4nb478vqa48y8uayal0z0m2nc9nd2nqa44pt8sdpa19e9zf93wp9bkxwdzyd8vw1xgnfsi1swx2o85zfruhp7d8jlxekygu5:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://3fs5de49aqjtgsndcax67d4jj13pk1gh4nb478vqa48y8uayal0z0m2nc9nd2nqa44pt8sdpa19e9zf93wp9bkxwdzyd8vw1xgnfsi1swx2o85zfruhp7d8jlxekygu5:latest/predictions.table.json', 'path': 'media/table/predictions_1_bbde19fa1aadb33aa195.table.json', 'size': 170479, '_type': 'table-file', 'ncols': 9}",46.467282647943954,,,False,True,validation,False,Yes | No,4,CTBase,145dd841-b971-4550-bc88-305ad3278d58,rte,CLASSIFICATION,False,28,bigscience/T0_3B,0,True,good_deal_for_seller_no_list_price_implicit,prompts/general_fixed_choice.yaml,Craigslist,,2,,,GenFC,"['aqua_rat/raw', 'math_qa', 'craigslist_bargains']",False,NLI,rte,False,False,GeneralFixedChoice,False,False,False,,,prompts,,,True,good deal for seller no list price implicit,,cross_task,two_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.craigslist_bargains.good_deal_for_seller_no_list_price_implicit.LenNorm,RTE,69.79878258081571,74.39088152253477,RecognizingTextualEntailment,super_glue,,,,,,,,,,,,,,,,,90.0,86.0,42
9.89805242455236,25.312500000000004,0.5108412645604732,5.159571672404431,1.7520938023450587,0.3087705576239095,0.4654024802126164,6.405693950177936,0.0,1.0373387145037627,3.9949748743718594,191.4706867671692,3.708796858188495,2.8710217755443885,7.874015748031497,0.4134360997121737,0.4721182117764413,0.886377980376829,0.6027916950856942,1.3819095477386936,15.912897822445563,"{'_latest_artifact_path': 'wandb-client-artifact://7659wg98lm6k1v5axnegnulslsfmutmy16c2tntddeaeqwfm56ims3tisbd8hzyzggmzcjaw2n6obtkrivmpg6dtkstz7i3i8cl4tilc261o1hy3fkbygx55jq643gfm:latest/predictions.table.json', 'path': 'media/table/predictions_1_00a5469fbc854d43da7a.table.json', 'size': 525698, '_type': 'table-file', 'ncols': 13, 'nrows': 597, 'sha256': '00a5469fbc854d43da7acee5403475f584eb1547594096252ebda9c8852bb324', 'artifact_path': 'wandb-client-artifact://7659wg98lm6k1v5axnegnulslsfmutmy16c2tntddeaeqwfm56ims3tisbd8hzyzggmzcjaw2n6obtkrivmpg6dtkstz7i3i8cl4tilc261o1hy3fkbygx55jq643gfm:latest/predictions.table.json'}",78.1171728355754,0.7508909194844338,0.1226789509118964,False,True,validation,True,Seller | Buyer | Neither | Unknown,4,CTBase,c0403841-68b0-4c08-8c3b-a00a81272d05,craigslist_bargains,MCQ,False,12,bigscience/T0_3B,0,True,Answer_questions_from_options,prompts/general_fixed_choice.yaml,AQuA,['validation'],4,,,GenFC,"['aqua_rat/raw', 'math_qa', 'craigslist_bargains']",False,['Dialogue'],craigslist_bargains,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,Answer questions from options,,cross_task,craigslist,,,,False,,,False,,True,,,False,False,CTBase.GenFC.aqua_rat_raw.Answer_questions_from_options.LenNorm,Craigslist,,,,,,,,,,,,,,,,,,,,,72.0,69.0,11
19.95164240239273,26.51933701657459,0.4978851324751787,4.656759544033901,2.1976549413735342,0.3323481129821504,0.6683522037101591,30.72625698324022,0.0,0.4425496687641495,3.9949748743718594,203.4706867671692,3.798892249613751,2.0686767169179228,22.560975609756092,0.4153176256560001,0.9208039006548834,0.5902134915988937,0.7735538524589879,1.7386934673366834,23.45058626465661,"{'path': 'media/table/predictions_1_53a6d84692df8ff9f06d.table.json', 'size': 551646, '_type': 'table-file', 'ncols': 13, 'nrows': 597, 'sha256': '53a6d84692df8ff9f06dccdbe4a27a86be32e69a1595014d6e109460d979c39b', 'artifact_path': 'wandb-client-artifact://wm7ga75yktbszni7htt9zdl3zjulmegfsq3e1xv859n0lsva3au4lyr1mhoxzsoj4mwr4nxjhgadds9tfs7bacyducdyh8xe6ix9qtgmmb39pizohxlok7v2ntwgddpl:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://wm7ga75yktbszni7htt9zdl3zjulmegfsq3e1xv859n0lsva3au4lyr1mhoxzsoj4mwr4nxjhgadds9tfs7bacyducdyh8xe6ix9qtgmmb39pizohxlok7v2ntwgddpl:latest/predictions.table.json'}",78.1171728355754,0.41164345913205,0.1226789509118964,False,True,validation,True,Seller | Buyer | Neither | Unknown,4,CTBase,815acaf5-2e59-4f81-8190-ae75dc237cf1,craigslist_bargains,MCQ,False,12,bigscience/T0_3B,0,True,answer_quiz,prompts/general_fixed_choice.yaml,AQuA,['validation'],4,,,GenFC,"['aqua_rat/raw', 'math_qa', 'craigslist_bargains']",False,['Dialogue'],craigslist_bargains,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,answer_quiz,,cross_task,craigslist,,,,False,,,False,,True,,,False,False,CTBase.GenFC.aqua_rat_raw.answer_quiz.LenNorm,Craigslist,,,,,,,,,,,,,,,,,,,,,21.0,8.0,23
11.167314134410292,17.29106628242075,0.531954076989296,7.743990478403804,2.0284757118927974,0.4882692125684917,0.1663275254580423,0.0,0.0,0.6104769894425793,4.0,188.3986599664992,6.08248274290382,1.8710217755443883,27.37819025522042,1.0510307460574049,0.9916474260624478,0.7345850215898443,0.980522071692302,2.100502512562814,14.90787269681742,"{'ncols': 13, 'nrows': 597, 'sha256': 'af74e03448adc64ba32827f5a0cb92bbba892c80344db84ee1c9ba8c83f931b1', 'artifact_path': 'wandb-client-artifact://132y9g53ljwyehv268s619zh5rgtnmdti1ck9l5w6nrvfmouuzyb3929aswlp3iqu03kxkaf8z1mr19t20nxzjd2kmqfvj8dbp490oeivbcr93t28cj348iwqm0mu3u1:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://132y9g53ljwyehv268s619zh5rgtnmdti1ck9l5w6nrvfmouuzyb3929aswlp3iqu03kxkaf8z1mr19t20nxzjd2kmqfvj8dbp490oeivbcr93t28cj348iwqm0mu3u1:latest/predictions.table.json', 'path': 'media/table/predictions_1_af74e03448adc64ba328.table.json', 'size': 523787, '_type': 'table-file'}",78.15334236504172,0.505424499761372,0.0,False,True,validation,True,Seller | Buyer | Neither | Unknown,4,CTBase,5acfaa48-e1b6-44df-8e92-c58b94bff595,craigslist_bargains,MCQ,False,12,bigscience/T0_3B,0,True,generate_rationale,prompts/general_fixed_choice.yaml,AQuA,['validation'],4,,,GenFC,"['aqua_rat/raw', 'math_qa', 'craigslist_bargains']",False,['Dialogue'],craigslist_bargains,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,generate_rationale,,cross_task,craigslist,,,,False,,,False,,True,,,False,False,CTBase.GenFC.aqua_rat_raw.generate_rationale.LenNorm,Craigslist,,,,,,,,,,,,,,,,,,,,,80.0,57.0,17
23.76325354938828,7.751937984496124,0.604232462048035,5.0395288962615,2.814070351758794,0.6576499240195574,0.4527263568421969,59.47955390334572,0.0,0.3162005183285405,4.0,213.4706867671692,3.690455590061207,1.5896147403685092,27.821522309711284,1.032872787871752,0.6186054606100923,0.4516523406895616,0.6467440586371439,1.5963149078726968,36.515912897822446,"{'_latest_artifact_path': 'wandb-client-artifact://11simgr8p4k10am62es6wdy6vbv95arjigyonq77t2uc7oj8cdmxoqjwypu706gjed2xw5fugwriz74etwjyff6tobbvypc9pe5g9vgux4jvmwhkoazozqcoj33i0oc7:latest/predictions.table.json', 'path': 'media/table/predictions_1_f3d9fe72f1a055685aec.table.json', 'size': 570195, '_type': 'table-file', 'ncols': 13, 'nrows': 597, 'sha256': 'f3d9fe72f1a055685aec7859d180fa05c8aa1a5cb9588e31554ec570234ae9cf', 'artifact_path': 'wandb-client-artifact://11simgr8p4k10am62es6wdy6vbv95arjigyonq77t2uc7oj8cdmxoqjwypu706gjed2xw5fugwriz74etwjyff6tobbvypc9pe5g9vgux4jvmwhkoazozqcoj33i0oc7:latest/predictions.table.json'}",78.1171728355754,0.2319481003411293,0.0,False,True,validation,True,Seller | Buyer | Neither | Unknown,4,CTBase,58a6aa2b-ca26-473d-9bf8-385dd1a743cd,craigslist_bargains,MCQ,False,12,bigscience/T0_3B,0,True,generate_rational_and_correct_choice,prompts/general_fixed_choice.yaml,AQuA,['validation'],4,,,GenFC,"['aqua_rat/raw', 'math_qa', 'craigslist_bargains']",False,['Dialogue'],craigslist_bargains,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,generate_rational_and_correct_choice,,cross_task,craigslist,,,,False,,,False,,True,,,False,False,CTBase.GenFC.aqua_rat_raw.generate_rational_and_correct_choice.LenNorm,Craigslist,,,,,,,,,,,,,,,,,,,,,3.0,3.0,33
20.29692018938219,25.83732057416268,0.6945694193299315,5.5407595083342125,2.4857621440536013,0.4139317857827646,0.5447003359530476,26.66666666666667,0.0,0.5413242967883546,4.0,192.4706867671692,4.433701276379813,1.509212730318258,28.68369351669941,0.5657339351660442,0.8115573567872618,0.7866316710002754,0.7535343018684157,2.0050251256281406,24.12060301507537,"{'_type': 'table-file', 'ncols': 13, 'nrows': 597, 'sha256': '3443abee9b1aa8570a3771b4fa77a9617e1d182d1394cc1d283d2fad8f227527', 'artifact_path': 'wandb-client-artifact://v1m1xel8u68t3d6i29yi1ubscm4ygf5oy2e06ymkktvxfjzcprfwsek3ghg4z3xepnewmav4ciqxq7w6laqw0jgojcv25hip62hdgfc62kl73g7qb7rer6qmlv0pzr3x:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://v1m1xel8u68t3d6i29yi1ubscm4ygf5oy2e06ymkktvxfjzcprfwsek3ghg4z3xepnewmav4ciqxq7w6laqw0jgojcv25hip62hdgfc62kl73g7qb7rer6qmlv0pzr3x:latest/predictions.table.json', 'path': 'media/table/predictions_1_3443abee9b1aa8570a37.table.json', 'size': 526273}",78.1171728355754,0.4404502852890511,0.0,False,True,validation,True,Seller | Buyer | Neither | Unknown,4,CTBase,13bd5099-33fa-4383-a441-33a7d2e1746f,craigslist_bargains,MCQ,False,12,bigscience/T0_3B,0,True,select_the_best_option,prompts/general_fixed_choice.yaml,AQuA,['validation'],4,,,GenFC,"['aqua_rat/raw', 'math_qa', 'craigslist_bargains']",False,['Dialogue'],craigslist_bargains,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,select_the_best_option,,cross_task,craigslist,,,,False,,,False,,True,,,False,False,CTBase.GenFC.aqua_rat_raw.select_the_best_option.LenNorm,Craigslist,,,,,,,,,,,,,,,,,,,,,19.5,7.0,12
7.927178844887098,3.4782608695652173,0.8016067864197801,6.406602064369112,2.6147403685092128,0.4391557508071504,0.4866566015522341,0.7380073800738007,0.0,0.968255618509136,4.0,178.47068676716918,4.847098584550509,1.0954773869346734,27.49244712990937,0.5912478613094668,0.424457065646723,0.7111972519772309,0.5504188624192078,2.289782244556114,15.745393634840871,"{'size': 503695, '_type': 'table-file', 'ncols': 13, 'nrows': 597, 'sha256': '5d8053697e6f93d0159de2a6b8c9ed16ae12361fd206905d0e16924bdc4a22fa', 'artifact_path': 'wandb-client-artifact://71j386hs2egrdfn6sie1d5as1hjz4i4lqadl0qwxgw21bmrpkpgtc7e8hmfnn7ensvnw2hbelmup2yz5hqjcao2cnhx1gfdh71tiqvjjh50w2hhfcinltcqmv24ceez8:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://71j386hs2egrdfn6sie1d5as1hjz4i4lqadl0qwxgw21bmrpkpgtc7e8hmfnn7ensvnw2hbelmup2yz5hqjcao2cnhx1gfdh71tiqvjjh50w2hhfcinltcqmv24ceez8:latest/predictions.table.json', 'path': 'media/table/predictions_1_5d8053697e6f93d0159d.table.json'}",78.1171728355754,0.4445726070649264,0.0,False,True,validation,True,Seller | Buyer | Neither | Unknown,4,CTBase,eb89c860-5849-461a-9081-3bd466f5642c,craigslist_bargains,MCQ,False,12,bigscience/T0_3B,0,True,gre_problem,prompts/general_fixed_choice.yaml,MathQA,['validation'],4,,,GenFC,"['aqua_rat/raw', 'math_qa', 'craigslist_bargains']",False,['Dialogue'],craigslist_bargains,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,gre_problem,,cross_task,craigslist,,,,False,,,False,,True,,,False,False,CTBase.GenFC.math_qa.gre_problem.LenNorm,Craigslist,,,,,,,,,,,,,,,,,,,,,75.5,79.0,8
11.268428485790634,17.61006289308176,0.8703466978266274,6.182470826048347,2.753768844221105,0.7605939137003055,0.4308147788814635,0.0,0.0,0.9536419014635198,4.0,191.4706867671692,4.019853657414166,1.2412060301507537,27.463651050080777,1.2089752671706615,0.6513307234580764,0.8031125862056174,0.496191398445515,2.0050251256281406,16.582914572864322,"{'nrows': 597, 'sha256': '6e33a98eeb011d7913621005d1f26786447714fb453932570127d39bf1e83c9b', 'artifact_path': 'wandb-client-artifact://yht2x3bktpb4g0spwjl5novrl2wuyj7rd24qx97hrcq9x5estv1pzbj89d7l5h8gdtyb8ypmraete6uqlmsqefjfmejbi5feicq1eu3jz7p91wlut82f95m8umdlh9o6:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://yht2x3bktpb4g0spwjl5novrl2wuyj7rd24qx97hrcq9x5estv1pzbj89d7l5h8gdtyb8ypmraete6uqlmsqefjfmejbi5feicq1eu3jz7p91wlut82f95m8umdlh9o6:latest/predictions.table.json', 'path': 'media/table/predictions_1_6e33a98eeb011d791362.table.json', 'size': 544241, '_type': 'table-file', 'ncols': 13}",78.1171728355754,0.491181944444508,0.0,False,True,validation,True,Seller | Buyer | Neither | Unknown,4,CTBase,a313a5f8-53cd-4b76-abb6-fea2ac4e9ef4,craigslist_bargains,MCQ,False,12,bigscience/T0_3B,0,True,first_choice_then_problem,prompts/general_fixed_choice.yaml,MathQA,['validation'],4,,,GenFC,"['aqua_rat/raw', 'math_qa', 'craigslist_bargains']",False,['Dialogue'],craigslist_bargains,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,first_choice_then_problem,,cross_task,craigslist,,,,False,,,False,,True,,,False,False,CTBase.GenFC.math_qa.first_choice_then_problem.LenNorm,Craigslist,,,,,,,,,,,,,,,,,,,,,61.5,55.0,21
8.747699406382042,3.8095238095238098,0.7761388461772429,6.3826118601826165,2.765494137353434,0.4927971856674393,0.4236895833401572,3.636363636363636,0.0,0.963826423114668,4.0,180.4706867671692,4.66816823486507,1.068676716917923,27.54491017964072,0.7506172022028784,0.352507777231917,0.666199507461925,0.4640924115450597,2.1658291457286434,16.582914572864322,"{'size': 513882, '_type': 'table-file', 'ncols': 13, 'nrows': 597, 'sha256': '824f076357058622abbea6f02c8f41f8ef61f62face3f4faf21c741d0638db53', 'artifact_path': 'wandb-client-artifact://1745uzrh2rxxerczsfpy8pr4q6cp1vi8bkma8w7zhd7i6qxvyq4c7jotchmnkv94j687wggobclecr2hpa6ptyv5cxzhdasy1qyasq6ns9406wve0tnb6uesnbg3qc9b:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://1745uzrh2rxxerczsfpy8pr4q6cp1vi8bkma8w7zhd7i6qxvyq4c7jotchmnkv94j687wggobclecr2hpa6ptyv5cxzhdasy1qyasq6ns9406wve0tnb6uesnbg3qc9b:latest/predictions.table.json', 'path': 'media/table/predictions_1_824f076357058622abbe.table.json'}",78.1171728355754,0.4481124926645948,0.0,False,True,validation,True,Seller | Buyer | Neither | Unknown,4,CTBase,8c4c81cc-ca54-45fc-a69a-4b97a5f2b465,craigslist_bargains,MCQ,False,12,bigscience/T0_3B,0,True,pick_the_correct,prompts/general_fixed_choice.yaml,MathQA,['validation'],4,,,GenFC,"['aqua_rat/raw', 'math_qa', 'craigslist_bargains']",False,['Dialogue'],craigslist_bargains,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,pick_the_correct,,cross_task,craigslist,,,,False,,,False,,True,,,False,False,CTBase.GenFC.math_qa.pick_the_correct.LenNorm,Craigslist,,,,,,,,,,,,,,,,,,,,,61.5,70.0,10
10.280766109575822,15.555555555555555,0.5817895974384825,5.7240565362288125,2.2311557788944723,0.4496900184903838,0.4333278620564844,0.7352941176470589,0.0,0.7067565486658758,4.0,187.4706867671692,4.3619819917471165,1.3149078726968175,24.832214765100677,0.6553179958158202,0.7261533538827085,0.6723301205124244,0.7457116367569344,2.45393634840871,14.90787269681742,"{'size': 532330, '_type': 'table-file', 'ncols': 13, 'nrows': 597, 'sha256': 'd63f5b8cac862b6d138fdb7c489ca995f6c116f225f0128461968afa70bc43d5', 'artifact_path': 'wandb-client-artifact://erhb5lsc5rmvvx3varfw6ne594ho3x8fm2ibptlql15fhtj43p7e54yz7wrr0i7n5lyk2yimin7nrc8ez0r2qau0la4c1kgbw9zghr88j25e95pru7hspq8ndwzhntoe:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://erhb5lsc5rmvvx3varfw6ne594ho3x8fm2ibptlql15fhtj43p7e54yz7wrr0i7n5lyk2yimin7nrc8ez0r2qau0la4c1kgbw9zghr88j25e95pru7hspq8ndwzhntoe:latest/predictions.table.json', 'path': 'media/table/predictions_1_d63f5b8cac862b6d138f.table.json'}",78.1171728355754,0.4223013991497888,0.0,False,True,validation,True,Seller | Buyer | Neither | Unknown,4,CTBase,6312d599-8ca4-4bc8-a76f-81f2e36727bd,craigslist_bargains,MCQ,False,12,bigscience/T0_3B,0,True,choose_correct_og,prompts/general_fixed_choice.yaml,MathQA,['validation'],4,,,GenFC,"['aqua_rat/raw', 'math_qa', 'craigslist_bargains']",False,['Dialogue'],craigslist_bargains,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,choose_correct_og,,cross_task,craigslist,,,,False,,,False,,True,,,False,False,CTBase.GenFC.math_qa.choose_correct_og.LenNorm,Craigslist,,,,,,,,,,,,,,,,,,,,,80.0,67.0,17
8.187037956000049,1.96078431372549,0.8064515367066641,6.481230719405003,2.845896147403685,0.5564573169099072,0.361048272688415,3.6231884057971007,0.0,1.011158001882147,4.0,184.4706867671692,4.610120403507048,1.0603015075376885,27.164179104477608,0.8599523140158086,0.3269808740703003,0.6159231160968214,0.3941512703443929,2.0938023450586263,16.24790619765494,"{'size': 522821, '_type': 'table-file', 'ncols': 13, 'nrows': 597, 'sha256': '5a616909e20101f45ba99450447dc0d21ae13ef4e1c508cc4783fd1512e90739', 'artifact_path': 'wandb-client-artifact://lh56jvfiynhcih2segwxgoh57mhsuk8w3kxfuo606c505nwm54janyw3vmvfmxbsxftcgs5x754lhj0f73won2o955hvfd0jfh4rczi8zpt37n9nazuvepw0o4spc88d:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://lh56jvfiynhcih2segwxgoh57mhsuk8w3kxfuo606c505nwm54janyw3vmvfmxbsxftcgs5x754lhj0f73won2o955hvfd0jfh4rczi8zpt37n9nazuvepw0o4spc88d:latest/predictions.table.json', 'path': 'media/table/predictions_1_5a616909e20101f45ba9.table.json'}",78.1171728355754,0.4472790019356647,0.0,False,True,validation,True,Seller | Buyer | Neither | Unknown,4,CTBase,091ba88e-d208-4a3a-ada7-d9698aeb5568,craigslist_bargains,MCQ,False,12,bigscience/T0_3B,0,True,choose_correct_variant,prompts/general_fixed_choice.yaml,MathQA,['validation'],4,,,GenFC,"['aqua_rat/raw', 'math_qa', 'craigslist_bargains']",False,['Dialogue'],craigslist_bargains,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,choose_correct_variant,,cross_task,craigslist,,,,False,,,False,,True,,,False,False,CTBase.GenFC.math_qa.choose_correct_variant.LenNorm,Craigslist,,,,,,,,,,,,,,,,,,,,,66.0,73.0,14
6.996096047917002,0.0,0.4629207639852629,8.861680563570467,3.0,0.5632652951352448,0.0,0.7380073800738007,0.0,1.0343233037434232,4.0,223.4706867671692,5.63640188651668,1.001675041876047,27.246376811594203,2.190955373310364,0.0408929836372988,0.3375756446070621,0.0408929836372988,1.998324958123953,15.912897822445563,"{'ncols': 13, 'nrows': 597, 'sha256': '3837ac59f4b8280592c083620b751de23b9f6134c56e4cd3ac6b7eb62cb5c66c', 'artifact_path': 'wandb-client-artifact://nru2r058hhpqqm6lw8ihhx9uhhl82dy8qcdxhr7fkr88gzlh59sfny3jooiuk0lf2zx9df6ytl6b3ep2bl6ebds8o9ckvaes0oj6k6d1c3own9ljwgxm6buqkxmrd3mu:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://nru2r058hhpqqm6lw8ihhx9uhhl82dy8qcdxhr7fkr88gzlh59sfny3jooiuk0lf2zx9df6ytl6b3ep2bl6ebds8o9ckvaes0oj6k6d1c3own9ljwgxm6buqkxmrd3mu:latest/predictions.table.json', 'path': 'media/table/predictions_1_3837ac59f4b8280592c0.table.json', 'size': 613730, '_type': 'table-file'}",78.1171728355754,0.352041808401963,0.0,False,True,validation,True,Seller | Buyer | Neither | Unknown,4,CTBase,a1dbb258-2e5c-4160-986b-46fc03546965,craigslist_bargains,MCQ,False,12,bigscience/T0_3B,0,True,best_deal,prompts/general_fixed_choice.yaml,Craigslist,['validation'],4,,,GenFC,"['aqua_rat/raw', 'math_qa', 'craigslist_bargains']",True,['Dialogue'],craigslist_bargains,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,best deal,,cross_task,craigslist,,,,False,,,False,,True,,,False,False,CTBase.GenFC.craigslist_bargains.best_deal.LenNorm,Craigslist,,,,,,,,,,,,,,,,,,,,,72.0,81.0,53
18.21218032356272,4.255319148936171,0.6338433593988231,6.751542457583762,2.943048576214405,0.5538489510670205,0.2525038818922783,43.4567901234568,0.0,0.4019953150246012,4.0,217.0435510887772,5.16975318087605,1.2495812395309882,25.136612021857925,1.1797939616831103,0.4590653882289759,0.5168590070992527,0.485721710325512,1.8073701842546064,26.633165829145728,"{'path': 'media/table/predictions_1_9edf4b4ccfce3d11fa57.table.json', 'size': 605627, '_type': 'table-file', 'ncols': 13, 'nrows': 597, 'sha256': '9edf4b4ccfce3d11fa5738c7cfe2c808cd06311f59e40e2bfff579190a4daa65', 'artifact_path': 'wandb-client-artifact://k2gbidpqw4npcjo3vsufrnzmfwy0usz2rpgdgzo2tzhazzac1tjounyfkdc4yg9k0cq89wwa98mrz4jho8g2awo3jm60f53ovczga3csoj6hpm82wangsjzfbo9k37hq:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://k2gbidpqw4npcjo3vsufrnzmfwy0usz2rpgdgzo2tzhazzac1tjounyfkdc4yg9k0cq89wwa98mrz4jho8g2awo3jm60f53ovczga3csoj6hpm82wangsjzfbo9k37hq:latest/predictions.table.json'}",78.2349344664796,0.3179297172526756,0.0,False,True,validation,False,Seller | Buyer | Neither | Unknown,4,CTBase,78d1b487-c535-4a0d-ae49-055d321db3fd,craigslist_bargains,CLASSIFICATION,False,12,bigscience/T0_3B,0,True,good_deal_for_seller,prompts/general_fixed_choice.yaml,Craigslist,['validation'],4,,,GenFC,"['aqua_rat/raw', 'math_qa', 'craigslist_bargains']",True,['Dialogue'],craigslist_bargains,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,good deal for seller,,cross_task,craigslist,,,,False,,,False,,True,,,False,False,CTBase.GenFC.craigslist_bargains.good_deal_for_seller.LenNorm,Craigslist,,,,,,,,,,,,,,,,,,,,,10.0,16.0,52
18.263171949977867,4.3478260869565215,0.6539135402475145,6.816932161848749,2.92964824120603,0.562458717918641,0.2980821616488003,44.86873508353222,0.0,0.3967975495848024,4.0,209.4706867671692,5.244450235286949,1.2663316582914572,23.83612662942272,1.1756843769769971,0.4605969223123931,0.4955321289404042,0.5080101288884467,1.8040201005025125,26.800670016750416,"{'nrows': 597, 'sha256': '277049f950dcbb5a313faa788240e840b368f5d9a5b7c9c0299e3f7bc356e368', 'artifact_path': 'wandb-client-artifact://1za114t611y9mpmx1u5qjc8y7q8yc1mn4tzffhrg6yxauuds4j8mxkry32tjzlaa23nnqk6ug5in6hd6lgvvdstnpfupmoq4mked2ue6grlhy9aq3es42hncc9juah23:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://1za114t611y9mpmx1u5qjc8y7q8yc1mn4tzffhrg6yxauuds4j8mxkry32tjzlaa23nnqk6ug5in6hd6lgvvdstnpfupmoq4mked2ue6grlhy9aq3es42hncc9juah23:latest/predictions.table.json', 'path': 'media/table/predictions_1_277049f950dcbb5a313f.table.json', 'size': 588173, '_type': 'table-file', 'ncols': 13}",78.1171728355754,0.3173624375075456,0.0,False,True,validation,False,Seller | Buyer | Neither | Unknown,4,CTBase,27010b55-dd5b-4ee9-9e14-a4b809aa6cdb,craigslist_bargains,CLASSIFICATION,False,12,bigscience/T0_3B,0,True,good_deal_for_seller_no_list_price,prompts/general_fixed_choice.yaml,Craigslist,['validation'],4,,,GenFC,"['aqua_rat/raw', 'math_qa', 'craigslist_bargains']",True,['Dialogue'],craigslist_bargains,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,good deal for seller no list price,,cross_task,craigslist,,,,False,,,False,,True,,,False,False,CTBase.GenFC.craigslist_bargains.good_deal_for_seller_no_list_price.LenNorm,Craigslist,,,,,,,,,,,,,,,,,,,,,9.0,15.0,43
14.724656755705784,0.0,1.7307842324831444,9.00028084909896,1.2428810720268006,0.4862275556803872,0.6468351563763978,16.91842900302115,40.0,1.0372653438817316,3.0016750418760467,194.4706867671692,7.361815460562906,3.760469011725293,1.98019801980198,0.6012000446543222,0.6759162385995331,1.7415977672332237,0.6687383113123876,1.9949748743718592,27.470686767169177,"{'_latest_artifact_path': 'wandb-client-artifact://tixtxqax4gyzv37uzaci2vj69wy0ler8ha0x5qzflob1oh3c3nh9kx5s3zu0tjj71wwie3oqb1ymblzjlpb64uiqz5iwqangmhucyouc23phkcxdywbcktfsu2zz12ka:latest/predictions.table.json', 'path': 'media/table/predictions_1_80b52446d97854e844ab.table.json', 'size': 569135, '_type': 'table-file', 'ncols': 13, 'nrows': 597, 'sha256': '80b52446d97854e844abedeb6f4577bfa536a77279de27c1abe1b9bfb476ebfd', 'artifact_path': 'wandb-client-artifact://tixtxqax4gyzv37uzaci2vj69wy0ler8ha0x5qzflob1oh3c3nh9kx5s3zu0tjj71wwie3oqb1ymblzjlpb64uiqz5iwqangmhucyouc23phkcxdywbcktfsu2zz12ka:latest/predictions.table.json'}",78.1171728355754,0.7486083583024309,0.0408929836372988,False,True,validation,False,Seller | Buyer | Neither | Unknown,4,CTBase,145dd841-b971-4550-bc88-305ad3278d58,craigslist_bargains,CLASSIFICATION,False,12,bigscience/T0_3B,0,True,good_deal_for_seller_no_list_price_implicit,prompts/general_fixed_choice.yaml,Craigslist,['validation'],4,,,GenFC,"['aqua_rat/raw', 'math_qa', 'craigslist_bargains']",True,['Dialogue'],craigslist_bargains,False,False,GeneralFixedChoice,False,False,False,,,prompts,,,True,good deal for seller no list price implicit,,cross_task,craigslist,,,,False,,,False,,True,,,False,False,CTBase.GenFC.craigslist_bargains.good_deal_for_seller_no_list_price_implicit.LenNorm,Craigslist,,,,,,,,,,,,,,,,,,,,,8.0,39.0,42
25.12877081799135,27.804107424960502,0.4185457406200641,1.3267213554382324,2.0,0.3512149644486038,0.0632455532033675,0.0,,,,145.051,0.8466861538887024,1.6,47.58220502901354,0.48003520154953,0.916515138991168,0.347533927108724,0.9143303560529968,2.4,33.4,"{'nrows': 1000, 'sha256': '630e341bbb75821ae377b3d97d361cb6c8a858d5f3d3b39b6e27d963c0002311', 'artifact_path': 'wandb-client-artifact://18fy00w8vunxt8rem3j10c2c9x48aar12bdnwnterqp7i34wyk6egra8n7s3nnj1dohqa07u42ptbuljjxck6dvt4ywrhlonrs6tprkrpvl32269pob5kb8dfic9squr:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://18fy00w8vunxt8rem3j10c2c9x48aar12bdnwnterqp7i34wyk6egra8n7s3nnj1dohqa07u42ptbuljjxck6dvt4ywrhlonrs6tprkrpvl32269pob5kb8dfic9squr:latest/predictions.table.json', 'path': 'media/table/predictions_1_630e341bbb75821ae377.table.json', 'size': 633425, '_type': 'table-file', 'ncols': 11}",17.873231353059804,,,False,True,dev_r2,True,Yes | Maybe | No,4,CTBase,c0403841-68b0-4c08-8c3b-a00a81272d05,anli,MCQ,False,28,bigscience/T0_3B,0,True,Answer_questions_from_options,prompts/general_fixed_choice.yaml,AQuA,,3,,,GenFC,"['aqua_rat/raw', 'math_qa', 'craigslist_bargains']",False,['NLI'],anli,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,Answer questions from options,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.aqua_rat_raw.Answer_questions_from_options.LenNorm,ANLI R2,,,,,,,,,,,,,,,,,,,,,29.0,41.0,11
24.349581593509185,24.65277777777778,0.3847352756652344,1.607774720668793,2.001,0.3333566324700392,0.0316069612585582,0.0,,,,157.051,1.1489001812934876,1.486,48.39596700274977,0.4588745393753052,0.8577901841359575,0.3179773945670304,0.8578059221059271,2.513,33.5,"{'size': 677497, '_type': 'table-file', 'ncols': 11, 'nrows': 1000, 'sha256': '4a0153faff1d9b791a3aa555efe9d5055716435c9204edc49b558e98f278bf50', 'artifact_path': 'wandb-client-artifact://2lb7jskd5ua6hu9ouh7il5wxvfgyi2r26n6dufelhr0lnm9gpy67sqzmm573hd6oj6y5vu4xd5qest6yrosofolbrf7xenxz32s45pbipj98w5llmc68035cswngpde4:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://2lb7jskd5ua6hu9ouh7il5wxvfgyi2r26n6dufelhr0lnm9gpy67sqzmm573hd6oj6y5vu4xd5qest6yrosofolbrf7xenxz32s45pbipj98w5llmc68035cswngpde4:latest/predictions.table.json', 'path': 'media/table/predictions_1_4a0153faff1d9b791a3a.table.json'}",17.873231353059804,,,False,True,dev_r2,True,Yes | Maybe | No,4,CTBase,815acaf5-2e59-4f81-8190-ae75dc237cf1,anli,MCQ,False,28,bigscience/T0_3B,0,True,answer_quiz,prompts/general_fixed_choice.yaml,AQuA,,3,,,GenFC,"['aqua_rat/raw', 'math_qa', 'craigslist_bargains']",False,['NLI'],anli,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,answer_quiz,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.aqua_rat_raw.answer_quiz.LenNorm,ANLI R2,,,,,,,,,,,,,,,,,,,,,26.0,47.0,23
26.826609563599902,33.68983957219252,0.4555783129834836,2.3472494621276856,2.0,0.3997070980239666,0.0,0.0,,,,143.051,1.8362298052310944,1.83,46.78998911860718,0.5110196568965912,0.9854440623394104,0.4001932817117138,0.9854440623394104,2.17,34.1,"{'artifact_path': 'wandb-client-artifact://141bsy6k246f0cdodabif2oq2msoqzm9ine6gq6niw0ny2f0pps3uol8yn2tj6dzmlm59r5slk34ajgqrpic0yg06h3eggggn7r1dkhzwncd2pjf1h9u0tsel4w91dyz:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://141bsy6k246f0cdodabif2oq2msoqzm9ine6gq6niw0ny2f0pps3uol8yn2tj6dzmlm59r5slk34ajgqrpic0yg06h3eggggn7r1dkhzwncd2pjf1h9u0tsel4w91dyz:latest/predictions.table.json', 'path': 'media/table/predictions_1_d396a84f4ad468f58477.table.json', 'size': 632517, '_type': 'table-file', 'ncols': 11, 'nrows': 1000, 'sha256': 'd396a84f4ad468f584775792012bc5c9037ade8b0daa3ed8d38553dc153d3240'}",17.873231353059804,,,False,True,dev_r2,True,Yes | Maybe | No,4,CTBase,5acfaa48-e1b6-44df-8e92-c58b94bff595,anli,MCQ,False,28,bigscience/T0_3B,0,True,generate_rationale,prompts/general_fixed_choice.yaml,AQuA,,3,,,GenFC,"['aqua_rat/raw', 'math_qa', 'craigslist_bargains']",False,['NLI'],anli,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,generate_rationale,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.aqua_rat_raw.generate_rationale.LenNorm,ANLI R2,,,,,,,,,,,,,,,,,,,,,16.5,16.0,17
22.442858620333027,18.181818181818183,0.3999199862179894,1.907047591209412,2.0,0.3849518629076129,0.0,0.0,,,,167.051,1.3289836258888246,1.324,49.146757679180894,0.5780639653205871,0.736901621656514,0.3202025707685091,0.736901621656514,2.676,33.300000000000004,"{'nrows': 1000, 'sha256': '40524f2a9cea1108b5a8ce52ae9915066a9de01e1b2dcf75b9d270c77611f1d7', 'artifact_path': 'wandb-client-artifact://12b4dmqzo8l2a82vvv6wuds1sun9k0x514ef02wjvoqxhguua0e64fa66phn9usumqmx7dlygh6oqx6qb14din5fxhgpdmvc3l5rxm6w9toyftubwwkjda8f9cbvv79c:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://12b4dmqzo8l2a82vvv6wuds1sun9k0x514ef02wjvoqxhguua0e64fa66phn9usumqmx7dlygh6oqx6qb14din5fxhgpdmvc3l5rxm6w9toyftubwwkjda8f9cbvv79c:latest/predictions.table.json', 'path': 'media/table/predictions_1_40524f2a9cea1108b5a8.table.json', 'size': 709764, '_type': 'table-file', 'ncols': 11}",17.873231353059804,,,False,True,dev_r2,True,Yes | Maybe | No,4,CTBase,58a6aa2b-ca26-473d-9bf8-385dd1a743cd,anli,MCQ,False,28,bigscience/T0_3B,0,True,generate_rational_and_correct_choice,prompts/general_fixed_choice.yaml,AQuA,,3,,,GenFC,"['aqua_rat/raw', 'math_qa', 'craigslist_bargains']",False,['NLI'],anli,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,generate_rational_and_correct_choice,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.aqua_rat_raw.generate_rational_and_correct_choice.LenNorm,ANLI R2,,,,,,,,,,,,,,,,,,,,,34.0,64.0,33
25.37626398076961,29.117647058823533,0.4421707062870688,4.107739199638367,2.0,0.3646171928060256,0.0,0.0,,,,146.051,3.611664346218109,1.694,47.0111448834853,0.4960748534202576,0.9520315120835025,0.3851552430047912,0.9520315120835025,2.306,33.1,"{'path': 'media/table/predictions_1_89f01b9fd688deaa9dac.table.json', 'size': 635849, '_type': 'table-file', 'ncols': 11, 'nrows': 1000, 'sha256': '89f01b9fd688deaa9dacd0c87fa784e0997ff5562e918e73a290455bd21d0e65', 'artifact_path': 'wandb-client-artifact://17m7534tkkspx3lafv2ijl01whc9f0jw64mj7bzgv04udkhgoqqskbbqnsr4jl57htx7nj8q501v2n9s5ypireo5nq8qz5r9mzpjne7o7i10ub9qjl0j6h1tepqsy1rh:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://17m7534tkkspx3lafv2ijl01whc9f0jw64mj7bzgv04udkhgoqqskbbqnsr4jl57htx7nj8q501v2n9s5ypireo5nq8qz5r9mzpjne7o7i10ub9qjl0j6h1tepqsy1rh:latest/predictions.table.json'}",17.873231353059804,,,False,True,dev_r2,True,Yes | Maybe | No,4,CTBase,13bd5099-33fa-4383-a441-33a7d2e1746f,anli,MCQ,False,28,bigscience/T0_3B,0,True,select_the_best_option,prompts/general_fixed_choice.yaml,AQuA,,3,,,GenFC,"['aqua_rat/raw', 'math_qa', 'craigslist_bargains']",False,['NLI'],anli,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,select_the_best_option,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.aqua_rat_raw.select_the_best_option.LenNorm,ANLI R2,,,,,,,,,,,,,,,,,,,,,46.5,38.0,12
27.42416744083744,35.96377749029754,0.4929442692263733,2.341197068452835,2.0,0.4199909538135404,0.0,0.0,,,,134.051,1.818454777956009,1.88,46.30872483221477,0.5227422904968262,0.9927738916792684,0.4170300211281243,0.9927738916792684,2.12,34.599999999999994,"{'ncols': 11, 'nrows': 1000, 'sha256': '009a1642630f4f2a2138406bfe4827194a63c0a9d7b1bf39cd10fd8ba28a97aa', 'artifact_path': 'wandb-client-artifact://nba4itwo6nzk06dgu9uh29akcp4xq8928o806fbxve7d3ywfktwg816hstovzxza6z2qnq6yzdv8ltegr0yitlcgp0je4yntf9sguwmehqmtfgt61khnlselxvtgp70s:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://nba4itwo6nzk06dgu9uh29akcp4xq8928o806fbxve7d3ywfktwg816hstovzxza6z2qnq6yzdv8ltegr0yitlcgp0je4yntf9sguwmehqmtfgt61khnlselxvtgp70s:latest/predictions.table.json', 'path': 'media/table/predictions_1_009a1642630f4f2a2138.table.json', 'size': 599678, '_type': 'table-file'}",17.873231353059804,,,False,True,dev_r2,True,Yes | Maybe | No,4,CTBase,eb89c860-5849-461a-9081-3bd466f5642c,anli,MCQ,False,28,bigscience/T0_3B,0,True,gre_problem,prompts/general_fixed_choice.yaml,MathQA,,3,,,GenFC,"['aqua_rat/raw', 'math_qa', 'craigslist_bargains']",False,['NLI'],anli,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,gre_problem,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.math_qa.gre_problem.LenNorm,ANLI R2,,,,,,,,,,,,,,,,,,,,,11.0,9.0,8
26.51859359373769,35.47995139732685,0.6022450351393371,3.6635050800442697,2.0,0.4852166555499447,0.0,0.0,,,,147.051,3.0547958635091783,1.98,44.07582938388626,0.6087092165350914,0.999799979995999,0.5402961488905835,0.999799979995999,2.02,33.2,"{'_type': 'table-file', 'ncols': 11, 'nrows': 1000, 'sha256': '2abb71431df9306fbfe9ee44bbbe8ed940588178d165264d7b322cc5a3bea8c7', 'artifact_path': 'wandb-client-artifact://18rl2sg4n8gwc9e8he5pdv1ayhiwgmd4ggiumwrfa6hzpe9y8ne79kzxezpl1vws4lfiqum41ylg66glb5dxhz6f4mvqz1szzpgjxgnilxzvwsjr2m1258e48rc9qv7u:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://18rl2sg4n8gwc9e8he5pdv1ayhiwgmd4ggiumwrfa6hzpe9y8ne79kzxezpl1vws4lfiqum41ylg66glb5dxhz6f4mvqz1szzpgjxgnilxzvwsjr2m1258e48rc9qv7u:latest/predictions.table.json', 'path': 'media/table/predictions_1_2abb71431df9306fbfe9.table.json', 'size': 674218}",17.873231353059804,,,False,True,dev_r2,True,Yes | Maybe | No,4,CTBase,a313a5f8-53cd-4b76-abb6-fea2ac4e9ef4,anli,MCQ,False,28,bigscience/T0_3B,0,True,first_choice_then_problem,prompts/general_fixed_choice.yaml,MathQA,,3,,,GenFC,"['aqua_rat/raw', 'math_qa', 'craigslist_bargains']",False,['NLI'],anli,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,first_choice_then_problem,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.math_qa.first_choice_then_problem.LenNorm,ANLI R2,,,,,,,,,,,,,,,,,,,,,40.5,23.0,21
26.80794546918439,36.51551312649165,0.4405760756523659,2.187613440990448,2.0,0.3892179004536573,0.0,0.0,,,,136.051,1.6980615413188935,2.01,43.90832328106152,0.4895518996715545,0.9999499987499376,0.3971205162961491,0.9999499987499374,1.99,33.5,"{'artifact_path': 'wandb-client-artifact://cmx97e09qn18ov0v7oj9tcgndmwt7jgudnwskfpc3krnsnoibxqphb5fkaf1n4hq6ikdshsbvhm0hs0mua43mevvik5rcu6f11psmhvctfmst7i3soosyhquouvq0zzn:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://cmx97e09qn18ov0v7oj9tcgndmwt7jgudnwskfpc3krnsnoibxqphb5fkaf1n4hq6ikdshsbvhm0hs0mua43mevvik5rcu6f11psmhvctfmst7i3soosyhquouvq0zzn:latest/predictions.table.json', 'path': 'media/table/predictions_1_ec1ef94c63534adc7fde.table.json', 'size': 616531, '_type': 'table-file', 'ncols': 11, 'nrows': 1000, 'sha256': 'ec1ef94c63534adc7fdeef5e2126eaf301201e70780ae6a6428b8fd851131048'}",17.873231353059804,,,False,True,dev_r2,True,Yes | Maybe | No,4,CTBase,8c4c81cc-ca54-45fc-a69a-4b97a5f2b465,anli,MCQ,False,28,bigscience/T0_3B,0,True,pick_the_correct,prompts/general_fixed_choice.yaml,MathQA,,3,,,GenFC,"['aqua_rat/raw', 'math_qa', 'craigslist_bargains']",False,['NLI'],anli,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,pick_the_correct,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.math_qa.pick_the_correct.LenNorm,ANLI R2,,,,,,,,,,,,,,,,,,,,,26.0,18.0,10
26.090667751811804,33.244680851063826,0.4121581084077702,2.0860551946163177,2.0,0.3480530344594154,0.0,0.0,,,,143.051,1.6416300387382508,1.838,45.02732240437158,0.444425155878067,0.986790757962396,0.3633010924398653,0.986790757962396,2.162,33.1,"{'sha256': '3d63949d7087b5c7d092b1a5a3fb050a3a312e23bcef860b0685e3e956afbb6b', 'artifact_path': 'wandb-client-artifact://4r6dwhhf23m8xv7q363ldoul0ptzrnbwyfcfolmpvivo2bqclp3nmkod0y141u175g2pbx09gc6xdyqxpbppmqh5ru7wt9h7quq2gz8m5f8pragrpkq7x1pskumv6kpq:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://4r6dwhhf23m8xv7q363ldoul0ptzrnbwyfcfolmpvivo2bqclp3nmkod0y141u175g2pbx09gc6xdyqxpbppmqh5ru7wt9h7quq2gz8m5f8pragrpkq7x1pskumv6kpq:latest/predictions.table.json', 'path': 'media/table/predictions_1_3d63949d7087b5c7d092.table.json', 'size': 647594, '_type': 'table-file', 'ncols': 11, 'nrows': 1000}",17.873231353059804,,,False,True,dev_r2,True,Yes | Maybe | No,4,CTBase,6312d599-8ca4-4bc8-a76f-81f2e36727bd,anli,MCQ,False,28,bigscience/T0_3B,0,True,choose_correct_og,prompts/general_fixed_choice.yaml,MathQA,,3,,,GenFC,"['aqua_rat/raw', 'math_qa', 'craigslist_bargains']",False,['NLI'],anli,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,choose_correct_og,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.math_qa.choose_correct_og.LenNorm,ANLI R2,,,,,,,,,,,,,,,,,,,,,46.5,30.0,17
25.5421686746988,,0.3981224095745611,0.5570724884918117,,,,25.5421686746988,,,,71.62068965517241,0.5570724884918117,1.1504702194357366,64.11149825783973,,0.357531722366978,0.3981224095745611,0.357531722366978,1.8495297805642632,51.56739811912225,"{'nrows': 638, 'sha256': '989f014b31d05dd8a0cf01b9c693ba170fe62ed25ba86ce427b98b410e168f7d', 'artifact_path': 'wandb-client-artifact://8fmx635w8j3zw6ktlnfm305nvmuubxsqi8kf15xiurknuhdodnn72fad83lm70cxbvz5ji70mmzbqcw1l7ro1qgqspchpwy9kkzrk53ncyybice11zzo12ug9v3lud25:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://8fmx635w8j3zw6ktlnfm305nvmuubxsqi8kf15xiurknuhdodnn72fad83lm70cxbvz5ji70mmzbqcw1l7ro1qgqspchpwy9kkzrk53ncyybice11zzo12ug9v3lud25:latest/predictions.table.json', 'path': 'media/table/predictions_1_989f014b31d05dd8a0cf.table.json', 'size': 208319, '_type': 'table-file', 'ncols': 9}",7.037985482349875,,,False,True,validation,True,No | Yes,4,CTBase,c0403841-68b0-4c08-8c3b-a00a81272d05,wic,MCQ,False,28,bigscience/T0_3B,0,True,Answer_questions_from_options,prompts/general_fixed_choice.yaml,AQuA,,2,,,GenFC,"['aqua_rat/raw', 'math_qa', 'craigslist_bargains']",False,Word Sense Disambiguation,wic,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,Answer questions from options,,cross_task,wic,,,,False,,,False,,True,,,False,,CTBase.GenFC.aqua_rat_raw.Answer_questions_from_options.LenNorm,WiC,54.17395823837736,55.256925541219125,WordsinContext,super_glue,,,,,,,,,,,,,,,,,8.0,6.5,11
9.195402298850572,,0.3710897185482353,0.6433347183335164,,,,9.195402298850572,,,,83.62068965517241,0.6433347183335164,1.0454545454545454,65.94827586206897,,0.2082988952252654,0.3710897185482353,0.2082988952252654,1.9545454545454544,50.470219435736674,"{'size': 236247, '_type': 'table-file', 'ncols': 9, 'nrows': 638, 'sha256': '2c7cae3e9ed639248bd062f3d451503ec82328e3ac9c71349dbf71e1fb26d0f4', 'artifact_path': 'wandb-client-artifact://biu81hu8je2r2309tkb58ofcs8agwpm36msseg4d2nf3avh6n4f2lfl29zo7dwqxxqrlhq81i7u422d1hfr3e8kgiidc4lgcdz1kg2kygodh9cblw6g7b8dtb5363lhf:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://biu81hu8je2r2309tkb58ofcs8agwpm36msseg4d2nf3avh6n4f2lfl29zo7dwqxxqrlhq81i7u422d1hfr3e8kgiidc4lgcdz1kg2kygodh9cblw6g7b8dtb5363lhf:latest/predictions.table.json', 'path': 'media/table/predictions_1_2c7cae3e9ed639248bd0.table.json'}",7.037985482349875,,,False,True,validation,True,No | Yes,4,CTBase,815acaf5-2e59-4f81-8190-ae75dc237cf1,wic,MCQ,False,28,bigscience/T0_3B,0,True,answer_quiz,prompts/general_fixed_choice.yaml,AQuA,,2,,,GenFC,"['aqua_rat/raw', 'math_qa', 'craigslist_bargains']",False,Word Sense Disambiguation,wic,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,answer_quiz,,cross_task,wic,,,,False,,,False,,True,,,False,,CTBase.GenFC.aqua_rat_raw.answer_quiz.LenNorm,WiC,55.79546856991219,56.48332858364207,WordsinContext,super_glue,,,,,,,,,,,,,,,,,47.5,35.0,23
25.5421686746988,,0.4322526251926091,0.6073503614779924,,,,25.5421686746988,,,,71.62068965517241,0.6073503614779924,1.1504702194357366,64.11149825783973,,0.3575317223669781,0.4322526251926091,0.3575317223669781,1.8495297805642632,51.56739811912225,"{'_type': 'table-file', 'ncols': 9, 'nrows': 638, 'sha256': 'f911a5e7fcbbe9a5d5817082c1cd69f5f72426cf64f7b8a8a45819bed3555c96', 'artifact_path': 'wandb-client-artifact://wga8iuaghvterjh7928orwms3s686woydp0mbn8dsti9se3bwpc4o8kgt70fe9pj6kxg4hydpe6bzam5co16et7vpq1k2iqdqzczg0xtx3zqnt617fc7o2uv58hb1ehg:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://wga8iuaghvterjh7928orwms3s686woydp0mbn8dsti9se3bwpc4o8kgt70fe9pj6kxg4hydpe6bzam5co16et7vpq1k2iqdqzczg0xtx3zqnt617fc7o2uv58hb1ehg:latest/predictions.table.json', 'path': 'media/table/predictions_1_f911a5e7fcbbe9a5d581.table.json', 'size': 209666}",7.037985482349875,,,False,True,validation,True,No | Yes,4,CTBase,5acfaa48-e1b6-44df-8e92-c58b94bff595,wic,MCQ,False,28,bigscience/T0_3B,0,True,generate_rationale,prompts/general_fixed_choice.yaml,AQuA,,2,,,GenFC,"['aqua_rat/raw', 'math_qa', 'craigslist_bargains']",False,Word Sense Disambiguation,wic,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,generate_rationale,,cross_task,wic,,,,False,,,False,,True,,,False,,CTBase.GenFC.aqua_rat_raw.generate_rationale.LenNorm,WiC,53.0777808484413,53.60698106347226,WordsinContext,super_glue,,,,,,,,,,,,,,,,,8.0,6.5,17
26.90023279813761,36.23011015911873,0.4758971247243712,2.447095261335373,2.0,0.3953776850716585,0.0,0.0,,,,140.051,1.9480827920436856,1.968,44.47058823529411,0.499012469291687,0.999487868860848,0.4233289456734067,0.999487868860848,2.032,33.7,"{'path': 'media/table/predictions_1_c03a83f6cec74e7b6e22.table.json', 'size': 631516, '_type': 'table-file', 'ncols': 11, 'nrows': 1000, 'sha256': 'c03a83f6cec74e7b6e2297df48cf4d47adc7fc77f4d81ad5c67652904a3c4a47', 'artifact_path': 'wandb-client-artifact://kyfup5ufcs5574a19jflj0gjz9univilj78s14bx4xc6b5iidbj9wozknl49n6jzd78m7arlws8fmcoiow8bwmalpa0t6uzd5569ek8byh40brhvd6mt1b4bfl7tcz9z:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://kyfup5ufcs5574a19jflj0gjz9univilj78s14bx4xc6b5iidbj9wozknl49n6jzd78m7arlws8fmcoiow8bwmalpa0t6uzd5569ek8byh40brhvd6mt1b4bfl7tcz9z:latest/predictions.table.json'}",17.873231353059804,,,False,True,dev_r2,True,Yes | Maybe | No,4,CTBase,091ba88e-d208-4a3a-ada7-d9698aeb5568,anli,MCQ,False,28,bigscience/T0_3B,0,True,choose_correct_variant,prompts/general_fixed_choice.yaml,MathQA,,3,,,GenFC,"['aqua_rat/raw', 'math_qa', 'craigslist_bargains']",False,['NLI'],anli,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,choose_correct_variant,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.math_qa.choose_correct_variant.LenNorm,ANLI R2,,,,,,,,,,,,,,,,,,,,,19.5,15.0,14
23.44139650872817,,0.3620892260802911,0.5208944228001896,,,,23.44139650872817,,,,93.6206896551724,0.5208944228001896,1.128526645768025,64.91428571428571,,0.3346752860544764,0.3620892260802911,0.3346752860544764,1.871473354231975,51.88087774294671,"{'sha256': '99ee8fabf7d29e73d8de6a0510c0139bbf10f736b113bc3ecc52451652e563b8', 'artifact_path': 'wandb-client-artifact://8u6xj7smae1u0vwx26l6saskal6ni1qleh0l8o4ma0tibzevmdz963lkcea5pugnrfqnhxyhyabryfjfxjy7xhk5ksz10a0p15gx8ugap6zvv3zk7p822u5a9yssrb2y:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://8u6xj7smae1u0vwx26l6saskal6ni1qleh0l8o4ma0tibzevmdz963lkcea5pugnrfqnhxyhyabryfjfxjy7xhk5ksz10a0p15gx8ugap6zvv3zk7p822u5a9yssrb2y:latest/predictions.table.json', 'path': 'media/table/predictions_1_99ee8fabf7d29e73d8de.table.json', 'size': 256790, '_type': 'table-file', 'ncols': 9, 'nrows': 638}",7.037985482349875,,,False,True,validation,True,No | Yes,4,CTBase,58a6aa2b-ca26-473d-9bf8-385dd1a743cd,wic,MCQ,False,28,bigscience/T0_3B,0,True,generate_rational_and_correct_choice,prompts/general_fixed_choice.yaml,AQuA,,2,,,GenFC,"['aqua_rat/raw', 'math_qa', 'craigslist_bargains']",False,Word Sense Disambiguation,wic,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,generate_rational_and_correct_choice,,cross_task,wic,,,,False,,,False,,True,,,False,,CTBase.GenFC.aqua_rat_raw.generate_rational_and_correct_choice.LenNorm,WiC,54.646628605709225,55.43086251117815,WordsinContext,super_glue,,,,,,,,,,,,,,,,,4.0,10.0,33
61.83699870633894,,0.2957194516956945,0.4168527892390762,,,,61.83699870633894,,,,72.62068965517241,0.4168527892390762,1.7115987460815048,41.35188866799204,,0.4530187310219467,0.2957194516956945,0.4530187310219467,1.2884012539184952,53.76175548589342,"{'size': 210507, '_type': 'table-file', 'ncols': 9, 'nrows': 638, 'sha256': 'ebd7c10f0e60ba72b1cbf9b57f3f07a301bd54d8fecc80d45548f04f2de18771', 'artifact_path': 'wandb-client-artifact://eoh606voh5t3tuildwraovoiofuvj80umopbtvi0gzdslbc7tm70y9xzoit8drj3ytti98n1j7ha3d0p0smpspyhov86krldzn9qdh1007yf3xnqfgc3slta8fx2h0l7:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://eoh606voh5t3tuildwraovoiofuvj80umopbtvi0gzdslbc7tm70y9xzoit8drj3ytti98n1j7ha3d0p0smpspyhov86krldzn9qdh1007yf3xnqfgc3slta8fx2h0l7:latest/predictions.table.json', 'path': 'media/table/predictions_1_ebd7c10f0e60ba72b1cb.table.json'}",7.037985482349875,,,False,True,validation,True,No | Yes,4,CTBase,13bd5099-33fa-4383-a441-33a7d2e1746f,wic,MCQ,False,28,bigscience/T0_3B,0,True,select_the_best_option,prompts/general_fixed_choice.yaml,AQuA,,2,,,GenFC,"['aqua_rat/raw', 'math_qa', 'craigslist_bargains']",False,Word Sense Disambiguation,wic,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,select_the_best_option,,cross_task,wic,,,,False,,,False,,True,,,False,,CTBase.GenFC.aqua_rat_raw.select_the_best_option.LenNorm,WiC,52.98473840911318,54.06393412014426,WordsinContext,super_glue,,,,,,,,,,,,,,,,,1.0,4.0,12
21.890547263681597,,0.4620334884074682,0.6765186938465949,,,,21.890547263681597,,,,62.62068965517241,0.6765186938465949,1.1300940438871474,64.07322654462243,,0.3364068721537007,0.4620334884074682,0.3364068721537007,1.8699059561128528,50.78369905956113,"{'artifact_path': 'wandb-client-artifact://i4ire9q3wkmw297ekusgrnr1okwrp4k954848g22es7orn7j8pww4tiqwt2dusa6sfchdn5jisq038y7gkguwcqfnmuwh54s29rmwzk7to4k6ibidfelno1gy5ud28mv:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://i4ire9q3wkmw297ekusgrnr1okwrp4k954848g22es7orn7j8pww4tiqwt2dusa6sfchdn5jisq038y7gkguwcqfnmuwh54s29rmwzk7to4k6ibidfelno1gy5ud28mv:latest/predictions.table.json', 'path': 'media/table/predictions_1_7794b65aa25b44cc5d40.table.json', 'size': 188735, '_type': 'table-file', 'ncols': 9, 'nrows': 638, 'sha256': '7794b65aa25b44cc5d4080f635c4aa9bb4e6507b249def9fc4443fc24cf0e516'}",7.037985482349875,,,False,True,validation,True,No | Yes,4,CTBase,eb89c860-5849-461a-9081-3bd466f5642c,wic,MCQ,False,28,bigscience/T0_3B,0,True,gre_problem,prompts/general_fixed_choice.yaml,MathQA,,2,,,GenFC,"['aqua_rat/raw', 'math_qa', 'craigslist_bargains']",False,Word Sense Disambiguation,wic,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,gre_problem,,cross_task,wic,,,,False,,,False,,True,,,False,,CTBase.GenFC.math_qa.gre_problem.LenNorm,WiC,53.22091010997904,53.6806831693871,WordsinContext,super_glue,,,,,,,,,,,,,,,,,28.0,13.0,8
23.01551744772884,42.05693296602387,0.3039880878947307,2.922058623790741,2.0,0.257406831299721,0.0,0.0,,,,179.051,2.5943808162212374,2.512,26.989619377162636,0.3276778075695037,0.8589854480723175,0.3158430749640883,0.8589854480723175,1.488,30.7,"{'_latest_artifact_path': 'wandb-client-artifact://1997y9akxl42m3vnds77c85j3ahfjz2cpoy71war0aetewmko9nfrudv95bgibifm907r54i6tdgscfvgzyuovxqoaoyyub3eedgcpicshm427xn1aawhdmi19mhgetb:latest/predictions.table.json', 'path': 'media/table/predictions_1_4069fc68b5abb02a901d.table.json', 'size': 783580, '_type': 'table-file', 'ncols': 11, 'nrows': 1000, 'sha256': '4069fc68b5abb02a901d6727f74cad0f36d5e00bff92b6b457778a9fe6211cbd', 'artifact_path': 'wandb-client-artifact://1997y9akxl42m3vnds77c85j3ahfjz2cpoy71war0aetewmko9nfrudv95bgibifm907r54i6tdgscfvgzyuovxqoaoyyub3eedgcpicshm427xn1aawhdmi19mhgetb:latest/predictions.table.json'}",17.873231353059804,,,False,True,dev_r2,True,Yes | Maybe | No,4,CTBase,a1dbb258-2e5c-4160-986b-46fc03546965,anli,MCQ,False,28,bigscience/T0_3B,0,True,best_deal,prompts/general_fixed_choice.yaml,Craigslist,,3,,,GenFC,"['aqua_rat/raw', 'math_qa', 'craigslist_bargains']",False,['NLI'],anli,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,best deal,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.craigslist_bargains.best_deal.LenNorm,ANLI R2,,,,,,,,,,,,,,,,,,,,,90.0,58.0,53
8.771929824561402,,0.55079488225561,1.0130161313707926,,,,8.771929824561402,,,,75.62068965517241,1.0130161313707926,1.036050156739812,66.59528907922912,,0.1864149750927937,0.55079488225561,0.1864149750927937,1.963949843260188,51.09717868338558,"{'sha256': '781081c92f84a06a245f99c081f7e9906a977e7bba70414547373cf36bbdbfb9', 'artifact_path': 'wandb-client-artifact://8pp7wpq2v04ue3ulejhyae48j4jgzm5f3vrvwikohxybt40r7dy5bw3hvyhlguvd895szm93b9u8hug243mr40eva5avwb8lth6yu44ew4rmyo0z18bp6r7qaz9lat1p:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://8pp7wpq2v04ue3ulejhyae48j4jgzm5f3vrvwikohxybt40r7dy5bw3hvyhlguvd895szm93b9u8hug243mr40eva5avwb8lth6yu44ew4rmyo0z18bp6r7qaz9lat1p:latest/predictions.table.json', 'path': 'media/table/predictions_1_781081c92f84a06a245f.table.json', 'size': 235890, '_type': 'table-file', 'ncols': 9, 'nrows': 638}",7.037985482349875,,,False,True,validation,True,No | Yes,4,CTBase,a313a5f8-53cd-4b76-abb6-fea2ac4e9ef4,wic,MCQ,False,28,bigscience/T0_3B,0,True,first_choice_then_problem,prompts/general_fixed_choice.yaml,MathQA,,2,,,GenFC,"['aqua_rat/raw', 'math_qa', 'craigslist_bargains']",False,Word Sense Disambiguation,wic,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,first_choice_then_problem,,cross_task,wic,,,,False,,,False,,True,,,False,,CTBase.GenFC.math_qa.first_choice_then_problem.LenNorm,WiC,54.69750101587497,54.5690392193473,WordsinContext,super_glue,,,,,,,,,,,,,,,,,18.5,36.0,21
17.894736842105264,,0.478762087652208,0.7634454940133334,,,,17.894736842105264,,,,64.62068965517241,0.7634454940133334,1.0956112852664577,65.17857142857142,,0.2940574219368621,0.478762087652208,0.2940574219368621,1.9043887147335423,51.09717868338558,"{'nrows': 638, 'sha256': '1cb898f31412271a3529e984e8438cdce31da6a87665505c5b4567ca00bcf96a', 'artifact_path': 'wandb-client-artifact://rmsd2ho1drq421ivw3bg7qj4qbahkjfbhesfsdynjsui9g0rbr5bacfbmxutyl51iawt8k90p68z8pvg4pdkirb50g28ykz7qzlp0iiuve6fdrgwdeeiw1zrirbf1ted:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://rmsd2ho1drq421ivw3bg7qj4qbahkjfbhesfsdynjsui9g0rbr5bacfbmxutyl51iawt8k90p68z8pvg4pdkirb50g28ykz7qzlp0iiuve6fdrgwdeeiw1zrirbf1ted:latest/predictions.table.json', 'path': 'media/table/predictions_1_1cb898f31412271a3529.table.json', 'size': 199599, '_type': 'table-file', 'ncols': 9}",7.037985482349875,,,False,True,validation,True,No | Yes,4,CTBase,8c4c81cc-ca54-45fc-a69a-4b97a5f2b465,wic,MCQ,False,28,bigscience/T0_3B,0,True,pick_the_correct,prompts/general_fixed_choice.yaml,MathQA,,2,,,GenFC,"['aqua_rat/raw', 'math_qa', 'craigslist_bargains']",False,Word Sense Disambiguation,wic,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,pick_the_correct,,cross_task,wic,,,,False,,,False,,True,,,False,,CTBase.GenFC.math_qa.pick_the_correct.LenNorm,WiC,53.28220761989178,53.44483643045961,WordsinContext,super_glue,,,,,,,,,,,,,,,,,18.5,17.0,10
23.383084577114428,,0.4033145863087024,0.5858515401992678,,,,23.383084577114428,,,,71.62068965517241,0.5858515401992678,1.1300940438871474,64.75972540045767,,0.3364068721537007,0.4033145863087024,0.3364068721537007,1.8699059561128528,51.72413793103448,"{'sha256': '316924934134afbbbd4c8645af2309cd6789b29db2c353e209f908085116a0d5', 'artifact_path': 'wandb-client-artifact://h6qcx3rj75sunmrheoo1vrb1v67e6emkdk8327z1986chp74ipxzvxxveb8q7iux1znbxgdmlurt01q90lhvnilir57g5swsm9t76v18vdfopfjtcifxxpkwr19n9o7b:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://h6qcx3rj75sunmrheoo1vrb1v67e6emkdk8327z1986chp74ipxzvxxveb8q7iux1znbxgdmlurt01q90lhvnilir57g5swsm9t76v18vdfopfjtcifxxpkwr19n9o7b:latest/predictions.table.json', 'path': 'media/table/predictions_1_316924934134afbbbd4c.table.json', 'size': 219031, '_type': 'table-file', 'ncols': 9, 'nrows': 638}",7.037985482349875,,,False,True,validation,True,No | Yes,4,CTBase,6312d599-8ca4-4bc8-a76f-81f2e36727bd,wic,MCQ,False,28,bigscience/T0_3B,0,True,choose_correct_og,prompts/general_fixed_choice.yaml,MathQA,,2,,,GenFC,"['aqua_rat/raw', 'math_qa', 'craigslist_bargains']",False,Word Sense Disambiguation,wic,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,choose_correct_og,,cross_task,wic,,,,False,,,False,,True,,,False,,CTBase.GenFC.math_qa.choose_correct_og.LenNorm,WiC,53.72286900912791,54.12486119436719,WordsinContext,super_glue,,,,,,,,,,,,,,,,,5.5,11.0,17
18.461538461538463,,0.4683535134922503,0.7147573700238918,,,,18.461538461538463,,,,68.62068965517241,0.7147573700238918,1.1112852664576802,64.10835214446952,,0.3144850647123378,0.4683535134922503,0.3144850647123378,1.88871473354232,50.15673981191222,"{'size': 209261, '_type': 'table-file', 'ncols': 9, 'nrows': 638, 'sha256': 'b52291f7c2542e2ae45495708c58bde08797ce8a30e2c98b035b8b58d109d4b0', 'artifact_path': 'wandb-client-artifact://yuiie42yyvnn2pxs6hcu7nea85jbtpllgha3f5dow9oel35yyw7ywhqz0230y1is4b96nan8mh25dv8vytgfpgeb44x0d37oqkj5yyvlxy4t31u9k2ns3atsv18bxukk:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://yuiie42yyvnn2pxs6hcu7nea85jbtpllgha3f5dow9oel35yyw7ywhqz0230y1is4b96nan8mh25dv8vytgfpgeb44x0d37oqkj5yyvlxy4t31u9k2ns3atsv18bxukk:latest/predictions.table.json', 'path': 'media/table/predictions_1_b52291f7c2542e2ae454.table.json'}",7.037985482349875,,,False,True,validation,True,No | Yes,4,CTBase,091ba88e-d208-4a3a-ada7-d9698aeb5568,wic,MCQ,False,28,bigscience/T0_3B,0,True,choose_correct_variant,prompts/general_fixed_choice.yaml,MathQA,,2,,,GenFC,"['aqua_rat/raw', 'math_qa', 'craigslist_bargains']",False,Word Sense Disambiguation,wic,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,choose_correct_variant,,cross_task,wic,,,,False,,,False,,True,,,False,,CTBase.GenFC.math_qa.choose_correct_variant.LenNorm,WiC,52.70534372833096,52.68619608690952,WordsinContext,super_glue,,,,,,,,,,,,,,,,,70.5,15.5,14
19.20647649597128,46.19085805934242,0.4068092424151252,2.881174197435379,2.0,0.4920013361239766,0.0,0.0,,,,175.051,2.026151777744293,2.828,11.428571428571429,0.8550224196910858,0.5607280981010314,0.5031352784944924,0.5607280981010314,1.172,31.2,"{'artifact_path': 'wandb-client-artifact://jk0a8caer31vop3wgy2pf5gtwvxs2vf4c21ev5n12zcn4xena6bux775cjytabmtuxn73g0bsyitdu1gpkkf220kyoob94li8q84hbjz1yca4y0lt2p60r2ne1e3abrq:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://jk0a8caer31vop3wgy2pf5gtwvxs2vf4c21ev5n12zcn4xena6bux775cjytabmtuxn73g0bsyitdu1gpkkf220kyoob94li8q84hbjz1yca4y0lt2p60r2ne1e3abrq:latest/predictions.table.json', 'path': 'media/table/predictions_1_9f21cd58d69e6f673654.table.json', 'size': 766969, '_type': 'table-file', 'ncols': 11, 'nrows': 1000, 'sha256': '9f21cd58d69e6f6736548ad35c9f50f67bfe8f75c9dd3ef86bc8581d349f6e25'}",17.873231353059804,,,False,True,dev_r2,False,Yes | Maybe | No,4,CTBase,78d1b487-c535-4a0d-ae49-055d321db3fd,anli,CLASSIFICATION,False,28,bigscience/T0_3B,0,True,good_deal_for_seller,prompts/general_fixed_choice.yaml,Craigslist,,3,,,GenFC,"['aqua_rat/raw', 'math_qa', 'craigslist_bargains']",False,['NLI'],anli,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,good deal for seller,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.craigslist_bargains.good_deal_for_seller.LenNorm,ANLI R2,,,,,,,,,,,,,,,,,,,,,87.0,78.0,52
0.625,,0.2872194181486367,1.3840480177753771,,,,0.625,,,,107.6206896551724,1.3840480177753771,1.0015673981191222,66.73640167364016,,0.0395593400129277,0.2872194181486367,0.0395593400129277,1.9984326018808776,50.15673981191222,"{'nrows': 638, 'sha256': '055b79241c12820e827ba0730600ba95565f568d546e01c0427a331f354bd21d', 'artifact_path': 'wandb-client-artifact://ohaacwohvstmrflfms8u1dofv80qyacywzsbnk4a07i2xqkhjaxf6x3ou42898tevbz0hdndxvj4az63ngu90cb9fwhl0uk0scsv5twssndf3wqm7xc947jpgvduz8u0:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://ohaacwohvstmrflfms8u1dofv80qyacywzsbnk4a07i2xqkhjaxf6x3ou42898tevbz0hdndxvj4az63ngu90cb9fwhl0uk0scsv5twssndf3wqm7xc947jpgvduz8u0:latest/predictions.table.json', 'path': 'media/table/predictions_1_055b79241c12820e827b.table.json', 'size': 306003, '_type': 'table-file', 'ncols': 9}",7.037985482349875,,,False,True,validation,True,No | Yes,4,CTBase,a1dbb258-2e5c-4160-986b-46fc03546965,wic,MCQ,False,28,bigscience/T0_3B,0,True,best_deal,prompts/general_fixed_choice.yaml,Craigslist,,2,,,GenFC,"['aqua_rat/raw', 'math_qa', 'craigslist_bargains']",False,Word Sense Disambiguation,wic,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,best deal,,cross_task,wic,,,,False,,,False,,True,,,False,,CTBase.GenFC.craigslist_bargains.best_deal.LenNorm,WiC,53.14627147302081,53.9676300350822,WordsinContext,super_glue,,,,,,,,,,,,,,,,,70.5,87.5,53
0.625,,0.4441170734409304,1.970204666490465,,,,0.625,,,,103.6206896551724,1.970204666490465,1.0015673981191222,66.73640167364016,,0.0395593400129277,0.4441170734409304,0.0395593400129277,1.9984326018808776,50.15673981191222,"{'_latest_artifact_path': 'wandb-client-artifact://z0um203lrwv14n8j8ds5epd2zx8n9cd3lgj6w8coplwe6ka50h04z7oijb11g45hzr2zpf63151n02pwb0dojbejmdfguiipzw8uwjsj57n7tbzg3ownda2l9drifcuz:latest/predictions.table.json', 'path': 'media/table/predictions_1_b91457db6ee6a5df06c9.table.json', 'size': 294564, '_type': 'table-file', 'ncols': 9, 'nrows': 638, 'sha256': 'b91457db6ee6a5df06c9b0c3d2898833b583261373b9dea7fc3990f2f7ed36fe', 'artifact_path': 'wandb-client-artifact://z0um203lrwv14n8j8ds5epd2zx8n9cd3lgj6w8coplwe6ka50h04z7oijb11g45hzr2zpf63151n02pwb0dojbejmdfguiipzw8uwjsj57n7tbzg3ownda2l9drifcuz:latest/predictions.table.json'}",7.037985482349875,,,False,True,validation,False,No | Yes,4,CTBase,78d1b487-c535-4a0d-ae49-055d321db3fd,wic,CLASSIFICATION,False,28,bigscience/T0_3B,0,True,good_deal_for_seller,prompts/general_fixed_choice.yaml,Craigslist,,2,,,GenFC,"['aqua_rat/raw', 'math_qa', 'craigslist_bargains']",False,Word Sense Disambiguation,wic,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,good deal for seller,,cross_task,wic,,,,False,,,False,,True,,,False,,CTBase.GenFC.craigslist_bargains.good_deal_for_seller.LenNorm,WiC,54.05757485646407,56.10106032763044,WordsinContext,super_glue,,,,,,,,,,,,,,,,,70.5,87.5,52
0.625,,0.4864837287426802,1.9369930723991515,,,,0.625,,,,94.6206896551724,1.9369930723991515,1.0015673981191222,66.73640167364016,,0.0395593400129277,0.4864837287426802,0.0395593400129277,1.9984326018808776,50.15673981191222,"{'sha256': '25bb153c0269576c3e1d968a219bf299d7caebfeca255119cc378b97a2aa8755', 'artifact_path': 'wandb-client-artifact://yhneuqq9xk29udc727m9tkk48isgfab7zmtdiv0l33v21ncq3ak9pdzn21i5qz31zjqbasf753p41ch9uc34gpb248e3tdlit1e2xg5w95yzg7mmhh93eayte1lp54ia:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://yhneuqq9xk29udc727m9tkk48isgfab7zmtdiv0l33v21ncq3ak9pdzn21i5qz31zjqbasf753p41ch9uc34gpb248e3tdlit1e2xg5w95yzg7mmhh93eayte1lp54ia:latest/predictions.table.json', 'path': 'media/table/predictions_1_25bb153c0269576c3e1d.table.json', 'size': 277316, '_type': 'table-file', 'ncols': 9, 'nrows': 638}",7.037985482349875,,,False,True,validation,False,No | Yes,4,CTBase,27010b55-dd5b-4ee9-9e14-a4b809aa6cdb,wic,CLASSIFICATION,False,28,bigscience/T0_3B,0,True,good_deal_for_seller_no_list_price,prompts/general_fixed_choice.yaml,Craigslist,,2,,,GenFC,"['aqua_rat/raw', 'math_qa', 'craigslist_bargains']",False,Word Sense Disambiguation,wic,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,good deal for seller no list price,,cross_task,wic,,,,False,,,False,,True,,,False,,CTBase.GenFC.craigslist_bargains.good_deal_for_seller_no_list_price.LenNorm,WiC,54.74725307520545,56.24551645522351,WordsinContext,super_glue,,,,,,,,,,,,,,,,,70.5,87.5,43
20.173484778526795,46.04081632653062,0.4225628592870012,2.841376060962677,2.0,0.4886746735853071,0.0,0.0,,,,166.051,2.052797677516937,2.784,14.479638009049776,0.7885783834457397,0.620760823506123,0.512962818350843,0.620760823506123,1.216,31.4,"{'size': 739949, '_type': 'table-file', 'ncols': 11, 'nrows': 1000, 'sha256': 'f108a2b6730cc9138be9644fffd35063948941e9941826dde80eb11ac555e4e4', 'artifact_path': 'wandb-client-artifact://robl1nj936hkoc463nnlnp7dg258qdzx8726y6brqidhr4czdb5bxbd3jj58eem1q1hh8a2ndjv9g2yp40pm3of8fwn6yknvubheizx6iw82cq658zyrf922uyi0fkx9:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://robl1nj936hkoc463nnlnp7dg258qdzx8726y6brqidhr4czdb5bxbd3jj58eem1q1hh8a2ndjv9g2yp40pm3of8fwn6yknvubheizx6iw82cq658zyrf922uyi0fkx9:latest/predictions.table.json', 'path': 'media/table/predictions_1_f108a2b6730cc9138be9.table.json'}",17.873231353059804,,,False,True,dev_r2,False,Yes | Maybe | No,4,CTBase,27010b55-dd5b-4ee9-9e14-a4b809aa6cdb,anli,CLASSIFICATION,False,28,bigscience/T0_3B,0,True,good_deal_for_seller_no_list_price,prompts/general_fixed_choice.yaml,Craigslist,,3,,,GenFC,"['aqua_rat/raw', 'math_qa', 'craigslist_bargains']",False,['NLI'],anli,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,good deal for seller no list price,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.craigslist_bargains.good_deal_for_seller_no_list_price.LenNorm,ANLI R2,,,,,,,,,,,,,,,,,,,,,84.5,75.0,43
0.625,,0.6761601017001788,2.530792755766722,,,,0.625,,,,88.62068965517241,2.530792755766722,1.0015673981191222,66.73640167364016,,0.0395593400129277,0.6761601017001788,0.0395593400129277,1.9984326018808776,50.15673981191222,"{'nrows': 638, 'sha256': '67234231edf26d1008319300f2622aeb5f1d3639f706fe5dd9bc52676560bb1b', 'artifact_path': 'wandb-client-artifact://10154seaq5m18csbgk52q49uez4enm8qzzguocxchzmdkn27v2uwv1j9ln8idbw58s7umwrsjg96ay796rc5i0ouwrvq5245qrk7mb6n6d651bcmgacbifhn1ls0gjfr:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://10154seaq5m18csbgk52q49uez4enm8qzzguocxchzmdkn27v2uwv1j9ln8idbw58s7umwrsjg96ay796rc5i0ouwrvq5245qrk7mb6n6d651bcmgacbifhn1ls0gjfr:latest/predictions.table.json', 'path': 'media/table/predictions_1_67234231edf26d100831.table.json', 'size': 276799, '_type': 'table-file', 'ncols': 9}",7.037985482349875,,,False,True,validation,False,No | Yes,4,CTBase,145dd841-b971-4550-bc88-305ad3278d58,wic,CLASSIFICATION,False,28,bigscience/T0_3B,0,True,good_deal_for_seller_no_list_price_implicit,prompts/general_fixed_choice.yaml,Craigslist,,2,,,GenFC,"['aqua_rat/raw', 'math_qa', 'craigslist_bargains']",False,Word Sense Disambiguation,wic,False,False,GeneralFixedChoice,False,False,False,,,prompts,,,True,good deal for seller no list price implicit,,cross_task,wic,,,,False,,,False,,True,,,False,,CTBase.GenFC.craigslist_bargains.good_deal_for_seller_no_list_price_implicit.LenNorm,WiC,54.554869900345125,54.843211053350494,WordsinContext,super_glue,,,,,,,,,,,,,,,,,70.5,87.5,42
27.781230981670248,31.778929188255606,0.4429938987112889,1.393760585308075,2.002,0.4057267932983855,0.126475294030099,0.5988023952095808,,,,147.056,0.8580004186630249,1.493,50.96596136154554,0.53576016664505,0.8613657759628021,0.3834518584315551,0.8543857442630933,2.505,37.0,"{'size': 638675, '_type': 'table-file', 'ncols': 11, 'nrows': 1000, 'sha256': '41136e498c2133dc5763534b42437175bf24a261a90f6facc8cd2ff93e3b36b9', 'artifact_path': 'wandb-client-artifact://dmqkq9h6dxvv2f2dmfpoye8wmk619ne14dc0jmzzavsuwx74iswbjrzlcgek6mc7n8a31b367sfeufzdat39odyx3lw2n2zpfq7rylpv2jmuywvt2nqa57jaetsb6s97:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://dmqkq9h6dxvv2f2dmfpoye8wmk619ne14dc0jmzzavsuwx74iswbjrzlcgek6mc7n8a31b367sfeufzdat39odyx3lw2n2zpfq7rylpv2jmuywvt2nqa57jaetsb6s97:latest/predictions.table.json', 'path': 'media/table/predictions_1_41136e498c2133dc5763.table.json'}",18.09101611297718,,,False,True,dev_r1,True,Yes | Maybe | No,4,CTBase,c0403841-68b0-4c08-8c3b-a00a81272d05,anli,MCQ,False,28,bigscience/T0_3B,0,True,Answer_questions_from_options,prompts/general_fixed_choice.yaml,AQuA,,3,,,GenFC,"['aqua_rat/raw', 'math_qa', 'craigslist_bargains']",False,['NLI'],anli,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,Answer questions from options,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.aqua_rat_raw.Answer_questions_from_options.LenNorm,ANLI R1,,,,,,,,,,,,,,,,,,,,,21.0,35.0,11
16.814289800150153,49.84939759036144,0.6052053750169656,2.346989064693451,1.353,0.643940672481648,0.4779027097642364,0.0,,,,156.051,0.6617135105133056,2.992,0.5934718100890207,1.6852755541801452,0.1180508365069896,0.496660206693121,0.4857725805353777,1.655,33.2,"{'_latest_artifact_path': 'wandb-client-artifact://rp84dkn17xqq1e55ilzqsfemzibn08g8itu2u8hssallzubayig141nwlfuq84zux8ig5n6ev2vxkv5fohylte8mrpt0m6ux7agzlzn2w9cvge4vrpc369nx2ba9yrda:latest/predictions.table.json', 'path': 'media/table/predictions_1_34087b3ffb1df382d3e8.table.json', 'size': 730299, '_type': 'table-file', 'ncols': 11, 'nrows': 1000, 'sha256': '34087b3ffb1df382d3e8fe3c51afb938f3e1635ce4ee8d80417d3abd417c213c', 'artifact_path': 'wandb-client-artifact://rp84dkn17xqq1e55ilzqsfemzibn08g8itu2u8hssallzubayig141nwlfuq84zux8ig5n6ev2vxkv5fohylte8mrpt0m6ux7agzlzn2w9cvge4vrpc369nx2ba9yrda:latest/predictions.table.json'}",17.873231353059804,,,False,True,dev_r2,False,Yes | Maybe | No,4,CTBase,145dd841-b971-4550-bc88-305ad3278d58,anli,CLASSIFICATION,False,28,bigscience/T0_3B,0,True,good_deal_for_seller_no_list_price_implicit,prompts/general_fixed_choice.yaml,Craigslist,,3,,,GenFC,"['aqua_rat/raw', 'math_qa', 'craigslist_bargains']",False,['NLI'],anli,False,False,GeneralFixedChoice,False,False,False,,,prompts,,,True,good deal for seller no list price implicit,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.craigslist_bargains.good_deal_for_seller_no_list_price_implicit.LenNorm,ANLI R2,,,,,,,,,,,,,,,,,,,,,40.5,88.0,42
26.04872544831137,27.03703703703703,0.4065352436723276,1.6756201739311218,1.999,0.3824533757271758,0.0316069612585582,0.0,,,,159.056,1.1626306929588317,1.414,51.10913930789708,0.51298948097229,0.8103110513870585,0.3484853709573338,0.8089690970611918,2.587,36.1,"{'artifact_path': 'wandb-client-artifact://1fa7ov2n88qpq6occ2ie9l8v0qgtkrx9ooqmdo3nmxvp9br9j0h76em6ai801v4q71cq9ef7eclc8bdteujmeog1txf69fsimop23bhqy693f71tk4kkmb1a41h9cn0a:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://1fa7ov2n88qpq6occ2ie9l8v0qgtkrx9ooqmdo3nmxvp9br9j0h76em6ai801v4q71cq9ef7eclc8bdteujmeog1txf69fsimop23bhqy693f71tk4kkmb1a41h9cn0a:latest/predictions.table.json', 'path': 'media/table/predictions_1_b95f92ffa5614ed376ad.table.json', 'size': 682768, '_type': 'table-file', 'ncols': 11, 'nrows': 1000, 'sha256': 'b95f92ffa5614ed376ada7ed67b7dbac57d010fd5e2fecdf7621f14e28e6fbbb'}",18.09101611297718,,,False,True,dev_r1,True,Yes | Maybe | No,4,CTBase,815acaf5-2e59-4f81-8190-ae75dc237cf1,anli,MCQ,False,28,bigscience/T0_3B,0,True,answer_quiz,prompts/general_fixed_choice.yaml,AQuA,,3,,,GenFC,"['aqua_rat/raw', 'math_qa', 'craigslist_bargains']",False,['NLI'],anli,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,answer_quiz,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.aqua_rat_raw.answer_quiz.LenNorm,ANLI R1,,,,,,,,,,,,,,,,,,,,,26.5,51.0,23
29.78671921113072,37.04545454545454,0.4521121732503905,1.0301845141251882,2.0216666666666665,0.3239989368113735,0.2935936345056245,3.357314148681056,,,,139.23583333333335,0.6164332083861033,1.8191666666666664,48.95738893925657,0.4137513057390848,0.9771383246785256,0.3843962363188681,0.9489464186957846,2.1591666666666667,36.66666666666666,"{'ncols': 11, 'nrows': 1200, 'sha256': '39dd422651a117dc3f32e4385e496ab65b624965d6e9f1367084143dc01551ab', 'artifact_path': 'wandb-client-artifact://llt0y10vau5k1g18afyvpn8yva0sgociww6lw6o9gzjauiwza52kc8l0ihqs7hg0lg0l2x8kap57vj0ih5qygg5sjw0fawk0x33n1p84rsrtrqw8n4qta15usx8vxqvs:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://llt0y10vau5k1g18afyvpn8yva0sgociww6lw6o9gzjauiwza52kc8l0ihqs7hg0lg0l2x8kap57vj0ih5qygg5sjw0fawk0x33n1p84rsrtrqw8n4qta15usx8vxqvs:latest/predictions.table.json', 'path': 'media/table/predictions_1_39dd422651a117dc3f32.table.json', 'size': 744185, '_type': 'table-file'}",32.01257902719214,,,False,True,dev_r3,True,Yes | Maybe | No,4,CTBase,c0403841-68b0-4c08-8c3b-a00a81272d05,anli,MCQ,False,28,bigscience/T0_3B,0,True,Answer_questions_from_options,prompts/general_fixed_choice.yaml,AQuA,,3,,,GenFC,"['aqua_rat/raw', 'math_qa', 'craigslist_bargains']",False,['NLI'],anli,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,Answer questions from options,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.aqua_rat_raw.Answer_questions_from_options.LenNorm,ANLI R3,,,,,,,,,,,,,,,,,,,,,1.0,1.0,11
29.089023557108668,37.16312056737589,0.4723898469007866,2.429347218751907,1.999,0.4667373113069716,0.0316069612585582,0.0,,,,145.056,1.8692429649829865,1.744,50.1039501039501,0.5601042537689209,0.966676781556276,0.4222192932628197,0.9658938865113498,2.257,37.2,"{'_latest_artifact_path': 'wandb-client-artifact://183bhxhgl950razkxsfvqkh03cp151qclhn6lq54cd8fh651pdbvp5qsq4901raimvsipieow8us5cb07rmx44q1y13q7hfmqf1rtqh2jyntkny69e22kz78vgvaupkh:latest/predictions.table.json', 'path': 'media/table/predictions_1_8e32bfb32aeed9d10d84.table.json', 'size': 637783, '_type': 'table-file', 'ncols': 11, 'nrows': 1000, 'sha256': '8e32bfb32aeed9d10d84d88b8a8c37545ebb3f14381fc3b648b2e8aef5931b98', 'artifact_path': 'wandb-client-artifact://183bhxhgl950razkxsfvqkh03cp151qclhn6lq54cd8fh651pdbvp5qsq4901raimvsipieow8us5cb07rmx44q1y13q7hfmqf1rtqh2jyntkny69e22kz78vgvaupkh:latest/predictions.table.json'}",18.09101611297718,,,False,True,dev_r1,True,Yes | Maybe | No,4,CTBase,5acfaa48-e1b6-44df-8e92-c58b94bff595,anli,MCQ,False,28,bigscience/T0_3B,0,True,generate_rationale,prompts/general_fixed_choice.yaml,AQuA,,3,,,GenFC,"['aqua_rat/raw', 'math_qa', 'craigslist_bargains']",False,['NLI'],anli,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,generate_rationale,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.aqua_rat_raw.generate_rationale.LenNorm,ANLI R1,,,,,,,,,,,,,,,,,,,,,17.0,23.0,17
27.38161203699757,33.8689740420272,0.4162379933340735,1.4043822085857391,2.005,0.3111702163637498,0.0814964211893176,0.0,,,,151.23583333333335,1.0093319749832153,1.6883333333333332,48.27586206896552,0.3950502336025238,0.9501915011664168,0.3803541524541153,0.9483084355255356,2.306666666666666,35.333333333333336,"{'_latest_artifact_path': 'wandb-client-artifact://ahfylq130c18oy9gjckehs2sxpfdmblvh1wvjoqk5a1n3hcdbvudki7sqyc83mgm1wln8n6mnylrtxxuzre5t5c81skiyd26w5t9tqdyts9rywywc6a3zuwn9o2rteww:latest/predictions.table.json', 'path': 'media/table/predictions_1_99af404336fefaa67a19.table.json', 'size': 797146, '_type': 'table-file', 'ncols': 11, 'nrows': 1200, 'sha256': '99af404336fefaa67a19af8b577ae7a526aaf9c3e9ca0f1bf8109fcdeb217ca9', 'artifact_path': 'wandb-client-artifact://ahfylq130c18oy9gjckehs2sxpfdmblvh1wvjoqk5a1n3hcdbvudki7sqyc83mgm1wln8n6mnylrtxxuzre5t5c81skiyd26w5t9tqdyts9rywywc6a3zuwn9o2rteww:latest/predictions.table.json'}",32.01257902719214,,,False,True,dev_r3,True,Yes | Maybe | No,4,CTBase,815acaf5-2e59-4f81-8190-ae75dc237cf1,anli,MCQ,False,28,bigscience/T0_3B,0,True,answer_quiz,prompts/general_fixed_choice.yaml,AQuA,,3,,,GenFC,"['aqua_rat/raw', 'math_qa', 'craigslist_bargains']",False,['NLI'],anli,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,answer_quiz,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.aqua_rat_raw.answer_quiz.LenNorm,ANLI R3,,,,,,,,,,,,,,,,,,,,,4.0,11.0,23
24.22095427694532,21.702127659574465,0.4063953609913248,1.9743980693817136,1.999,0.4208318561340827,0.0316069612585582,0.0,,,,169.056,1.322609601020813,1.274,50.96073517126148,0.6517884683609009,0.6876946997032912,0.3544261405878585,0.6859088860774439,2.727,35.6,"{'sha256': '9ddc4693ac1becee34890ea27178c596e9df3f0ab24c186c75658bda509aad6c', 'artifact_path': 'wandb-client-artifact://depqnnsfk8v05iolws1cc9uw2ty4e9q091w6xu3lwyrsh3et3k6itgpce9914hq0ul45n3ztgkaqf00r2tlx0yivzmynwfuongxu1rekn2gj00h89464qxvu5fspie3s:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://depqnnsfk8v05iolws1cc9uw2ty4e9q091w6xu3lwyrsh3et3k6itgpce9914hq0ul45n3ztgkaqf00r2tlx0yivzmynwfuongxu1rekn2gj00h89464qxvu5fspie3s:latest/predictions.table.json', 'path': 'media/table/predictions_1_9ddc4693ac1becee3489.table.json', 'size': 714904, '_type': 'table-file', 'ncols': 11, 'nrows': 1000}",18.09101611297718,,,False,True,dev_r1,True,Yes | Maybe | No,4,CTBase,58a6aa2b-ca26-473d-9bf8-385dd1a743cd,anli,MCQ,False,28,bigscience/T0_3B,0,True,generate_rational_and_correct_choice,prompts/general_fixed_choice.yaml,AQuA,,3,,,GenFC,"['aqua_rat/raw', 'math_qa', 'craigslist_bargains']",False,['NLI'],anli,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,generate_rational_and_correct_choice,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.aqua_rat_raw.generate_rational_and_correct_choice.LenNorm,ANLI R1,,,,,,,,,,,,,,,,,,,,,31.5,66.0,33
27.56023768286439,42.07746478873239,0.5097183064604531,1.9140991598367687,1.9975,0.3866309229076409,0.0499374608885954,0.0,,,,137.23583333333335,1.4179623981316885,2.2333333333333334,40.60324825986079,0.4961367617050806,0.972396809720988,0.4896563596803497,0.9717077607090632,1.7691666666666668,34.5,"{'ncols': 11, 'nrows': 1200, 'sha256': 'ec589ede7770929b91a72e6b675fd9003863cc83f48f081895481ab6495c3027', 'artifact_path': 'wandb-client-artifact://y6soyz3etm7sucohufo5yblgn5betkwfptqptrj6697ht4wr00w7b68a4n66bqy084rh3hyj3wc9mb6pkwp7ndzo91fq97q2w4irpybgq7slkf9b6f848jtbwcdecnkm:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://y6soyz3etm7sucohufo5yblgn5betkwfptqptrj6697ht4wr00w7b68a4n66bqy084rh3hyj3wc9mb6pkwp7ndzo91fq97q2w4irpybgq7slkf9b6f848jtbwcdecnkm:latest/predictions.table.json', 'path': 'media/table/predictions_1_ec589ede7770929b91a7.table.json', 'size': 743138, '_type': 'table-file'}",32.01257902719214,,,False,True,dev_r3,True,Yes | Maybe | No,4,CTBase,5acfaa48-e1b6-44df-8e92-c58b94bff595,anli,MCQ,False,28,bigscience/T0_3B,0,True,generate_rationale,prompts/general_fixed_choice.yaml,AQuA,,3,,,GenFC,"['aqua_rat/raw', 'math_qa', 'craigslist_bargains']",False,['NLI'],anli,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,generate_rationale,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.aqua_rat_raw.generate_rationale.LenNorm,ANLI R3,,,,,,,,,,,,,,,,,,,,,8.5,7.0,17
27.28005118362124,32.32,0.4701790353976109,4.162318556785584,2.0,0.4227851228522553,0.0,0.0,,,,148.056,3.628921974420547,1.584,49.520153550863725,0.5333965823650361,0.909364613342745,0.4148940730734556,0.909364613342745,2.416,35.9,"{'path': 'media/table/predictions_1_a78ac0494ac4d5515d5e.table.json', 'size': 641044, '_type': 'table-file', 'ncols': 11, 'nrows': 1000, 'sha256': 'a78ac0494ac4d5515d5ed9c78a0d0bb7a32d10bdf41981a0d5492994d209ba93', 'artifact_path': 'wandb-client-artifact://12jakbr90jq3ppgrvja1wnbvgl6hekumkyblff0hoyrqxj7xlykupg5n0fknwpbdfz1eq94juiojspvzo2213f2rt3ohjseeg30lnva6yq1zjvnx8f2180r0mq568b1h:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://12jakbr90jq3ppgrvja1wnbvgl6hekumkyblff0hoyrqxj7xlykupg5n0fknwpbdfz1eq94juiojspvzo2213f2rt3ohjseeg30lnva6yq1zjvnx8f2180r0mq568b1h:latest/predictions.table.json'}",18.09101611297718,,,False,True,dev_r1,True,Yes | Maybe | No,4,CTBase,13bd5099-33fa-4383-a441-33a7d2e1746f,anli,MCQ,False,28,bigscience/T0_3B,0,True,select_the_best_option,prompts/general_fixed_choice.yaml,AQuA,,3,,,GenFC,"['aqua_rat/raw', 'math_qa', 'craigslist_bargains']",False,['NLI'],anli,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,select_the_best_option,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.aqua_rat_raw.select_the_best_option.LenNorm,ANLI R1,,,,,,,,,,,,,,,,,,,,,29.5,40.0,12
26.843463672731964,31.16531165311653,0.4416968040039498,1.5690475757916769,2.000833333333333,0.348628713855069,0.0288554828219679,0.0,,,,161.23583333333335,1.1104993482430776,1.57,49.365079365079374,0.4585482275485993,0.9028288874421332,0.3885016422805674,0.9027638887820496,2.4291666666666667,35.5,"{'ncols': 11, 'nrows': 1200, 'sha256': 'ebb8fe74ee242d40c471f2d1955cf2b27e24af18de22b5bc562421e7a244ba6c', 'artifact_path': 'wandb-client-artifact://frusgho6dc1pwio9jvmmaayjb2n8x6hqld872pbd3e316szmhm1b4d3wzt4ar7sigmt76rajgdg59t6avwbs7p085f862udwfxjsj0b6jmp7u880e7z33je3yy0w79ht:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://frusgho6dc1pwio9jvmmaayjb2n8x6hqld872pbd3e316szmhm1b4d3wzt4ar7sigmt76rajgdg59t6avwbs7p085f862udwfxjsj0b6jmp7u880e7z33je3yy0w79ht:latest/predictions.table.json', 'path': 'media/table/predictions_1_ebb8fe74ee242d40c471.table.json', 'size': 835704, '_type': 'table-file'}",32.01257902719214,,,False,True,dev_r3,True,Yes | Maybe | No,4,CTBase,58a6aa2b-ca26-473d-9bf8-385dd1a743cd,anli,MCQ,False,28,bigscience/T0_3B,0,True,generate_rational_and_correct_choice,prompts/general_fixed_choice.yaml,AQuA,,3,,,GenFC,"['aqua_rat/raw', 'math_qa', 'craigslist_bargains']",False,['NLI'],anli,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,generate_rational_and_correct_choice,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.aqua_rat_raw.generate_rational_and_correct_choice.LenNorm,ANLI R3,,,,,,,,,,,,,,,,,,,,,2.0,17.0,33
29.59674078839003,38.630136986301366,0.5158054175051591,2.4334948530197145,1.999,0.4855051476806317,0.0316069612585582,0.0,,,,136.056,1.858751089811325,1.794,50.16008537886872,0.5747437632083893,0.97855199146494,0.4470910794999907,0.977829739780909,2.207,37.6,"{'_type': 'table-file', 'ncols': 11, 'nrows': 1000, 'sha256': '45ff5f75e15fc96b6d2f12f7abde9087920eead30a902f4a454c4428bf43495d', 'artifact_path': 'wandb-client-artifact://ldjm4su6b0xsptt7vonmbts6zuqo6k7r7ujmzu56rjhannin3hciajowtwh1clmab89e48g5gmm660xfgbx1mb7f2919ymxs6bmicqu22zvde01iy4q5b615cnusaz5m:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://ldjm4su6b0xsptt7vonmbts6zuqo6k7r7ujmzu56rjhannin3hciajowtwh1clmab89e48g5gmm660xfgbx1mb7f2919ymxs6bmicqu22zvde01iy4q5b615cnusaz5m:latest/predictions.table.json', 'path': 'media/table/predictions_1_45ff5f75e15fc96b6d2f.table.json', 'size': 604895}",18.09101611297718,,,False,True,dev_r1,True,Yes | Maybe | No,4,CTBase,eb89c860-5849-461a-9081-3bd466f5642c,anli,MCQ,False,28,bigscience/T0_3B,0,True,gre_problem,prompts/general_fixed_choice.yaml,MathQA,,3,,,GenFC,"['aqua_rat/raw', 'math_qa', 'craigslist_bargains']",False,['NLI'],anli,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,gre_problem,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.math_qa.gre_problem.LenNorm,ANLI R1,,,,,,,,,,,,,,,,,,,,,12.5,17.0,8
28.234847732015577,37.82654127481714,0.4972708514783793,3.771047055919965,2.0,0.3593355952796403,0.0,0.0,,,,140.23583333333335,3.300994303623835,1.935,46.87800192122959,0.4700527522961298,0.9978852639457104,0.4713590350019945,0.9978852639457104,2.065,35.41666666666667,"{'_latest_artifact_path': 'wandb-client-artifact://12p6xvv5q5axqo1qdae9jv6cverp22rlcf79npwvqjfmy4urwityqx2nkf6y7bzhheeaepz0gch8a4jy52suoajjqkyq193gji2na3pbk4hve7d8o7kgocpsbhdft56n:latest/predictions.table.json', 'path': 'media/table/predictions_1_efd74dcec86630ff439b.table.json', 'size': 746976, '_type': 'table-file', 'ncols': 11, 'nrows': 1200, 'sha256': 'efd74dcec86630ff439b37ff11614de21ec8517a71f36d280415c0cf90e4a864', 'artifact_path': 'wandb-client-artifact://12p6xvv5q5axqo1qdae9jv6cverp22rlcf79npwvqjfmy4urwityqx2nkf6y7bzhheeaepz0gch8a4jy52suoajjqkyq193gji2na3pbk4hve7d8o7kgocpsbhdft56n:latest/predictions.table.json'}",32.01257902719214,,,False,True,dev_r3,True,Yes | Maybe | No,4,CTBase,13bd5099-33fa-4383-a441-33a7d2e1746f,anli,MCQ,False,28,bigscience/T0_3B,0,True,select_the_best_option,prompts/general_fixed_choice.yaml,AQuA,,3,,,GenFC,"['aqua_rat/raw', 'math_qa', 'craigslist_bargains']",False,['NLI'],anli,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,select_the_best_option,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.aqua_rat_raw.select_the_best_option.LenNorm,ANLI R3,,,,,,,,,,,,,,,,,,,,,3.0,3.0,12
29.941314011448288,39.54081632653061,0.6295240289907306,3.759894698858261,2.0,0.5847484184341845,0.0,0.0,,,,149.056,3.084250961661339,1.902,50.28312570781427,0.6756437371969223,0.9951864146982716,0.5374614583259293,0.9951864146982712,2.098,37.7,"{'sha256': '95b5622bf2bc2e5c3f87ada7c0c011ceaa0031093d202e4ffc72974327f4ae35', 'artifact_path': 'wandb-client-artifact://10pv5qu3p9iouoj0qaba62y16ey6n09ee7bnc7x2rt1112d7elz541r41onqqtpa8mp21qy0586upcyimo55o42ai4k2ixgm5ljqzhfd7q2ul1tshciz08iuuqzujlak:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://10pv5qu3p9iouoj0qaba62y16ey6n09ee7bnc7x2rt1112d7elz541r41onqqtpa8mp21qy0586upcyimo55o42ai4k2ixgm5ljqzhfd7q2ul1tshciz08iuuqzujlak:latest/predictions.table.json', 'path': 'media/table/predictions_1_95b5622bf2bc2e5c3f87.table.json', 'size': 679341, '_type': 'table-file', 'ncols': 11, 'nrows': 1000}",18.09101611297718,,,False,True,dev_r1,True,Yes | Maybe | No,4,CTBase,a313a5f8-53cd-4b76-abb6-fea2ac4e9ef4,anli,MCQ,False,28,bigscience/T0_3B,0,True,first_choice_then_problem,prompts/general_fixed_choice.yaml,MathQA,,3,,,GenFC,"['aqua_rat/raw', 'math_qa', 'craigslist_bargains']",False,['NLI'],anli,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,first_choice_then_problem,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.math_qa.first_choice_then_problem.LenNorm,ANLI R1,,,,,,,,,,,,,,,,,,,,,10.0,12.0,21
28.127708886516476,41.73441734417344,0.5392118862351518,1.950661844611168,2.0,0.3973672455457717,0.0,0.0,,,,128.23583333333335,1.4332857398192087,2.185,42.64870931537598,0.5173761047919592,0.982738520665594,0.509559490415379,0.982738520665594,1.815,35.083333333333336,"{'size': 703640, '_type': 'table-file', 'ncols': 11, 'nrows': 1200, 'sha256': 'bb6fa141b71863b330aa93a445bc951cb93387c77a49693dfe49a632d498bb1f', 'artifact_path': 'wandb-client-artifact://sve2icxzgevwn5zptmtfcpro6n4k1anytzdsxbyp5u8mk024371id1x88fjqrjfq7ntaxza9oler85hqsqwr0he1psop5k1t64nxf4ibnfsvs2w3sm8s59j9b1ftbsns:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://sve2icxzgevwn5zptmtfcpro6n4k1anytzdsxbyp5u8mk024371id1x88fjqrjfq7ntaxza9oler85hqsqwr0he1psop5k1t64nxf4ibnfsvs2w3sm8s59j9b1ftbsns:latest/predictions.table.json', 'path': 'media/table/predictions_1_bb6fa141b71863b330aa.table.json'}",32.01257902719214,,,False,True,dev_r3,True,Yes | Maybe | No,4,CTBase,eb89c860-5849-461a-9081-3bd466f5642c,anli,MCQ,False,28,bigscience/T0_3B,0,True,gre_problem,prompts/general_fixed_choice.yaml,MathQA,,3,,,GenFC,"['aqua_rat/raw', 'math_qa', 'craigslist_bargains']",False,['NLI'],anli,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,gre_problem,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.math_qa.gre_problem.LenNorm,ANLI R3,,,,,,,,,,,,,,,,,,,,,5.5,4.0,8
29.211257012550213,39.29471032745592,0.4696795109309827,2.2565720574855805,1.999,0.4486283271209199,0.0316069612585582,0.0,,,,138.056,1.730690945863724,1.922,48.33906071019473,0.5258811116218567,0.9969533589892756,0.4230009780740941,0.9963729221531464,2.079,36.7,"{'sha256': 'f9c4db9137fbce842f0fe399979d76f3cfe6471ed753eae4d3a4d7750c96bbd9', 'artifact_path': 'wandb-client-artifact://cvqg0sfudcaggdd8j9ovh3y8p6ztfy98x6aivu4mq3ntv222w2yaelv1n5c5g6sm3n4c3sf5kwoui7czf5jtm8l422op2w51evov215kbvqu7bpp3acx5j6g7hbanfi9:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://cvqg0sfudcaggdd8j9ovh3y8p6ztfy98x6aivu4mq3ntv222w2yaelv1n5c5g6sm3n4c3sf5kwoui7czf5jtm8l422op2w51evov215kbvqu7bpp3acx5j6g7hbanfi9:latest/predictions.table.json', 'path': 'media/table/predictions_1_f9c4db9137fbce842f0f.table.json', 'size': 621702, '_type': 'table-file', 'ncols': 11, 'nrows': 1000}",18.09101611297718,,,False,True,dev_r1,True,Yes | Maybe | No,4,CTBase,8c4c81cc-ca54-45fc-a69a-4b97a5f2b465,anli,MCQ,False,28,bigscience/T0_3B,0,True,pick_the_correct,prompts/general_fixed_choice.yaml,MathQA,,3,,,GenFC,"['aqua_rat/raw', 'math_qa', 'craigslist_bargains']",False,['NLI'],anli,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,pick_the_correct,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.math_qa.pick_the_correct.LenNorm,ANLI R1,,,,,,,,,,,,,,,,,,,,,23.0,21.0,10
26.47178468378979,42.63374485596707,0.6583290915537249,3.075893505960703,2.0,0.490312368728097,0.0,0.0,,,,141.23583333333335,2.447759725848833,2.365,36.7816091954023,0.6281337801118692,0.9310075187666316,0.6462498700394816,0.9310075187666316,1.635,33.58333333333333,"{'size': 792911, '_type': 'table-file', 'ncols': 11, 'nrows': 1200, 'sha256': 'aa714f1b50b2c8894453dae2a3737619f08b7cfbdd4a776600c847272a60d36d', 'artifact_path': 'wandb-client-artifact://5sqydrrurjdy585qyfz7x8r5cwuseb2jwss5gh2fhzcktbbn0y02wcyl5jdq28sxdtasns13a8fsx2g2q669rzc7stgwolsypij4ruluindsrls3ypr7y84ab55mdcbg:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://5sqydrrurjdy585qyfz7x8r5cwuseb2jwss5gh2fhzcktbbn0y02wcyl5jdq28sxdtasns13a8fsx2g2q669rzc7stgwolsypij4ruluindsrls3ypr7y84ab55mdcbg:latest/predictions.table.json', 'path': 'media/table/predictions_1_aa714f1b50b2c8894453.table.json'}",32.01257902719214,,,False,True,dev_r3,True,Yes | Maybe | No,4,CTBase,a313a5f8-53cd-4b76-abb6-fea2ac4e9ef4,anli,MCQ,False,28,bigscience/T0_3B,0,True,first_choice_then_problem,prompts/general_fixed_choice.yaml,MathQA,,3,,,GenFC,"['aqua_rat/raw', 'math_qa', 'craigslist_bargains']",False,['NLI'],anli,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,first_choice_then_problem,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.math_qa.first_choice_then_problem.LenNorm,ANLI R3,,,,,,,,,,,,,,,,,,,,,29.0,21.0,21
29.116642005062275,37.660485021398,0.4363396547959886,2.150399750709534,1.999,0.4057716582954497,0.0316069612585582,0.0,,,,145.056,1.668609506368637,1.736,49.68944099378882,0.4817902443408966,0.9645226798784982,0.4012476591431517,0.9637297338984616,2.265,37.2,"{'size': 652749, '_type': 'table-file', 'ncols': 11, 'nrows': 1000, 'sha256': '15aa2ab090e0c433ecb3c290852e6f1ec781b416e14b45e976fb32cfd0cf174b', 'artifact_path': 'wandb-client-artifact://5ic1r1rnz5c6nrrapjwe9v2k2x4voofejqnam0cpuwtrsptlt467xffl0m62n9njdlzimna0li20h729usw2i89xt5qde790etonauci79oq9487jlmwci7aj1i389hz:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://5ic1r1rnz5c6nrrapjwe9v2k2x4voofejqnam0cpuwtrsptlt467xffl0m62n9njdlzimna0li20h729usw2i89xt5qde790etonauci79oq9487jlmwci7aj1i389hz:latest/predictions.table.json', 'path': 'media/table/predictions_1_15aa2ab090e0c433ecb3.table.json'}",18.09101611297718,,,False,True,dev_r1,True,Yes | Maybe | No,4,CTBase,6312d599-8ca4-4bc8-a76f-81f2e36727bd,anli,MCQ,False,28,bigscience/T0_3B,0,True,choose_correct_og,prompts/general_fixed_choice.yaml,MathQA,,3,,,GenFC,"['aqua_rat/raw', 'math_qa', 'craigslist_bargains']",False,['NLI'],anli,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,choose_correct_og,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.math_qa.choose_correct_og.LenNorm,ANLI R1,,,,,,,,,,,,,,,,,,,,,17.0,22.0,17
26.965796431445288,42.06955046649704,0.4954338851640023,1.8445066744089127,1.9983333333333333,0.389149671263634,0.0407907941684013,0.0,,,,130.23583333333335,1.33692915558815,2.305,38.82783882783883,0.5075775188207626,0.9523523507609984,0.4830162686102416,0.9520095704467588,1.6966666666666668,33.916666666666664,"{'_type': 'table-file', 'ncols': 11, 'nrows': 1200, 'sha256': '07654dc555fedf161fb318a0b486d9301542ea36d22c2a15570844dadec900bf', 'artifact_path': 'wandb-client-artifact://6zr30z41uaamlgc6jjw0bfbvjq1lmeq80wmod10qh38d1oshht35s050bjugsutsww2ax0ga2aj16w2bj9m5gift7tx55r7aqj3o2q2o5ja4pup3qfdpi7waa8la8vq4:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://6zr30z41uaamlgc6jjw0bfbvjq1lmeq80wmod10qh38d1oshht35s050bjugsutsww2ax0ga2aj16w2bj9m5gift7tx55r7aqj3o2q2o5ja4pup3qfdpi7waa8la8vq4:latest/predictions.table.json', 'path': 'media/table/predictions_1_07654dc555fedf161fb3.table.json', 'size': 723878}",32.01257902719214,,,False,True,dev_r3,True,Yes | Maybe | No,4,CTBase,8c4c81cc-ca54-45fc-a69a-4b97a5f2b465,anli,MCQ,False,28,bigscience/T0_3B,0,True,pick_the_correct,prompts/general_fixed_choice.yaml,MathQA,,3,,,GenFC,"['aqua_rat/raw', 'math_qa', 'craigslist_bargains']",False,['NLI'],anli,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,pick_the_correct,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.math_qa.pick_the_correct.LenNorm,ANLI R3,,,,,,,,,,,,,,,,,,,,,21.5,16.0,10
29.65330172770984,40.256410256410255,0.4999467489276635,2.533773010969162,1.999,0.4630907308558502,0.0316069612585582,0.0,,,,142.056,1.992984357595444,1.894,48.70349492671927,0.5407886533737183,0.9943661297530202,0.4413443079147311,0.9937560062711572,2.107,37.3,"{'_type': 'table-file', 'ncols': 11, 'nrows': 1000, 'sha256': 'fc85aee7f474b5bcdb97d18dfe9b042c2db4df1aae6f956ede5e078151ffe130', 'artifact_path': 'wandb-client-artifact://rgr0y693ee6z86sm5k1s1l6xp8igkkwrdn9e2rd3mnbcra1nmly5dlceukd11usie11tj2apg6pzv12kng8nk6agokex0wuahmuyqsiium3y3mcruidveuihpfgys4he:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://rgr0y693ee6z86sm5k1s1l6xp8igkkwrdn9e2rd3mnbcra1nmly5dlceukd11usie11tj2apg6pzv12kng8nk6agokex0wuahmuyqsiium3y3mcruidveuihpfgys4he:latest/predictions.table.json', 'path': 'media/table/predictions_1_fc85aee7f474b5bcdb97.table.json', 'size': 636736}",18.09101611297718,,,False,True,dev_r1,True,Yes | Maybe | No,4,CTBase,091ba88e-d208-4a3a-ada7-d9698aeb5568,anli,MCQ,False,28,bigscience/T0_3B,0,True,choose_correct_variant,prompts/general_fixed_choice.yaml,MathQA,,3,,,GenFC,"['aqua_rat/raw', 'math_qa', 'craigslist_bargains']",False,['NLI'],anli,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,choose_correct_variant,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.math_qa.choose_correct_variant.LenNorm,ANLI R1,,,,,,,,,,,,,,,,,,,,,15.0,15.0,14
27.599156560205955,41.74843889384478,0.4720595857020391,1.7919382951656977,1.9991666666666668,0.3534301990176064,0.0288554828219679,0.0,,,,137.23583333333335,1.3445443371931711,2.208333333333333,41.049030786773095,0.4473939579725265,0.9780578828587918,0.458547293061755,0.9778089878226046,1.7925,34.5,"{'ncols': 11, 'nrows': 1200, 'sha256': '99b96202a33898c72494839f7bc77f7a4c76318c478e05dd6efeb8b9d818d837', 'artifact_path': 'wandb-client-artifact://ta5slpm6wuxstjm6prvnzlju9zms1z7tw164q5dq5spkg6z02falbxqv44lfit6s4i0kcfcvzt60p1xth4ruu2na97puz2dvp3f8i0rzkdcgehaag3zqq3q08p0elnfw:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://ta5slpm6wuxstjm6prvnzlju9zms1z7tw164q5dq5spkg6z02falbxqv44lfit6s4i0kcfcvzt60p1xth4ruu2na97puz2dvp3f8i0rzkdcgehaag3zqq3q08p0elnfw:latest/predictions.table.json', 'path': 'media/table/predictions_1_99b96202a33898c72494.table.json', 'size': 761143, '_type': 'table-file'}",32.01257902719214,,,False,True,dev_r3,True,Yes | Maybe | No,4,CTBase,6312d599-8ca4-4bc8-a76f-81f2e36727bd,anli,MCQ,False,28,bigscience/T0_3B,0,True,choose_correct_og,prompts/general_fixed_choice.yaml,MathQA,,3,,,GenFC,"['aqua_rat/raw', 'math_qa', 'craigslist_bargains']",False,['NLI'],anli,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,choose_correct_og,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.math_qa.choose_correct_og.LenNorm,ANLI R3,,,,,,,,,,,,,,,,,,,,,8.5,6.0,17
24.83273980505692,41.42011834319527,0.3169849966505707,2.9512441351413727,2.0,0.2667252660386159,0.0,0.0,,,,181.056,2.627770435094833,2.362,33.078101071975496,0.3234737000465393,0.9321780945720618,0.3185028010568318,0.9321780945720618,1.638,31.8,"{'artifact_path': 'wandb-client-artifact://7yzurw439z3ovxz5rlxiukuhis1v1op7qegq2mto33c47rfz8qz08lyefdj68de2ff7pkv8k08ffyzb0p930nio6m6ehjmim8jvqkh72ucptds7mbxhwciu1611xd5w4:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://7yzurw439z3ovxz5rlxiukuhis1v1op7qegq2mto33c47rfz8qz08lyefdj68de2ff7pkv8k08ffyzb0p930nio6m6ehjmim8jvqkh72ucptds7mbxhwciu1611xd5w4:latest/predictions.table.json', 'path': 'media/table/predictions_1_ce9bcf37a0bcbd61b82e.table.json', 'size': 788868, '_type': 'table-file', 'ncols': 11, 'nrows': 1000, 'sha256': 'ce9bcf37a0bcbd61b82e3063d57c06444a295a58b064acc9933513d2c4583945'}",18.09101611297718,,,False,True,dev_r1,True,Yes | Maybe | No,4,CTBase,a1dbb258-2e5c-4160-986b-46fc03546965,anli,MCQ,False,28,bigscience/T0_3B,0,True,best_deal,prompts/general_fixed_choice.yaml,Craigslist,,3,,,GenFC,"['aqua_rat/raw', 'math_qa', 'craigslist_bargains']",False,['NLI'],anli,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,best deal,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.craigslist_bargains.best_deal.LenNorm,ANLI R1,,,,,,,,,,,,,,,,,,,,,84.5,63.0,53
27.301176083559504,42.14162348877375,0.5337595329138826,2.0450781629482906,2.0,0.3964602125604744,0.0,0.0,,,,134.23583333333335,1.535975650747617,2.27,39.761904761904766,0.5091025122006734,0.9628603221651624,0.5133724631642256,0.9628603221651624,1.73,34.25,"{'nrows': 1200, 'sha256': 'd6456c06a58913d0d7b43c84f8e2743b65454bc14204118f312ab1a80b12cad4', 'artifact_path': 'wandb-client-artifact://17h1uuq4plij5s6tokc6zp006xrgcxcrzogrmtxm8vz8xc1qm33tklglz2rnrbnh2z3lunsxgos5lvhsmk9hmojj4hztdv79jt20yljch93x2tsfbv9q8nnhrsm475pe:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://17h1uuq4plij5s6tokc6zp006xrgcxcrzogrmtxm8vz8xc1qm33tklglz2rnrbnh2z3lunsxgos5lvhsmk9hmojj4hztdv79jt20yljch93x2tsfbv9q8nnhrsm475pe:latest/predictions.table.json', 'path': 'media/table/predictions_1_d6456c06a58913d0d7b4.table.json', 'size': 741931, '_type': 'table-file', 'ncols': 11}",32.01257902719214,,,False,True,dev_r3,True,Yes | Maybe | No,4,CTBase,091ba88e-d208-4a3a-ada7-d9698aeb5568,anli,MCQ,False,28,bigscience/T0_3B,0,True,choose_correct_variant,prompts/general_fixed_choice.yaml,MathQA,,3,,,GenFC,"['aqua_rat/raw', 'math_qa', 'craigslist_bargains']",False,['NLI'],anli,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,choose_correct_variant,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.math_qa.choose_correct_variant.LenNorm,ANLI R3,,,,,,,,,,,,,,,,,,,,,13.0,13.0,14
19.955797703696867,45.38775510204082,0.432961852399759,2.924542993068695,2.0,0.5338268256727988,0.0,0.0,,,,177.056,2.108970722198486,2.784,14.479638009049776,0.8155722708702088,0.620760823506123,0.4981623163426626,0.6207608235061229,1.216,31.0,"{'ncols': 11, 'nrows': 1000, 'sha256': 'f680d48dea5c7143cb600efa06451646a41fdbd874b65c0b82770c3e659093d3', 'artifact_path': 'wandb-client-artifact://72q46sbvs3fneh4u4m9wr1m6ppl3my9jbrpp1pzkxjyegqs56nqdhde78ss2pj142utk9s6u18dsw7vsf86s3n3798rw9w75yvuddtffjerz0qjhs8obclvpxn991q1o:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://72q46sbvs3fneh4u4m9wr1m6ppl3my9jbrpp1pzkxjyegqs56nqdhde78ss2pj142utk9s6u18dsw7vsf86s3n3798rw9w75yvuddtffjerz0qjhs8obclvpxn991q1o:latest/predictions.table.json', 'path': 'media/table/predictions_1_f680d48dea5c7143cb60.table.json', 'size': 772135, '_type': 'table-file'}",18.09101611297718,,,False,True,dev_r1,False,Yes | Maybe | No,4,CTBase,78d1b487-c535-4a0d-ae49-055d321db3fd,anli,CLASSIFICATION,False,28,bigscience/T0_3B,0,True,good_deal_for_seller,prompts/general_fixed_choice.yaml,Craigslist,,3,,,GenFC,"['aqua_rat/raw', 'math_qa', 'craigslist_bargains']",False,['NLI'],anli,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,good deal for seller,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.craigslist_bargains.good_deal_for_seller.LenNorm,ANLI R1,,,,,,,,,,,,,,,,,,,,,89.0,80.0,52
22.59463683393177,46.86192468619247,0.3714133138801752,2.9901077443361284,2.0,0.3331012214152996,0.0,0.0,,,,173.23583333333335,2.531983849008878,2.73,20.92198581560284,0.4581238953272502,0.6834471449936711,0.3397306401284044,0.6834471449936711,1.27,32.916666666666664,"{'sha256': 'aea1b001f26e3ccf01ab3390f17334a484810e9635a40733fc1322bea0cdf59b', 'artifact_path': 'wandb-client-artifact://19pxuyxc85q65a0qlvo2o27cstnzlxa97uoqdta8fcwzfes6p8xbwovr8jjnn2xyse315l3b0zaxdm1yk13m5mbgdkxj34l7736s9mzuifk6q7i4ar4ptwyxez19rwlj:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://19pxuyxc85q65a0qlvo2o27cstnzlxa97uoqdta8fcwzfes6p8xbwovr8jjnn2xyse315l3b0zaxdm1yk13m5mbgdkxj34l7736s9mzuifk6q7i4ar4ptwyxez19rwlj:latest/predictions.table.json', 'path': 'media/table/predictions_1_aea1b001f26e3ccf01ab.table.json', 'size': 924548, '_type': 'table-file', 'ncols': 11, 'nrows': 1200}",32.01257902719214,,,False,True,dev_r3,True,Yes | Maybe | No,4,CTBase,a1dbb258-2e5c-4160-986b-46fc03546965,anli,MCQ,False,28,bigscience/T0_3B,0,True,best_deal,prompts/general_fixed_choice.yaml,Craigslist,,3,,,GenFC,"['aqua_rat/raw', 'math_qa', 'craigslist_bargains']",False,['NLI'],anli,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,best deal,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.craigslist_bargains.best_deal.LenNorm,ANLI R3,,,,,,,,,,,,,,,,,,,,,58.5,55.0,53
21.47739532941217,43.898305084745765,0.4589207308557734,2.88319553732872,2.0,0.5392668256094927,0.0,0.0,,,,168.056,2.1242337579727173,2.694,20.53388090349076,0.7589617793560028,0.7199749995659572,0.5103828860338662,0.7199749995659572,1.306,30.9,"{'ncols': 11, 'nrows': 1000, 'sha256': '30e1afad0faa26997c9a23200480bf34f15a1751bc59443e1be75ca5e2290d32', 'artifact_path': 'wandb-client-artifact://zr8qraa6gr7rk1sdeiew583rbjvm6es5vt38yep1k52f1q3g5sbfh9k6q5j8ayljy3ky9uy0kv1m2i6dybctlacvbha59a6uwdnni5j4kvexfhs1w3jd8o6puiw3nb0g:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://zr8qraa6gr7rk1sdeiew583rbjvm6es5vt38yep1k52f1q3g5sbfh9k6q5j8ayljy3ky9uy0kv1m2i6dybctlacvbha59a6uwdnni5j4kvexfhs1w3jd8o6puiw3nb0g:latest/predictions.table.json', 'path': 'media/table/predictions_1_30e1afad0faa26997c9a.table.json', 'size': 745230, '_type': 'table-file'}",18.09101611297718,,,False,True,dev_r1,False,Yes | Maybe | No,4,CTBase,27010b55-dd5b-4ee9-9e14-a4b809aa6cdb,anli,CLASSIFICATION,False,28,bigscience/T0_3B,0,True,good_deal_for_seller_no_list_price,prompts/general_fixed_choice.yaml,Craigslist,,3,,,GenFC,"['aqua_rat/raw', 'math_qa', 'craigslist_bargains']",False,['NLI'],anli,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,good deal for seller no list price,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.craigslist_bargains.good_deal_for_seller_no_list_price.LenNorm,ANLI R1,,,,,,,,,,,,,,,,,,,,,90.0,75.0,43
17.47312108468728,49.14067472947167,0.4931405901980213,2.84913380185763,1.9991666666666668,0.6103402286360612,0.0288554828219679,0.0,,,,169.23583333333335,1.6025826867421469,2.958333333333333,3.278688524590165,1.2465511151154836,0.2856522750167102,0.5089492231841659,0.2869850460680254,1.0425,32.75,"{'artifact_path': 'wandb-client-artifact://91yl72tku2tzv91rxm9bxweky2r99xe2umzr1no4lz8wahqgqzl5gx3kzxd2bi43kcpqa2dqf8pcyv11dqkomyphjp290598dpom92zccl8inld2poxdqhijzwxckpg3:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://91yl72tku2tzv91rxm9bxweky2r99xe2umzr1no4lz8wahqgqzl5gx3kzxd2bi43kcpqa2dqf8pcyv11dqkomyphjp290598dpom92zccl8inld2poxdqhijzwxckpg3:latest/predictions.table.json', 'path': 'media/table/predictions_1_7749c977421346953981.table.json', 'size': 904575, '_type': 'table-file', 'ncols': 11, 'nrows': 1200, 'sha256': '7749c9774213469539813c514805f604fb6b3ff66bdc384dabd50601abc9a2cb'}",32.01257902719214,,,False,True,dev_r3,False,Yes | Maybe | No,4,CTBase,78d1b487-c535-4a0d-ae49-055d321db3fd,anli,CLASSIFICATION,False,28,bigscience/T0_3B,0,True,good_deal_for_seller,prompts/general_fixed_choice.yaml,Craigslist,,3,,,GenFC,"['aqua_rat/raw', 'math_qa', 'craigslist_bargains']",False,['NLI'],anli,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,good deal for seller,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.craigslist_bargains.good_deal_for_seller.LenNorm,ANLI R3,,,,,,,,,,,,,,,,,,,,,67.5,87.0,52
17.343625932490706,49.66037735849056,0.660488717540625,2.310770428657532,1.432,0.6588421262030669,0.4953544185732071,1.1940298507462686,,,,158.056,0.6436890144348144,2.986,1.1764705882352942,1.6670814142227173,0.1606362350156402,0.486507660564827,0.5091915160330148,1.582,33.300000000000004,"{'artifact_path': 'wandb-client-artifact://vektjx19p0sr8svlsm7rbi32nkirs51j92aiumob0av0myyj765x7jy5cpskk8ly9aq7lem5qgv68uj2b2v7pcwy6pto8i776y93c1eos5mh6j1w0exxhs6gfgl8fc0a:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://vektjx19p0sr8svlsm7rbi32nkirs51j92aiumob0av0myyj765x7jy5cpskk8ly9aq7lem5qgv68uj2b2v7pcwy6pto8i776y93c1eos5mh6j1w0exxhs6gfgl8fc0a:latest/predictions.table.json', 'path': 'media/table/predictions_1_5f5ef1ed3e896499b62c.table.json', 'size': 735485, '_type': 'table-file', 'ncols': 11, 'nrows': 1000, 'sha256': '5f5ef1ed3e896499b62cf9395fd9f593b8341d5ae2da0fb618a830ce387b7af1'}",18.09101611297718,,,False,True,dev_r1,False,Yes | Maybe | No,4,CTBase,145dd841-b971-4550-bc88-305ad3278d58,anli,CLASSIFICATION,False,28,bigscience/T0_3B,0,True,good_deal_for_seller_no_list_price_implicit,prompts/general_fixed_choice.yaml,Craigslist,,3,,,GenFC,"['aqua_rat/raw', 'math_qa', 'craigslist_bargains']",False,['NLI'],anli,False,False,GeneralFixedChoice,False,False,False,,,prompts,,,True,good deal for seller no list price implicit,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.craigslist_bargains.good_deal_for_seller_no_list_price_implicit.LenNorm,ANLI R1,,,,,,,,,,,,,,,,,,,,,66.0,89.0,42
17.395967395967396,48.13384813384814,0.5156878198233263,2.793747385541598,1.9983333333333333,0.6374416969213882,0.0407907941684013,0.0,,,,160.23583333333335,1.6418392503261563,2.93,4.0540540540540535,1.1519081352154414,0.3675595189897821,0.5151794540022021,0.3695004134714271,1.0716666666666668,31.916666666666664,"{'_type': 'table-file', 'ncols': 11, 'nrows': 1200, 'sha256': 'b8495419b43116a48dcb1bec043ae44b9c6373244a94fe1fe6d81bfa7bb79988', 'artifact_path': 'wandb-client-artifact://sjhfe5k0kh5cb4h1u26x2av5rpuxe36wlk0cfd68dujw2ordft5xdjht9n8wbah8qhlieslgoagbk8k4jcsxaqjzs9ff67mkesgnvmkdznvjj7zpipr8rnjn119v48wn:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://sjhfe5k0kh5cb4h1u26x2av5rpuxe36wlk0cfd68dujw2ordft5xdjht9n8wbah8qhlieslgoagbk8k4jcsxaqjzs9ff67mkesgnvmkdznvjj7zpipr8rnjn119v48wn:latest/predictions.table.json', 'path': 'media/table/predictions_1_b8495419b43116a48dcb.table.json', 'size': 872260}",32.01257902719214,,,False,True,dev_r3,False,Yes | Maybe | No,4,CTBase,27010b55-dd5b-4ee9-9e14-a4b809aa6cdb,anli,CLASSIFICATION,False,28,bigscience/T0_3B,0,True,good_deal_for_seller_no_list_price,prompts/general_fixed_choice.yaml,Craigslist,,3,,,GenFC,"['aqua_rat/raw', 'math_qa', 'craigslist_bargains']",False,['NLI'],anli,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,good deal for seller no list price,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.craigslist_bargains.good_deal_for_seller_no_list_price.LenNorm,ANLI R3,,,,,,,,,,,,,,,,,,,,,89.5,89.0,43
23.25375773651636,7.6923076923076925,0.3915824683525379,1.1619219865117754,2.017857142857143,0.3310334063058445,0.132432115840994,0.0,,,,144.78571428571428,0.6751863275255475,1.75,62.06896551724138,0.4867356589862278,0.9682458365518544,0.2746921623746627,0.9634586400154436,2.232142857142857,33.92857142857143,"{'sha256': 'a0cbd832892b166345fe489432879b69c1b2ab4bda270f2506edc056c17d81c9', 'artifact_path': 'wandb-client-artifact://16egut3c51p8662ki6dcep2fjkpbcv2qu3m2b2mowwb7t64rjx1gh2k1s2i6wrufspkg5qp94r4wnbjrdwp4994jrc4gfithruzcvkbj4yl5h3eulisyfqjwfyjrg6f9:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://16egut3c51p8662ki6dcep2fjkpbcv2qu3m2b2mowwb7t64rjx1gh2k1s2i6wrufspkg5qp94r4wnbjrdwp4994jrc4gfithruzcvkbj4yl5h3eulisyfqjwfyjrg6f9:latest/predictions.table.json', 'path': 'media/table/predictions_1_a0cbd832892b166345fe.table.json', 'size': 34366, '_type': 'table-file', 'ncols': 11, 'nrows': 56}",55.06285832888571,,,False,True,validation,True,Yes | Maybe | No,4,CTBase,c0403841-68b0-4c08-8c3b-a00a81272d05,cb,MCQ,False,28,bigscience/T0_3B,0,True,Answer_questions_from_options,prompts/general_fixed_choice.yaml,AQuA,,3,,,GenFC,"['aqua_rat/raw', 'math_qa', 'craigslist_bargains']",False,['NLI'],cb,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,Answer questions from options,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.aqua_rat_raw.Answer_questions_from_options.LenNorm,CB,,,CommitmentBank,super_glue,,,,,,,,,,,,,,,,,8.5,18.0,11
22.777777777777786,8.333333333333332,0.3494092701555547,1.6225111484527588,2.0,0.3183161235223466,0.0,0.0,,,,156.78571428571428,1.1629467521395005,1.6785714285714286,60.00000000000001,0.4595643963132585,0.9469338273973468,0.2903625416609338,0.9469338273973468,2.321428571428572,33.92857142857143,"{'size': 36845, '_type': 'table-file', 'ncols': 11, 'nrows': 56, 'sha256': '05fc8323d2861e1f4691bc8102017bc5ebff72f8c63bade96f03fbde3ab9afed', 'artifact_path': 'wandb-client-artifact://9ahqs25qfe71b24j2vya3u9dsxm785q7cn6joah4d2klxarcito4cnq7s0ec4l5qxh1isc6ssrvphbe8s60ot61xxa647nqb4w1yai0wwxifpxxdai9x7zxf1m78naf7:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://9ahqs25qfe71b24j2vya3u9dsxm785q7cn6joah4d2klxarcito4cnq7s0ec4l5qxh1isc6ssrvphbe8s60ot61xxa647nqb4w1yai0wwxifpxxdai9x7zxf1m78naf7:latest/predictions.table.json', 'path': 'media/table/predictions_1_05fc8323d2861e1f4691.table.json'}",55.06285832888571,,,False,True,validation,True,Yes | Maybe | No,4,CTBase,815acaf5-2e59-4f81-8190-ae75dc237cf1,cb,MCQ,False,28,bigscience/T0_3B,0,True,answer_quiz,prompts/general_fixed_choice.yaml,AQuA,,3,,,GenFC,"['aqua_rat/raw', 'math_qa', 'craigslist_bargains']",False,['NLI'],cb,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,answer_quiz,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.aqua_rat_raw.answer_quiz.LenNorm,CB,,,CommitmentBank,super_glue,,,,,,,,,,,,,,,,,8.5,22.0,23
17.662703675900616,49.681528662420384,0.7608870695255037,2.350337703625361,1.1741666666666666,0.7818699458512361,0.3836221737885105,2.810304449648712,,,,150.23583333333335,0.826608095963796,2.9775,0.4962779156327544,1.5237296076615652,0.1538194287684968,0.5563171286041424,0.4106870936478146,1.8483333333333336,33.08333333333333,"{'nrows': 1200, 'sha256': 'a0b310656e46107b123ce3a8f0ed9d509c95c2ae81c844fd52f0d22bd45f0ea2', 'artifact_path': 'wandb-client-artifact://o921d2yhqln5g8hxcqm7kvdqegzr54mmw7zab2kt5o17q9q7h1y55bppdohx0g50kryk803d1cmspytg20gqrsw3y06hd61dig4rb6pxhvxc4mo96pgadzpkvfbix8ge:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://o921d2yhqln5g8hxcqm7kvdqegzr54mmw7zab2kt5o17q9q7h1y55bppdohx0g50kryk803d1cmspytg20gqrsw3y06hd61dig4rb6pxhvxc4mo96pgadzpkvfbix8ge:latest/predictions.table.json', 'path': 'media/table/predictions_1_a0b310656e46107b123c.table.json', 'size': 860386, '_type': 'table-file', 'ncols': 11}",32.01257902719214,,,False,True,dev_r3,False,Yes | Maybe | No,4,CTBase,145dd841-b971-4550-bc88-305ad3278d58,anli,CLASSIFICATION,False,28,bigscience/T0_3B,0,True,good_deal_for_seller_no_list_price_implicit,prompts/general_fixed_choice.yaml,Craigslist,,3,,,GenFC,"['aqua_rat/raw', 'math_qa', 'craigslist_bargains']",False,['NLI'],anli,False,False,GeneralFixedChoice,False,False,False,,,prompts,,,True,good deal for seller no list price implicit,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.craigslist_bargains.good_deal_for_seller_no_list_price_implicit.LenNorm,ANLI R3,,,,,,,,,,,,,,,,,,,,,48.5,86.0,42
21.296296296296298,5.555555555555555,0.4472736630780512,1.896616620676858,2.0,0.3214015138483853,0.0,0.0,,,,142.78571428571428,1.3906405653272356,2.107142857142857,58.333333333333336,0.5059760553496224,0.9942436362196468,0.3449420441093358,0.9942436362196468,1.8928571428571428,26.785714285714285,"{'nrows': 56, 'sha256': 'd7f6017f1a95f59cb26592c82d85d25e885431c34bb2a09f93aabc697bcadcb8', 'artifact_path': 'wandb-client-artifact://rf9dkrys4awzwqwboafv86acmrehy85gxsw7bpp61dt5f61tjw9cohdapic36cnfrymmqkp29badldl4bywq5atk8cwppclbeml8pweyr1eyvuu16qd50raaed876g5u:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://rf9dkrys4awzwqwboafv86acmrehy85gxsw7bpp61dt5f61tjw9cohdapic36cnfrymmqkp29badldl4bywq5atk8cwppclbeml8pweyr1eyvuu16qd50raaed876g5u:latest/predictions.table.json', 'path': 'media/table/predictions_1_d7f6017f1a95f59cb265.table.json', 'size': 34330, '_type': 'table-file', 'ncols': 11}",55.06285832888571,,,False,True,validation,True,Yes | Maybe | No,4,CTBase,5acfaa48-e1b6-44df-8e92-c58b94bff595,cb,MCQ,False,28,bigscience/T0_3B,0,True,generate_rationale,prompts/general_fixed_choice.yaml,AQuA,,3,,,GenFC,"['aqua_rat/raw', 'math_qa', 'craigslist_bargains']",False,['NLI'],cb,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,generate_rationale,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.aqua_rat_raw.generate_rationale.LenNorm,CB,,,CommitmentBank,super_glue,,,,,,,,,,,,,,,,,27.5,31.0,17
24.33862433862434,9.523809523809524,0.3591842308914145,1.5925401364054,2.0,0.3469734512301931,0.0,0.0,,,,166.78571428571428,1.1009589348520552,1.5714285714285714,63.4920634920635,0.4915812015533447,0.9035079029052512,0.3335421562859124,0.9035079029052512,2.4285714285714284,37.5,"{'_type': 'table-file', 'ncols': 11, 'nrows': 56, 'sha256': '7e3cc7f9394dc4f2cd321e3ea55960e5fb9278f514a22c554734e30cc350d3a8', 'artifact_path': 'wandb-client-artifact://ifnzba9w8s4lk83dk84xhlpl7wl3kpoy9seo2mxd5pcxxxxzq6ewfb0mvjmjirtr83w65prwdtd4f0k9knfaa18ce5cfkeg1mam5i25eipj923qlnu63l5qpwcnsnkm6:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://ifnzba9w8s4lk83dk84xhlpl7wl3kpoy9seo2mxd5pcxxxxzq6ewfb0mvjmjirtr83w65prwdtd4f0k9knfaa18ce5cfkeg1mam5i25eipj923qlnu63l5qpwcnsnkm6:latest/predictions.table.json', 'path': 'media/table/predictions_1_7e3cc7f9394dc4f2cd32.table.json', 'size': 38629}",55.06285832888571,,,False,True,validation,True,Yes | Maybe | No,4,CTBase,58a6aa2b-ca26-473d-9bf8-385dd1a743cd,cb,MCQ,False,28,bigscience/T0_3B,0,True,generate_rational_and_correct_choice,prompts/general_fixed_choice.yaml,AQuA,,3,,,GenFC,"['aqua_rat/raw', 'math_qa', 'craigslist_bargains']",False,['NLI'],cb,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,generate_rational_and_correct_choice,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.aqua_rat_raw.generate_rational_and_correct_choice.LenNorm,CB,,,CommitmentBank,super_glue,,,,,,,,,,,,,,,,,4.5,11.0,33
24.13559322033898,8.000000000000002,0.5015751139978022,3.766780419009073,2.0,0.3755606772929442,0.0,0.0,,,,145.78571428571428,3.227078599589212,1.7142857142857142,64.40677966101694,0.5397018194198608,0.95831484749991,0.4272034880858815,0.95831484749991,2.2857142857142856,35.714285714285715,"{'_type': 'table-file', 'ncols': 11, 'nrows': 56, 'sha256': '2751d94a7cfe6414e081a64a06e484ec92961a1a300a7c663a2e1605b09036e1', 'artifact_path': 'wandb-client-artifact://10uz5iibq9o8mho84c7w7jph8ducyq1lrvgsm2cqc9qtqeye0a9vei07o90j99hlc2h2ztrt37xv2snug47xlod9t561elqf9h095srn2cuyh0qje1j8jmnfruqw41tj:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://10uz5iibq9o8mho84c7w7jph8ducyq1lrvgsm2cqc9qtqeye0a9vei07o90j99hlc2h2ztrt37xv2snug47xlod9t561elqf9h095srn2cuyh0qje1j8jmnfruqw41tj:latest/predictions.table.json', 'path': 'media/table/predictions_1_2751d94a7cfe6414e081.table.json', 'size': 34499}",55.06285832888571,,,False,True,validation,True,Yes | Maybe | No,4,CTBase,13bd5099-33fa-4383-a441-33a7d2e1746f,cb,MCQ,False,28,bigscience/T0_3B,0,True,select_the_best_option,prompts/general_fixed_choice.yaml,AQuA,,3,,,GenFC,"['aqua_rat/raw', 'math_qa', 'craigslist_bargains']",False,['NLI'],cb,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,select_the_best_option,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.aqua_rat_raw.select_the_best_option.LenNorm,CB,,,CommitmentBank,super_glue,,,,,,,,,,,,,,,,,6.0,13.0,12
21.628045157456924,6.0606060606060606,0.5091910911359384,1.9473807939461296,2.0,0.3522775260237623,0.0,0.0,,,,133.78571428571428,1.408670731953212,2.0,58.82352941176471,0.5387100619929177,1.0,0.3673516420505127,1.0,2.0,28.57142857142857,"{'_latest_artifact_path': 'wandb-client-artifact://txlmj95m8dxv2ermqu4b1zt55poi62w0fytttlijktotg1httr2sdao8qkrdvnvcy2rbofmif0qexwcnyczrpeqxgjok7limvmusybb7kqt7t9x2knxz3uoyh0u0hgsb:latest/predictions.table.json', 'path': 'media/table/predictions_1_e29a18ee0eb805932021.table.json', 'size': 32490, '_type': 'table-file', 'ncols': 11, 'nrows': 56, 'sha256': 'e29a18ee0eb805932021c0397fdb086bd04d4678cc79c81fe7792908b81e1617', 'artifact_path': 'wandb-client-artifact://txlmj95m8dxv2ermqu4b1zt55poi62w0fytttlijktotg1httr2sdao8qkrdvnvcy2rbofmif0qexwcnyczrpeqxgjok7limvmusybb7kqt7t9x2knxz3uoyh0u0hgsb:latest/predictions.table.json'}",55.06285832888571,,,False,True,validation,True,Yes | Maybe | No,4,CTBase,eb89c860-5849-461a-9081-3bd466f5642c,cb,MCQ,False,28,bigscience/T0_3B,0,True,gre_problem,prompts/general_fixed_choice.yaml,MathQA,,3,,,GenFC,"['aqua_rat/raw', 'math_qa', 'craigslist_bargains']",False,['NLI'],cb,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,gre_problem,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.math_qa.gre_problem.LenNorm,CB,,,CommitmentBank,super_glue,,,,,,,,,,,,,,,,,21.0,29.0,8
19.90740740740741,5.555555555555555,0.6199382735903677,2.9659159907272885,2.0,0.3620858964537096,0.0,0.0,,,,146.78571428571428,2.4309508204460144,2.107142857142857,54.16666666666667,0.534965170281274,0.9942436362196468,0.4876268447600228,0.9942436362196468,1.8928571428571428,25.0,"{'nrows': 56, 'sha256': '4f3733e847ce54e762e98ea4c71454c26285d2bc5cfa09259c86b397d7180a80', 'artifact_path': 'wandb-client-artifact://fz73mkm1k8iikowqyf2b8282193iunvdcuv154isllvdvki25jqgz2ovzrfql55gm4liutvfu7lqx5kktbna292u8bmaf0jsouzvbqokr88txhzan2fu0d2hf8m25drw:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://fz73mkm1k8iikowqyf2b8282193iunvdcuv154isllvdvki25jqgz2ovzrfql55gm4liutvfu7lqx5kktbna292u8bmaf0jsouzvbqokr88txhzan2fu0d2hf8m25drw:latest/predictions.table.json', 'path': 'media/table/predictions_1_4f3733e847ce54e762e9.table.json', 'size': 36656, '_type': 'table-file', 'ncols': 11}",55.06285832888571,,,False,True,validation,True,Yes | Maybe | No,4,CTBase,a313a5f8-53cd-4b76-abb6-fea2ac4e9ef4,cb,MCQ,False,28,bigscience/T0_3B,0,True,first_choice_then_problem,prompts/general_fixed_choice.yaml,MathQA,,3,,,GenFC,"['aqua_rat/raw', 'math_qa', 'craigslist_bargains']",False,['NLI'],cb,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,first_choice_then_problem,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.math_qa.first_choice_then_problem.LenNorm,CB,,,CommitmentBank,super_glue,,,,,,,,,,,,,,,,,35.5,47.0,21
21.65995783017059,5.405405405405405,0.4817100872709498,1.8024268022605352,2.0,0.3389848384054259,0.0,0.0,,,,135.78571428571428,1.2851332681519645,2.142857142857143,59.57446808510638,0.5172935341085706,0.989743318610787,0.3790617868192825,0.989743318610787,1.8571428571428568,26.785714285714285,"{'artifact_path': 'wandb-client-artifact://hij45ptl9o3wr9ybdevqmojiqp73qudtsjim4alhfcvq2jkwuq84rzv8r5n6xj68kt9fbikfetqvnqlzgqd009th2utx8uu4239w40e69a8qmn3l8bp0v4hfe2tbk8ua:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://hij45ptl9o3wr9ybdevqmojiqp73qudtsjim4alhfcvq2jkwuq84rzv8r5n6xj68kt9fbikfetqvnqlzgqd009th2utx8uu4239w40e69a8qmn3l8bp0v4hfe2tbk8ua:latest/predictions.table.json', 'path': 'media/table/predictions_1_126f19a1b7db8e5f43f9.table.json', 'size': 33440, '_type': 'table-file', 'ncols': 11, 'nrows': 56, 'sha256': '126f19a1b7db8e5f43f922eb85f12f57934e7e5e82be9d37ab54183028996f40'}",55.06285832888571,,,False,True,validation,True,Yes | Maybe | No,4,CTBase,8c4c81cc-ca54-45fc-a69a-4b97a5f2b465,cb,MCQ,False,28,bigscience/T0_3B,0,True,pick_the_correct,prompts/general_fixed_choice.yaml,MathQA,,3,,,GenFC,"['aqua_rat/raw', 'math_qa', 'craigslist_bargains']",False,['NLI'],cb,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,pick_the_correct,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.math_qa.pick_the_correct.LenNorm,CB,,,CommitmentBank,super_glue,,,,,,,,,,,,,,,,,27.5,28.0,10
20.95238095238096,5.714285714285714,0.4316090838182158,1.795422307082585,2.0,0.2680345172255618,0.0,0.0,,,,142.78571428571428,1.342510734285627,2.071428571428572,57.14285714285715,0.4529115727969578,0.9974457174120672,0.363618990221167,0.9974457174120672,1.9285714285714288,26.785714285714285,"{'nrows': 56, 'sha256': '1daa2b1f9c6eac9535c335b06c88c76a6936790612804cf82d929184ab7c59de', 'artifact_path': 'wandb-client-artifact://mqstw4fhyexlk7jacs6mkq276o2c4q4t5nq9fy60trcblhiau6hya0dqn1do3jrkezul12s5leklwu4c9yrjn8zjb6sjehssjiz5eq4maqsia3b4yfc7y4w5hwnvqcal:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://mqstw4fhyexlk7jacs6mkq276o2c4q4t5nq9fy60trcblhiau6hya0dqn1do3jrkezul12s5leklwu4c9yrjn8zjb6sjehssjiz5eq4maqsia3b4yfc7y4w5hwnvqcal:latest/predictions.table.json', 'path': 'media/table/predictions_1_1daa2b1f9c6eac9535c3.table.json', 'size': 35167, '_type': 'table-file', 'ncols': 11}",55.06285832888571,,,False,True,validation,True,Yes | Maybe | No,4,CTBase,6312d599-8ca4-4bc8-a76f-81f2e36727bd,cb,MCQ,False,28,bigscience/T0_3B,0,True,choose_correct_og,prompts/general_fixed_choice.yaml,MathQA,,3,,,GenFC,"['aqua_rat/raw', 'math_qa', 'craigslist_bargains']",False,['NLI'],cb,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,choose_correct_og,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.math_qa.choose_correct_og.LenNorm,CB,,,CommitmentBank,super_glue,,,,,,,,,,,,,,,,,27.5,33.0,17
20.24151811385854,5.405405405405405,0.4783284800401624,2.02287586246218,2.0,0.3327901525870219,0.0,0.0,,,,139.78571428571428,1.5341235143797738,2.142857142857143,55.319148936170215,0.4887523480824062,0.989743318610787,0.3633259834563754,0.989743318610787,1.8571428571428568,25.0,"{'artifact_path': 'wandb-client-artifact://sx0rhd00u2rwdvj9yr9s0qmc601vjy3s6nnre8jru0dx6upfkgk01lk2nun5lgogqavdlakcd289x25e3tfojeadc6ao0zn8eeujycuplk8va0r52mgohqlk2webhmxv:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://sx0rhd00u2rwdvj9yr9s0qmc601vjy3s6nnre8jru0dx6upfkgk01lk2nun5lgogqavdlakcd289x25e3tfojeadc6ao0zn8eeujycuplk8va0r52mgohqlk2webhmxv:latest/predictions.table.json', 'path': 'media/table/predictions_1_1fcde49de9957b79228a.table.json', 'size': 34283, '_type': 'table-file', 'ncols': 11, 'nrows': 56, 'sha256': '1fcde49de9957b79228aa1bce8f4d56ec9961d353e3eb8e4133a952a0970de36'}",55.06285832888571,,,False,True,validation,True,Yes | Maybe | No,4,CTBase,091ba88e-d208-4a3a-ada7-d9698aeb5568,cb,MCQ,False,28,bigscience/T0_3B,0,True,choose_correct_variant,prompts/general_fixed_choice.yaml,MathQA,,3,,,GenFC,"['aqua_rat/raw', 'math_qa', 'craigslist_bargains']",False,['NLI'],cb,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,choose_correct_variant,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.math_qa.choose_correct_variant.LenNorm,CB,,,CommitmentBank,super_glue,,,,,,,,,,,,,,,,,35.5,43.0,14
8.447043534762834,10.526315789473683,0.2878081099864999,3.152764795081956,2.0,0.333557467482478,0.0,0.0,,,,178.78571428571428,2.6371273483548845,2.857142857142857,14.814814814814817,0.5156374467270715,0.5150787536377127,0.2855465494835317,0.5150787536377127,1.1428571428571428,8.928571428571429,"{'_type': 'table-file', 'ncols': 11, 'nrows': 56, 'sha256': '26a1bdb0abff3eca22f771cd151265c309d76ce69d9d00d9f73aa5ea41a1c40f', 'artifact_path': 'wandb-client-artifact://llirlyuw40jp77c9d26zabx60vbmyvw5xej2pzndfadoa3ssf6yilrqjjg5rfvw798g0pykhsn5jh4hld1zfl8x9uihqftmwxerwy4k9gcnc5sn68k85is9vd8yfoxkm:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://llirlyuw40jp77c9d26zabx60vbmyvw5xej2pzndfadoa3ssf6yilrqjjg5rfvw798g0pykhsn5jh4hld1zfl8x9uihqftmwxerwy4k9gcnc5sn68k85is9vd8yfoxkm:latest/predictions.table.json', 'path': 'media/table/predictions_1_26a1bdb0abff3eca22f7.table.json', 'size': 42783}",55.06285832888571,,,False,True,validation,True,Yes | Maybe | No,4,CTBase,a1dbb258-2e5c-4160-986b-46fc03546965,cb,MCQ,False,28,bigscience/T0_3B,0,True,best_deal,prompts/general_fixed_choice.yaml,Craigslist,,3,,,GenFC,"['aqua_rat/raw', 'math_qa', 'craigslist_bargains']",False,['NLI'],cb,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,best deal,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.craigslist_bargains.best_deal.LenNorm,CB,,,CommitmentBank,super_glue,,,,,,,,,,,,,,,,,86.0,80.0,53
4.444444444444445,13.333333333333334,0.352126662413217,2.7775117499487743,2.0,0.4449526807555394,0.0,0.0,,,,174.78571428571428,1.6044375555855888,2.9642857142857144,0.0,1.1730741943631853,0.264864231681988,0.2997961919459089,0.264864231681988,1.0357142857142858,7.142857142857142,"{'sha256': 'd6785b020446c46f06d2f5389430e80b6c321d67553076b259eb38dae3c4cb25', 'artifact_path': 'wandb-client-artifact://civ8qolpya0lfcqwi8rvtpnzzfbt51lri9isesrsu08az16f1b7nvphvhuc5enwcaz9n0kawr43dju670w6zyui6b0vushj1yjnlkn4zqd4wkqk97xp6b37v6e3b83rb:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://civ8qolpya0lfcqwi8rvtpnzzfbt51lri9isesrsu08az16f1b7nvphvhuc5enwcaz9n0kawr43dju670w6zyui6b0vushj1yjnlkn4zqd4wkqk97xp6b37v6e3b83rb:latest/predictions.table.json', 'path': 'media/table/predictions_1_d6785b020446c46f06d2.table.json', 'size': 41873, '_type': 'table-file', 'ncols': 11, 'nrows': 56}",55.06285832888571,,,False,True,validation,False,Yes | Maybe | No,4,CTBase,78d1b487-c535-4a0d-ae49-055d321db3fd,cb,CLASSIFICATION,False,28,bigscience/T0_3B,0,True,good_deal_for_seller,prompts/general_fixed_choice.yaml,Craigslist,,3,,,GenFC,"['aqua_rat/raw', 'math_qa', 'craigslist_bargains']",False,['NLI'],cb,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,good deal for seller,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.craigslist_bargains.good_deal_for_seller.LenNorm,CB,,,CommitmentBank,super_glue,,,,,,,,,,,,,,,,,89.5,89.5,52
4.444444444444445,13.333333333333334,0.3470169636392213,2.68014566387449,2.0,0.4430840928328667,0.0,0.0,,,,165.78571428571428,1.59112971169608,2.9642857142857144,0.0,1.0890159521784102,0.264864231681988,0.2851443138128435,0.264864231681988,1.0357142857142858,7.142857142857142,"{'nrows': 56, 'sha256': '31f442030bf77263fab581972466838ace88cce9d4bd9b94756164f306b68e08', 'artifact_path': 'wandb-client-artifact://146p9v4xx4u82w8u5g6862awyco2178wfgct4ezmwmhegkern7v6n7kclbmg2qyoxi78oetdqltwau9wq6j8472dtlex75126gj4rl3f8dmy4bt6kjigob8q2mewvfgz:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://146p9v4xx4u82w8u5g6862awyco2178wfgct4ezmwmhegkern7v6n7kclbmg2qyoxi78oetdqltwau9wq6j8472dtlex75126gj4rl3f8dmy4bt6kjigob8q2mewvfgz:latest/predictions.table.json', 'path': 'media/table/predictions_1_31f442030bf77263fab5.table.json', 'size': 40356, '_type': 'table-file', 'ncols': 11}",55.06285832888571,,,False,True,validation,False,Yes | Maybe | No,4,CTBase,27010b55-dd5b-4ee9-9e14-a4b809aa6cdb,cb,CLASSIFICATION,False,28,bigscience/T0_3B,0,True,good_deal_for_seller_no_list_price,prompts/general_fixed_choice.yaml,Craigslist,,3,,,GenFC,"['aqua_rat/raw', 'math_qa', 'craigslist_bargains']",False,['NLI'],cb,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,good deal for seller no list price,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.craigslist_bargains.good_deal_for_seller_no_list_price.LenNorm,CB,,,CommitmentBank,super_glue,,,,,,,,,,,,,,,,,89.5,89.5,43
5.464480874316941,16.393442622950822,0.5176314840881967,2.1622021879468645,1.3214285714285714,0.5587879173935064,0.4670248868079293,0.0,,,,155.78571428571428,0.5783226490020752,3.0,0.0,1.5838795389447893,0.0,0.4736277990393762,0.4670248868079293,1.6785714285714286,8.928571428571429,"{'size': 39815, '_type': 'table-file', 'ncols': 11, 'nrows': 56, 'sha256': 'c9222b55462b1b8eaf9cbd093e7d3322fd02df868ae3c9007494a7e0ce28ed9b', 'artifact_path': 'wandb-client-artifact://1288dz65yeq4veobwnfr8zzk64lr3s44op19lfc8pr5n8vv9iu0lsultotxis7bb7frdtunmc9bpgecsztk6hk5fmrlshueef5txaojjp8ygammc9915ocbfjxeknamk:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://1288dz65yeq4veobwnfr8zzk64lr3s44op19lfc8pr5n8vv9iu0lsultotxis7bb7frdtunmc9bpgecsztk6hk5fmrlshueef5txaojjp8ygammc9915ocbfjxeknamk:latest/predictions.table.json', 'path': 'media/table/predictions_1_c9222b55462b1b8eaf9c.table.json'}",55.06285832888571,,,False,True,validation,False,Yes | Maybe | No,4,CTBase,145dd841-b971-4550-bc88-305ad3278d58,cb,CLASSIFICATION,False,28,bigscience/T0_3B,0,True,good_deal_for_seller_no_list_price_implicit,prompts/general_fixed_choice.yaml,Craigslist,,3,,,GenFC,"['aqua_rat/raw', 'math_qa', 'craigslist_bargains']",False,['NLI'],cb,False,False,GeneralFixedChoice,False,False,False,,,prompts,,,True,good deal for seller no list price implicit,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.craigslist_bargains.good_deal_for_seller_no_list_price_implicit.LenNorm,CB,,,CommitmentBank,super_glue,,,,,,,,,,,,,,,,,86.0,87.5,42
15.217391304347828,,0.6060596308301551,0.9742182578459428,,,,15.217391304347828,,,,57.62068965517241,0.9742182578459428,1.0768025078369905,65.63876651982379,,0.266277829769847,0.6060596308301551,0.266277829769847,1.9231974921630093,51.09717868338558,"{'_latest_artifact_path': 'wandb-client-artifact://mw1ejytksedgp550a136rb45p3guemp7552asgse99ycn5fwvhvyg1w4l5dg9namntdhzyi3gzfxq8f4cl0jxh984xnjxc81qnqls0idvktrcks59wu10jo7q21pbyq3:latest/predictions.table.json', 'path': 'media/table/predictions_1_b46f3c82f798f4ec8f56.table.json', 'size': 181010, '_type': 'table-file', 'ncols': 9, 'nrows': 638, 'sha256': 'b46f3c82f798f4ec8f569ecf609be692de0db8f999c6c6d73ce80940be426a4c', 'artifact_path': 'wandb-client-artifact://mw1ejytksedgp550a136rb45p3guemp7552asgse99ycn5fwvhvyg1w4l5dg9namntdhzyi3gzfxq8f4cl0jxh984xnjxc81qnqls0idvktrcks59wu10jo7q21pbyq3:latest/predictions.table.json'}",7.037985482349875,,,False,True,validation,False,No | Yes,4,CTBase,f32348cd-d3cb-4619-87b9-e24f99c78567,wic,COMPLETION,False,28,bigscience/T0_3B,0,True,choose,prompts/general_fixed_choice.yaml,COPA,,2,,,GenFC,,False,Word Sense Disambiguation,,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,choose,,cross_task,wic,,,,False,,,False,,True,,,False,,CTBase.GenFC.super_glue_copa.choose.LenNorm,WiC,53.75448780586807,54.20151138451863,WordsinContext,super_glue,,,,,,,,,,,,,,,,,18.5,20.0,8
15.013404825737268,,0.6719838955127487,1.0804463039724548,,,,15.013404825737268,,,,68.62068965517241,1.0804463039724548,1.084639498432602,64.89479512735326,,0.2783444875288164,0.6719838955127487,0.2783444875288164,1.915360501567398,50.313479623824456,"{'nrows': 638, 'sha256': '8bef3de56cad83c429d5ca63498fad5d7099ef7bf2e89458a992e7713bff8908', 'artifact_path': 'wandb-client-artifact://e329laeusaoltrtz61m738qeioqlzds7f1knrlvu0fwv85co2csfp9taoa8nzfsshhnvxtoalwyor1qop5wh5gkrvev2zyimjjy42i34z7dz61pr5fguvqrv1bjo5u8c:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://e329laeusaoltrtz61m738qeioqlzds7f1knrlvu0fwv85co2csfp9taoa8nzfsshhnvxtoalwyor1qop5wh5gkrvev2zyimjjy42i34z7dz61pr5fguvqrv1bjo5u8c:latest/predictions.table.json', 'path': 'media/table/predictions_1_8bef3de56cad83c429d5.table.json', 'size': 213162, '_type': 'table-file', 'ncols': 9}",7.037985482349875,,,False,True,validation,False,No | Yes,4,CTBase,a1f9951e-2b6b-4530-9636-9cdf4c1658c5,wic,COMPLETION,False,28,bigscience/T0_3B,0,True,more_likely,prompts/general_fixed_choice.yaml,COPA,,2,,,GenFC,,False,Word Sense Disambiguation,,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,more likely,,cross_task,wic,,,,False,,,False,,True,,,False,,CTBase.GenFC.super_glue_copa.more_likely.LenNorm,WiC,53.56101459801994,53.86149900256483,WordsinContext,super_glue,,,,,,,,,,,,,,,,,58.0,21.0,19
4.25531914893617,,0.6788263978896077,1.636416207053071,,,,4.25531914893617,,,,62.62068965517241,1.636416207053071,1.0156739811912223,66.73706441393875,,0.1242107382831282,0.6788263978896077,0.1242107382831282,1.9843260188087777,50.626959247648905,"{'path': 'media/table/predictions_1_356ede3933225bb2282e.table.json', 'size': 202129, '_type': 'table-file', 'ncols': 9, 'nrows': 638, 'sha256': '356ede3933225bb2282e686dc4b55dd35791e482eea4df7f4e5e3df6beb668bd', 'artifact_path': 'wandb-client-artifact://c29p4bhprh3x1a6tcq2wjlagq1hrxwya77swqzredd40k81r9hft2s3qzvm1q6dzelhy17pwmnhcyemvv897anj3ep9qpnc593sjcaja618coi2i1ryc8zw0u42ln195:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://c29p4bhprh3x1a6tcq2wjlagq1hrxwya77swqzredd40k81r9hft2s3qzvm1q6dzelhy17pwmnhcyemvv897anj3ep9qpnc593sjcaja618coi2i1ryc8zw0u42ln195:latest/predictions.table.json'}",7.037985482349875,,,False,True,validation,False,No | Yes,4,CTBase,0edd8660-f299-4819-a5ac-633c11177228,wic,COMPLETION,False,28,bigscience/T0_3B,0,True,exercise,prompts/general_fixed_choice.yaml,COPA,,2,,,GenFC,,False,Word Sense Disambiguation,,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,exercise,,cross_task,wic,,,,False,,,False,,True,,,False,,CTBase.GenFC.super_glue_copa.exercise.LenNorm,WiC,55.03271740691903,55.3974508898301,WordsinContext,super_glue,,,,,,,,,,,,,,,,,36.5,63.0,13
10.140845070422538,,0.6282948473335349,1.0338627563374918,,,,10.140845070422538,,,,63.62068965517241,1.0338627563374918,1.056426332288401,65.36373507057547,,0.2307431500887516,0.6282948473335349,0.2307431500887516,1.943573667711599,50.0,"{'sha256': '2f6de05d37b8e396d89cfde94224e7fe8a21065d813f010c8e9995d56c216220', 'artifact_path': 'wandb-client-artifact://5ok71fiawykiu8yz6d8s3m91l273usfi3n5f2rnmdwt5mifmpij37zav38gunlufrz5vg7e5q04d7f3usqmgdh66gjithrmwh69fcrfjbgeqj3cxg4648kov95dmbt7h:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://5ok71fiawykiu8yz6d8s3m91l273usfi3n5f2rnmdwt5mifmpij37zav38gunlufrz5vg7e5q04d7f3usqmgdh66gjithrmwh69fcrfjbgeqj3cxg4648kov95dmbt7h:latest/predictions.table.json', 'path': 'media/table/predictions_1_2f6de05d37b8e396d89c.table.json', 'size': 191312, '_type': 'table-file', 'ncols': 9, 'nrows': 638}",7.037985482349875,,,False,True,validation,False,No | Yes,4,CTBase,2d0d63da-ffcf-4f6e-941a-b8da922be43e,wic,ENTAILMENT,False,28,bigscience/T0_3B,0,True,guaranteed_true,prompts/general_fixed_choice.yaml,ANLI,,2,,,GenFC,,False,Word Sense Disambiguation,,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,guaranteed true,,cross_task,wic,,,,False,,,False,,True,,,False,,CTBase.GenFC.anli.guaranteed_true.LenNorm,WiC,52.95991315291568,53.03407002682757,WordsinContext,super_glue,,,,,,,,,,,,,,,,,82.5,33.0,12
2.4539877300613497,,0.617461377304514,1.357150700772444,,,,2.4539877300613497,,,,75.62068965517241,1.357150700772444,1.0109717868338557,66.52631578947368,,0.1041700855693621,0.617461377304514,0.1041700855693621,1.9890282131661443,50.15673981191222,"{'size': 197409, '_type': 'table-file', 'ncols': 9, 'nrows': 638, 'sha256': '4fe4e1bf3cb01b9ff4eac37be788dcee17f7f5c9b1551ed93881b01978dc9195', 'artifact_path': 'wandb-client-artifact://17rqx0o6krbthwjaz1miyb989z7sedmrb6mx6r97qxplv3grvachdsznaho4bk699b4pgj0mwbjgw83y1g7ol1tf9innxspop7jhe7mimny8fm5357b64dmk8cz7siwf:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://17rqx0o6krbthwjaz1miyb989z7sedmrb6mx6r97qxplv3grvachdsznaho4bk699b4pgj0mwbjgw83y1g7ol1tf9innxspop7jhe7mimny8fm5357b64dmk8cz7siwf:latest/predictions.table.json', 'path': 'media/table/predictions_1_4fe4e1bf3cb01b9ff4ea.table.json'}",7.037985482349875,,,False,True,validation,False,No | Yes,4,CTBase,9e078fb4-505b-413c-bb5e-3cd16ddcf5d7,wic,ENTAILMENT,False,28,bigscience/T0_3B,0,True,does_this_imply,prompts/general_fixed_choice.yaml,ANLI,,2,,,GenFC,,False,Word Sense Disambiguation,,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,does this imply,,cross_task,wic,,,,False,,,False,,True,,,False,,CTBase.GenFC.anli.does_this_imply.LenNorm,WiC,53.63872710314812,53.70426784327984,WordsinContext,super_glue,,,,,,,,,,,,,,,,,70.5,79.0,23
25.24271844660194,,0.5615799335861832,0.7567620090556368,,,,25.24271844660194,,,,65.62068965517241,0.7567620090556368,1.14576802507837,64.35185185185185,,0.3528735013331571,0.5615799335861832,0.3528735013331571,1.85423197492163,51.72413793103448,"{'_latest_artifact_path': 'wandb-client-artifact://l5ywmbosan1o743b718t7iudt2ikryzky7l4emm110gvtgtqyqoc1z2ipcgamouk7a44crnfnx3a7o0iz6wrfpdpsn5rm6gbp5ip7raqkrh5h6rnx8qdxgi8s3h7k6je:latest/predictions.table.json', 'path': 'media/table/predictions_1_fa455a1bc37d893f90a2.table.json', 'size': 197803, '_type': 'table-file', 'ncols': 9, 'nrows': 638, 'sha256': 'fa455a1bc37d893f90a2065da14338a70373fcf85336d08ee4c78161d9240849', 'artifact_path': 'wandb-client-artifact://l5ywmbosan1o743b718t7iudt2ikryzky7l4emm110gvtgtqyqoc1z2ipcgamouk7a44crnfnx3a7o0iz6wrfpdpsn5rm6gbp5ip7raqkrh5h6rnx8qdxgi8s3h7k6je:latest/predictions.table.json'}",7.037985482349875,,,False,True,validation,False,No | Yes,4,CTBase,fb4f8144-37f5-4977-88da-37a5d0bfd0e8,wic,ENTAILMENT,False,28,bigscience/T0_3B,0,True,must_be_true,prompts/general_fixed_choice.yaml,ANLI,,2,,,GenFC,,False,Word Sense Disambiguation,,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,must be true,,cross_task,wic,,,,False,,,False,,True,,,False,,CTBase.GenFC.anli.must_be_true.LenNorm,WiC,52.81819282745128,52.92400821532808,WordsinContext,super_glue,,,,,,,,,,,,,,,,,5.5,8.0,14
18.461538461538463,,0.5810623434242865,0.8275491638243385,,,,18.461538461538463,,,,68.62068965517241,0.8275491638243385,1.1112852664576802,64.10835214446952,,0.3144850647123378,0.5810623434242865,0.3144850647123378,1.88871473354232,50.15673981191222,"{'path': 'media/table/predictions_1_900a3e69a0968b134d3e.table.json', 'size': 208934, '_type': 'table-file', 'ncols': 9, 'nrows': 638, 'sha256': '900a3e69a0968b134d3edcabf12f8f9aa1c93d1eac55bd58a7792c8645ff65de', 'artifact_path': 'wandb-client-artifact://ffkpfw83iadxqtcxiootlouf4r5xjxlictanqnhn0mafm7nkerxj5ckd3lyn45vxtuh6wt9vukrtq9zc128kcanot7o6y3i2bxprxo9faxqqe1jw10wno18xmo9fqflo:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://ffkpfw83iadxqtcxiootlouf4r5xjxlictanqnhn0mafm7nkerxj5ckd3lyn45vxtuh6wt9vukrtq9zc128kcanot7o6y3i2bxprxo9faxqqe1jw10wno18xmo9fqflo:latest/predictions.table.json'}",7.037985482349875,,,False,True,validation,False,No | Yes,4,CTBase,bab86d5a-4f9c-40db-b619-a7b7d5cae681,wic,ENTAILMENT,False,28,bigscience/T0_3B,0,True,take_the_following_as_truth,prompts/general_fixed_choice.yaml,ANLI,,2,,,GenFC,,False,Word Sense Disambiguation,,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,take the following as truth,,cross_task,wic,,,,False,,,False,,True,,,False,,CTBase.GenFC.anli.take_the_following_as_truth.LenNorm,WiC,52.15335473191687,52.35011448393786,WordsinContext,super_glue,,,,,,,,,,,,,,,,,70.5,15.5,17
4.216867469879518,,0.6671033194397296,1.3249100584968878,,,,4.216867469879518,,,,62.62068965517241,1.3249100584968878,1.0203761755485894,66.3135593220339,,0.1412833571890278,0.6671033194397296,0.1412833571890278,1.9796238244514104,50.15673981191222,"{'_type': 'table-file', 'ncols': 9, 'nrows': 638, 'sha256': '2e95247d92e1ef348a2945358b4c6b7d00ac7bca9e30d442b39b459760fed345', 'artifact_path': 'wandb-client-artifact://eol1kjnrgdrzmvzouuuw9jkoniiu8yb2cunt9qqz0ofdljawf3h6r8pgjkenbgcgs9kw06bx63cmu90y7ehjxjub38paqya0xsyh6pcaojxp9yvppt71oarzzyonje4q:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://eol1kjnrgdrzmvzouuuw9jkoniiu8yb2cunt9qqz0ofdljawf3h6r8pgjkenbgcgs9kw06bx63cmu90y7ehjxjub38paqya0xsyh6pcaojxp9yvppt71oarzzyonje4q:latest/predictions.table.json', 'path': 'media/table/predictions_1_2e95247d92e1ef348a29.table.json', 'size': 190576}",7.037985482349875,,,False,True,validation,False,No | Yes,4,CTBase,a850110d-f1a3-49b4-949a-d3bfe9f81344,wic,ENTAILMENT,False,28,bigscience/T0_3B,0,True,justified_in_saying,prompts/general_fixed_choice.yaml,ANLI,,2,,,GenFC,,False,Word Sense Disambiguation,,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,justified in saying,,cross_task,wic,,,,False,,,False,,True,,,False,,CTBase.GenFC.anli.justified_in_saying.LenNorm,WiC,53.10680979925594,53.07534320613987,WordsinContext,super_glue,,,,,,,,,,,,,,,,,70.5,65.0,11
7.53623188405797,,0.6519559264682517,1.162119994529736,,,,7.53623188405797,,,,66.62068965517241,1.162119994529736,1.0407523510971788,65.73576799140709,,0.197715950234752,0.6519559264682517,0.197715950234752,1.9592476489028208,50.0,"{'size': 200242, '_type': 'table-file', 'ncols': 9, 'nrows': 638, 'sha256': 'f29a833ce16efee2dad4a7277cd7eb3a053ee9149fd04ec78a53bf46aefa3033', 'artifact_path': 'wandb-client-artifact://sy4d61mi173v6ofv5k6hym943ko9n2wyjki7bt42awqaibel9et55gyyi4nmrslh3adhfacvj5bpsb9z89mx68rtnzukp67mi1v0bcc6ugf1md32t2u28g70bywkc3ji:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://sy4d61mi173v6ofv5k6hym943ko9n2wyjki7bt42awqaibel9et55gyyi4nmrslh3adhfacvj5bpsb9z89mx68rtnzukp67mi1v0bcc6ugf1md32t2u28g70bywkc3ji:latest/predictions.table.json', 'path': 'media/table/predictions_1_f29a833ce16efee2dad4.table.json'}",7.037985482349875,,,False,True,validation,False,No | Yes,4,CTBase,9b613182-c6ab-4427-9221-3d68f6d62765,wic,ENTAILMENT,False,28,bigscience/T0_3B,0,True,based_on_the_previous_passage,prompts/general_fixed_choice.yaml,ANLI,,2,,,GenFC,,False,Word Sense Disambiguation,,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,based on the previous passage,,cross_task,wic,,,,False,,,False,,True,,,False,,CTBase.GenFC.anli.based_on_the_previous_passage.LenNorm,WiC,51.89003877880377,51.44603531804916,WordsinContext,super_glue,,,,,,,,,,,,,,,,,82.5,45.0,15
6.413994169096209,,0.6527201092086479,1.1706944601289158,,,,6.413994169096209,,,,56.62068965517241,1.1706944601289158,1.037617554858934,65.59485530546624,,0.1902694784387902,0.6527201092086479,0.1902694784387902,1.962382445141066,49.68652037617554,"{'nrows': 638, 'sha256': '5e9d3906b651841ed484a731de7e10420247293c4c947a5a343cb2d29cf6f8ce', 'artifact_path': 'wandb-client-artifact://17ol1lk331ioz3dsnxu7o2mw6lco2etm9vqry50elobel9d68pw7t27o82489cra209m64oyot2ok4wp82sxl29h332h0t2w1bax84xlfbsjqn96oape3fh2sr0x4nxh:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://17ol1lk331ioz3dsnxu7o2mw6lco2etm9vqry50elobel9d68pw7t27o82489cra209m64oyot2ok4wp82sxl29h332h0t2w1bax84xlfbsjqn96oape3fh2sr0x4nxh:latest/predictions.table.json', 'path': 'media/table/predictions_1_5e9d3906b651841ed484.table.json', 'size': 173475, '_type': 'table-file', 'ncols': 9}",7.037985482349875,,,False,True,validation,False,No | Yes,4,CTBase,620aa3fc-d5eb-46f5-a1ee-4c754527aa97,wic,ENTAILMENT,False,28,bigscience/T0_3B,0,True,GPT_3_style,prompts/general_fixed_choice.yaml,ANLI,,2,,,GenFC,,False,Word Sense Disambiguation,,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,GPT-3 style,,cross_task,wic,,,,False,,,False,,True,,,False,,CTBase.GenFC.anli.GPT_3_style.LenNorm,WiC,53.38960384499734,53.72392173819046,WordsinContext,super_glue,,,,,,,,,,,,,,,,,88.5,52.0,4
8.069164265129682,,0.6600582147395694,1.127074826847423,,,,8.069164265129682,,,,64.62068965517241,1.127074826847423,1.0438871473354232,65.66200215285252,,0.2048440031687089,0.6600582147395694,0.2048440031687089,1.9561128526645768,50.0,"{'nrows': 638, 'sha256': '8cc90b1b26f3fdec07c8adf25df7b0d609a2b32deabf6460cd4dd87cd221dc8b', 'artifact_path': 'wandb-client-artifact://xn5tphatq5652ivmgn8spgd8gpn6j3pfb10r0pdkq0pxah2s5usvo4pnhbroldtard290fhqmgedh1gytp5x43tgbayytye9f0ymbqzr6h4nsosvoeykf33dnmerhbdc:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://xn5tphatq5652ivmgn8spgd8gpn6j3pfb10r0pdkq0pxah2s5usvo4pnhbroldtard290fhqmgedh1gytp5x43tgbayytye9f0ymbqzr6h4nsosvoeykf33dnmerhbdc:latest/predictions.table.json', 'path': 'media/table/predictions_1_8cc90b1b26f3fdec07c8.table.json', 'size': 195448, '_type': 'table-file', 'ncols': 9}",7.037985482349875,,,False,True,validation,False,No | Yes,4,CTBase,ec249357-e672-4e7d-b8b6-d97ed7d090c5,wic,ENTAILMENT,False,28,bigscience/T0_3B,0,True,claim_true_false_inconclusive,prompts/general_fixed_choice.yaml,ANLI,,2,,,GenFC,,False,Word Sense Disambiguation,,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,claim true/false/inconclusive,,cross_task,wic,,,,False,,,False,,True,,,False,,CTBase.GenFC.anli.claim_true_false_inconclusive.LenNorm,WiC,53.157930550312656,53.31413802930396,WordsinContext,super_glue,,,,,,,,,,,,,,,,,82.5,41.0,13
3.6474164133738607,,0.6629609953423571,1.333308315576057,,,,3.6474164133738607,,,,63.62068965517241,1.333308315576057,1.0156739811912223,66.52587117212249,,0.1242107382831282,0.6629609953423571,0.1242107382831282,1.9843260188087777,50.313479623824456,"{'sha256': '9e2ce111b330fbb4dbcd9067118315d9cfec7ee74b17e7419402e5847facc768', 'artifact_path': 'wandb-client-artifact://sgz86xjqmqxito9n8iyqqo2pbvxtrxb66fod4an2hjgz3dx6fqo4b7c7csq0htulb322a2aqvuz8l7s5cl2yfptkquuix1t665u7iv8b9bciacjq605pl0ed9cfj6ity:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://sgz86xjqmqxito9n8iyqqo2pbvxtrxb66fod4an2hjgz3dx6fqo4b7c7csq0htulb322a2aqvuz8l7s5cl2yfptkquuix1t665u7iv8b9bciacjq605pl0ed9cfj6ity:latest/predictions.table.json', 'path': 'media/table/predictions_1_9e2ce111b330fbb4dbcd.table.json', 'size': 186703, '_type': 'table-file', 'ncols': 9, 'nrows': 638}",7.037985482349875,,,False,True,validation,False,No | Yes,4,CTBase,c4ed37ae-d7d7-4197-a725-ef2152fa3b1f,wic,ENTAILMENT,False,28,bigscience/T0_3B,0,True,can_we_infer,prompts/general_fixed_choice.yaml,ANLI,,2,,,GenFC,,False,Word Sense Disambiguation,,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,can we infer,,cross_task,wic,,,,False,,,False,,True,,,False,,CTBase.GenFC.anli.can_we_infer.LenNorm,WiC,53.71786471217197,53.7848488124134,WordsinContext,super_glue,,,,,,,,,,,,,,,,,58.0,66.0,12
6.606606606606606,,0.9663288838532336,2.0223071130465566,,,,6.606606606606606,,,,58.62068965517241,2.0223071130465566,1.0219435736677116,67.02014846235419,,0.1464993284708203,0.9663288838532336,0.1464993284708203,1.9780564263322884,51.2539184952978,"{'_type': 'table-file', 'ncols': 9, 'nrows': 638, 'sha256': '1b3e8df036b107a8c63d13d301399a872744a298ae3b989cfc4d79abbc94a1cd', 'artifact_path': 'wandb-client-artifact://2h0ybfsn4asaqmsuhn19m6v70lzzb2lrjbtfbarup03lelgso0f82m5fbl2ltsxif0uweymwhru82hm3wpo7dyivjuftyaqal85x9ol5mc7i9lj9mtughs86dq8kl8wj:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://2h0ybfsn4asaqmsuhn19m6v70lzzb2lrjbtfbarup03lelgso0f82m5fbl2ltsxif0uweymwhru82hm3wpo7dyivjuftyaqal85x9ol5mc7i9lj9mtughs86dq8kl8wj:latest/predictions.table.json', 'path': 'media/table/predictions_1_1b3e8df036b107a8c63d.table.json', 'size': 189762}",7.037985482349875,,,False,True,validation,False,No | Yes,4,CTBase,ed215962-8e51-45e7-b025-6e822f877098,wic,CLASSIFICATION,False,28,bigscience/T0_3B,0,True,sentence_to_concepts,prompts/general_fixed_choice.yaml,CommonGen,,2,,,GenFC,,False,Word Sense Disambiguation,,True,False,GeneralFixedChoice,False,False,False,,,prompts,,,True,sentence to concepts,,cross_task,wic,,,,False,,,False,,True,,,False,,CTBase.GenFC.common_gen.sentence_to_concepts.LenNorm,WiC,56.16707982729896,54.85008991656921,WordsinContext,super_glue,,,,,,,,,,,,,,,,,12.5,50.0,13
5.454545454545455,,1.0030221468041671,2.1295678667887623,,,,5.454545454545455,,,,54.62068965517241,2.1295678667887623,1.0172413793103448,67.01902748414378,,0.130169559228806,1.0030221468041671,0.130169559228806,1.9827586206896552,51.09717868338558,"{'_type': 'table-file', 'ncols': 9, 'nrows': 638, 'sha256': 'e7451af6bef40463e8fdab1ffda4dc267ad6755755d21db382d38ece970508d3', 'artifact_path': 'wandb-client-artifact://ts2nwe6k5xkm870lp343uwlab5zepxyqy5upm93v2uuxwnuriorss3lj33pn151c67p8p341e5amof8inxxsota9a7eqz77oen32aaai7mb7gzjm6wmeifnwx173cesh:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://ts2nwe6k5xkm870lp343uwlab5zepxyqy5upm93v2uuxwnuriorss3lj33pn151c67p8p341e5amof8inxxsota9a7eqz77oen32aaai7mb7gzjm6wmeifnwx173cesh:latest/predictions.table.json', 'path': 'media/table/predictions_1_e7451af6bef40463e8fd.table.json', 'size': 178517}",7.037985482349875,,,False,True,validation,False,No | Yes,4,CTBase,b7012213-04c4-424d-85fb-39d63d8a0ca2,wic,CLASSIFICATION,False,28,bigscience/T0_3B,0,True,topics_from_the_sentence,prompts/general_fixed_choice.yaml,CommonGen,,2,,,GenFC,,False,Word Sense Disambiguation,,True,False,GeneralFixedChoice,False,False,False,,,prompts,,,True,topics from the sentence,,cross_task,wic,,,,False,,,False,,True,,,False,,CTBase.GenFC.common_gen.topics_from_the_sentence.LenNorm,WiC,56.65141359247765,55.3630565737365,WordsinContext,super_glue,,,,,,,,,,,,,,,,,18.5,55.0,8
10.76487252124646,,0.6689887025458885,1.1461180430781506,,,,10.76487252124646,,,,68.62068965517241,1.1461180430781506,1.053291536050157,65.87215601300109,,0.2246142209112584,0.6689887025458885,0.2246142209112584,1.946708463949843,50.626959247648905,"{'ncols': 9, 'nrows': 638, 'sha256': '6f7f0c5f4d5d53514e5aec2c72c14b00f877fc15ab78ef850fee7b522a0e75ec', 'artifact_path': 'wandb-client-artifact://bdustrt0l135szv0915712q7d254itcvjig36rv7eoizp0sfztfhbzhayzfedrefh1hp2n5g46ssywb9vx72yyfs9g8w15m2xykw8ud6wyt6jpmfzgnjvfgqzmgfuvg9:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://bdustrt0l135szv0915712q7d254itcvjig36rv7eoizp0sfztfhbzhayzfedrefh1hp2n5g46ssywb9vx72yyfs9g8w15m2xykw8ud6wyt6jpmfzgnjvfgqzmgfuvg9:latest/predictions.table.json', 'path': 'media/table/predictions_1_6f7f0c5f4d5d53514e5a.table.json', 'size': 223092, '_type': 'table-file'}",7.037985482349875,,,False,True,validation,False,No | Yes,4,CTBase,fc76beb7-c258-412f-a623-42fc8d2331b6,wic,COMPLETION,False,28,bigscience/T0_3B,0,True,fill_in_the_blank_with_instruction_and_choices,prompts/general_fixed_choice.yaml,NumerSense,,2,,,GenFC,,False,Word Sense Disambiguation,,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,fill_in_the_blank_with_instruction_and_choices,,cross_task,wic,,,,False,,,False,,True,,,False,,CTBase.GenFC.numer_sense.fill_in_the_blank_with_instruction_and_choices.LenNorm,WiC,53.63337447580061,54.29781546958068,WordsinContext,super_glue,,,,,,,,,,,,,,,,,36.5,30.0,20
7.0588235294117645,,0.8929055967278224,1.725675698171215,,,,7.0588235294117645,,,,57.62068965517241,1.725675698171215,1.0329153605015673,66.23931623931625,,0.1784150765619858,0.8929055967278224,0.1784150765619858,1.9670846394984327,50.470219435736674,"{'size': 182289, '_type': 'table-file', 'ncols': 9, 'nrows': 638, 'sha256': '817fe54a2155e0385d440d578dc87f10c68dde2c9a5746239dbbc6bd04470739', 'artifact_path': 'wandb-client-artifact://eku5gx3s3reqsm04ip4nv0mgi18ytbluoydd9eoew3e93jqrjta38du2i6ghdjnjn851ev35mtr62t4c34f4e3nwdcwez7bfcz8djq5fotmpy2cvuqwo0kwwlwj272yw:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://eku5gx3s3reqsm04ip4nv0mgi18ytbluoydd9eoew3e93jqrjta38du2i6ghdjnjn851ev35mtr62t4c34f4e3nwdcwez7bfcz8djq5fotmpy2cvuqwo0kwwlwj272yw:latest/predictions.table.json', 'path': 'media/table/predictions_1_817fe54a2155e0385d44.table.json'}",7.037985482349875,,,False,True,validation,False,No | Yes,4,CTBase,cacee36c-e2b7-458e-9d51-6fcfd83842b4,wic,COMPLETION,False,28,bigscience/T0_3B,0,True,fill_in_the_blank_before_sentence,prompts/general_fixed_choice.yaml,NumerSense,,2,,,GenFC,,False,Word Sense Disambiguation,,False,False,GeneralFixedChoice,False,False,False,,,prompts,,,True,fill_in_the_blank_before_sentence,,cross_task,wic,,,,False,,,False,,True,,,False,,CTBase.GenFC.numer_sense.fill_in_the_blank_before_sentence.LenNorm,WiC,55.1663693009964,54.80095517929266,WordsinContext,super_glue,,,,,,,,,,,,,,,,,47.5,47.0,11
9.221902017291065,,0.6281379856239229,1.1094953641762555,,,,9.221902017291065,,,,72.62068965517241,1.1094953641762555,1.0438871473354232,66.09257265877287,,0.2048440031687089,0.6281379856239229,0.2048440031687089,1.9561128526645768,50.626959247648905,"{'sha256': 'bb4b1b9c02852fb0e98451115c521f2074013f838f275bbc8797f6ae42e41c58', 'artifact_path': 'wandb-client-artifact://illik9b7t3r1x02486xv421cjm6s2a4iwa9req4hg5keiogbusimqa4zhyuxqcbtxkf78sw9o69gcyzwbzwz2fpdy7eyaydkn028a5qlnqixbmfaib2cx4i189y6psmi:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://illik9b7t3r1x02486xv421cjm6s2a4iwa9req4hg5keiogbusimqa4zhyuxqcbtxkf78sw9o69gcyzwbzwz2fpdy7eyaydkn028a5qlnqixbmfaib2cx4i189y6psmi:latest/predictions.table.json', 'path': 'media/table/predictions_1_bb4b1b9c02852fb0e984.table.json', 'size': 229680, '_type': 'table-file', 'ncols': 9, 'nrows': 638}",7.037985482349875,,,False,True,validation,False,No | Yes,4,CTBase,5d8e8d21-8059-4373-bbf2-a25cbe1e6960,wic,COMPLETION,False,28,bigscience/T0_3B,0,True,fill_in_the_blank_with_choices_before,prompts/general_fixed_choice.yaml,NumerSense,,2,,,GenFC,,False,Word Sense Disambiguation,,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,fill_in_the_blank_with_choices_before,,cross_task,wic,,,,False,,,False,,True,,,False,,CTBase.GenFC.numer_sense.fill_in_the_blank_with_choices_before.LenNorm,WiC,54.42612089155261,54.9689959807785,WordsinContext,super_glue,,,,,,,,,,,,,,,,,36.5,34.0,24
1.2461059190031152,,0.83909238783596,2.860949296188952,,,,1.2461059190031152,,,,85.62068965517241,2.860949296188952,1.0031347962382444,66.8062827225131,,0.0559014247652884,0.83909238783596,0.0559014247652884,1.996865203761756,50.313479623824456,"{'nrows': 638, 'sha256': '98e0e66aac05de65dd5fa19e7f362ec040fed6bda41294623b74b9e5726aef25', 'artifact_path': 'wandb-client-artifact://19mcxc8i1g2epv62md76gwharqw6hryw0ugkkaclkozuhao09enzh2h6k9zx4q1an8tt6cgbo6fvflv8bary7iwsqk3a5c2whhv5gdnp211zf0ywf702xpobo20qe7hg:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://19mcxc8i1g2epv62md76gwharqw6hryw0ugkkaclkozuhao09enzh2h6k9zx4q1an8tt6cgbo6fvflv8bary7iwsqk3a5c2whhv5gdnp211zf0ywf702xpobo20qe7hg:latest/predictions.table.json', 'path': 'media/table/predictions_1_98e0e66aac05de65dd5f.table.json', 'size': 256992, '_type': 'table-file', 'ncols': 9}",7.037985482349875,,,False,True,validation,False,No | Yes,4,CTBase,4e9da2b8-2502-44a7-a7da-ae62f2d554c9,wic,COMPLETION,False,28,bigscience/T0_3B,0,True,fill_in_the_blank_with_instruction,prompts/general_fixed_choice.yaml,NumerSense,,2,,,GenFC,,False,Word Sense Disambiguation,,False,False,GeneralFixedChoice,False,False,False,,,prompts,,,True,fill_in_the_blank_with_instruction,,cross_task,wic,,,,False,,,False,,True,,,False,,CTBase.GenFC.numer_sense.fill_in_the_blank_with_instruction.LenNorm,WiC,54.96126622353792,55.25790823596467,WordsinContext,super_glue,,,,,,,,,,,,,,,,,58.0,82.5,39
8.720930232558139,,0.6427678576599263,1.2064566806098884,,,,8.720930232558139,,,,68.62068965517241,1.2064566806098884,1.0391849529780564,66.30901287553648,,0.19403477120909,0.6427678576599263,0.19403477120909,1.960815047021944,50.78369905956113,"{'_type': 'table-file', 'ncols': 9, 'nrows': 638, 'sha256': '35ffc7e9ec7492cf8c55221ac4de4de89e0da8744ca17ecaf24276d48b965063', 'artifact_path': 'wandb-client-artifact://e84k3yshtptgpdwst9wa6m9laf9nco2mg6iydytp61qdc6641f7q6ib31a3l75drej1xx1k7s534g0hbqb4dzmb9zcqb1wwi398zojz9tfpibeb6ailxofocck7kbcgh:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://e84k3yshtptgpdwst9wa6m9laf9nco2mg6iydytp61qdc6641f7q6ib31a3l75drej1xx1k7s534g0hbqb4dzmb9zcqb1wwi398zojz9tfpibeb6ailxofocck7kbcgh:latest/predictions.table.json', 'path': 'media/table/predictions_1_35ffc7e9ec7492cf8c55.table.json', 'size': 230771}",7.037985482349875,,,False,True,validation,False,No | Yes,4,CTBase,1f959d92-dca8-4647-9840-69391dfbd000,wic,COMPLETION,False,28,bigscience/T0_3B,0,True,fill_in_the_blank_with_choices_after,prompts/general_fixed_choice.yaml,NumerSense,,2,,,GenFC,,False,Word Sense Disambiguation,,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,fill_in_the_blank_with_choices_after,,cross_task,wic,,,,False,,,False,,True,,,False,,CTBase.GenFC.numer_sense.fill_in_the_blank_with_choices_after.LenNorm,WiC,54.85166222813566,54.91494776977427,WordsinContext,super_glue,,,,,,,,,,,,,,,,,28.0,37.5,20
1.2461059190031152,,0.9060468181104624,2.539768523930756,,,,1.2461059190031152,,,,83.62068965517241,2.539768523930756,1.0031347962382444,66.8062827225131,,0.0559014247652884,0.9060468181104624,0.0559014247652884,1.996865203761756,50.313479623824456,"{'nrows': 638, 'sha256': '752d45d8f8644c055f03f5a1fafe79d4d2d67baa59f3fc3e6bf0d2e1d6606e95', 'artifact_path': 'wandb-client-artifact://jh8u17sch7syso9fehy4ih3sl516wf2gkr4umkmni4tba9rvvk3wxexsgyj7iwf56f0en73ab55iny32bzo8gzq4g2f08xx8k9u81k40ukzhkuuvr1uo9xy1eqrnxexx:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://jh8u17sch7syso9fehy4ih3sl516wf2gkr4umkmni4tba9rvvk3wxexsgyj7iwf56f0en73ab55iny32bzo8gzq4g2f08xx8k9u81k40ukzhkuuvr1uo9xy1eqrnxexx:latest/predictions.table.json', 'path': 'media/table/predictions_1_752d45d8f8644c055f03.table.json', 'size': 238286, '_type': 'table-file', 'ncols': 9}",7.037985482349875,,,False,True,validation,False,No | Yes,4,CTBase,c97e7bbf-b7f0-4cee-ada5-431ce7d606cc,wic,CLASSIFICATION,False,28,bigscience/T0_3B,0,True,semantic_relations_nominials_without_options,prompts/general_fixed_choice.yaml,SemEval2010,,2,,,GenFC,,False,Word Sense Disambiguation,,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,semantic relations nominials without options,,cross_task,wic,,,,False,,,False,,True,,,False,,CTBase.GenFC.sem_eval_2010_task_8.semantic_relations_nominials_without_options.LenNorm,WiC,54.38091987328235,54.49435441868693,WordsinContext,super_glue,,,,,,,,,,,,,,,,,58.0,82.5,37
1.8633540372670807,,0.6403471349721556,1.92825199279432,,,,1.8633540372670807,,,,69.62068965517241,1.92825199279432,1.0047021943573669,66.87631027253668,,0.0684111374382294,0.6403471349721556,0.0684111374382294,1.9952978056426327,50.470219435736674,"{'_type': 'table-file', 'ncols': 9, 'nrows': 638, 'sha256': 'efeb1972f5a027007d03f8a6fa3636902a955a6f0c164c114242d23f040cdfc4', 'artifact_path': 'wandb-client-artifact://58s8jim5ie9710l3cbv3dmv4poqwarlzgksh08a4y79rd9u52ww9dbballcvfyhti1bytnxdmw1pdwnkcrfxr2wp57ul4nkodkp6x137y3lnlaj7canab4q0k645mdrw:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://58s8jim5ie9710l3cbv3dmv4poqwarlzgksh08a4y79rd9u52ww9dbballcvfyhti1bytnxdmw1pdwnkcrfxr2wp57ul4nkodkp6x137y3lnlaj7canab4q0k645mdrw:latest/predictions.table.json', 'path': 'media/table/predictions_1_efeb1972f5a027007d03.table.json', 'size': 216630}",7.037985482349875,,,False,True,validation,False,No | Yes,4,CTBase,5d7123a8-4ed4-42ce-bcfb-4af415962efc,wic,CLASSIFICATION,False,28,bigscience/T0_3B,0,True,semantically_related_nominials_with_options,prompts/general_fixed_choice.yaml,SemEval2010,,2,,,GenFC,,False,Word Sense Disambiguation,,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,semantically related nominials with options,,cross_task,wic,,,,False,,,False,,True,,,False,,CTBase.GenFC.sem_eval_2010_task_8.semantically_related_nominials_with_options.LenNorm,WiC,53.97460655323927,53.91456451882352,WordsinContext,super_glue,,,,,,,,,,,,,,,,,47.5,80.5,17
1.8633540372670807,,0.7551407815150653,2.112860037054761,,,,1.8633540372670807,,,,91.6206896551724,2.112860037054761,1.0047021943573669,66.87631027253668,,0.0684111374382294,0.7551407815150653,0.0684111374382294,1.9952978056426327,50.470219435736674,"{'ncols': 9, 'nrows': 638, 'sha256': 'db40873f08e3945646ad90f2847a4d05a282d991ea041f5d9bd22df884e706f4', 'artifact_path': 'wandb-client-artifact://zzuysz3190wd68btmlu41ttzj9aak0ar12a65m1j9yufbmrvgwv3lh1c6e7a1fm2octi74990utierbsr5srt9lkyuueaeqh6kcbkhw8dzy8c5ooaikr85gqkjkazxeh:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://zzuysz3190wd68btmlu41ttzj9aak0ar12a65m1j9yufbmrvgwv3lh1c6e7a1fm2octi74990utierbsr5srt9lkyuueaeqh6kcbkhw8dzy8c5ooaikr85gqkjkazxeh:latest/predictions.table.json', 'path': 'media/table/predictions_1_db40873f08e3945646ad.table.json', 'size': 264629, '_type': 'table-file'}",7.037985482349875,,,False,True,validation,False,No | Yes,4,CTBase,202246b0-3f82-42b9-bc8d-d36997b5f2cb,wic,CLASSIFICATION,False,28,bigscience/T0_3B,0,True,semantic_relations_with_options,prompts/general_fixed_choice.yaml,SemEval2010,,2,,,GenFC,,False,Word Sense Disambiguation,,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,semantic relations with options,,cross_task,wic,,,,False,,,False,,True,,,False,,CTBase.GenFC.sem_eval_2010_task_8.semantic_relations_with_options.LenNorm,WiC,53.28853086363399,53.65906388498541,WordsinContext,super_glue,,,,,,,,,,,,,,,,,47.5,80.5,40
11.89801699716714,,0.8443073733840669,1.508187848572447,,,,11.89801699716714,,,,55.62068965517241,1.508187848572447,1.053291536050157,66.30552546045504,,0.2246142209112584,0.8443073733840669,0.2246142209112584,1.946708463949843,51.2539184952978,"{'_type': 'table-file', 'ncols': 9, 'nrows': 638, 'sha256': '0a9bd2c7d5e56b34cec47d947d73bffb8ec4a09bdeb5a871e07b9b48fcbf0197', 'artifact_path': 'wandb-client-artifact://2zp7hr5wvxl1bcjci14ayrfnt97crqey4itp5pvoyknb91itr8jcdr7kkedkerua1l3botx3lji57wtf596vdsj0gc5la5f8uuigqnalr8xsp6cfg83la1k8e50avpas:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://2zp7hr5wvxl1bcjci14ayrfnt97crqey4itp5pvoyknb91itr8jcdr7kkedkerua1l3botx3lji57wtf596vdsj0gc5la5f8uuigqnalr8xsp6cfg83la1k8e50avpas:latest/predictions.table.json', 'path': 'media/table/predictions_1_0a9bd2c7d5e56b34cec4.table.json', 'size': 182689}",7.037985482349875,,,False,True,validation,False,No | Yes,4,CTBase,af4d550e-54b8-471e-97af-2b2c50a1382e,wic,SUMMARIZATION,False,28,bigscience/T0_3B,0,True,relatedwork_abstract,prompts/general_fixed_choice.yaml,Multi-XSci,,2,,,GenFC,,False,Word Sense Disambiguation,,False,False,GeneralFixedChoice,False,False,False,,,prompts,,,True,relatedwork_abstract,,cross_task,wic,,,,False,,,False,,True,,,False,,CTBase.GenFC.multi_x_science_sum.relatedwork_abstract.LenNorm,WiC,56.414241478001095,56.07256218001002,WordsinContext,super_glue,,,,,,,,,,,,,,,,,12.5,24.0,9
7.038123167155426,,0.743592930502954,1.4438068431372926,,,,7.038123167155426,,,,63.62068965517241,1.4438068431372926,1.0344827586206895,66.09625668449198,,0.1824656076596269,0.743592930502954,0.1824656076596269,1.9655172413793105,50.313479623824456,"{'_type': 'table-file', 'ncols': 9, 'nrows': 638, 'sha256': '68ca7cf023851a6dd48a0da1cc200f8d9d2a28fe1b026467805845433f279518', 'artifact_path': 'wandb-client-artifact://b50cytq6sz5oesfhqwy3kox5ifh2nbn6wu2uvtb1pqyru8ake6gkcl50gubi1rhxsml3g53srymmlov9z66783qxjrmpv1pj7lv7mxox1ornvr70gonsu34oiynuq3rd:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://b50cytq6sz5oesfhqwy3kox5ifh2nbn6wu2uvtb1pqyru8ake6gkcl50gubi1rhxsml3g53srymmlov9z66783qxjrmpv1pj7lv7mxox1ornvr70gonsu34oiynuq3rd:latest/predictions.table.json', 'path': 'media/table/predictions_1_68ca7cf023851a6dd48a.table.json', 'size': 209566}",7.037985482349875,,,False,True,validation,False,No | Yes,4,CTBase,3bd082cb-4e28-4eb7-9fa2-dd03f1f86219,wic,SUMMARIZATION,False,28,bigscience/T0_3B,0,True,abstract_relatedwork,prompts/general_fixed_choice.yaml,Multi-XSci,,2,,,GenFC,,False,Word Sense Disambiguation,,False,False,GeneralFixedChoice,False,False,False,,,prompts,,,True,abstract_relatedwork,,cross_task,wic,,,,False,,,False,,True,,,False,,CTBase.GenFC.multi_x_science_sum.abstract_relatedwork.LenNorm,WiC,55.265271547332105,55.6686746395967,WordsinContext,super_glue,,,,,,,,,,,,,,,,,58.0,48.0,17
11.142061281337048,,0.7808881974133579,1.3527304281635344,,,,11.142061281337048,,,,56.62068965517241,1.3527304281635344,1.0626959247648904,65.21264994547437,,0.2424152342217079,0.7808881974133579,0.2424152342217079,1.9373040752351096,50.0,"{'size': 189189, '_type': 'table-file', 'ncols': 9, 'nrows': 638, 'sha256': 'eb43e1549ec9099cce5b8f6588c3b6ce12d930fd89aafe45ff152a57b2e4ea1f', 'artifact_path': 'wandb-client-artifact://6gk9aoafs6y5vguqflyk4ctq1r2wvn837zumn116oznzi79wgozkskb36u5m7uxmdienwdaxphc2cue56gpce3oebb1uiowtncn9jq7m7hn7fg1bfrqua6vmqnm9yu5k:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://6gk9aoafs6y5vguqflyk4ctq1r2wvn837zumn116oznzi79wgozkskb36u5m7uxmdienwdaxphc2cue56gpce3oebb1uiowtncn9jq7m7hn7fg1bfrqua6vmqnm9yu5k:latest/predictions.table.json', 'path': 'media/table/predictions_1_eb43e1549ec9099cce5b.table.json'}",7.037985482349875,,,False,True,validation,False,No | Yes,4,CTBase,2bca0197-e3d4-4870-bd95-178411e52e09,wic,SUMMARIZATION,False,28,bigscience/T0_3B,0,True,ref_relatedwork,prompts/general_fixed_choice.yaml,Multi-XSci,,2,,,GenFC,,False,Word Sense Disambiguation,,False,False,GeneralFixedChoice,False,False,False,,,prompts,,,True,ref_relatedwork,,cross_task,wic,,,,False,,,False,,True,,,False,,CTBase.GenFC.multi_x_science_sum.ref_relatedwork.LenNorm,WiC,55.46969036123397,55.51832234353042,WordsinContext,super_glue,,,,,,,,,,,,,,,,,82.5,29.0,10
8.720930232558139,,0.8014049018470024,1.514577928007957,,,,8.720930232558139,,,,56.62068965517241,1.514577928007957,1.0391849529780564,66.30901287553648,,0.19403477120909,0.8014049018470024,0.19403477120909,1.960815047021944,50.78369905956113,"{'path': 'media/table/predictions_1_7b6d1af52fada4281af6.table.json', 'size': 182116, '_type': 'table-file', 'ncols': 9, 'nrows': 638, 'sha256': '7b6d1af52fada4281af6baa6c02d06b7d5fc836fcc4988e5f1343a0861c19aef', 'artifact_path': 'wandb-client-artifact://18ctup4baye2upalu1879lerj5zwbs35psoyaywm2988yp8ycb0deftedy4v4acl6nwmrdwi530gvxoiwfmswi1b4jp3wsk9m4ct3p0uynsl7r56nrugyqjgjhoglkbn:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://18ctup4baye2upalu1879lerj5zwbs35psoyaywm2988yp8ycb0deftedy4v4acl6nwmrdwi530gvxoiwfmswi1b4jp3wsk9m4ct3p0uynsl7r56nrugyqjgjhoglkbn:latest/predictions.table.json'}",7.037985482349875,,,False,True,validation,False,No | Yes,4,CTBase,774b4349-0524-4a34-881b-b344f8f5c34e,wic,COMPLETION,False,28,bigscience/T0_3B,0,True,what_comes_next,prompts/general_fixed_choice.yaml,LAMBADA,,2,,,GenFC,,False,Word Sense Disambiguation,,False,False,GeneralFixedChoice,False,False,False,,,prompts,,,True,what comes next,,cross_task,wic,,,,False,,,False,,True,,,False,,CTBase.GenFC.craffel_openai_lambada.what_comes_next.LenNorm,WiC,56.5003286676113,56.62581932174409,WordsinContext,super_glue,,,,,,,,,,,,,,,,,28.0,37.5,10
7.647058823529411,,0.8755342136403464,1.6595198414916157,,,,7.647058823529411,,,,57.62068965517241,1.6595198414916157,1.0329153605015673,66.45299145299145,,0.1784150765619858,0.8755342136403464,0.1784150765619858,1.9670846394984327,50.78369905956113,"{'ncols': 9, 'nrows': 638, 'sha256': 'a229004096b7b49ba782a11078dc47a6b28cce8deaa44a01c3ed08f0e673ec12', 'artifact_path': 'wandb-client-artifact://5l8kmvm4i3bmivb2fuwpf360i73i2g8c6j7ojv0kpm6n22ylmustbkjivzth1d9pzb7ca97vllwwwd6yq6zi77g7n236atni9gp6lpli69u4x6og7y79jm6ex94ou7i3:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://5l8kmvm4i3bmivb2fuwpf360i73i2g8c6j7ojv0kpm6n22ylmustbkjivzth1d9pzb7ca97vllwwwd6yq6zi77g7n236atni9gp6lpli69u4x6og7y79jm6ex94ou7i3:latest/predictions.table.json', 'path': 'media/table/predictions_1_a229004096b7b49ba782.table.json', 'size': 170651, '_type': 'table-file'}",7.037985482349875,,,False,True,validation,False,No | Yes,4,CTBase,4f08e9d4-bcff-4bc0-9902-87c497625d17,wic,COMPLETION,False,28,bigscience/T0_3B,0,True,GPT_3_style,prompts/general_fixed_choice.yaml,LAMBADA,,2,,,GenFC,,False,Word Sense Disambiguation,,False,False,GeneralFixedChoice,False,False,False,,,prompts,,,True,GPT-3 style,,cross_task,wic,,,,False,,,False,,True,,,False,,CTBase.GenFC.craffel_openai_lambada.GPT_3_style.LenNorm,WiC,56.2912617771004,56.32020125588389,WordsinContext,super_glue,,,,,,,,,,,,,,,,,28.0,43.5,11
3.058103975535168,,0.897532591100704,1.975439052223038,,,,3.058103975535168,,,,55.62068965517241,1.975439052223038,1.012539184952978,66.59641728134879,,0.1112742278952906,0.897532591100704,0.1112742278952906,1.987460815047022,50.313479623824456,"{'_type': 'table-file', 'ncols': 9, 'nrows': 638, 'sha256': '571ae3342eece0e884f51f6d0ba239b2ec19a08a3b672bf8e0a1e1ba7463a8ee', 'artifact_path': 'wandb-client-artifact://80at0rti83125fbh6b0xsbx7u07pjbhqe1sxplsud1ybgqn2fhe4ak1uibidsqrrgy5fxjqg6eoh3ogy4naatnhkzn7x57b4qs510nni0haa18xxo15ylwmmfm3cgqm4:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://80at0rti83125fbh6b0xsbx7u07pjbhqe1sxplsud1ybgqn2fhe4ak1uibidsqrrgy5fxjqg6eoh3ogy4naatnhkzn7x57b4qs510nni0haa18xxo15ylwmmfm3cgqm4:latest/predictions.table.json', 'path': 'media/table/predictions_1_571ae3342eece0e884f5.table.json', 'size': 176387}",7.037985482349875,,,False,True,validation,False,No | Yes,4,CTBase,1ee5ddef-fffb-4b73-a2f7-f600ffac63cb,wic,COMPLETION,False,28,bigscience/T0_3B,0,True,ellipses,prompts/general_fixed_choice.yaml,LAMBADA,,2,,,GenFC,,False,Word Sense Disambiguation,,False,False,GeneralFixedChoice,False,False,False,,,prompts,,,True,ellipses,,cross_task,wic,,,,False,,,False,,True,,,False,,CTBase.GenFC.craffel_openai_lambada.ellipses.LenNorm,WiC,55.856645699112086,56.58847692141392,WordsinContext,super_glue,,,,,,,,,,,,,,,,,58.0,71.5,11
7.079646017699116,,0.8644180529697155,1.712630915604415,,,,7.079646017699116,,,,67.62068965517241,1.712630915604415,1.031347962382445,66.3820704375667,,0.174256327394198,0.8644180529697155,0.174256327394198,1.968652037617555,50.626959247648905,"{'artifact_path': 'wandb-client-artifact://r3f8cozf00tyy1z47xwr7v9oxsj8opnq557w3qxq6ulhmtr97ih946hw8e8134svtys3n6gkrbw1p7wsjvrsbv8jxue66numgj77k5p0myvcnyg3arxeydrefiz8rym0:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://r3f8cozf00tyy1z47xwr7v9oxsj8opnq557w3qxq6ulhmtr97ih946hw8e8134svtys3n6gkrbw1p7wsjvrsbv8jxue66numgj77k5p0myvcnyg3arxeydrefiz8rym0:latest/predictions.table.json', 'path': 'media/table/predictions_1_07617cbd40b94e1343d0.table.json', 'size': 216022, '_type': 'table-file', 'ncols': 9, 'nrows': 638, 'sha256': '07617cbd40b94e1343d06ca510ec2680a03215295d25aa69bca18ea09cc1c8f1'}",7.037985482349875,,,False,True,validation,False,No | Yes,4,CTBase,9a3f617f-628f-4fa5-9b74-47d0b166a487,wic,SUMMARIZATION,False,28,bigscience/T0_3B,0,True,read_below_DOC_write_abstract,prompts/general_fixed_choice.yaml,XSum,,2,,,GenFC,,False,Word Sense Disambiguation,,True,False,GeneralFixedChoice,False,False,False,,,prompts,,,True,read_below_DOC_write_abstract,,cross_task,wic,,,,False,,,False,,True,,,False,,CTBase.GenFC.xsum.read_below_DOC_write_abstract.LenNorm,WiC,55.476611974439535,55.98018887393008,WordsinContext,super_glue,,,,,,,,,,,,,,,,,36.5,46.0,21
6.024096385542168,,0.7907473986669984,1.569624346368552,,,,6.024096385542168,,,,70.62068965517241,1.569624346368552,1.0203761755485894,66.94915254237289,,0.1412833571890278,0.7907473986669984,0.1412833571890278,1.9796238244514104,51.09717868338558,"{'_type': 'table-file', 'ncols': 9, 'nrows': 638, 'sha256': '969d326555ff930314c6ecf22eaa67c647d68cffb1b273e456cba448fa9ebd17', 'artifact_path': 'wandb-client-artifact://ysta0w6cr625w1wp6sac48udtsy4eoppa973b0081ok93vzgxb619zepq2qx3g87m0m5wmwk6ttlz18psimtnld7yuh4479nhx9nz1lufpwauulq9gxjnf2d88oiuu8u:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://ysta0w6cr625w1wp6sac48udtsy4eoppa973b0081ok93vzgxb619zepq2qx3g87m0m5wmwk6ttlz18psimtnld7yuh4479nhx9nz1lufpwauulq9gxjnf2d88oiuu8u:latest/predictions.table.json', 'path': 'media/table/predictions_1_969d326555ff930314c6.table.json', 'size': 212381}",7.037985482349875,,,False,True,validation,False,No | Yes,4,CTBase,4cfe4126-b9f5-44eb-8a98-973987c5f32e,wic,SUMMARIZATION,False,28,bigscience/T0_3B,0,True,college_roommate_asked_DOC_so_I_recap,prompts/general_fixed_choice.yaml,XSum,,2,,,GenFC,,False,Word Sense Disambiguation,,True,False,GeneralFixedChoice,False,False,False,,,prompts,,,True,college_roommate_asked_DOC_so_I_recap,,cross_task,wic,,,,False,,,False,,True,,,False,,CTBase.GenFC.xsum.college_roommate_asked_DOC_so_I_recap.LenNorm,WiC,56.15260164754834,56.13348925423296,WordsinContext,super_glue,,,,,,,,,,,,,,,,,18.5,53.5,24
6.024096385542168,,0.8813549608124495,1.814305375081992,,,,6.024096385542168,,,,59.62068965517241,1.814305375081992,1.0203761755485894,66.94915254237289,,0.1412833571890278,0.8813549608124495,0.1412833571890278,1.9796238244514104,51.09717868338558,"{'size': 182838, '_type': 'table-file', 'ncols': 9, 'nrows': 638, 'sha256': '46101407f284501c24401e82346a4b99f1148e96520c4e448c3be1fdd56d6fda', 'artifact_path': 'wandb-client-artifact://2eu8fgxbcubu1c8dc9xssgag1mboizxa3h9axvrsx9vjdzzqy0o2147rbowmt4wk2c1e5q6pp1yirh2ssnz6zxav6ou4dr0ryz6x6znjt4r36l3e38trwdnoxxei3otk:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://2eu8fgxbcubu1c8dc9xssgag1mboizxa3h9axvrsx9vjdzzqy0o2147rbowmt4wk2c1e5q6pp1yirh2ssnz6zxav6ou4dr0ryz6x6znjt4r36l3e38trwdnoxxei3otk:latest/predictions.table.json', 'path': 'media/table/predictions_1_46101407f284501c2440.table.json'}",7.037985482349875,,,False,True,validation,False,No | Yes,4,CTBase,3d388a1e-3361-407b-baa7-61397cc58382,wic,SUMMARIZATION,False,28,bigscience/T0_3B,0,True,DOC_how_would_you_rephrase_few_words,prompts/general_fixed_choice.yaml,XSum,,2,,,GenFC,,False,Word Sense Disambiguation,,True,False,GeneralFixedChoice,False,False,False,,,prompts,,,True,DOC_how_would_you_rephrase_few_words,,cross_task,wic,,,,False,,,False,,True,,,False,,CTBase.GenFC.xsum.DOC_how_would_you_rephrase_few_words.LenNorm,WiC,55.57872295774688,55.633297628757575,WordsinContext,super_glue,,,,,,,,,,,,,,,,,18.5,53.5,13
7.017543859649124,,0.912697877314674,1.6963913902219934,,,,7.017543859649124,,,,59.62068965517241,1.6963913902219934,1.036050156739812,65.95289079229123,,0.1864149750927937,0.912697877314674,0.1864149750927937,1.963949843260188,50.15673981191222,"{'artifact_path': 'wandb-client-artifact://17prf8at12ljip021x07zu1u3pdc8354239ypfstlogq89v7kzxy1jkxrwssorz8di58e7xdu489xcxtvjpdc6zvlcrgr1hne4xhugyyo2guht6s6jyw5usc4b044h0s:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://17prf8at12ljip021x07zu1u3pdc8354239ypfstlogq89v7kzxy1jkxrwssorz8di58e7xdu489xcxtvjpdc6zvlcrgr1hne4xhugyyo2guht6s6jyw5usc4b044h0s:latest/predictions.table.json', 'path': 'media/table/predictions_1_aa028f3277b79d4e804c.table.json', 'size': 180137, '_type': 'table-file', 'ncols': 9, 'nrows': 638, 'sha256': 'aa028f3277b79d4e804c46020121d2d96a022a70868b14a62fc7c5dd21e8768a'}",7.037985482349875,,,False,True,validation,False,No | Yes,4,CTBase,13c02904-e4e2-4b4f-b115-44b437d22041,wic,SUMMARIZATION,False,28,bigscience/T0_3B,0,True,DOC_write_summary_of_above,prompts/general_fixed_choice.yaml,XSum,,2,,,GenFC,,False,Word Sense Disambiguation,,True,False,GeneralFixedChoice,False,False,False,,,prompts,,,True,DOC_write_summary_of_above,,cross_task,wic,,,,False,,,False,,True,,,False,,CTBase.GenFC.xsum.DOC_write_summary_of_above.LenNorm,WiC,55.68189533638272,55.63231493401205,WordsinContext,super_glue,,,,,,,,,,,,,,,,,70.5,49.0,13
3.636363636363636,,0.7249165691220688,1.726469276840784,,,,3.636363636363636,,,,62.62068965517241,1.726469276840784,1.0172413793103448,66.384778012685,,0.130169559228806,0.7249165691220688,0.130169559228806,1.9827586206896552,50.15673981191222,"{'artifact_path': 'wandb-client-artifact://idyozdgsu6u38kiqzo1bp1q6p0v708jldxu3v54ao6qlzwpopkv22f9b81rz8wmqe1ojolfmnic38j86ud3oslkry5xnfvgx6vmo3gkx5bovg0db0nowhgkebnytfl3g:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://idyozdgsu6u38kiqzo1bp1q6p0v708jldxu3v54ao6qlzwpopkv22f9b81rz8wmqe1ojolfmnic38j86ud3oslkry5xnfvgx6vmo3gkx5bovg0db0nowhgkebnytfl3g:latest/predictions.table.json', 'path': 'media/table/predictions_1_8cc09bef70059e9e8cc9.table.json', 'size': 196752, '_type': 'table-file', 'ncols': 9, 'nrows': 638, 'sha256': '8cc09bef70059e9e8cc99730e328685391abf484784151cda39e36c735819383'}",7.037985482349875,,,False,True,validation,False,No | Yes,4,CTBase,5fa16d31-b513-480d-bd1b-1fa8c182fb76,wic,SENTIMENT,False,28,bigscience/T0_3B,0,True,bullish_neutral_bearish,prompts/general_fixed_choice.yaml,FinNews,,2,,,GenFC,,False,Word Sense Disambiguation,,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,bullish_neutral_bearish,,cross_task,wic,,,,False,,,False,,True,,,False,,CTBase.GenFC.financial_phrasebank_sentences_allagree.bullish_neutral_bearish.LenNorm,WiC,53.97619471044016,54.6103123986596,WordsinContext,super_glue,,,,,,,,,,,,,,,,,70.5,67.0,9
3.0769230769230766,,0.7794035018452349,1.9932700677725217,,,,3.0769230769230766,,,,57.62068965517241,1.9932700677725217,1.0094043887147337,66.8769716088328,,0.0965191493312893,0.7794035018452349,0.0965191493312893,1.9905956112852663,50.626959247648905,"{'_latest_artifact_path': 'wandb-client-artifact://as1kizmup23iw29hgsf7ts0v5mdk6pjcmknuiub5a4zxrl93eusl7wzycj8k74bk525vu89rfsqf4582ez1b8y66undbz2te8tild3ub65xicnrdg1tlw1nn8y7xg4x4:latest/predictions.table.json', 'path': 'media/table/predictions_1_daa8387b6ba75c00a0f4.table.json', 'size': 200676, '_type': 'table-file', 'ncols': 9, 'nrows': 638, 'sha256': 'daa8387b6ba75c00a0f40ce6bc587dde893c9a5f31b75ca1bca509cbce3ee253', 'artifact_path': 'wandb-client-artifact://as1kizmup23iw29hgsf7ts0v5mdk6pjcmknuiub5a4zxrl93eusl7wzycj8k74bk525vu89rfsqf4582ez1b8y66undbz2te8tild3ub65xicnrdg1tlw1nn8y7xg4x4:latest/predictions.table.json'}",7.037985482349875,,,False,True,validation,False,No | Yes,4,CTBase,461efe04-6883-41e8-80f0-e722a75260fe,wic,SENTIMENT,False,28,bigscience/T0_3B,0,True,complementary_industries,prompts/general_fixed_choice.yaml,FinNews,,2,,,GenFC,,False,Word Sense Disambiguation,,False,False,GeneralFixedChoice,False,False,False,,,prompts,,,True,complementary_industries,,cross_task,wic,,,,False,,,False,,True,,,False,,CTBase.GenFC.financial_phrasebank_sentences_allagree.complementary_industries.LenNorm,WiC,57.40282365803597,58.39565255844577,WordsinContext,super_glue,,,,,,,,,,,,,,,,,36.5,69.0,11
24.03846153846154,,0.7339195708230991,1.0202952522469164,,,,24.03846153846154,,,,54.62068965517241,1.0202952522469164,1.152037617554859,63.25581395348837,,0.3590573497410983,0.7339195708230991,0.3590573497410983,1.847962382445141,50.470219435736674,"{'size': 180117, '_type': 'table-file', 'ncols': 9, 'nrows': 638, 'sha256': '10131d1ce5b93027d1cef12907a6a4b1e3a5456699c0a80cd13d22dc44c1c739', 'artifact_path': 'wandb-client-artifact://16ekwm0904m9r8i8b52lhxsy1u3cmwf7362f6f9u1c1snmp1t7mn18aqrlamf2ys2wx3ppbtg4lifo9h6u9oeydnyi4saqwm93jl4of6bu47knfl32pdnmfq7yfyo3ub:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://16ekwm0904m9r8i8b52lhxsy1u3cmwf7362f6f9u1c1snmp1t7mn18aqrlamf2ys2wx3ppbtg4lifo9h6u9oeydnyi4saqwm93jl4of6bu47knfl32pdnmfq7yfyo3ub:latest/predictions.table.json', 'path': 'media/table/predictions_1_10131d1ce5b93027d1ce.table.json'}",7.037985482349875,,,False,True,validation,False,No | Yes,4,CTBase,0beba048-f949-4034-83b6-a3e0e7363f46,wic,SENTIMENT,False,28,bigscience/T0_3B,0,True,sentiment,prompts/general_fixed_choice.yaml,FinNews,,2,,,GenFC,,False,Word Sense Disambiguation,,False,False,GeneralFixedChoice,False,False,False,,,prompts,,,True,sentiment,,cross_task,wic,,,,False,,,False,,True,,,False,,CTBase.GenFC.financial_phrasebank_sentences_allagree.sentiment.LenNorm,WiC,55.16948673520088,55.3660046579731,WordsinContext,super_glue,,,,,,,,,,,,,,,,,47.5,9.0,8
1.234567901234568,,0.5714918681350318,1.4634233472115568,,,,1.234567901234568,,,,73.62068965517241,1.4634233472115568,1.0078369905956113,66.38655462184873,,0.0881792048842332,0.5714918681350318,0.0881792048842332,1.9921630094043887,49.843260188087775,"{'path': 'media/table/predictions_1_c7421df81a2140b150c8.table.json', 'size': 234634, '_type': 'table-file', 'ncols': 9, 'nrows': 638, 'sha256': 'c7421df81a2140b150c89f7b939f8ebe9bb7c0c103a289344d6716d99f844742', 'artifact_path': 'wandb-client-artifact://10n4yy52pbzomaq6ksa2hlam069azmt1gsqg6kntp5sqhp454806fs0cdanlk05qjswc6hwkr8dn68dtd5s788kf8kuap93fka428f9ezy9ljwhztaz1tehd8crzks36:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://10n4yy52pbzomaq6ksa2hlam069azmt1gsqg6kntp5sqhp454806fs0cdanlk05qjswc6hwkr8dn68dtd5s788kf8kuap93fka428f9ezy9ljwhztaz1tehd8crzks36:latest/predictions.table.json'}",7.037985482349875,,,False,True,validation,False,No | Yes,4,CTBase,06719321-62e7-4f6e-8f95-464cd2b5ca5c,wic,SENTIMENT,False,28,bigscience/T0_3B,0,True,share_price_option,prompts/general_fixed_choice.yaml,FinNews,,2,,,GenFC,,False,Word Sense Disambiguation,,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,share_price_option,,cross_task,wic,,,,False,,,False,,True,,,False,,CTBase.GenFC.financial_phrasebank_sentences_allagree.share_price_option.LenNorm,WiC,53.19021816570457,54.85303800080581,WordsinContext,super_glue,,,,,,,,,,,,,,,,,87.0,85.0,20
21.759259259259263,11.11111111111111,0.5960364579414517,2.4056115677314147,2.0,0.4135263033195199,0.0,0.0,,,,127.78571428571428,1.7099181839397974,2.107142857142857,54.16666666666667,0.6956933837916169,0.9942436362196468,0.4824063406869833,0.9942436362196468,1.8928571428571428,26.785714285714285,"{'_type': 'table-file', 'ncols': 11, 'nrows': 56, 'sha256': 'cd507e2941377f7a8af87bf3b7b849200d00ace3b097c2c8ee213c0f5c16d048', 'artifact_path': 'wandb-client-artifact://t5u2dgruuksjhug1q0sqncy9meyn95t9uhnezl5e8r502mfrnrlpswugjkva6mau8tdm2izl01ec0p833404a93btostj22jw3eg76wd5k31iti3y3qvkktkxit6xrv3:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://t5u2dgruuksjhug1q0sqncy9meyn95t9uhnezl5e8r502mfrnrlpswugjkva6mau8tdm2izl01ec0p833404a93btostj22jw3eg76wd5k31iti3y3qvkktkxit6xrv3:latest/predictions.table.json', 'path': 'media/table/predictions_1_cd507e2941377f7a8af8.table.json', 'size': 31817}",55.06285832888572,,,False,True,validation,False,Yes | Maybe | No,4,CTBase,f32348cd-d3cb-4619-87b9-e24f99c78567,cb,COMPLETION,False,28,bigscience/T0_3B,0,True,choose,prompts/general_fixed_choice.yaml,COPA,,3,,,GenFC,,False,['NLI'],,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,choose,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.super_glue_copa.choose.LenNorm,CB,,,CommitmentBank,super_glue,,,,,,,,,,,,,,,,,27.5,27.0,8
74.16413373860182,,0.8503835179837106,1.2914320282127023,,,,74.16413373860182,,,,100.5956678700361,1.2914320282127023,1.7148014440433212,62.22222222222222,,0.4515089585344945,0.8503835179837106,0.4515089585344945,1.2851985559566788,69.31407942238266,"{'nrows': 277, 'sha256': 'd61cea2d8811915e8356d9357510d888a04f726aa9764c6e441ade0dc63a63be', 'artifact_path': 'wandb-client-artifact://14n49hzcgqi3d2eerhcfmev3705x2lu6glezvpg84vw6fo6cy23wo2wkoy8m9zppibi2gk0atl8wq1k8zl901xjzhnjevo55pux726mdmn4e98wrtdatib3tkyccpjml:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://14n49hzcgqi3d2eerhcfmev3705x2lu6glezvpg84vw6fo6cy23wo2wkoy8m9zppibi2gk0atl8wq1k8zl901xjzhnjevo55pux726mdmn4e98wrtdatib3tkyccpjml:latest/predictions.table.json', 'path': 'media/table/predictions_1_d61cea2d8811915e8356.table.json', 'size': 128552, '_type': 'table-file', 'ncols': 9}",46.467282647943954,,,False,True,validation,False,Yes | No,4,CTBase,f32348cd-d3cb-4619-87b9-e24f99c78567,rte,COMPLETION,False,32,bigscience/T0_3B,0,True,choose,prompts/general_fixed_choice.yaml,COPA,,2,,,GenFC,,False,NLI,,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,choose,,cross_task,two_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.super_glue_copa.choose.LenNorm,RTE,78.75780669889737,81.81532991738995,RecognizingTextualEntailment,super_glue,,,,,,,,,,,,,,,,,16.5,16.0,8
24.197530864197528,13.333333333333334,0.7192655285951005,2.1011483387223318,2.017857142857143,0.6988352439988654,0.132432115840994,0.0,,,,138.78571428571428,1.2122057697602682,1.8928571428571428,59.25925925925925,0.8889425689620631,0.9942436362196468,0.4556380487624815,0.98700097181682,2.0892857142857144,32.142857142857146,"{'size': 34647, '_type': 'table-file', 'ncols': 11, 'nrows': 56, 'sha256': '93b1143f299b5194829889ca38a3ef670c85e8e0d86f44169ed03cb7be49ad34', 'artifact_path': 'wandb-client-artifact://4praa1513e6v4y71quh2c9f97x9f4txjjuaj84rtqwok9w69v06in35zu9joerwrrtrv66x9mobm2nwj17f1i2remosu3bwfosnmq0fnw0vh79be29fo9m8r21ngsbu4:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://4praa1513e6v4y71quh2c9f97x9f4txjjuaj84rtqwok9w69v06in35zu9joerwrrtrv66x9mobm2nwj17f1i2remosu3bwfosnmq0fnw0vh79be29fo9m8r21ngsbu4:latest/predictions.table.json', 'path': 'media/table/predictions_1_93b1143f299b51948298.table.json'}",55.06285832888571,,,False,True,validation,False,Yes | Maybe | No,4,CTBase,a1f9951e-2b6b-4530-9636-9cdf4c1658c5,cb,COMPLETION,False,28,bigscience/T0_3B,0,True,more_likely,prompts/general_fixed_choice.yaml,COPA,,3,,,GenFC,,False,['NLI'],,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,more likely,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.super_glue_copa.more_likely.LenNorm,CB,,,CommitmentBank,super_glue,,,,,,,,,,,,,,,,,12.5,12.0,19
78.2051282051282,,0.8354230531128183,1.236895816205641,,,,78.2051282051282,,,,111.5956678700361,1.236895816205641,1.6534296028880866,71.900826446281,,0.4758774600226449,0.8354230531128183,0.4758774600226449,1.3465703971119134,75.45126353790613,"{'size': 142431, '_type': 'table-file', 'ncols': 9, 'nrows': 277, 'sha256': 'f03605497598987032d914fcd42d87081fdf118a8013cb77853fef81d8c57ddf', 'artifact_path': 'wandb-client-artifact://kkuv7e8c3e6vx7oixbf6hd2j9v2uodnlrud9842m6ltub0qnzikxf7wmbyjok34cso62h4vt57mx55z80yydc407xh46unk55q4veophwbc4c4nguhc25o0hxd76fjwm:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://kkuv7e8c3e6vx7oixbf6hd2j9v2uodnlrud9842m6ltub0qnzikxf7wmbyjok34cso62h4vt57mx55z80yydc407xh46unk55q4veophwbc4c4nguhc25o0hxd76fjwm:latest/predictions.table.json', 'path': 'media/table/predictions_1_f03605497598987032d9.table.json'}",46.467282647943954,,,False,True,validation,False,Yes | No,4,CTBase,a1f9951e-2b6b-4530-9636-9cdf4c1658c5,rte,COMPLETION,False,32,bigscience/T0_3B,0,True,more_likely,prompts/general_fixed_choice.yaml,COPA,,2,,,GenFC,,False,NLI,,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,more likely,,cross_task,two_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.super_glue_copa.more_likely.LenNorm,RTE,78.98345664920208,83.00742444839486,RecognizingTextualEntailment,super_glue,,,,,,,,,,,,,,,,,1.0,1.0,19
20.900076277650648,10.526315789473683,0.5726186291318894,2.297820319820727,2.0,0.4561957970683937,0.0,0.0,,,,132.78571428571428,1.4927242451480456,2.1785714285714284,52.17391304347826,0.805096074672682,0.9839269509968508,0.4536916344625619,0.9839269509968508,1.8214285714285712,25.0,"{'path': 'media/table/predictions_1_e8f55109797a5b47b57c.table.json', 'size': 33687, '_type': 'table-file', 'ncols': 11, 'nrows': 56, 'sha256': 'e8f55109797a5b47b57c6b0f4143481dd9b1a2d35760128630cc60cb3576393f', 'artifact_path': 'wandb-client-artifact://yoa64brl7y7pvmtjnz0f3b6w0sf29wuo62x4yr2dzkl29ry9b6kvxtqj513ldpjx2egwh9zbnsr60oly2whp7c1c06r6qcbp1uflpohx0vjfct5xjpuolotavp6ok9cx:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://yoa64brl7y7pvmtjnz0f3b6w0sf29wuo62x4yr2dzkl29ry9b6kvxtqj513ldpjx2egwh9zbnsr60oly2whp7c1c06r6qcbp1uflpohx0vjfct5xjpuolotavp6ok9cx:latest/predictions.table.json'}",55.06285832888571,,,False,True,validation,False,Yes | Maybe | No,4,CTBase,0edd8660-f299-4819-a5ac-633c11177228,cb,COMPLETION,False,28,bigscience/T0_3B,0,True,exercise,prompts/general_fixed_choice.yaml,COPA,,3,,,GenFC,,False,['NLI'],,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,exercise,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.super_glue_copa.exercise.LenNorm,CB,,,CommitmentBank,super_glue,,,,,,,,,,,,,,,,,35.5,38.5,13
26.290491118077323,20.689655172413797,0.5256570340629841,2.437749215534755,2.0,0.4662259400459175,0.0,0.0,,,,121.85714285714286,1.790476794753756,1.8571428571428568,58.18181818181818,0.6472724207809993,0.989743318610787,0.4840427779271357,0.989743318610787,2.142857142857143,33.92857142857143,"{'sha256': '3835b88c856ef0e263222db5c24160c9ea63ea6575a95891fff789a94633f0e2', 'artifact_path': 'wandb-client-artifact://16pg58wse1mb7motnof12oo57p5d1cc3w0rrncc21vzv8l38hw53njnzqicj3l51ji597n58ecoygdtem3m3okfe3q76prit421dsmeffzblw0b5y4gc787jvy89x3s3:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://16pg58wse1mb7motnof12oo57p5d1cc3w0rrncc21vzv8l38hw53njnzqicj3l51ji597n58ecoygdtem3m3okfe3q76prit421dsmeffzblw0b5y4gc787jvy89x3s3:latest/predictions.table.json', 'path': 'media/table/predictions_1_3835b88c856ef0e26322.table.json', 'size': 31083, '_type': 'table-file', 'ncols': 11, 'nrows': 56}",55.07216971893354,,,False,True,validation,False,Yes | Maybe | No,4,CTBase,2d0d63da-ffcf-4f6e-941a-b8da922be43e,cb,ENTAILMENT,False,28,bigscience/T0_3B,0,True,guaranteed_true,prompts/general_fixed_choice.yaml,ANLI,,3,,,GenFC,,True,['NLI'],,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,guaranteed true,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.anli.guaranteed_true.LenNorm,CB,,,CommitmentBank,super_glue,,,,,,,,,,,,,,,,,8.5,5.0,12
73.80952380952382,,0.917602026022692,1.3591018996944495,,,,73.80952380952382,,,,105.5956678700361,1.3591018996944495,1.740072202166065,59.63302752293577,,0.4385947306422366,0.917602026022692,0.4385947306422366,1.259927797833935,68.23104693140795,"{'_latest_artifact_path': 'wandb-client-artifact://44ruz53cmfyqlx8awa9ls9avqsq9958pn0rp7k7mx8omab6wlqfz0nzsrjmbc37vhsh87ej7wwvnjto9p3ldigxuprxi50yitdwufdmbcvm3pklnaw6mpoo7myiab0nw:latest/predictions.table.json', 'path': 'media/table/predictions_1_6c0e410a432e6c94b910.table.json', 'size': 137779, '_type': 'table-file', 'ncols': 9, 'nrows': 277, 'sha256': '6c0e410a432e6c94b91069fec348c2d911748594edd3498a7616d3bb01e675ae', 'artifact_path': 'wandb-client-artifact://44ruz53cmfyqlx8awa9ls9avqsq9958pn0rp7k7mx8omab6wlqfz0nzsrjmbc37vhsh87ej7wwvnjto9p3ldigxuprxi50yitdwufdmbcvm3pklnaw6mpoo7myiab0nw:latest/predictions.table.json'}",46.467282647943954,,,False,True,validation,False,Yes | No,4,CTBase,0edd8660-f299-4819-a5ac-633c11177228,rte,COMPLETION,False,32,bigscience/T0_3B,0,True,exercise,prompts/general_fixed_choice.yaml,COPA,,2,,,GenFC,,False,NLI,,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,exercise,,cross_task,two_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.super_glue_copa.exercise.LenNorm,RTE,79.92832056416663,82.80351354177559,RecognizingTextualEntailment,super_glue,,,,,,,,,,,,,,,,,23.0,18.0,13
23.14814814814815,11.11111111111111,0.5253604944158391,2.8003829632486616,2.0,0.389539660014564,0.0,0.0,,,,132.78571428571428,2.186333426407405,2.107142857142857,58.333333333333336,0.6140495368412563,0.9942436362196468,0.450259168009449,0.9942436362196468,1.8928571428571428,28.57142857142857,"{'nrows': 56, 'sha256': '537d2ba72ff9887c0a353aadbb4b7c7ff50c2cf13e33aa40c970d487ae7a8245', 'artifact_path': 'wandb-client-artifact://irs6hpqv3eqzqiuuxs8cpsgh38bkpq9v6uizydymvffm5pxip2ryzb5mrnab193ufok4ju871v3ze3kydlmssupf9wo6hqkquydfg0en845wgma9fmvwtge7bo3h5ay9:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://irs6hpqv3eqzqiuuxs8cpsgh38bkpq9v6uizydymvffm5pxip2ryzb5mrnab193ufok4ju871v3ze3kydlmssupf9wo6hqkquydfg0en845wgma9fmvwtge7bo3h5ay9:latest/predictions.table.json', 'path': 'media/table/predictions_1_537d2ba72ff9887c0a35.table.json', 'size': 31644, '_type': 'table-file', 'ncols': 11}",55.06285832888571,,,False,True,validation,False,Yes | Maybe | No,4,CTBase,9e078fb4-505b-413c-bb5e-3cd16ddcf5d7,cb,ENTAILMENT,False,28,bigscience/T0_3B,0,True,does_this_imply,prompts/general_fixed_choice.yaml,ANLI,,3,,,GenFC,,True,['NLI'],,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,does this imply,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.anli.does_this_imply.LenNorm,CB,,,CommitmentBank,super_glue,,,,,,,,,,,,,,,,,21.0,20.0,23
71.67630057803468,,0.8235267270570159,1.1905814069272809,,,,71.67630057803468,,,,91.93862815884476,1.1905814069272809,1.776173285198556,52.88461538461539,,0.4168072894547756,0.8235267270570159,0.4168072894547756,1.223826714801444,64.62093862815884,"{'ncols': 9, 'nrows': 277, 'sha256': 'daea9acb1f00e16c87acd64af62f1ed420ad46f06486015a6a6c9bfbd74e4fac', 'artifact_path': 'wandb-client-artifact://d15l5sxvmkzcn7qtr45ek69a0gukk6mgy7tfy0m3za4do4oajgn8c0ilrrhk00vdqry09vdp6hc87h7nk8pkjb5wax1um6skxd4e1zftxsckox75cafvazwmwwnkuopq:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://d15l5sxvmkzcn7qtr45ek69a0gukk6mgy7tfy0m3za4do4oajgn8c0ilrrhk00vdqry09vdp6hc87h7nk8pkjb5wax1um6skxd4e1zftxsckox75cafvazwmwwnkuopq:latest/predictions.table.json', 'path': 'media/table/predictions_1_daea9acb1f00e16c87ac.table.json', 'size': 124513, '_type': 'table-file'}",46.47129297794757,,,False,True,validation,False,Yes | No,4,CTBase,2d0d63da-ffcf-4f6e-941a-b8da922be43e,rte,ENTAILMENT,False,32,bigscience/T0_3B,0,True,guaranteed_true,prompts/general_fixed_choice.yaml,ANLI,,2,,,GenFC,,False,NLI,,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,guaranteed true,,cross_task,two_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.anli.guaranteed_true.LenNorm,RTE,78.17983926719717,81.05197113876399,RecognizingTextualEntailment,super_glue,,,,,,,,,,,,,,,,,40.0,36.0,12
25.185185185185183,20.0,0.5152118643189102,2.293335222772189,2.0,0.4640668769637135,0.0,0.0,,,,123.85714285714286,1.6715344658919744,1.8928571428571428,55.55555555555556,0.6218007568802152,0.9942436362196468,0.4910193866155927,0.9942436362196468,2.107142857142857,32.142857142857146,"{'sha256': '12df496d6f6f51952d201d40e51257501cc4dd8a8882df6c0f46f8467873a66b', 'artifact_path': 'wandb-client-artifact://j58q4tgr38jrqu6zxwxgp3v2ek8s5ckpkl2k68xw6frssac03r5j5chjvxc8md62kogctryz4zpcql72oezhmw70lu1hnhc03abhjkfttxq29g0127aucf2fhm9fc1x7:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://j58q4tgr38jrqu6zxwxgp3v2ek8s5ckpkl2k68xw6frssac03r5j5chjvxc8md62kogctryz4zpcql72oezhmw70lu1hnhc03abhjkfttxq29g0127aucf2fhm9fc1x7:latest/predictions.table.json', 'path': 'media/table/predictions_1_12df496d6f6f51952d20.table.json', 'size': 31651, '_type': 'table-file', 'ncols': 11, 'nrows': 56}",55.07216971893354,,,False,True,validation,False,Yes | Maybe | No,4,CTBase,fb4f8144-37f5-4977-88da-37a5d0bfd0e8,cb,ENTAILMENT,False,28,bigscience/T0_3B,0,True,must_be_true,prompts/general_fixed_choice.yaml,ANLI,,3,,,GenFC,,True,['NLI'],,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,must be true,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.anli.must_be_true.LenNorm,CB,,,CommitmentBank,super_glue,,,,,,,,,,,,,,,,,12.5,7.0,14
24.821312540610784,14.814814814814811,0.5969040586925994,2.79524718437876,2.0,0.5062382621361768,0.0,0.0,,,,126.85714285714286,2.158074515206473,1.7857142857142858,59.64912280701754,0.637172669172287,0.9767710236555244,0.5409743300540931,0.9767710236555244,2.2142857142857144,33.92857142857143,"{'_type': 'table-file', 'ncols': 11, 'nrows': 56, 'sha256': '08e75c436282704741ab9ab88ac7e005da4aff1ca94328b5540c99e448d68bfd', 'artifact_path': 'wandb-client-artifact://sm0h6sw0j4mlsxxfscit4kdu0pwxqu5baqywx4agzedw4daylz5tv5p5y4zza02xor112ze7gj82u53ujz7v2cunurm4q82ogbp38tlqyxe95rjwl6yvvpdljyxnbf1z:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://sm0h6sw0j4mlsxxfscit4kdu0pwxqu5baqywx4agzedw4daylz5tv5p5y4zza02xor112ze7gj82u53ujz7v2cunurm4q82ogbp38tlqyxe95rjwl6yvvpdljyxnbf1z:latest/predictions.table.json', 'path': 'media/table/predictions_1_08e75c436282704741ab.table.json', 'size': 32655}",55.07216971893354,,,False,True,validation,False,Yes | Maybe | No,4,CTBase,bab86d5a-4f9c-40db-b619-a7b7d5cae681,cb,ENTAILMENT,False,28,bigscience/T0_3B,0,True,take_the_following_as_truth,prompts/general_fixed_choice.yaml,ANLI,,3,,,GenFC,,True,['NLI'],,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,take the following as truth,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.anli.take_the_following_as_truth.LenNorm,CB,,,CommitmentBank,super_glue,,,,,,,,,,,,,,,,,8.5,8.0,17
70.49180327868852,,1.061462400590069,1.5260949513542093,,,,70.49180327868852,,,,104.5956678700361,1.5260949513542093,1.848375451263538,42.5531914893617,,0.3586565835962395,1.061462400590069,0.3586565835962395,1.151624548736462,61.01083032490975,"{'size': 127232, '_type': 'table-file', 'ncols': 9, 'nrows': 277, 'sha256': '45fa5a42d221fbb8700962a15ed7c537dee117d6ae3381e45043719422ce8085', 'artifact_path': 'wandb-client-artifact://8n25pdkcbsyds6d3l1tbqpesqyq3p0ymsap79no19sxri0xun3lz6fj8b8lrurnp3lz0aubdxln6j0rl4wf9ly6d4vhnmiq7vi9tdynhenglnw1dbpgi1sfo3ewkqbhr:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://8n25pdkcbsyds6d3l1tbqpesqyq3p0ymsap79no19sxri0xun3lz6fj8b8lrurnp3lz0aubdxln6j0rl4wf9ly6d4vhnmiq7vi9tdynhenglnw1dbpgi1sfo3ewkqbhr:latest/predictions.table.json', 'path': 'media/table/predictions_1_45fa5a42d221fbb87009.table.json'}",46.467282647943954,,,False,True,validation,False,Yes | No,4,CTBase,9e078fb4-505b-413c-bb5e-3cd16ddcf5d7,rte,ENTAILMENT,False,32,bigscience/T0_3B,0,True,does_this_imply,prompts/general_fixed_choice.yaml,ANLI,,2,,,GenFC,,False,NLI,,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,does this imply,,cross_task,two_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.anli.does_this_imply.LenNorm,RTE,79.26884757977206,82.47934748509881,RecognizingTextualEntailment,super_glue,,,,,,,,,,,,,,,,,47.5,43.0,23
22.654462242562925,15.789473684210526,0.5551962045223066,2.776882674012865,2.0,0.4590991834290314,0.0,0.0,,,,120.85714285714286,2.1311520848955428,2.1785714285714284,52.17391304347826,0.6457305891173226,0.9839269509968508,0.4808798270153445,0.9839269509968508,1.8214285714285712,26.785714285714285,"{'sha256': '5fd84fd381d68295de0d3e4b9dcbb67d4862b97635ac48e8da4dd7055874d71e', 'artifact_path': 'wandb-client-artifact://13y4h10pta3b0ino1wekgrsoxbwyxcn00ixhoda4d22gp0ufh8h3q6z3e5bun3ykaqfiyxh6ek9brdsg6qodj7y22prd0qfon51909q86bkn2pge8yfw7xq75jf6kwlu:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://13y4h10pta3b0ino1wekgrsoxbwyxcn00ixhoda4d22gp0ufh8h3q6z3e5bun3ykaqfiyxh6ek9brdsg6qodj7y22prd0qfon51909q86bkn2pge8yfw7xq75jf6kwlu:latest/predictions.table.json', 'path': 'media/table/predictions_1_5fd84fd381d68295de0d.table.json', 'size': 31030, '_type': 'table-file', 'ncols': 11, 'nrows': 56}",55.07216971893354,,,False,True,validation,False,Yes | Maybe | No,4,CTBase,a850110d-f1a3-49b4-949a-d3bfe9f81344,cb,ENTAILMENT,False,28,bigscience/T0_3B,0,True,justified_in_saying,prompts/general_fixed_choice.yaml,ANLI,,3,,,GenFC,,True,['NLI'],,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,justified in saying,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.anli.justified_in_saying.LenNorm,CB,,,CommitmentBank,super_glue,,,,,,,,,,,,,,,,,27.5,23.0,11
26.45833333333333,20.0,0.533510273097106,3.126244376812662,2.0,0.5816910349584195,0.0,0.0,,,,124.85714285714286,2.375642648765019,1.5357142857142858,59.375,0.7506017280476434,0.8856854834026604,0.4784918349951109,0.8856854834026604,2.4642857142857144,37.5,"{'size': 31889, '_type': 'table-file', 'ncols': 11, 'nrows': 56, 'sha256': '51aecd84489cf7e0c244d0810c262a1eecf58b796397949ca4f403404a6967c6', 'artifact_path': 'wandb-client-artifact://cozdggm2pdyawy13z4cok5rzcxxi9ykamakzfid4b5ymh2s8rohqtnwapfsgc09t7sxmywzcaaims71r2427shwhey0dhenl3scaz6ly4tevxuajw7sq0g5ikvxmnn6j:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://cozdggm2pdyawy13z4cok5rzcxxi9ykamakzfid4b5ymh2s8rohqtnwapfsgc09t7sxmywzcaaims71r2427shwhey0dhenl3scaz6ly4tevxuajw7sq0g5ikvxmnn6j:latest/predictions.table.json', 'path': 'media/table/predictions_1_51aecd84489cf7e0c244.table.json'}",55.07216971893354,,,False,True,validation,False,Yes | Maybe | No,4,CTBase,9b613182-c6ab-4427-9221-3d68f6d62765,cb,ENTAILMENT,False,28,bigscience/T0_3B,0,True,based_on_the_previous_passage,prompts/general_fixed_choice.yaml,ANLI,,3,,,GenFC,,True,['NLI'],,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,based on the previous passage,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.anli.based_on_the_previous_passage.LenNorm,CB,,,CommitmentBank,super_glue,,,,,,,,,,,,,,,,,4.5,2.0,15
76.3076923076923,,0.7644193093014622,1.0777852569676478,,,,76.3076923076923,,,,93.93862815884476,1.0777852569676478,1.7003610108303249,66.37554585152837,,0.4580998421076462,0.7644193093014622,0.4580998421076462,1.2996389891696751,72.20216606498195,"{'sha256': 'f7673a70b5ab301004ea736d69854557bbc9e8144254e14695807e2a21b2d03b', 'artifact_path': 'wandb-client-artifact://e9dk6na0n59ywkgll4t1pupeik2nlk33no4zmrg68sg93c7eeni96btz0po8mekhaq4lsg2jdq9j36clydbodujjwjb5goipo3naligdve53h7zry0m1paf8ji7j789u:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://e9dk6na0n59ywkgll4t1pupeik2nlk33no4zmrg68sg93c7eeni96btz0po8mekhaq4lsg2jdq9j36clydbodujjwjb5goipo3naligdve53h7zry0m1paf8ji7j789u:latest/predictions.table.json', 'path': 'media/table/predictions_1_f7673a70b5ab301004ea.table.json', 'size': 127310, '_type': 'table-file', 'ncols': 9, 'nrows': 277}",46.47129297794757,,,False,True,validation,False,Yes | No,4,CTBase,fb4f8144-37f5-4977-88da-37a5d0bfd0e8,rte,ENTAILMENT,False,32,bigscience/T0_3B,0,True,must_be_true,prompts/general_fixed_choice.yaml,ANLI,,2,,,GenFC,,False,NLI,,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,must be true,,cross_task,two_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.anli.must_be_true.LenNorm,RTE,79.81648086474662,82.99173899403954,RecognizingTextualEntailment,super_glue,,,,,,,,,,,,,,,,,7.0,6.0,14
23.3974358974359,12.5,0.5387573960257785,2.740982085466385,2.0,0.4187786407380981,0.0,0.0,,,,113.73214285714286,2.100286160196577,1.9642857142857144,57.6923076923077,0.6406959252698081,0.9993620414023732,0.4810014467496394,0.9993620414023732,2.0357142857142856,30.357142857142858,"{'_type': 'table-file', 'ncols': 11, 'nrows': 56, 'sha256': '634e05153ce543fdca10acf3f9b7db7a3efb114a35fe35d5bcce9102b94f5335', 'artifact_path': 'wandb-client-artifact://abcswcwg4a2tvymngzx9v26i6jt9w3cv3kuoftcw6ulk0w1k980h7xysjyclxsz6ebph7450rtp56ee8eqnj4zcvz3np8e5k8t9ltwjo2fw6fsfyczlg8q3xcp9n7lrk:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://abcswcwg4a2tvymngzx9v26i6jt9w3cv3kuoftcw6ulk0w1k980h7xysjyclxsz6ebph7450rtp56ee8eqnj4zcvz3np8e5k8t9ltwjo2fw6fsfyczlg8q3xcp9n7lrk:latest/predictions.table.json', 'path': 'media/table/predictions_1_634e05153ce543fdca10.table.json', 'size': 29520}",55.07997142837876,,,False,True,validation,False,Yes | Maybe | No,4,CTBase,620aa3fc-d5eb-46f5-a1ee-4c754527aa97,cb,ENTAILMENT,False,28,bigscience/T0_3B,0,True,GPT_3_style,prompts/general_fixed_choice.yaml,ANLI,,3,,,GenFC,,True,['NLI'],,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,GPT-3 style,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.anli.GPT_3_style.LenNorm,CB,,,CommitmentBank,super_glue,,,,,,,,,,,,,,,,,16.5,17.0,4
74.99999999999999,,0.9335996623842644,1.332954600399582,,,,74.99999999999999,,,,96.93862815884476,1.332954600399582,1.740072202166065,61.46788990825688,,0.4385947306422366,0.9335996623842644,0.4385947306422366,1.259927797833935,69.67509025270758,"{'size': 132247, '_type': 'table-file', 'ncols': 9, 'nrows': 277, 'sha256': '768a1b00701ff8730263b915fe0a75875313c1b958206edc5e0f9c96cb3eb92d', 'artifact_path': 'wandb-client-artifact://1304tdsfhq63v9jsmkxgvtiusz3dz7slkay6kkv1ilr6xaodab25y0xigg151dv8dy96cd2fh87p04eyres2bv370yppkzhksyhu0x03ln5i35wuz6brhwe38s4yke6u:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://1304tdsfhq63v9jsmkxgvtiusz3dz7slkay6kkv1ilr6xaodab25y0xigg151dv8dy96cd2fh87p04eyres2bv370yppkzhksyhu0x03ln5i35wuz6brhwe38s4yke6u:latest/predictions.table.json', 'path': 'media/table/predictions_1_768a1b00701ff8730263.table.json'}",46.47129297794757,,,False,True,validation,False,Yes | No,4,CTBase,bab86d5a-4f9c-40db-b619-a7b7d5cae681,rte,ENTAILMENT,False,32,bigscience/T0_3B,0,True,take_the_following_as_truth,prompts/general_fixed_choice.yaml,ANLI,,2,,,GenFC,,False,NLI,,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,take the following as truth,,cross_task,two_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.anli.take_the_following_as_truth.LenNorm,RTE,82.71587815781761,85.10404684722367,RecognizingTextualEntailment,super_glue,,,,,,,,,,,,,,,,,15.0,10.0,17
20.944669365721992,10.52631578947368,0.5277550240276597,3.103346871478217,2.0,0.5283908630886384,0.0,0.0,,,,122.85714285714286,2.3657888003758023,1.5,52.3076923076923,0.7375580711024148,0.8660254037844386,0.4861425774966828,0.8660254037844386,2.5,32.142857142857146,"{'path': 'media/table/predictions_1_f07bdd29f8626d8390c7.table.json', 'size': 31486, '_type': 'table-file', 'ncols': 11, 'nrows': 56, 'sha256': 'f07bdd29f8626d8390c7f545aea730b5801add57c59d20479977e7ac9fdb40fd', 'artifact_path': 'wandb-client-artifact://4ede1f05d9xm68mmdjr0ajinxk9qdin8gxztqzd6qhijq6jpujnmak8heslk1lj4skv00t653eq3fr7kh9qpthrl2objh5wjn9urd1fabfplpo9szbimgerz32wwn267:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://4ede1f05d9xm68mmdjr0ajinxk9qdin8gxztqzd6qhijq6jpujnmak8heslk1lj4skv00t653eq3fr7kh9qpthrl2objh5wjn9urd1fabfplpo9szbimgerz32wwn267:latest/predictions.table.json'}",55.07216971893354,,,False,True,validation,False,Yes | Maybe | No,4,CTBase,ec249357-e672-4e7d-b8b6-d97ed7d090c5,cb,ENTAILMENT,False,28,bigscience/T0_3B,0,True,claim_true_false_inconclusive,prompts/general_fixed_choice.yaml,ANLI,,3,,,GenFC,,True,['NLI'],,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,claim true/false/inconclusive,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.anli.claim_true_false_inconclusive.LenNorm,CB,,,CommitmentBank,super_glue,,,,,,,,,,,,,,,,,12.5,34.0,13
26.38888888888889,16.666666666666664,0.5086331771771596,2.720004533018385,2.0,0.4712992494502905,0.0,0.0,,,,121.85714285714286,2.029895382268088,2.107142857142857,62.500000000000014,0.6901091507502964,0.9942436362196468,0.4341115887689834,0.9942436362196468,1.8928571428571428,32.142857142857146,"{'path': 'media/table/predictions_1_bb37ded41138c6abd9b0.table.json', 'size': 30679, '_type': 'table-file', 'ncols': 11, 'nrows': 56, 'sha256': 'bb37ded41138c6abd9b0eb4bb26ffcf84aa3d572f29cd7cf29cb1482dd4a825e', 'artifact_path': 'wandb-client-artifact://vfbbe5deska1yww3fkxr7af4my3s4myruhtj102mzbxppulw4x0s5inh7eq5r6smqapluf8svaslo1k1ca5pvda0cy822kuwlxiw4t9bygggzme4lmkj4zrb12c3xoa7:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://vfbbe5deska1yww3fkxr7af4my3s4myruhtj102mzbxppulw4x0s5inh7eq5r6smqapluf8svaslo1k1ca5pvda0cy822kuwlxiw4t9bygggzme4lmkj4zrb12c3xoa7:latest/predictions.table.json'}",55.07216971893354,,,False,True,validation,False,Yes | Maybe | No,4,CTBase,c4ed37ae-d7d7-4197-a725-ef2152fa3b1f,cb,ENTAILMENT,False,28,bigscience/T0_3B,0,True,can_we_infer,prompts/general_fixed_choice.yaml,ANLI,,3,,,GenFC,,True,['NLI'],,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,can we infer,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.anli.can_we_infer.LenNorm,CB,,,CommitmentBank,super_glue,,,,,,,,,,,,,,,,,12.5,4.0,12
71.50837988826815,,0.9024644807227924,1.2863426673283216,,,,71.50837988826815,,,,90.93862815884476,1.2863426673283216,1.8194945848375448,47.9591836734694,,0.3846078655715255,0.9024644807227924,0.3846078655715255,1.1805054151624548,63.1768953068592,"{'artifact_path': 'wandb-client-artifact://ktvumxkzw6hisx3llj7v1uf6b8az4pz3i0vwgnfver999arb848gsiq55armnro1p6mgu1x3ehsq6lqjo6owpsjf4bh7frdipm6bm9iprm6wok9z3grnzwxppffwa50o:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://ktvumxkzw6hisx3llj7v1uf6b8az4pz3i0vwgnfver999arb848gsiq55armnro1p6mgu1x3ehsq6lqjo6owpsjf4bh7frdipm6bm9iprm6wok9z3grnzwxppffwa50o:latest/predictions.table.json', 'path': 'media/table/predictions_1_63d643dd9fbaac0e2e63.table.json', 'size': 124204, '_type': 'table-file', 'ncols': 9, 'nrows': 277, 'sha256': '63d643dd9fbaac0e2e6308892b80a17e4d18c1ad68da34ddc35bdd2c76096312'}",46.47129297794757,,,False,True,validation,False,Yes | No,4,CTBase,a850110d-f1a3-49b4-949a-d3bfe9f81344,rte,ENTAILMENT,False,32,bigscience/T0_3B,0,True,justified_in_saying,prompts/general_fixed_choice.yaml,ANLI,,2,,,GenFC,,False,NLI,,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,justified in saying,,cross_task,two_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.anli.justified_in_saying.LenNorm,RTE,78.70447607345123,81.68984628254732,RecognizingTextualEntailment,super_glue,,,,,,,,,,,,,,,,,42.0,37.0,11
13.095238095238091,17.857142857142854,1.0449386908989475,3.794631029878344,1.9464285714285712,0.9781572461942508,0.2251700038021159,0.0,,,,125.78571428571428,2.0980904272624423,2.821428571428572,21.428571428571427,1.6965406026159011,0.5703114079525468,1.130353710586999,0.5973474529884905,1.2321428571428572,14.285714285714285,"{'nrows': 56, 'sha256': '3b39e989a74d9b5e15806d968759a4b7180363c14bce010535e9ae716f556338', 'artifact_path': 'wandb-client-artifact://bl25948i9jsvo2hrbepjviy68skh5gc6o56mjx2oe2rbftd11s9chbgh2e0kfd1havvpknn34e972mv3gn6m4hv1e3cjaq83cclluztnbkkyc8fo2wilqi077gb2xdos:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://bl25948i9jsvo2hrbepjviy68skh5gc6o56mjx2oe2rbftd11s9chbgh2e0kfd1havvpknn34e972mv3gn6m4hv1e3cjaq83cclluztnbkkyc8fo2wilqi077gb2xdos:latest/predictions.table.json', 'path': 'media/table/predictions_1_3b39e989a74d9b5e1580.table.json', 'size': 32157, '_type': 'table-file', 'ncols': 11}",55.06285832888572,,,False,True,validation,False,Yes | Maybe | No,4,CTBase,ed215962-8e51-45e7-b025-6e822f877098,cb,CLASSIFICATION,False,28,bigscience/T0_3B,0,True,sentence_to_concepts,prompts/general_fixed_choice.yaml,CommonGen,,3,,,GenFC,,False,['NLI'],,True,False,GeneralFixedChoice,False,False,False,,,prompts,,,True,sentence to concepts,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.common_gen.sentence_to_concepts.LenNorm,CB,,,CommitmentBank,super_glue,,,,,,,,,,,,,,,,,67.5,70.0,13
77.06422018348624,,0.9250106806148498,1.2733296977914197,,,,77.06422018348624,,,,94.93862815884476,1.2733296977914197,1.7075812274368232,66.96035242290749,,0.4548736462093863,0.9250106806148498,0.4548736462093863,1.2924187725631768,72.92418772563177,"{'size': 128383, '_type': 'table-file', 'ncols': 9, 'nrows': 277, 'sha256': '6db387cfba2768b52a2525b799609bb769168d636b5d83362937be34e686180b', 'artifact_path': 'wandb-client-artifact://16wubmzc8pcooxszjjl5l2x6gnkpdiqrlbrmed3zc75dhupswyjtc1lmtfitzhm9txqosprh2z7oheo9894dw85h0km5boshldi57kb510z3skcis7jmmzf9kyy9ip4c:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://16wubmzc8pcooxszjjl5l2x6gnkpdiqrlbrmed3zc75dhupswyjtc1lmtfitzhm9txqosprh2z7oheo9894dw85h0km5boshldi57kb510z3skcis7jmmzf9kyy9ip4c:latest/predictions.table.json', 'path': 'media/table/predictions_1_6db387cfba2768b52a25.table.json'}",46.47129297794757,,,False,True,validation,False,Yes | No,4,CTBase,9b613182-c6ab-4427-9221-3d68f6d62765,rte,ENTAILMENT,False,32,bigscience/T0_3B,0,True,based_on_the_previous_passage,prompts/general_fixed_choice.yaml,ANLI,,2,,,GenFC,,False,NLI,,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,based on the previous passage,,cross_task,two_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.anli.based_on_the_previous_passage.LenNorm,RTE,81.09826413766594,83.55118686604621,RecognizingTextualEntailment,super_glue,,,,,,,,,,,,,,,,,6.0,2.0,15
11.904761904761903,14.285714285714285,1.1681943612385428,4.3205980232783725,1.9821428571428568,1.0170751740900856,0.132432115840994,0.0,,,,121.78571428571428,2.7480853285108293,2.821428571428572,21.428571428571427,1.5725126947675432,0.5703114079525468,1.2221788385868355,0.5800136346039898,1.1964285714285714,12.5,"{'ncols': 11, 'nrows': 56, 'sha256': '0fa8a0f7b94ad4fc89dcd134a619ba82857dfa027ea4bcc5a8e34d4ca8154ff1', 'artifact_path': 'wandb-client-artifact://11639rl1huuhb7wwwiog25t1lcxi3jel94rf63eldrvl1b4lkgyqpnqq73uaz5usnfa9aywh35zcxyn2vlc3wwdqvu3viabdfvch0ade76ez532m4hbxmfue3aephrg6:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://11639rl1huuhb7wwwiog25t1lcxi3jel94rf63eldrvl1b4lkgyqpnqq73uaz5usnfa9aywh35zcxyn2vlc3wwdqvu3viabdfvch0ade76ez532m4hbxmfue3aephrg6:latest/predictions.table.json', 'path': 'media/table/predictions_1_0fa8a0f7b94ad4fc89dc.table.json', 'size': 31192, '_type': 'table-file'}",55.06285832888572,,,False,True,validation,False,Yes | Maybe | No,4,CTBase,b7012213-04c4-424d-85fb-39d63d8a0ca2,cb,CLASSIFICATION,False,28,bigscience/T0_3B,0,True,topics_from_the_sentence,prompts/general_fixed_choice.yaml,CommonGen,,3,,,GenFC,,False,['NLI'],,True,False,GeneralFixedChoice,False,False,False,,,prompts,,,True,topics from the sentence,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.common_gen.topics_from_the_sentence.LenNorm,CB,,,CommitmentBank,super_glue,,,,,,,,,,,,,,,,,74.0,73.0,8
69.00269541778977,,1.0369549465026455,1.5768461451203384,,,,69.00269541778977,,,,84.03971119133574,1.5768461451203384,1.8664259927797835,37.15846994535519,,0.3401940502350828,1.0369549465026455,0.3401940502350828,1.1335740072202165,58.48375451263538,"{'_latest_artifact_path': 'wandb-client-artifact://tn18955dw1mrujvh1w7gmsrokpxqe1f2o2rageicvt3odygeypgeqfbwqqsqm5ndfhk0ywwblj4d3y3r3uq8pgsbdnssfm8nfucih51emqh6zkex5n5g84fytr29tsat:latest/predictions.table.json', 'path': 'media/table/predictions_1_d32d2815dab10ba9912b.table.json', 'size': 116761, '_type': 'table-file', 'ncols': 9, 'nrows': 277, 'sha256': 'd32d2815dab10ba9912b8736f284846f3867a0e0298d65b92c9ef34ee2a1c7fe', 'artifact_path': 'wandb-client-artifact://tn18955dw1mrujvh1w7gmsrokpxqe1f2o2rageicvt3odygeypgeqfbwqqsqm5ndfhk0ywwblj4d3y3r3uq8pgsbdnssfm8nfucih51emqh6zkex5n5g84fytr29tsat:latest/predictions.table.json'}",46.50913357668334,,,False,True,validation,False,Yes | No,4,CTBase,620aa3fc-d5eb-46f5-a1ee-4c754527aa97,rte,ENTAILMENT,False,32,bigscience/T0_3B,0,True,GPT_3_style,prompts/general_fixed_choice.yaml,ANLI,,2,,,GenFC,,False,NLI,,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,GPT-3 style,,cross_task,two_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.anli.GPT_3_style.LenNorm,RTE,81.32325875353301,83.62961413782286,RecognizingTextualEntailment,super_glue,,,,,,,,,,,,,,,,,56.5,54.5,4
20.32085561497326,6.0606060606060606,0.5141752052781524,1.6760914267173834,2.0,0.4787314737290171,0.1889822365046136,0.0,,,,137.78571428571428,0.9680818298033306,2.0,54.90196078431373,0.708009596914053,1.0,0.3676566630942912,0.9819805060619656,2.0,26.785714285714285,"{'sha256': '67a7e2517be5f1d4e73f999633be13e3c8b5ca7f7ea8872b2ed3fa2906d8c3ad', 'artifact_path': 'wandb-client-artifact://k6iuooc8lp5644clgeihf5iroit9z6aafqqawohft2qi12copmredjlah9ptmzzz7obaffwu048i48tailbfj2k8917we84uf8inmwn4wy7c1amcj8s8yb0zcdbbc6fs:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://k6iuooc8lp5644clgeihf5iroit9z6aafqqawohft2qi12copmredjlah9ptmzzz7obaffwu048i48tailbfj2k8917we84uf8inmwn4wy7c1amcj8s8yb0zcdbbc6fs:latest/predictions.table.json', 'path': 'media/table/predictions_1_67a7e2517be5f1d4e73f.table.json', 'size': 35427, '_type': 'table-file', 'ncols': 11, 'nrows': 56}",55.06285832888571,,,False,True,validation,False,Yes | Maybe | No,4,CTBase,fc76beb7-c258-412f-a623-42fc8d2331b6,cb,COMPLETION,False,28,bigscience/T0_3B,0,True,fill_in_the_blank_with_instruction_and_choices,prompts/general_fixed_choice.yaml,NumerSense,,3,,,GenFC,,False,['NLI'],,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,fill_in_the_blank_with_instruction_and_choices,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.numer_sense.fill_in_the_blank_with_instruction_and_choices.LenNorm,CB,,,CommitmentBank,super_glue,,,,,,,,,,,,,,,,,27.5,42.0,20
14.043887147335424,14.545454545454543,1.0451724494904393,4.7006939734731406,2.0,0.8389579594877477,0.0,0.0,,,,124.78571428571428,3.3578922876289914,2.7857142857142856,27.58620689655172,1.342801685844149,0.6185895741317419,1.0698264454929556,0.6185895741317419,1.2142857142857142,14.285714285714285,"{'artifact_path': 'wandb-client-artifact://1487uibw74he7oj2eg4ipv11w9wt0czjey4uke4r3epkyqmsatjrvjra27c3evkm20rdw7kdtaoeea9aeqyeqowz8zy27070iwisvuub11colemstfs0icxmpc97sacg:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://1487uibw74he7oj2eg4ipv11w9wt0czjey4uke4r3epkyqmsatjrvjra27c3evkm20rdw7kdtaoeea9aeqyeqowz8zy27070iwisvuub11colemstfs0icxmpc97sacg:latest/predictions.table.json', 'path': 'media/table/predictions_1_51ba6f422d10180277ca.table.json', 'size': 31444, '_type': 'table-file', 'ncols': 11, 'nrows': 56, 'sha256': '51ba6f422d10180277ca3d3aa78cc638afa284d808d436e2952675520addd6f9'}",55.06285832888572,,,False,True,validation,False,Yes | Maybe | No,4,CTBase,cacee36c-e2b7-458e-9d51-6fcfd83842b4,cb,COMPLETION,False,28,bigscience/T0_3B,0,True,fill_in_the_blank_before_sentence,prompts/general_fixed_choice.yaml,NumerSense,,3,,,GenFC,,False,['NLI'],,False,False,GeneralFixedChoice,False,False,False,,,prompts,,,True,fill_in_the_blank_before_sentence,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.numer_sense.fill_in_the_blank_before_sentence.LenNorm,CB,,,CommitmentBank,super_glue,,,,,,,,,,,,,,,,,67.5,66.0,11
72.57142857142857,,0.9126830817020316,1.3048282822977335,,,,72.57142857142857,,,,92.93862815884476,1.3048282822977335,1.7906137184115525,52.94117647058824,,0.4068705772982496,0.9126830817020316,0.4068705772982496,1.2093862815884475,65.34296028880865,"{'_latest_artifact_path': 'wandb-client-artifact://rpqslwsto7mtl3lt7h835jjepl2o31ypb13iesbg8b1a0punbtx6d25rqykssivc3aqb61alwzemowtggf2k2hwu1mnr6ijfnehla0ofjnbeshh7ka6ef8e73x0ohcjp:latest/predictions.table.json', 'path': 'media/table/predictions_1_73fc722b037805fda741.table.json', 'size': 126409, '_type': 'table-file', 'ncols': 9, 'nrows': 277, 'sha256': '73fc722b037805fda74140e727ffa8befb86f17b336afe56fc94b65e777940ee', 'artifact_path': 'wandb-client-artifact://rpqslwsto7mtl3lt7h835jjepl2o31ypb13iesbg8b1a0punbtx6d25rqykssivc3aqb61alwzemowtggf2k2hwu1mnr6ijfnehla0ofjnbeshh7ka6ef8e73x0ohcjp:latest/predictions.table.json'}",46.47129297794757,,,False,True,validation,False,Yes | No,4,CTBase,ec249357-e672-4e7d-b8b6-d97ed7d090c5,rte,ENTAILMENT,False,32,bigscience/T0_3B,0,True,claim_true_false_inconclusive,prompts/general_fixed_choice.yaml,ANLI,,2,,,GenFC,,False,NLI,,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,claim true/false/inconclusive,,cross_task,two_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.anli.claim_true_false_inconclusive.LenNorm,RTE,78.08022409819432,82.05061173271984,RecognizingTextualEntailment,super_glue,,,,,,,,,,,,,,,,,37.5,27.0,13
23.24786324786325,13.333333333333334,0.5469822642922407,2.81656402588955,2.0,0.5190342661742842,0.0,0.0,,,,141.78571428571428,1.948603587491172,2.4285714285714284,56.41025641025642,0.8679604383983782,0.9035079029052512,0.4019463535031251,0.9035079029052512,1.5714285714285714,25.0,"{'_latest_artifact_path': 'wandb-client-artifact://byrr7shvmkjm6hqsypjz6wghyz7cb68obgdrzfux7qczyfh7745l8vesc7ydwscwgfd285xxknfew4qby3oh56255fuzu8yhxt0t0hkqa738kke0v61flwxwxweek4q5:latest/predictions.table.json', 'path': 'media/table/predictions_1_3d4f38dec97b531b74f9.table.json', 'size': 35952, '_type': 'table-file', 'ncols': 11, 'nrows': 56, 'sha256': '3d4f38dec97b531b74f912aa50492fefb8b83de81a9d0fc80c1d4f2e8f5c3a05', 'artifact_path': 'wandb-client-artifact://byrr7shvmkjm6hqsypjz6wghyz7cb68obgdrzfux7qczyfh7745l8vesc7ydwscwgfd285xxknfew4qby3oh56255fuzu8yhxt0t0hkqa738kke0v61flwxwxweek4q5:latest/predictions.table.json'}",55.06285832888571,,,False,True,validation,False,Yes | Maybe | No,4,CTBase,5d8e8d21-8059-4373-bbf2-a25cbe1e6960,cb,COMPLETION,False,28,bigscience/T0_3B,0,True,fill_in_the_blank_with_choices_before,prompts/general_fixed_choice.yaml,NumerSense,,3,,,GenFC,,False,['NLI'],,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,fill_in_the_blank_with_choices_before,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.numer_sense.fill_in_the_blank_with_choices_before.LenNorm,CB,,,CommitmentBank,super_glue,,,,,,,,,,,,,,,,,35.5,19.0,24
71.07438016528926,,1.0028570237466905,1.4460525443837962,,,,71.07438016528926,,,,91.93862815884476,1.4460525443837962,1.8375451263537903,45.026178010471206,,0.3688675747132073,1.0028570237466905,0.3688675747132073,1.1624548736462097,62.093862815884485,"{'nrows': 277, 'sha256': '178905318074cbb66d0f99ba4d852fbafe5ac442d71e3a6c1b27631d583305cc', 'artifact_path': 'wandb-client-artifact://gscntoza1p9y3wg68d9d66iu9lxm6aur0rfzzs7671q0i485xos138zq68ilykdrsrd308p1euhf8bxglrjaukg1czqlk1zwps6chnqgq1cxlmgyl3lk1wt43myvhtk5:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://gscntoza1p9y3wg68d9d66iu9lxm6aur0rfzzs7671q0i485xos138zq68ilykdrsrd308p1euhf8bxglrjaukg1czqlk1zwps6chnqgq1cxlmgyl3lk1wt43myvhtk5:latest/predictions.table.json', 'path': 'media/table/predictions_1_178905318074cbb66d0f.table.json', 'size': 122556, '_type': 'table-file', 'ncols': 9}",46.47129297794757,,,False,True,validation,False,Yes | No,4,CTBase,c4ed37ae-d7d7-4197-a725-ef2152fa3b1f,rte,ENTAILMENT,False,32,bigscience/T0_3B,0,True,can_we_infer,prompts/general_fixed_choice.yaml,ANLI,,2,,,GenFC,,False,NLI,,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,can we infer,,cross_task,two_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.anli.can_we_infer.LenNorm,RTE,81.7491149346149,84.27794625117642,RecognizingTextualEntailment,super_glue,,,,,,,,,,,,,,,,,43.0,39.0,12
10.983050847457628,16.94915254237288,0.8178401604096586,6.4095984654767175,2.0,0.9183348314766502,0.0,0.0,,,,152.78571428571428,4.685074916907719,2.9285714285714284,16.0,1.724523548568998,0.3711537444790451,0.8139354804221763,0.3711537444790451,1.0714285714285714,12.5,"{'sha256': '5c933d82eaa7a3624b67c4fec5524210b45b50af9203d425c9ebc7befe8034d7', 'artifact_path': 'wandb-client-artifact://ms20gg9xss1au1gvrs3j6r3x4adgbomijg09pwo83mqgpndnh7us5y62m36c3oi7q970eegzyub7rm83jli5cj4ah2l5ptfow4zpov1b5dhhuxc6t8ha1p87gyt4j1f3:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://ms20gg9xss1au1gvrs3j6r3x4adgbomijg09pwo83mqgpndnh7us5y62m36c3oi7q970eegzyub7rm83jli5cj4ah2l5ptfow4zpov1b5dhhuxc6t8ha1p87gyt4j1f3:latest/predictions.table.json', 'path': 'media/table/predictions_1_5c933d82eaa7a3624b67.table.json', 'size': 38002, '_type': 'table-file', 'ncols': 11, 'nrows': 56}",55.06285832888571,,,False,True,validation,False,Yes | Maybe | No,4,CTBase,4e9da2b8-2502-44a7-a7da-ae62f2d554c9,cb,COMPLETION,False,28,bigscience/T0_3B,0,True,fill_in_the_blank_with_instruction,prompts/general_fixed_choice.yaml,NumerSense,,3,,,GenFC,,False,['NLI'],,False,False,GeneralFixedChoice,False,False,False,,,prompts,,,True,fill_in_the_blank_with_instruction,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.numer_sense.fill_in_the_blank_with_instruction.LenNorm,CB,,,CommitmentBank,super_glue,,,,,,,,,,,,,,,,,74.0,75.5,39
65.47314578005115,,1.2377408722877712,2.3387470038789275,,,,65.47314578005115,,,,101.5956678700361,2.3387470038789275,1.9386281588447656,17.177914110429448,,0.2400111211349409,1.2377408722877712,0.2400111211349409,1.0613718411552346,51.26353790613718,"{'size': 132641, '_type': 'table-file', 'ncols': 9, 'nrows': 277, 'sha256': '874e8ee3a242f6e2bd4cb7b0af239101975f7c72d0834f49217a4adce71857d4', 'artifact_path': 'wandb-client-artifact://yuxmdj6p3x3vrzxzwa6l1izpm5oy4xyjxnd021ldvigcgmtadw7wv3d3yp3idv4irpxob9o4p7urc7ffvmsk8cz0avdoo0ouy9h3d637qu03kcdoa5sycb22mcbnz1yl:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://yuxmdj6p3x3vrzxzwa6l1izpm5oy4xyjxnd021ldvigcgmtadw7wv3d3yp3idv4irpxob9o4p7urc7ffvmsk8cz0avdoo0ouy9h3d637qu03kcdoa5sycb22mcbnz1yl:latest/predictions.table.json', 'path': 'media/table/predictions_1_874e8ee3a242f6e2bd4c.table.json'}",46.467282647943954,,,False,True,validation,False,Yes | No,4,CTBase,ed215962-8e51-45e7-b025-6e822f877098,rte,CLASSIFICATION,False,32,bigscience/T0_3B,0,True,sentence_to_concepts,prompts/general_fixed_choice.yaml,CommonGen,,2,,,GenFC,,False,NLI,,True,False,GeneralFixedChoice,False,False,False,,,prompts,,,True,sentence to concepts,,cross_task,two_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.common_gen.sentence_to_concepts.LenNorm,RTE,69.93812531298119,72.06943427794624,RecognizingTextualEntailment,super_glue,,,,,,,,,,,,,,,,,81.0,79.0,13
20.480668756530825,6.896551724137931,0.5206581646359267,1.8999436045331617,2.017857142857143,0.5056768413000535,0.132432115840994,0.0,,,,137.78571428571428,1.1932894204344069,1.8571428571428568,54.54545454545454,0.7066541840987546,0.989743318610787,0.3957621017014541,0.9831164006072004,2.125,28.57142857142857,"{'_latest_artifact_path': 'wandb-client-artifact://lz05fd1a0phaxe59k0pnilx86kmz40wnrm40ew07rmvdm7fnc3a8lyvzu7pk88diuc3rvt0wbgujxsarf8m9g3kmit6d9px0wyb01mq5f89r84c6y136enqjwkivlymw:latest/predictions.table.json', 'path': 'media/table/predictions_1_fe24a5cf40f171266ca7.table.json', 'size': 36087, '_type': 'table-file', 'ncols': 11, 'nrows': 56, 'sha256': 'fe24a5cf40f171266ca7f3dd01788855c6a2cd6cdb4fd954576d7de438a734cb', 'artifact_path': 'wandb-client-artifact://lz05fd1a0phaxe59k0pnilx86kmz40wnrm40ew07rmvdm7fnc3a8lyvzu7pk88diuc3rvt0wbgujxsarf8m9g3kmit6d9px0wyb01mq5f89r84c6y136enqjwkivlymw:latest/predictions.table.json'}",55.06285832888571,,,False,True,validation,False,Yes | Maybe | No,4,CTBase,1f959d92-dca8-4647-9840-69391dfbd000,cb,COMPLETION,False,28,bigscience/T0_3B,0,True,fill_in_the_blank_with_choices_after,prompts/general_fixed_choice.yaml,NumerSense,,3,,,GenFC,,False,['NLI'],,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,fill_in_the_blank_with_choices_after,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.numer_sense.fill_in_the_blank_with_choices_after.LenNorm,CB,,,CommitmentBank,super_glue,,,,,,,,,,,,,,,,,21.0,41.0,20
7.186440677966101,13.559322033898304,1.2060138923879582,4.98593944311142,2.0,0.923522028777158,0.0,0.0,,,,150.78571428571428,3.2434509311403548,2.9285714285714284,8.0,1.742488511971065,0.3711537444790451,1.0941442394521408,0.3711537444790451,1.0714285714285714,8.928571428571429,"{'sha256': 'bd91f8752aafef0e251a237227094ea6f830e9a87f1d47abbf7cbaa2b35377c8', 'artifact_path': 'wandb-client-artifact://uw0fuk2k9yfgn0mllppy4hfirzy05kl7ygbo2rsg3kajeyehhrf1scp0dou5hvusfmiray4unvuv07tmj4agwaxodeg7dufw7crtwemi4g4cnt0dsshjtt5j1o22gvyx:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://uw0fuk2k9yfgn0mllppy4hfirzy05kl7ygbo2rsg3kajeyehhrf1scp0dou5hvusfmiray4unvuv07tmj4agwaxodeg7dufw7crtwemi4g4cnt0dsshjtt5j1o22gvyx:latest/predictions.table.json', 'path': 'media/table/predictions_1_bd91f8752aafef0e251a.table.json', 'size': 36418, '_type': 'table-file', 'ncols': 11, 'nrows': 56}",55.06285832888571,,,False,True,validation,False,Yes | Maybe | No,4,CTBase,c97e7bbf-b7f0-4cee-ada5-431ce7d606cc,cb,CLASSIFICATION,False,28,bigscience/T0_3B,0,True,semantic_relations_nominials_without_options,prompts/general_fixed_choice.yaml,SemEval2010,,3,,,GenFC,,False,['NLI'],,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,semantic relations nominials without options,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.sem_eval_2010_task_8.semantic_relations_nominials_without_options.LenNorm,CB,,,CommitmentBank,super_glue,,,,,,,,,,,,,,,,,86.0,85.0,37
66.15384615384615,,1.4696755855767285,2.6775732419120706,,,,66.15384615384615,,,,97.5956678700361,2.6775732419120706,1.935018050541516,19.51219512195122,,0.2464940074384341,1.4696755855767285,0.2464940074384341,1.0649819494584838,52.34657039711191,"{'path': 'media/table/predictions_1_ae07dd6168be9e6db94d.table.json', 'size': 127854, '_type': 'table-file', 'ncols': 9, 'nrows': 277, 'sha256': 'ae07dd6168be9e6db94ded6e996783f6a9c696226ad8a69b647cd09fd1fab3bf', 'artifact_path': 'wandb-client-artifact://kf2qo8djvxtqr0d4ntr4kjq5wruq67xy5zhhs49eksq10o2a1i4ew3uh10f8droj2i9mxbwobu3icyykrzp96evxjae17xdjd7dtm9tqjz2zp2b9gte4056ae6d4qc4t:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://kf2qo8djvxtqr0d4ntr4kjq5wruq67xy5zhhs49eksq10o2a1i4ew3uh10f8droj2i9mxbwobu3icyykrzp96evxjae17xdjd7dtm9tqjz2zp2b9gte4056ae6d4qc4t:latest/predictions.table.json'}",46.467282647943954,,,False,True,validation,False,Yes | No,4,CTBase,b7012213-04c4-424d-85fb-39d63d8a0ca2,rte,CLASSIFICATION,False,32,bigscience/T0_3B,0,True,topics_from_the_sentence,prompts/general_fixed_choice.yaml,CommonGen,,2,,,GenFC,,False,NLI,,True,False,GeneralFixedChoice,False,False,False,,,prompts,,,True,topics from the sentence,,cross_task,two_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.common_gen.topics_from_the_sentence.LenNorm,RTE,74.24302531004409,75.69800271881209,RecognizingTextualEntailment,super_glue,,,,,,,,,,,,,,,,,80.0,76.0,8
13.82716049382716,14.814814814814811,0.6801294318906997,4.924754054950816,2.0,0.7133645929265138,0.0,0.0,,,,140.78571428571428,3.7642608157226016,2.75,26.666666666666668,1.1604932392282146,0.6614378277661477,0.6814130410186912,0.6614378277661477,1.25,14.285714285714285,"{'_type': 'table-file', 'ncols': 11, 'nrows': 56, 'sha256': 'e69b31065ec6c33fdea4c4f394e0553af3cbe472ceb5bd0d11c1c60b6cfa1e4b', 'artifact_path': 'wandb-client-artifact://114chtf3r2l7018efal0ekq3zmva51n5q509e9zyq70chk51ego2hm0dn39f1liyb74tv9h0zo2dtnswtvk8sr0f3uehuz83k2rreilpfah5ubge8db7jt4l203ydqkt:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://114chtf3r2l7018efal0ekq3zmva51n5q509e9zyq70chk51ego2hm0dn39f1liyb74tv9h0zo2dtnswtvk8sr0f3uehuz83k2rreilpfah5ubge8db7jt4l203ydqkt:latest/predictions.table.json', 'path': 'media/table/predictions_1_e69b31065ec6c33fdea4.table.json', 'size': 35046}",55.06285832888571,,,False,True,validation,False,Yes | Maybe | No,4,CTBase,5d7123a8-4ed4-42ce-bcfb-4af415962efc,cb,CLASSIFICATION,False,28,bigscience/T0_3B,0,True,semantically_related_nominials_with_options,prompts/general_fixed_choice.yaml,SemEval2010,,3,,,GenFC,,False,['NLI'],,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,semantically related nominials with options,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.sem_eval_2010_task_8.semantically_related_nominials_with_options.LenNorm,CB,,,CommitmentBank,super_glue,,,,,,,,,,,,,,,,,67.5,67.0,17
74.62686567164178,,0.7962739937744484,1.2154858463077338,,,,74.62686567164178,,,,111.5956678700361,1.2154858463077338,1.736462093862816,61.18721461187214,,0.4405515613024346,0.7962739937744484,0.4405515613024346,1.263537906137184,69.31407942238266,"{'_latest_artifact_path': 'wandb-client-artifact://94klyfhb3egt63aqkaphjm8ih6rosrc2hl1rtw6a5kpxkt4sleyic4bilmfrhl4w1oeet9zrrrhb47fy5zwqhmofdhk13008fscm4j5g600bzojddppesftz8dohsjve:latest/predictions.table.json', 'path': 'media/table/predictions_1_3f693dd9031f63dda0a3.table.json', 'size': 146819, '_type': 'table-file', 'ncols': 9, 'nrows': 277, 'sha256': '3f693dd9031f63dda0a303322d4a6508610c6690287495ca526737d870b3a962', 'artifact_path': 'wandb-client-artifact://94klyfhb3egt63aqkaphjm8ih6rosrc2hl1rtw6a5kpxkt4sleyic4bilmfrhl4w1oeet9zrrrhb47fy5zwqhmofdhk13008fscm4j5g600bzojddppesftz8dohsjve:latest/predictions.table.json'}",46.467282647943954,,,False,True,validation,False,Yes | No,4,CTBase,fc76beb7-c258-412f-a623-42fc8d2331b6,rte,COMPLETION,False,32,bigscience/T0_3B,0,True,fill_in_the_blank_with_instruction_and_choices,prompts/general_fixed_choice.yaml,NumerSense,,2,,,GenFC,,False,NLI,,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,fill_in_the_blank_with_instruction_and_choices,,cross_task,two_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.numer_sense.fill_in_the_blank_with_instruction_and_choices.LenNorm,RTE,77.61159041207179,80.86374568650005,RecognizingTextualEntailment,super_glue,,,,,,,,,,,,,,,,,16.5,12.0,20
16.04938271604938,14.814814814814811,0.8058021661881007,3.734692445823125,2.0,0.7187131018835395,0.0,0.0,,,,162.78571428571428,2.593540838786534,2.75,33.33333333333333,1.1411516070365906,0.6614378277661477,0.7629556367501202,0.6614378277661477,1.25,16.071428571428573,"{'_type': 'table-file', 'ncols': 11, 'nrows': 56, 'sha256': '8f6b30c6c7ca97f9fa399d5d2d1b38a87768fe8ca98ef9c261c88943a8c4112f', 'artifact_path': 'wandb-client-artifact://lnd7rcxlswkroe0j89ia1w88h2bgmtr4sj5f5ffi0l5z6rr1bxnw54kg5dv6ntyhdybnspwc30a7jok2t3t4lubf4lg7cdjll58y247kii49pzf4uqinxe466mkin8sv:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://lnd7rcxlswkroe0j89ia1w88h2bgmtr4sj5f5ffi0l5z6rr1bxnw54kg5dv6ntyhdybnspwc30a7jok2t3t4lubf4lg7cdjll58y247kii49pzf4uqinxe466mkin8sv:latest/predictions.table.json', 'path': 'media/table/predictions_1_8f6b30c6c7ca97f9fa39.table.json', 'size': 39250}",55.06285832888571,,,False,True,validation,False,Yes | Maybe | No,4,CTBase,202246b0-3f82-42b9-bc8d-d36997b5f2cb,cb,CLASSIFICATION,False,28,bigscience/T0_3B,0,True,semantic_relations_with_options,prompts/general_fixed_choice.yaml,SemEval2010,,3,,,GenFC,,False,['NLI'],,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,semantic relations with options,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.sem_eval_2010_task_8.semantic_relations_with_options.LenNorm,CB,,,CommitmentBank,super_glue,,,,,,,,,,,,,,,,,62.5,61.0,40
21.3903743315508,15.68627450980392,0.8282167604870139,2.5335962431771413,1.9285714285714288,0.6475050808462663,0.2575393768188563,0.0,,,,122.78571428571428,1.40447735786438,2.642857142857143,48.48484848484848,1.1291188853127616,0.7659860924831149,0.7278772546174173,0.7759128922285868,1.4285714285714286,21.428571428571427,"{'_latest_artifact_path': 'wandb-client-artifact://t8es0jqxavml68qscdnu573ahbc4vsutt3gvcksmgx3f1ppq2daavlgkmg4ebje6ue516yeqt7qlrfiy6xjhrq3e6u52w91tsipup7a0ve1nqbv12q2mxww943h55axb:latest/predictions.table.json', 'path': 'media/table/predictions_1_6ed2d396d7cb246e9e3a.table.json', 'size': 31505, '_type': 'table-file', 'ncols': 11, 'nrows': 56, 'sha256': '6ed2d396d7cb246e9e3a603830090c708b29cf85599d062727592192b2f6ce12', 'artifact_path': 'wandb-client-artifact://t8es0jqxavml68qscdnu573ahbc4vsutt3gvcksmgx3f1ppq2daavlgkmg4ebje6ue516yeqt7qlrfiy6xjhrq3e6u52w91tsipup7a0ve1nqbv12q2mxww943h55axb:latest/predictions.table.json'}",55.06285832888572,,,False,True,validation,False,Yes | Maybe | No,4,CTBase,af4d550e-54b8-471e-97af-2b2c50a1382e,cb,SUMMARIZATION,False,28,bigscience/T0_3B,0,True,relatedwork_abstract,prompts/general_fixed_choice.yaml,Multi-XSci,,3,,,GenFC,,False,['NLI'],,False,False,GeneralFixedChoice,False,False,False,,,prompts,,,True,relatedwork_abstract,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.multi_x_science_sum.relatedwork_abstract.LenNorm,CB,,,CommitmentBank,super_glue,,,,,,,,,,,,,,,,,50.0,30.0,9
68.09651474530831,,1.1009255426676463,1.852210574847266,,,,68.09651474530831,,,,100.5956678700361,1.852210574847266,1.8736462093862816,34.254143646408835,,0.3322476639666004,1.1009255426676463,0.3322476639666004,1.1263537906137184,57.03971119133574,"{'artifact_path': 'wandb-client-artifact://c8uegj5ftd1au3mw1s7ob0z2ebtfabaha8oys4417r3ro1zcpyxwddcb9vush2xc9buzoqbpxq5jlo2smcesvg4vbx5jw7r9dgbi1fptf4xmb5ueukz6bmt3k7ojzzh9:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://c8uegj5ftd1au3mw1s7ob0z2ebtfabaha8oys4417r3ro1zcpyxwddcb9vush2xc9buzoqbpxq5jlo2smcesvg4vbx5jw7r9dgbi1fptf4xmb5ueukz6bmt3k7ojzzh9:latest/predictions.table.json', 'path': 'media/table/predictions_1_7077edacf57d819e02b6.table.json', 'size': 129205, '_type': 'table-file', 'ncols': 9, 'nrows': 277, 'sha256': '7077edacf57d819e02b6aed0f82ed69242a86f4d2f9495a939bebdb799d90284'}",46.467282647943954,,,False,True,validation,False,Yes | No,4,CTBase,cacee36c-e2b7-458e-9d51-6fcfd83842b4,rte,COMPLETION,False,32,bigscience/T0_3B,0,True,fill_in_the_blank_before_sentence,prompts/general_fixed_choice.yaml,NumerSense,,2,,,GenFC,,False,NLI,,False,False,GeneralFixedChoice,False,False,False,,,prompts,,,True,fill_in_the_blank_before_sentence,,cross_task,two_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.numer_sense.fill_in_the_blank_before_sentence.LenNorm,RTE,73.28414345320779,76.90055421938722,RecognizingTextualEntailment,super_glue,,,,,,,,,,,,,,,,,66.0,62.0,11
19.71153846153846,15.384615384615383,0.8993315367982868,2.9479965354715074,1.9642857142857144,0.7129855760001721,0.1855768722395225,0.0,,,,130.78571428571428,1.7851303645542689,2.6785714285714284,43.75000000000001,1.1628661709172383,0.7345344214715405,0.8649834861272409,0.7423074889580902,1.3571428571428572,19.642857142857142,"{'nrows': 56, 'sha256': '83e3742291852cd31095e0b6a9d2383be2607b41d7968951f8e53f816d30c6b8', 'artifact_path': 'wandb-client-artifact://5vfnhk35hi1ymmif2bo1ctunwuvan6scilg30jvrqsq40prbq9ia4jbznuplx6lddvthakr51958mz8d3hs2s9zge04p5tsaq2ymd9pvfq1zyfo257gbgmmk6vt1n77t:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://5vfnhk35hi1ymmif2bo1ctunwuvan6scilg30jvrqsq40prbq9ia4jbznuplx6lddvthakr51958mz8d3hs2s9zge04p5tsaq2ymd9pvfq1zyfo257gbgmmk6vt1n77t:latest/predictions.table.json', 'path': 'media/table/predictions_1_83e3742291852cd31095.table.json', 'size': 33817, '_type': 'table-file', 'ncols': 11}",55.06285832888571,,,False,True,validation,False,Yes | Maybe | No,4,CTBase,3bd082cb-4e28-4eb7-9fa2-dd03f1f86219,cb,SUMMARIZATION,False,28,bigscience/T0_3B,0,True,abstract_relatedwork,prompts/general_fixed_choice.yaml,Multi-XSci,,3,,,GenFC,,False,['NLI'],,False,False,GeneralFixedChoice,False,False,False,,,prompts,,,True,abstract_relatedwork,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.multi_x_science_sum.abstract_relatedwork.LenNorm,CB,,,CommitmentBank,super_glue,,,,,,,,,,,,,,,,,54.5,50.0,17
72.30320699708454,,0.9268512142741028,1.4076230876174645,,,,72.30320699708454,,,,115.5956678700361,1.4076230876174645,1.7653429602888089,54.976303317535546,,0.4237842769914567,0.9268512142741028,0.4237842769914567,1.2346570397111911,65.70397111913357,"{'nrows': 277, 'sha256': '71d7816643033e31c90502dfa91acba74f82b3030596cad3b13f602bb69d458a', 'artifact_path': 'wandb-client-artifact://cy5i0q3f6mqy9719thxjkf28p9ih05tfzhnur55xu00cw99rdzqcik6ww0rgcgdp6hmy4jvhvnk1jitx0jyd29gqvksmh7yyhqdt6mvsppd594rexl4sz3kx9x3gxxdq:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://cy5i0q3f6mqy9719thxjkf28p9ih05tfzhnur55xu00cw99rdzqcik6ww0rgcgdp6hmy4jvhvnk1jitx0jyd29gqvksmh7yyhqdt6mvsppd594rexl4sz3kx9x3gxxdq:latest/predictions.table.json', 'path': 'media/table/predictions_1_71d7816643033e31c905.table.json', 'size': 149708, '_type': 'table-file', 'ncols': 9}",46.467282647943954,,,False,True,validation,False,Yes | No,4,CTBase,5d8e8d21-8059-4373-bbf2-a25cbe1e6960,rte,COMPLETION,False,32,bigscience/T0_3B,0,True,fill_in_the_blank_with_choices_before,prompts/general_fixed_choice.yaml,NumerSense,,2,,,GenFC,,False,NLI,,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,fill_in_the_blank_with_choices_before,,cross_task,two_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.numer_sense.fill_in_the_blank_with_choices_before.LenNorm,RTE,76.04614278380825,80.13175781658475,RecognizingTextualEntailment,super_glue,,,,,,,,,,,,,,,,,34.5,32.0,24
15.784134712923514,15.09433962264151,0.8776530894264545,3.246410948889596,1.9821428571428568,0.6867611474637288,0.132432115840994,0.0,,,,123.78571428571428,2.126050821372441,2.7142857142857144,32.25806451612903,1.1203601275171553,0.6998542122237652,0.79799715730371,0.7050745365142727,1.3035714285714286,16.071428571428573,"{'_latest_artifact_path': 'wandb-client-artifact://25yole3mwxrwaeoimuem5u0noobb1nqlgkofd3tfewzilbppudgdh77kwopv5c81igjinfygkuwjd6ho4oulhj3pen5k0sfzngt9uq1qnplz4sdebtql2rt10h2dulwt:latest/predictions.table.json', 'path': 'media/table/predictions_1_7bf2e80151ad9db7d035.table.json', 'size': 32064, '_type': 'table-file', 'ncols': 11, 'nrows': 56, 'sha256': '7bf2e80151ad9db7d0351e9655352d2121919eba9ff478cc6b0ae2bc390efb08', 'artifact_path': 'wandb-client-artifact://25yole3mwxrwaeoimuem5u0noobb1nqlgkofd3tfewzilbppudgdh77kwopv5c81igjinfygkuwjd6ho4oulhj3pen5k0sfzngt9uq1qnplz4sdebtql2rt10h2dulwt:latest/predictions.table.json'}",55.06285832888572,,,False,True,validation,False,Yes | Maybe | No,4,CTBase,2bca0197-e3d4-4870-bd95-178411e52e09,cb,SUMMARIZATION,False,28,bigscience/T0_3B,0,True,ref_relatedwork,prompts/general_fixed_choice.yaml,Multi-XSci,,3,,,GenFC,,False,['NLI'],,False,False,GeneralFixedChoice,False,False,False,,,prompts,,,True,ref_relatedwork,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.multi_x_science_sum.ref_relatedwork.LenNorm,CB,,,CommitmentBank,super_glue,,,,,,,,,,,,,,,,,62.5,63.0,10
21.7948717948718,15.384615384615383,0.8261492093561862,2.592037716082164,1.9642857142857144,0.6386341802966571,0.1855768722395225,0.0,,,,123.78571428571428,1.4092988329274314,2.6785714285714284,50.0,1.1827388831547327,0.7345344214715405,0.7592173353484926,0.7423074889580903,1.3571428571428572,21.428571428571427,"{'ncols': 11, 'nrows': 56, 'sha256': '47e8631004e7082c75c52c050843fe06a1d9b8d1610e42fab267125c282b28c0', 'artifact_path': 'wandb-client-artifact://qtithho56qq95sbiauefpacil3nbusry3e06go1wpcncnslnb2ftzwkg65vpg27m610t1s34btqfnnt0ceh5blmwxt9svdwap5wkbs5hwfjwrxzkv78fmy11siciqoxw:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://qtithho56qq95sbiauefpacil3nbusry3e06go1wpcncnslnb2ftzwkg65vpg27m610t1s34btqfnnt0ceh5blmwxt9svdwap5wkbs5hwfjwrxzkv78fmy11siciqoxw:latest/predictions.table.json', 'path': 'media/table/predictions_1_47e8631004e7082c75c5.table.json', 'size': 31422, '_type': 'table-file'}",55.06285832888572,,,False,True,validation,False,Yes | Maybe | No,4,CTBase,774b4349-0524-4a34-881b-b344f8f5c34e,cb,COMPLETION,False,28,bigscience/T0_3B,0,True,what_comes_next,prompts/general_fixed_choice.yaml,LAMBADA,,3,,,GenFC,,False,['NLI'],,False,False,GeneralFixedChoice,False,False,False,,,prompts,,,True,what comes next,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.craffel_openai_lambada.what_comes_next.LenNorm,CB,,,CommitmentBank,super_glue,,,,,,,,,,,,,,,,,50.0,26.0,10
65.32663316582915,,1.267043167516392,2.444607755337381,,,,65.32663316582915,,,,128.5956678700361,2.444607755337381,1.963898916967509,11.538461538461538,,0.1865416705092247,1.267043167516392,0.1865416705092247,1.036101083032491,50.18050541516246,"{'_type': 'table-file', 'ncols': 9, 'nrows': 277, 'sha256': 'fe154aa85ab7ea2008be8edd49878f5b2ee51e8184e77b730364e45c0201cc79', 'artifact_path': 'wandb-client-artifact://ktvkcyneam116lhzy0nsrd84ywg6nl5hmlgq492ago1y2q6dnd9ybj2vxr06z0weeowar8e8ji812lo59dcqt7i0p775o34lzgm4hj1dwifn0ueipy344lt1ddjm16zo:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://ktvkcyneam116lhzy0nsrd84ywg6nl5hmlgq492ago1y2q6dnd9ybj2vxr06z0weeowar8e8ji812lo59dcqt7i0p775o34lzgm4hj1dwifn0ueipy344lt1ddjm16zo:latest/predictions.table.json', 'path': 'media/table/predictions_1_fe154aa85ab7ea2008be.table.json', 'size': 161624}",46.467282647943954,,,False,True,validation,False,Yes | No,4,CTBase,4e9da2b8-2502-44a7-a7da-ae62f2d554c9,rte,COMPLETION,False,32,bigscience/T0_3B,0,True,fill_in_the_blank_with_instruction,prompts/general_fixed_choice.yaml,NumerSense,,2,,,GenFC,,False,NLI,,False,False,GeneralFixedChoice,False,False,False,,,prompts,,,True,fill_in_the_blank_with_instruction,,cross_task,two_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.numer_sense.fill_in_the_blank_with_instruction.LenNorm,RTE,79.52204428627493,81.52253476942384,RecognizingTextualEntailment,super_glue,,,,,,,,,,,,,,,,,85.0,81.0,39
17.934672347332114,15.09433962264151,0.9734944548921636,3.2771601251193454,1.9642857142857144,0.7776621890657124,0.1855768722395225,0.0,,,,124.78571428571428,2.0525937506130765,2.7142857142857144,38.70967741935483,1.2245663745062692,0.6998542122237653,0.934622446976844,0.7098073897982783,1.3214285714285714,17.857142857142858,"{'size': 30413, '_type': 'table-file', 'ncols': 11, 'nrows': 56, 'sha256': 'a50d9cd4c2f32d4b3e58eb114c61ad0b31ba23684ef7b84a38b7e3d94b9e8d8f', 'artifact_path': 'wandb-client-artifact://nm7uli7zny3yn07cig39pnf2lrrfojc1kjggnpj93zpbczk78mcv2kyf552wquzdb85fmrxgyd6e4iggyelhto87166myfsdu964ixu741hze0u88f5mddnwba4mc7d9:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://nm7uli7zny3yn07cig39pnf2lrrfojc1kjggnpj93zpbczk78mcv2kyf552wquzdb85fmrxgyd6e4iggyelhto87166myfsdu964ixu741hze0u88f5mddnwba4mc7d9:latest/predictions.table.json', 'path': 'media/table/predictions_1_a50d9cd4c2f32d4b3e58.table.json'}",55.06285832888572,,,False,True,validation,False,Yes | Maybe | No,4,CTBase,4f08e9d4-bcff-4bc0-9902-87c497625d17,cb,COMPLETION,False,28,bigscience/T0_3B,0,True,GPT_3_style,prompts/general_fixed_choice.yaml,LAMBADA,,3,,,GenFC,,False,['NLI'],,False,False,GeneralFixedChoice,False,False,False,,,prompts,,,True,GPT-3 style,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.craffel_openai_lambada.GPT_3_style.LenNorm,CB,,,CommitmentBank,super_glue,,,,,,,,,,,,,,,,,59.0,58.0,11
75.07692307692308,,0.75741182223638,1.1004054389275368,,,,75.07692307692308,,,,111.5956678700361,1.1004054389275368,1.7003610108303249,64.62882096069869,,0.4580998421076462,0.75741182223638,0.4580998421076462,1.2996389891696751,70.7581227436823,"{'sha256': 'd6020fb717093e1ee1170ab096a4d3429afa46b4c22e09d2cf3389239cd4c8c7', 'artifact_path': 'wandb-client-artifact://5oxrc6pi9m34btzpyzfue5mdblvr8pgzrh6wv07dxwiohvrx6t8ly79f0dujaket36kduvng9qikqhtoi9d2402y7anjv8rr1v0dg482mhp0newnqp8p5mlhxj6zdbz4:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://5oxrc6pi9m34btzpyzfue5mdblvr8pgzrh6wv07dxwiohvrx6t8ly79f0dujaket36kduvng9qikqhtoi9d2402y7anjv8rr1v0dg482mhp0newnqp8p5mlhxj6zdbz4:latest/predictions.table.json', 'path': 'media/table/predictions_1_d6020fb717093e1ee117.table.json', 'size': 150229, '_type': 'table-file', 'ncols': 9, 'nrows': 277}",46.467282647943954,,,False,True,validation,False,Yes | No,4,CTBase,1f959d92-dca8-4647-9840-69391dfbd000,rte,COMPLETION,False,32,bigscience/T0_3B,0,True,fill_in_the_blank_with_choices_after,prompts/general_fixed_choice.yaml,NumerSense,,2,,,GenFC,,False,NLI,,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,fill_in_the_blank_with_choices_after,,cross_task,two_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.numer_sense.fill_in_the_blank_with_choices_after.LenNorm,RTE,78.01764580289235,81.38136568022587,RecognizingTextualEntailment,super_glue,,,,,,,,,,,,,,,,,14.0,9.0,20
19.853709508881924,18.181818181818183,1.0088342314731331,3.514237437929426,2.0,0.8046218233139478,0.0,0.0,,,,122.78571428571428,2.081019937992096,2.7857142857142856,41.37931034482759,1.43321749993733,0.6185895741317419,0.9493011633078028,0.6185895741317419,1.2142857142857142,19.642857142857142,"{'ncols': 11, 'nrows': 56, 'sha256': 'e9ecd10bb8baa5ca7a38ef7f8904bdbd83c73fceb58b0d5702cab21941a0da97', 'artifact_path': 'wandb-client-artifact://s89fd9fdy2mctlpt3dyl016ju5zvcrsycok2hogjtjzyzc0im69cnehpjilfpek9a9pjig957bcon59nxvadipm3xhmzb7gz756rnb205yc12lstxjp47o0flinv26fy:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://s89fd9fdy2mctlpt3dyl016ju5zvcrsycok2hogjtjzyzc0im69cnehpjilfpek9a9pjig957bcon59nxvadipm3xhmzb7gz756rnb205yc12lstxjp47o0flinv26fy:latest/predictions.table.json', 'path': 'media/table/predictions_1_e9ecd10bb8baa5ca7a38.table.json', 'size': 30960, '_type': 'table-file'}",55.06285832888572,,,False,True,validation,False,Yes | Maybe | No,4,CTBase,1ee5ddef-fffb-4b73-a2f7-f600ffac63cb,cb,COMPLETION,False,28,bigscience/T0_3B,0,True,ellipses,prompts/general_fixed_choice.yaml,LAMBADA,,3,,,GenFC,,False,['NLI'],,False,False,GeneralFixedChoice,False,False,False,,,prompts,,,True,ellipses,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.craffel_openai_lambada.ellipses.LenNorm,CB,,,CommitmentBank,super_glue,,,,,,,,,,,,,,,,,54.5,48.0,11
8.333333333333332,16.666666666666668,0.7968864399700583,2.5698629021644592,1.9285714285714288,0.6636992243910026,0.2575393768188563,0.0,,,,134.78571428571428,1.2613904476165771,2.9642857142857144,8.333333333333332,1.308472454547882,0.2648642316819879,0.6753656414498587,0.3624604130390079,1.1071428571428572,10.714285714285714,"{'_latest_artifact_path': 'wandb-client-artifact://2hgwq95nw4obnnpbd1w0qbzzft629m88s21sr7udmf9u7zhfi44tzzu1l9l543924upfb8i0862fmvoikgm6dzi0snit03t3i0dacg5jdqvzxrfhlcw9ea8v0i10yvt3:latest/predictions.table.json', 'path': 'media/table/predictions_1_4a32082ac819efe21c42.table.json', 'size': 34401, '_type': 'table-file', 'ncols': 11, 'nrows': 56, 'sha256': '4a32082ac819efe21c42c30b65e0d28c28b091a13a8febc626e327e54a62319b', 'artifact_path': 'wandb-client-artifact://2hgwq95nw4obnnpbd1w0qbzzft629m88s21sr7udmf9u7zhfi44tzzu1l9l543924upfb8i0862fmvoikgm6dzi0snit03t3i0dacg5jdqvzxrfhlcw9ea8v0i10yvt3:latest/predictions.table.json'}",55.06285832888571,,,False,True,validation,False,Yes | Maybe | No,4,CTBase,9a3f617f-628f-4fa5-9b74-47d0b166a487,cb,SUMMARIZATION,False,28,bigscience/T0_3B,0,True,read_below_DOC_write_abstract,prompts/general_fixed_choice.yaml,XSum,,3,,,GenFC,,False,['NLI'],,True,False,GeneralFixedChoice,False,False,False,,,prompts,,,True,read_below_DOC_write_abstract,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.xsum.read_below_DOC_write_abstract.LenNorm,CB,,,CommitmentBank,super_glue,,,,,,,,,,,,,,,,,80.5,82.5,21
66.83804627249357,,1.238852007765488,2.238558693482988,,,,66.83804627249357,,,,126.5956678700361,2.238558693482988,1.931407942238267,21.81818181818182,,0.2527591489417227,1.238852007765488,0.2527591489417227,1.068592057761733,53.42960288808665,"{'_latest_artifact_path': 'wandb-client-artifact://16f3hqrfvx3sobsrep678h65zrt2eme0a6axupd34im6z7q8d597ysxori8i0j9aqytrmx3ofteew52sv95tpevcfxnavmb01fvvn4fyteg1q5eho2o8pij1fk1pnsxj:latest/predictions.table.json', 'path': 'media/table/predictions_1_cb9e4a13f6bcfb5a2c00.table.json', 'size': 153791, '_type': 'table-file', 'ncols': 9, 'nrows': 277, 'sha256': 'cb9e4a13f6bcfb5a2c00145cdc1a23a026cafab0cc5f064f026c1022e04bea49', 'artifact_path': 'wandb-client-artifact://16f3hqrfvx3sobsrep678h65zrt2eme0a6axupd34im6z7q8d597ysxori8i0j9aqytrmx3ofteew52sv95tpevcfxnavmb01fvvn4fyteg1q5eho2o8pij1fk1pnsxj:latest/predictions.table.json'}",46.467282647943954,,,False,True,validation,False,Yes | No,4,CTBase,c97e7bbf-b7f0-4cee-ada5-431ce7d606cc,rte,CLASSIFICATION,False,32,bigscience/T0_3B,0,True,semantic_relations_nominials_without_options,prompts/general_fixed_choice.yaml,SemEval2010,,2,,,GenFC,,False,NLI,,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,semantic relations nominials without options,,cross_task,two_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.sem_eval_2010_task_8.semantic_relations_nominials_without_options.LenNorm,RTE,71.12432640005633,73.6745791069748,RecognizingTextualEntailment,super_glue,,,,,,,,,,,,,,,,,76.5,73.0,37
8.333333333333332,16.666666666666668,0.7400943836326926,2.128241015332086,1.75,0.6281396914537845,0.4330127018922193,0.0,,,,137.78571428571428,0.7771874112742287,2.9642857142857144,8.333333333333332,1.351053604057857,0.2648642316819879,0.5421932210777776,0.4896896143143604,1.2857142857142858,10.714285714285714,"{'nrows': 56, 'sha256': '400eae938eff534a309831e70d5312372e44d51ee88d20d944701d1a5cad707a', 'artifact_path': 'wandb-client-artifact://17nfe59qtcoelgdpsvj3cck8686pqsb75fwgpw3k0mnua8ym74vci89nb3fqzqqfq1wd5gv3z4reyr88v1jh2f3kjomincayhujzxllhobw9sz9p62kns0fwd81eph0w:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://17nfe59qtcoelgdpsvj3cck8686pqsb75fwgpw3k0mnua8ym74vci89nb3fqzqqfq1wd5gv3z4reyr88v1jh2f3kjomincayhujzxllhobw9sz9p62kns0fwd81eph0w:latest/predictions.table.json', 'path': 'media/table/predictions_1_400eae938eff534a3098.table.json', 'size': 34028, '_type': 'table-file', 'ncols': 11}",55.06285832888571,,,False,True,validation,False,Yes | Maybe | No,4,CTBase,4cfe4126-b9f5-44eb-8a98-973987c5f32e,cb,SUMMARIZATION,False,28,bigscience/T0_3B,0,True,college_roommate_asked_DOC_so_I_recap,prompts/general_fixed_choice.yaml,XSum,,3,,,GenFC,,False,['NLI'],,True,False,GeneralFixedChoice,False,False,False,,,prompts,,,True,college_roommate_asked_DOC_so_I_recap,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.xsum.college_roommate_asked_DOC_so_I_recap.LenNorm,CB,,,CommitmentBank,super_glue,,,,,,,,,,,,,,,,,80.5,82.5,24
15.724496426250814,17.543859649122805,0.9113212373639152,3.1037786262375966,1.9642857142857144,0.7489541771791224,0.1855768722395225,0.0,,,,126.78571428571428,1.7786476824964796,2.857142857142857,29.629629629629637,1.3251309437411172,0.5150787536377127,0.8894741780291101,0.5380899704756915,1.1785714285714286,16.071428571428573,"{'_type': 'table-file', 'ncols': 11, 'nrows': 56, 'sha256': '42a458ca630c63796d2ea7ac19aa39b936c5599a36f4cb719b8055bb1344c2c1', 'artifact_path': 'wandb-client-artifact://pocjr625j5n6u265hxp20aa7zyoje3lwmhux84kl8y99ymz3t4bm1z09v8m9z3ohaj28vp1vqayglhuq1804a0enfbenet7v6b705f73ty0caph8th16sz5aqjkao9pp:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://pocjr625j5n6u265hxp20aa7zyoje3lwmhux84kl8y99ymz3t4bm1z09v8m9z3ohaj28vp1vqayglhuq1804a0enfbenet7v6b705f73ty0caph8th16sz5aqjkao9pp:latest/predictions.table.json', 'path': 'media/table/predictions_1_42a458ca630c63796d2e.table.json', 'size': 31492}",55.06285832888572,,,False,True,validation,False,Yes | Maybe | No,4,CTBase,3d388a1e-3361-407b-baa7-61397cc58382,cb,SUMMARIZATION,False,28,bigscience/T0_3B,0,True,DOC_how_would_you_rephrase_few_words,prompts/general_fixed_choice.yaml,XSum,,3,,,GenFC,,False,['NLI'],,True,False,GeneralFixedChoice,False,False,False,,,prompts,,,True,DOC_how_would_you_rephrase_few_words,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.xsum.DOC_how_would_you_rephrase_few_words.LenNorm,CB,,,CommitmentBank,super_glue,,,,,,,,,,,,,,,,,62.5,64.0,13
68.43501326259947,,1.0396201250464898,1.6455668406796369,,,,68.43501326259947,,,,112.5956678700361,1.6455668406796369,1.888086642599278,32.7683615819209,,0.3152598259151017,1.0396201250464898,0.3152598259151017,1.111913357400722,57.03971119133574,"{'ncols': 9, 'nrows': 277, 'sha256': '2c87f67ec05660656b6673f1908974e957f1e735fe6461f2f770837c6cdc7a2b', 'artifact_path': 'wandb-client-artifact://120bw302fgwcxq7rvzafmidf7g6i848jt9aupmfwcvw0jaazf3gog5iw1789izt8zzxyel64b5gd4r56rwuqhuwxoof08bem2rmg25ocozk9xinha6qmpsf113x8awul:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://120bw302fgwcxq7rvzafmidf7g6i848jt9aupmfwcvw0jaazf3gog5iw1789izt8zzxyel64b5gd4r56rwuqhuwxoof08bem2rmg25ocozk9xinha6qmpsf113x8awul:latest/predictions.table.json', 'path': 'media/table/predictions_1_2c87f67ec05660656b66.table.json', 'size': 144058, '_type': 'table-file'}",46.467282647943954,,,False,True,validation,False,Yes | No,4,CTBase,5d7123a8-4ed4-42ce-bcfb-4af415962efc,rte,CLASSIFICATION,False,32,bigscience/T0_3B,0,True,semantically_related_nominials_with_options,prompts/general_fixed_choice.yaml,SemEval2010,,2,,,GenFC,,False,NLI,,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,semantically related nominials with options,,cross_task,two_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.sem_eval_2010_task_8.semantically_related_nominials_with_options.LenNorm,RTE,77.12578264129031,79.1958590400502,RecognizingTextualEntailment,super_glue,,,,,,,,,,,,,,,,,66.0,59.0,17
8.333333333333332,16.666666666666668,0.9022397464908614,3.114033907651901,1.9642857142857144,0.7809075397812603,0.1855768722395225,0.0,,,,126.78571428571428,1.6786386285509385,2.9642857142857144,8.333333333333332,1.435395279100963,0.2648642316819879,0.8169362894169554,0.3194382824999699,1.0714285714285714,10.714285714285714,"{'artifact_path': 'wandb-client-artifact://19wxa6hb4ailnm9zqu2um8sylgagqytngbfd4be6ldn1tfc5tqbgdo742voikw9wd8hq57aijqyhdxjhp39lxqh60vxr8kt3dvs9hkbfecl0g614281f6cbl2zseek22:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://19wxa6hb4ailnm9zqu2um8sylgagqytngbfd4be6ldn1tfc5tqbgdo742voikw9wd8hq57aijqyhdxjhp39lxqh60vxr8kt3dvs9hkbfecl0g614281f6cbl2zseek22:latest/predictions.table.json', 'path': 'media/table/predictions_1_4ece4d982e34dc189348.table.json', 'size': 31265, '_type': 'table-file', 'ncols': 11, 'nrows': 56, 'sha256': '4ece4d982e34dc18934821fcc372f8fe6e0d72aeae9391032049ebe7b0650a41'}",55.06285832888572,,,False,True,validation,False,Yes | Maybe | No,4,CTBase,13c02904-e4e2-4b4f-b115-44b437d22041,cb,SUMMARIZATION,False,28,bigscience/T0_3B,0,True,DOC_write_summary_of_above,prompts/general_fixed_choice.yaml,XSum,,3,,,GenFC,,False,['NLI'],,True,False,GeneralFixedChoice,False,False,False,,,prompts,,,True,DOC_write_summary_of_above,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.xsum.DOC_write_summary_of_above.LenNorm,CB,,,CommitmentBank,super_glue,,,,,,,,,,,,,,,,,80.5,82.5,13
20.08520998174072,15.09433962264151,0.5753039728391182,3.6079810176576887,2.0,0.7026831283022156,0.0,0.0,,,,133.78571428571428,2.354257528270994,2.7142857142857144,45.16129032258065,1.2537234893866949,0.6998542122237652,0.6048098084415794,0.6998542122237652,1.2857142857142858,19.642857142857142,"{'artifact_path': 'wandb-client-artifact://5auq8iwp1oki7ky62dlbzzv1abegu0myyf8zk1jl80drjhmdhmsz6k6po28rcm0yuc3v4lh23tei6vlaa8loh50dr9jxqbjen61xkjm6ctbyddsgvtav3d8h7wubq22s:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://5auq8iwp1oki7ky62dlbzzv1abegu0myyf8zk1jl80drjhmdhmsz6k6po28rcm0yuc3v4lh23tei6vlaa8loh50dr9jxqbjen61xkjm6ctbyddsgvtav3d8h7wubq22s:latest/predictions.table.json', 'path': 'media/table/predictions_1_22b5521029f04a440423.table.json', 'size': 33320, '_type': 'table-file', 'ncols': 11, 'nrows': 56, 'sha256': '22b5521029f04a4404238bf266c6dae415b30f19c4f5d1728ea6cf9475380ac5'}",55.06285832888571,,,False,True,validation,False,Yes | Maybe | No,4,CTBase,5fa16d31-b513-480d-bd1b-1fa8c182fb76,cb,SENTIMENT,False,28,bigscience/T0_3B,0,True,bullish_neutral_bearish,prompts/general_fixed_choice.yaml,FinNews,,3,,,GenFC,,False,['NLI'],,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,bullish_neutral_bearish,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.financial_phrasebank_sentences_allagree.bullish_neutral_bearish.LenNorm,CB,,,CommitmentBank,super_glue,,,,,,,,,,,,,,,,,54.5,45.0,9
67.70833333333334,,1.0600893125046185,1.8519818378269457,,,,67.70833333333334,,,,134.5956678700361,1.8519818378269457,1.913357400722021,27.058823529411764,,0.281310609946255,1.0600893125046185,0.281310609946255,1.0866425992779782,55.23465703971119,"{'nrows': 277, 'sha256': '3ffb78b7f3a31683ced92ec5bfe2cf42f26c7bcf718de53b6a1329d5192fb21f', 'artifact_path': 'wandb-client-artifact://phphdjz98ksixhw6gjixfjorgnfu8zb8c2a3ndjdm92hze32splaul2egi5m3simfq8t362piqh5mec39d3mfhyos00qfl6247pcdjkxo9z31cggml0hjakhx535htna:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://phphdjz98ksixhw6gjixfjorgnfu8zb8c2a3ndjdm92hze32splaul2egi5m3simfq8t362piqh5mec39d3mfhyos00qfl6247pcdjkxo9z31cggml0hjakhx535htna:latest/predictions.table.json', 'path': 'media/table/predictions_1_3ffb78b7f3a31683ced9.table.json', 'size': 164974, '_type': 'table-file', 'ncols': 9}",46.467282647943954,,,False,True,validation,False,Yes | No,4,CTBase,202246b0-3f82-42b9-bc8d-d36997b5f2cb,rte,CLASSIFICATION,False,32,bigscience/T0_3B,0,True,semantic_relations_with_options,prompts/general_fixed_choice.yaml,SemEval2010,,2,,,GenFC,,False,NLI,,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,semantic relations with options,,cross_task,two_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.sem_eval_2010_task_8.semantic_relations_with_options.LenNorm,RTE,75.90798640691996,78.02467844818572,RecognizingTextualEntailment,super_glue,,,,,,,,,,,,,,,,,72.5,68.5,40
13.439434129089303,17.24137931034483,1.042349738404554,3.615458782230105,1.9821428571428568,0.7266253458943196,0.132432115840994,0.0,,,,124.78571428571428,2.152871302195958,2.892857142857143,23.07692307692308,1.462587480034147,0.4503400076042319,1.000705235336394,0.4653147935998351,1.125,14.285714285714285,"{'sha256': 'acf1380315f659a028567d6917e589ddb53131d7fa165e5b854e8b40d0d25add', 'artifact_path': 'wandb-client-artifact://im2g2lvofittmca31g52j1me6xjs9uknu372qj2hl4agrxcbuzofij7y43k5gel351lvsjov0mi4nwbc3lfadvwz1gissq1e17ztrvktdmbjl530fh60vjyzy1ktr7af:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://im2g2lvofittmca31g52j1me6xjs9uknu372qj2hl4agrxcbuzofij7y43k5gel351lvsjov0mi4nwbc3lfadvwz1gissq1e17ztrvktdmbjl530fh60vjyzy1ktr7af:latest/predictions.table.json', 'path': 'media/table/predictions_1_acf1380315f659a02856.table.json', 'size': 33043, '_type': 'table-file', 'ncols': 11, 'nrows': 56}",55.06285832888572,,,False,True,validation,False,Yes | Maybe | No,4,CTBase,461efe04-6883-41e8-80f0-e722a75260fe,cb,SENTIMENT,False,28,bigscience/T0_3B,0,True,complementary_industries,prompts/general_fixed_choice.yaml,FinNews,,3,,,GenFC,,False,['NLI'],,False,False,GeneralFixedChoice,False,False,False,,,prompts,,,True,complementary_industries,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.financial_phrasebank_sentences_allagree.complementary_industries.LenNorm,CB,,,CommitmentBank,super_glue,,,,,,,,,,,,,,,,,67.5,69.0,11
67.75067750677506,,1.126177632341094,1.89160199457988,,,,67.75067750677506,,,,98.5956678700361,1.89160199457988,1.8592057761732848,35.67567567567568,,0.347809157964174,1.126177632341094,0.347809157964174,1.1407942238267148,57.03971119133574,"{'artifact_path': 'wandb-client-artifact://sgn3oskope0nprla00ha1umo4e9silqc8w5w7evegd3j0h8v40hxdglugnrii8kavat33dlpgxtx6c7lx0ifa7vq2qg00fgyzqow94kf5mg03twds4wdfti9s2pjn48p:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://sgn3oskope0nprla00ha1umo4e9silqc8w5w7evegd3j0h8v40hxdglugnrii8kavat33dlpgxtx6c7lx0ifa7vq2qg00fgyzqow94kf5mg03twds4wdfti9s2pjn48p:latest/predictions.table.json', 'path': 'media/table/predictions_1_19d1062bb7fcc83fbabf.table.json', 'size': 129491, '_type': 'table-file', 'ncols': 9, 'nrows': 277, 'sha256': '19d1062bb7fcc83fbabff30c31b624ead1533f86c775a2147b45660bd104d6a9'}",46.467282647943954,,,False,True,validation,False,Yes | No,4,CTBase,af4d550e-54b8-471e-97af-2b2c50a1382e,rte,SUMMARIZATION,False,32,bigscience/T0_3B,0,True,relatedwork_abstract,prompts/general_fixed_choice.yaml,Multi-XSci,,2,,,GenFC,,False,NLI,,False,False,GeneralFixedChoice,False,False,False,,,prompts,,,True,relatedwork_abstract,,cross_task,two_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.multi_x_science_sum.relatedwork_abstract.LenNorm,RTE,74.66910651693748,77.56980027188122,RecognizingTextualEntailment,super_glue,,,,,,,,,,,,,,,,,66.0,66.5,9
26.65910380034033,19.51219512195122,1.0462228115289138,2.86789243561881,2.0,0.5529909829904054,0.0,0.0,,,,121.78571428571428,2.0495324645723616,2.2857142857142856,60.46511627906976,0.8183599710464478,0.95831484749991,0.91423564152181,0.95831484749991,1.7142857142857142,30.357142857142858,"{'nrows': 56, 'sha256': '718eccdb0f8ec306ca2ac1814ac03b51ae5d1146669a99bba1fbfe852ea37a38', 'artifact_path': 'wandb-client-artifact://7i1qnjv09kggs6u8y36oqmllqoo4emb8fczv9gq79adgtwe74kzzas7j5nlf3pxqw1ffcyjaa2ngp89v0rxe2en67stz9cm4ps8k0giuffkxzc25r42d8cdjpodd9gal:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://7i1qnjv09kggs6u8y36oqmllqoo4emb8fczv9gq79adgtwe74kzzas7j5nlf3pxqw1ffcyjaa2ngp89v0rxe2en67stz9cm4ps8k0giuffkxzc25r42d8cdjpodd9gal:latest/predictions.table.json', 'path': 'media/table/predictions_1_718eccdb0f8ec306ca2a.table.json', 'size': 31315, '_type': 'table-file', 'ncols': 11}",55.06285832888572,,,False,True,validation,False,Yes | Maybe | No,4,CTBase,0beba048-f949-4034-83b6-a3e0e7363f46,cb,SENTIMENT,False,28,bigscience/T0_3B,0,True,sentiment,prompts/general_fixed_choice.yaml,FinNews,,3,,,GenFC,,False,['NLI'],,False,False,GeneralFixedChoice,False,False,False,,,prompts,,,True,sentiment,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.financial_phrasebank_sentences_allagree.sentiment.LenNorm,CB,,,CommitmentBank,super_glue,,,,,,,,,,,,,,,,,16.5,1.0,8
18.429487179487182,11.538461538461537,0.4370693301146619,2.291141471692494,2.0,0.4959351841629724,0.0,0.0,,,,144.78571428571428,1.4537906902176994,2.6785714285714284,43.75000000000001,0.8373507814747947,0.7345344214715405,0.4404309477244541,0.7345344214715405,1.3214285714285714,17.857142857142858,"{'_latest_artifact_path': 'wandb-client-artifact://19qt5jfptmn6jvk3am7yup432m1uhqcnf30nyunkostfmpucbmkkw73f35063r6m7ljtujaz9r19lhxtexkttp85c77klghic376bq8fo3gixqdhhz90ooanjd37d17b:latest/predictions.table.json', 'path': 'media/table/predictions_1_e2700dbe0d804efed29c.table.json', 'size': 36610, '_type': 'table-file', 'ncols': 11, 'nrows': 56, 'sha256': 'e2700dbe0d804efed29c273016f1ebcf48efbce96f7dc2b7eee846845fbf54d8', 'artifact_path': 'wandb-client-artifact://19qt5jfptmn6jvk3am7yup432m1uhqcnf30nyunkostfmpucbmkkw73f35063r6m7ljtujaz9r19lhxtexkttp85c77klghic376bq8fo3gixqdhhz90ooanjd37d17b:latest/predictions.table.json'}",55.06285832888571,,,False,True,validation,False,Yes | Maybe | No,4,CTBase,06719321-62e7-4f6e-8f95-464cd2b5ca5c,cb,SENTIMENT,False,28,bigscience/T0_3B,0,True,share_price_option,prompts/general_fixed_choice.yaml,FinNews,,3,,,GenFC,,False,['NLI'],,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,share_price_option,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.financial_phrasebank_sentences_allagree.share_price_option.LenNorm,CB,,,CommitmentBank,super_glue,,,,,,,,,,,,,,,,,59.0,56.0,20
68.50828729281768,,1.049008458639717,1.7309339158371468,,,,68.50828729281768,,,,106.5956678700361,1.7309339158371468,1.8339350180505416,40.62500000000001,,0.3721389575408419,1.049008458639717,0.3721389575408419,1.1660649819494584,58.84476534296029,"{'artifact_path': 'wandb-client-artifact://ueawk9qgbz1ixjqor4gk7ixirhqblzjnbxbch59n2rutnelfzsebzx1x0g8zdx7q1yk1b9kzr8wigcvoeca8a32bdfq44x8j39z3j0hjm7twzycga6leai3g6syrmy63:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://ueawk9qgbz1ixjqor4gk7ixirhqblzjnbxbch59n2rutnelfzsebzx1x0g8zdx7q1yk1b9kzr8wigcvoeca8a32bdfq44x8j39z3j0hjm7twzycga6leai3g6syrmy63:latest/predictions.table.json', 'path': 'media/table/predictions_1_f311a0ff57e2a06c9fd7.table.json', 'size': 141098, '_type': 'table-file', 'ncols': 9, 'nrows': 277, 'sha256': 'f311a0ff57e2a06c9fd7b52e3dccad166e4281e1a06a746202327b9585d5ee7b'}",46.467282647943954,,,False,True,validation,False,Yes | No,4,CTBase,3bd082cb-4e28-4eb7-9fa2-dd03f1f86219,rte,SUMMARIZATION,False,32,bigscience/T0_3B,0,True,abstract_relatedwork,prompts/general_fixed_choice.yaml,Multi-XSci,,2,,,GenFC,,False,NLI,,False,False,GeneralFixedChoice,False,False,False,,,prompts,,,True,abstract_relatedwork,,cross_task,two_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.multi_x_science_sum.abstract_relatedwork.LenNorm,RTE,71.11539261910144,75.48886332740771,RecognizingTextualEntailment,super_glue,,,,,,,,,,,,,,,,,55.0,57.0,17
69.49152542372882,,1.0659666709312123,1.7336804074931231,,,,69.49152542372882,,,,99.5956678700361,1.7336804074931231,1.8050541516245489,46.0,,0.3961590142564306,1.0659666709312123,0.3961590142564306,1.1949458483754514,61.01083032490975,"{'sha256': '2483eafa86c118c051d3ee121c0a13eb46f7bbde78b101a9e2e9724668dd36cb', 'artifact_path': 'wandb-client-artifact://135zsr80dzia3gb6mrlvahlzvzt6iivtv6k1b6yomi9kq0sxmazcfkjed9ccog0j2v4fe75cr1oibq8n1ebaw02pip3u2q7rk232kx8ca2k9cuuknh1k5h1gk8eq153p:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://135zsr80dzia3gb6mrlvahlzvzt6iivtv6k1b6yomi9kq0sxmazcfkjed9ccog0j2v4fe75cr1oibq8n1ebaw02pip3u2q7rk232kx8ca2k9cuuknh1k5h1gk8eq153p:latest/predictions.table.json', 'path': 'media/table/predictions_1_2483eafa86c118c051d3.table.json', 'size': 132261, '_type': 'table-file', 'ncols': 9, 'nrows': 277}",46.467282647943954,,,False,True,validation,False,Yes | No,4,CTBase,2bca0197-e3d4-4870-bd95-178411e52e09,rte,SUMMARIZATION,False,32,bigscience/T0_3B,0,True,ref_relatedwork,prompts/general_fixed_choice.yaml,Multi-XSci,,2,,,GenFC,,False,NLI,,False,False,GeneralFixedChoice,False,False,False,,,prompts,,,True,ref_relatedwork,,cross_task,two_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.multi_x_science_sum.ref_relatedwork.LenNorm,RTE,71.53817094669937,75.16992575551605,RecognizingTextualEntailment,super_glue,,,,,,,,,,,,,,,,,47.5,48.0,10
68.29268292682927,,1.0579363536335322,1.7853275834438171,,,,68.29268292682927,,,,99.5956678700361,1.7853275834438171,1.8592057761732848,36.75675675675675,,0.347809157964174,1.0579363536335322,0.347809157964174,1.1407942238267148,57.76173285198555,"{'size': 129187, '_type': 'table-file', 'ncols': 9, 'nrows': 277, 'sha256': '982a5426ff5b900d021624bfa65cde5dfcc8a0ae041d4503ecef5d3a6b5c0284', 'artifact_path': 'wandb-client-artifact://nipcwll03ydtur17e40d01mqainjfj0ebz4hcp3q1ustma2hizf50rg8wwmpkacz71z5su4t5d53mavj7g246g9yhybwk6xfxnpybca4y0vsd4ajhb8t1rtrfywfe5o0:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://nipcwll03ydtur17e40d01mqainjfj0ebz4hcp3q1ustma2hizf50rg8wwmpkacz71z5su4t5d53mavj7g246g9yhybwk6xfxnpybca4y0vsd4ajhb8t1rtrfywfe5o0:latest/predictions.table.json', 'path': 'media/table/predictions_1_982a5426ff5b900d0216.table.json'}",46.467282647943954,,,False,True,validation,False,Yes | No,4,CTBase,774b4349-0524-4a34-881b-b344f8f5c34e,rte,COMPLETION,False,32,bigscience/T0_3B,0,True,what_comes_next,prompts/general_fixed_choice.yaml,LAMBADA,,2,,,GenFC,,False,NLI,,False,False,GeneralFixedChoice,False,False,False,,,prompts,,,True,what comes next,,cross_task,two_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.craffel_openai_lambada.what_comes_next.LenNorm,RTE,71.05985120923766,74.90850151626059,RecognizingTextualEntailment,super_glue,,,,,,,,,,,,,,,,,60.0,60.0,10
67.75067750677506,,1.141569589248168,1.9429787225241264,,,,67.75067750677506,,,,100.5956678700361,1.9429787225241264,1.8592057761732848,35.67567567567568,,0.347809157964174,1.141569589248168,0.347809157964174,1.1407942238267148,57.03971119133574,"{'_type': 'table-file', 'ncols': 9, 'nrows': 277, 'sha256': 'a2abd3a53c40c5e7404c18f96e7b0b7ad7faec146e244cf77f88d16e4b5456d3', 'artifact_path': 'wandb-client-artifact://zle5i7b3kxcf3fxbrlhp4514u1vwkusce3r860qo1crnergh8hsg1o5alnvbifmm19wr9dyh3hye52tivritza879z5nbkhw7rb6taczmrobl9po2mqm3a6sxkzfgmbq:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://zle5i7b3kxcf3fxbrlhp4514u1vwkusce3r860qo1crnergh8hsg1o5alnvbifmm19wr9dyh3hye52tivritza879z5nbkhw7rb6taczmrobl9po2mqm3a6sxkzfgmbq:latest/predictions.table.json', 'path': 'media/table/predictions_1_a2abd3a53c40c5e7404c.table.json', 'size': 124216}",46.467282647943954,,,False,True,validation,False,Yes | No,4,CTBase,4f08e9d4-bcff-4bc0-9902-87c497625d17,rte,COMPLETION,False,32,bigscience/T0_3B,0,True,GPT_3_style,prompts/general_fixed_choice.yaml,LAMBADA,,2,,,GenFC,,False,NLI,,False,False,GeneralFixedChoice,False,False,False,,,prompts,,,True,GPT-3 style,,cross_task,two_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.craffel_openai_lambada.GPT_3_style.LenNorm,RTE,71.94198844795201,75.18038272508628,RecognizingTextualEntailment,super_glue,,,,,,,,,,,,,,,,,66.0,66.5,11
69.83240223463687,,1.1108536816185874,1.8181103179601128,,,,69.83240223463687,,,,98.5956678700361,1.8181103179601128,1.8194945848375448,44.89795918367347,,0.3846078655715256,1.1108536816185874,0.3846078655715256,1.1805054151624548,61.01083032490975,"{'_latest_artifact_path': 'wandb-client-artifact://w8xn9bitgaw02el6ccf2mzwak7putoym0bbvfbwv0crcm4s4dy0wnsxmgmfwllxk4usw8ce97gzhfbcisntok50k3t9d8zpqrja3yq5m18fhhzbzmnk1x85qbq0p29zf:latest/predictions.table.json', 'path': 'media/table/predictions_1_aae2e7a2e323b589d510.table.json', 'size': 126725, '_type': 'table-file', 'ncols': 9, 'nrows': 277, 'sha256': 'aae2e7a2e323b589d510ae502a93c6d76c505d30589d632784b1b6d458acc29f', 'artifact_path': 'wandb-client-artifact://w8xn9bitgaw02el6ccf2mzwak7putoym0bbvfbwv0crcm4s4dy0wnsxmgmfwllxk4usw8ce97gzhfbcisntok50k3t9d8zpqrja3yq5m18fhhzbzmnk1x85qbq0p29zf:latest/predictions.table.json'}",46.467282647943954,,,False,True,validation,False,Yes | No,4,CTBase,1ee5ddef-fffb-4b73-a2f7-f600ffac63cb,rte,COMPLETION,False,32,bigscience/T0_3B,0,True,ellipses,prompts/general_fixed_choice.yaml,LAMBADA,,2,,,GenFC,,False,NLI,,False,False,GeneralFixedChoice,False,False,False,,,prompts,,,True,ellipses,,cross_task,two_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.craffel_openai_lambada.ellipses.LenNorm,RTE,72.80610116552091,75.52023423611838,RecognizingTextualEntailment,super_glue,,,,,,,,,,,,,,,,,47.5,45.5,11
69.04109589041096,,1.0309640035730805,1.6837621948779276,,,,69.04109589041096,,,,110.5956678700361,1.6837621948779276,1.8447653429602888,40.21164021164021,,0.3621282345985666,1.0309640035730805,0.3621282345985666,1.1552346570397112,59.2057761732852,"{'ncols': 9, 'nrows': 277, 'sha256': 'e1d2853631815ec37c847ed3da675089db83b07479ff3eb01fb6da289f366d1a', 'artifact_path': 'wandb-client-artifact://16r1rt1jscw2xm0t6whssvpx9grw8u5wpe2vluq9v6enntp76gff4rtdw6xwc6w81le08w8qxcw352um54aiuhcqpo3ml2ud2bng6z0lu2xtkgx9xgyx5c733j4zmawb:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://16r1rt1jscw2xm0t6whssvpx9grw8u5wpe2vluq9v6enntp76gff4rtdw6xwc6w81le08w8qxcw352um54aiuhcqpo3ml2ud2bng6z0lu2xtkgx9xgyx5c733j4zmawb:latest/predictions.table.json', 'path': 'media/table/predictions_1_e1d2853631815ec37c84.table.json', 'size': 143878, '_type': 'table-file'}",46.467282647943954,,,False,True,validation,False,Yes | No,4,CTBase,9a3f617f-628f-4fa5-9b74-47d0b166a487,rte,SUMMARIZATION,False,32,bigscience/T0_3B,0,True,read_below_DOC_write_abstract,prompts/general_fixed_choice.yaml,XSum,,2,,,GenFC,,False,NLI,,True,False,GeneralFixedChoice,False,False,False,,,prompts,,,True,read_below_DOC_write_abstract,,cross_task,two_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.xsum.read_below_DOC_write_abstract.LenNorm,RTE,68.20620782798824,73.00533305448081,RecognizingTextualEntailment,super_glue,,,,,,,,,,,,,,,,,53.0,52.5,21
67.02127659574468,,0.9916465110761556,1.6509629083454394,,,,67.02127659574468,,,,113.5956678700361,1.6509629083454394,1.8844765342960288,30.33707865168539,,0.3196526154682838,0.9916465110761556,0.3196526154682838,1.1155234657039712,55.23465703971119,"{'path': 'media/table/predictions_1_9bcf47c2e0dc1235d7c3.table.json', 'size': 142222, '_type': 'table-file', 'ncols': 9, 'nrows': 277, 'sha256': '9bcf47c2e0dc1235d7c33e921529699623fd7996e8f0499e16538d4152df6b04', 'artifact_path': 'wandb-client-artifact://gxouvx11i44tg8nc5v2iwjumknr8ms8dcezdisicaogs38gijt6rlvmbp935rupum74848g19f04f01kxz9vghgnvu8fj4zmn9bmu9w10sz4ctzrjggnwf5xuxxziva8:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://gxouvx11i44tg8nc5v2iwjumknr8ms8dcezdisicaogs38gijt6rlvmbp935rupum74848g19f04f01kxz9vghgnvu8fj4zmn9bmu9w10sz4ctzrjggnwf5xuxxziva8:latest/predictions.table.json'}",46.467282647943954,,,False,True,validation,False,Yes | No,4,CTBase,4cfe4126-b9f5-44eb-8a98-973987c5f32e,rte,SUMMARIZATION,False,32,bigscience/T0_3B,0,True,college_roommate_asked_DOC_so_I_recap,prompts/general_fixed_choice.yaml,XSum,,2,,,GenFC,,False,NLI,,True,False,GeneralFixedChoice,False,False,False,,,prompts,,,True,college_roommate_asked_DOC_so_I_recap,,cross_task,two_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.xsum.college_roommate_asked_DOC_so_I_recap.LenNorm,RTE,66.17389892575487,71.65115549513752,RecognizingTextualEntailment,super_glue,,,,,,,,,,,,,,,,,72.5,72.0,24
68.11989100817439,,1.1278624907793091,1.9177900066444589,,,,68.11989100817439,,,,102.5956678700361,1.9177900066444589,1.851985559566787,37.4331550802139,,0.3551142997070884,1.1278624907793091,0.3551142997070884,1.148014440433213,57.76173285198555,"{'size': 129473, '_type': 'table-file', 'ncols': 9, 'nrows': 277, 'sha256': '901cd7b7c50f8c87eee4eab92ca7a231bcd670f3bbd6b31b1ec872126353d692', 'artifact_path': 'wandb-client-artifact://ddp7nnml03tp3ttzddoswz918z4qp527ucfjfsxty63mwpvqrsyfgxmue9gjblyaxk69mi17k31eb3fc348u6j0cmy7jakldy0nne5nd2o3idnaoyopfhxhx92iia009:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://ddp7nnml03tp3ttzddoswz918z4qp527ucfjfsxty63mwpvqrsyfgxmue9gjblyaxk69mi17k31eb3fc348u6j0cmy7jakldy0nne5nd2o3idnaoyopfhxhx92iia009:latest/predictions.table.json', 'path': 'media/table/predictions_1_901cd7b7c50f8c87eee4.table.json'}",46.467282647943954,,,False,True,validation,False,Yes | No,4,CTBase,3d388a1e-3361-407b-baa7-61397cc58382,rte,SUMMARIZATION,False,32,bigscience/T0_3B,0,True,DOC_how_would_you_rephrase_few_words,prompts/general_fixed_choice.yaml,XSum,,2,,,GenFC,,False,NLI,,True,False,GeneralFixedChoice,False,False,False,,,prompts,,,True,DOC_how_would_you_rephrase_few_words,,cross_task,two_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.xsum.DOC_how_would_you_rephrase_few_words.LenNorm,RTE,71.46281446683845,74.87190212276482,RecognizingTextualEntailment,super_glue,,,,,,,,,,,,,,,,,60.0,61.0,13
67.3913043478261,,1.138363608794113,1.9204454688819308,,,,67.3913043478261,,,,102.5956678700361,1.9204454688819308,1.855595667870036,35.483870967741936,,0.3514992474985728,1.138363608794113,0.3514992474985728,1.144404332129964,56.678700361010826,"{'artifact_path': 'wandb-client-artifact://10x2qcpqy865047zbyy9foxh6tx3rq1m2ra3wj4nrsoc9q5e4jkzf0c6zkplpy0c7e0foo7qjxhv0nj9k36m0dlhwvutdic3sdjspa1ypgunuse730qbb8rv1j35qcxs:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://10x2qcpqy865047zbyy9foxh6tx3rq1m2ra3wj4nrsoc9q5e4jkzf0c6zkplpy0c7e0foo7qjxhv0nj9k36m0dlhwvutdic3sdjspa1ypgunuse730qbb8rv1j35qcxs:latest/predictions.table.json', 'path': 'media/table/predictions_1_f7796a19acb4d72cde47.table.json', 'size': 128350, '_type': 'table-file', 'ncols': 9, 'nrows': 277, 'sha256': 'f7796a19acb4d72cde477b818602514e9d36c0c555f773f95ba9449c341e55cd'}",46.467282647943954,,,False,True,validation,False,Yes | No,4,CTBase,13c02904-e4e2-4b4f-b115-44b437d22041,rte,SUMMARIZATION,False,32,bigscience/T0_3B,0,True,DOC_write_summary_of_above,prompts/general_fixed_choice.yaml,XSum,,2,,,GenFC,,False,NLI,,True,False,GeneralFixedChoice,False,False,False,,,prompts,,,True,DOC_write_summary_of_above,,cross_task,two_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.xsum.DOC_write_summary_of_above.LenNorm,RTE,69.30168212705796,72.74913730001045,RecognizingTextualEntailment,super_glue,,,,,,,,,,,,,,,,,69.0,71.0,13
67.5392670157068,,1.126265698448924,1.9322753477612988,,,,67.5392670157068,,,,105.5956678700361,1.9322753477612988,1.906137184115524,27.906976744186046,,0.2916377679223207,1.126265698448924,0.2916377679223207,1.0938628158844763,55.23465703971119,"{'ncols': 9, 'nrows': 277, 'sha256': 'b167ff1b8a1cce45a28bd106fe11f89d14bcbe4e7abaee47d100d222e5996501', 'artifact_path': 'wandb-client-artifact://no5lcnjn0ec8sqrvt8642u0figyvmpf43vq9egdnb28hszk2a5z3zk7a9sd5pxgj6sbeajdc5jwu6d4y30zktf73z4zliqykp8vipdnqj8bh30d3icbfrx9fd6jan2qt:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://no5lcnjn0ec8sqrvt8642u0figyvmpf43vq9egdnb28hszk2a5z3zk7a9sd5pxgj6sbeajdc5jwu6d4y30zktf73z4zliqykp8vipdnqj8bh30d3icbfrx9fd6jan2qt:latest/predictions.table.json', 'path': 'media/table/predictions_1_b167ff1b8a1cce45a28b.table.json', 'size': 135541, '_type': 'table-file'}",46.467282647943954,,,False,True,validation,False,Yes | No,4,CTBase,5fa16d31-b513-480d-bd1b-1fa8c182fb76,rte,SENTIMENT,False,32,bigscience/T0_3B,0,True,bullish_neutral_bearish,prompts/general_fixed_choice.yaml,FinNews,,2,,,GenFC,,False,NLI,,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,bullish_neutral_bearish,,cross_task,two_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.financial_phrasebank_sentences_allagree.bullish_neutral_bearish.LenNorm,RTE,76.5471258962644,80.50298023632752,RecognizingTextualEntailment,super_glue,,,,,,,,,,,,,,,,,72.5,70.0,9
66.4935064935065,,1.1811818008128754,2.096355709358243,,,,66.4935064935065,,,,100.5956678700361,2.096355709358243,1.916967509025271,23.66863905325444,,0.2759313255454348,1.1811818008128754,0.2759313255454348,1.083032490974729,53.42960288808665,"{'ncols': 9, 'nrows': 277, 'sha256': '51254b32de236350aea37ee578911f4dfe735f5044b779d1f9ea6db1937e6821', 'artifact_path': 'wandb-client-artifact://14w1und3qk1d5ilcvxxnlrcb18fst64tosi8ihpkvycglam7pvsh2juaxn8dklupkhskuhs8f62xmn9bva56s1lo2ty99r9tovpd4vg1a6rcfgoqsqoudyv6mm6xqxg3:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://14w1und3qk1d5ilcvxxnlrcb18fst64tosi8ihpkvycglam7pvsh2juaxn8dklupkhskuhs8f62xmn9bva56s1lo2ty99r9tovpd4vg1a6rcfgoqsqoudyv6mm6xqxg3:latest/predictions.table.json', 'path': 'media/table/predictions_1_51254b32de236350aea3.table.json', 'size': 137188, '_type': 'table-file'}",46.467282647943954,,,False,True,validation,False,Yes | No,4,CTBase,461efe04-6883-41e8-80f0-e722a75260fe,rte,SENTIMENT,False,32,bigscience/T0_3B,0,True,complementary_industries,prompts/general_fixed_choice.yaml,FinNews,,2,,,GenFC,,False,NLI,,False,False,GeneralFixedChoice,False,False,False,,,prompts,,,True,complementary_industries,,cross_task,two_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.financial_phrasebank_sentences_allagree.complementary_industries.LenNorm,RTE,73.86622902715956,78.01944996340062,RecognizingTextualEntailment,super_glue,,,,,,,,,,,,,,,,,76.5,75.0,11
72.51461988304094,,0.943821793051177,1.4395715940730236,,,,72.51461988304094,,,,97.5956678700361,1.4395715940730236,1.7617328519855595,55.66037735849058,,0.4260233728230239,0.943821793051177,0.4260233728230239,1.2382671480144405,66.06498194945848,"{'size': 128459, '_type': 'table-file', 'ncols': 9, 'nrows': 277, 'sha256': '7ad3d253f4715ca00ae925b0c701c90365b6d07901e6fe1f641c04f5379cf77a', 'artifact_path': 'wandb-client-artifact://zr70f9spq9pvydppxo1y9k1m8jig173ucn1elrqolse0a6mbfun45nu34ska4w2d9dqil4l2qrkyoudgcvueukw81v93gevf1fwaq8inzwtq6dl2cfnjkka447a6i6g4:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://zr70f9spq9pvydppxo1y9k1m8jig173ucn1elrqolse0a6mbfun45nu34ska4w2d9dqil4l2qrkyoudgcvueukw81v93gevf1fwaq8inzwtq6dl2cfnjkka447a6i6g4:latest/predictions.table.json', 'path': 'media/table/predictions_1_7ad3d253f4715ca00ae9.table.json'}",46.467282647943954,,,False,True,validation,False,Yes | No,4,CTBase,0beba048-f949-4034-83b6-a3e0e7363f46,rte,SENTIMENT,False,32,bigscience/T0_3B,0,True,sentiment,prompts/general_fixed_choice.yaml,FinNews,,2,,,GenFC,,False,NLI,,False,False,GeneralFixedChoice,False,False,False,,,prompts,,,True,sentiment,,cross_task,two_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.financial_phrasebank_sentences_allagree.sentiment.LenNorm,RTE,73.74656448159516,78.05082087211127,RecognizingTextualEntailment,super_glue,,,,,,,,,,,,,,,,,31.5,28.0,8
68.07387862796833,,0.866231603833801,1.4299970335908745,,,,68.07387862796833,,,,116.5956678700361,1.4299970335908745,1.895306859205776,30.85714285714286,,0.3061576180088692,0.866231603833801,0.3061576180088692,1.1046931407942238,56.317689530685925,"{'ncols': 9, 'nrows': 277, 'sha256': 'c6c5bb9c70dbf46ca0cdbb715c16515291877e36a3b5883e3300550c658f6b3b', 'artifact_path': 'wandb-client-artifact://2dwr2mbcan62yi0vxkhqfhesiq86oxz9rjjua0dvo7hxf5e1ps837n5exfcsa0fr6p3o8ghm62n4m0ktncpig43b3vl1v4t4w7d3f3tyl46bz6gblz6fxrjzf4t31v13:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://2dwr2mbcan62yi0vxkhqfhesiq86oxz9rjjua0dvo7hxf5e1ps837n5exfcsa0fr6p3o8ghm62n4m0ktncpig43b3vl1v4t4w7d3f3tyl46bz6gblz6fxrjzf4t31v13:latest/predictions.table.json', 'path': 'media/table/predictions_1_c6c5bb9c70dbf46ca0cd.table.json', 'size': 151894, '_type': 'table-file'}",46.467282647943954,,,False,True,validation,False,Yes | No,4,CTBase,06719321-62e7-4f6e-8f95-464cd2b5ca5c,rte,SENTIMENT,False,32,bigscience/T0_3B,0,True,share_price_option,prompts/general_fixed_choice.yaml,FinNews,,2,,,GenFC,,False,NLI,,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,share_price_option,,cross_task,two_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.financial_phrasebank_sentences_allagree.share_price_option.LenNorm,RTE,78.47267085512304,81.93558506744745,RecognizingTextualEntailment,super_glue,,,,,,,,,,,,,,,,,70.0,63.0,20
26.81183234254483,32.5452016689847,0.7577405323268116,3.186946616202593,2.0,0.6249881099066478,0.0,0.0,,,,128.051,2.36040656387806,1.772,47.89029535864978,0.8265400523245334,0.9736611320166784,0.6675014565203097,0.9736611320166784,2.228,34.4,"{'artifact_path': 'wandb-client-artifact://oks5rd0ib2kq2mzlij1ernmxsgrmynpa95s2fr3rp72cs260j33tmibqh8j76mik75wya70sbn4w42zwgaruvte89emxygb764j4b5xztxqssz0449rhr69f9k8yycyh:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://oks5rd0ib2kq2mzlij1ernmxsgrmynpa95s2fr3rp72cs260j33tmibqh8j76mik75wya70sbn4w42zwgaruvte89emxygb764j4b5xztxqssz0449rhr69f9k8yycyh:latest/predictions.table.json', 'path': 'media/table/predictions_1_87b6788f4b9d0ae46635.table.json', 'size': 587696, '_type': 'table-file', 'ncols': 11, 'nrows': 1000, 'sha256': '87b6788f4b9d0ae46635062c3e3b32a9404406ff621ad23de356ee103e9e6393'}",17.873231353059804,,,False,True,dev_r2,False,Yes | Maybe | No,4,CTBase,f32348cd-d3cb-4619-87b9-e24f99c78567,anli,COMPLETION,False,28,bigscience/T0_3B,0,True,choose,prompts/general_fixed_choice.yaml,COPA,,3,,,GenFC,,False,['NLI'],,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,choose,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.super_glue_copa.choose.LenNorm,ANLI R2,,,,,,,,,,,,,,,,,,,,,13.5,17.0,8
26.76012045154496,32.173913043478265,0.728393068774173,2.429780390650034,1.996,0.6781701644655797,0.063118935352238,0.0,,,,139.051,1.525562878072262,1.714,48.106448311156605,0.9042175125777722,0.9582296175760796,0.5934537745012922,0.9549345527312328,2.29,34.599999999999994,"{'ncols': 11, 'nrows': 1000, 'sha256': 'c3de58038722416dffdcf05c8ed806a72dae386dfe0dc9772955a19b9d48f281', 'artifact_path': 'wandb-client-artifact://13vzsf24aehrhqcv2gn2g0enluf551g7snwj8w5302zuwaalznlhokqkijnen0kalwxp7puus8iy4l0s91d7twkgisozta1iyhjefnpzj801aoxx82k8msbmmkd1u8vd:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://13vzsf24aehrhqcv2gn2g0enluf551g7snwj8w5302zuwaalznlhokqkijnen0kalwxp7puus8iy4l0s91d7twkgisozta1iyhjefnpzj801aoxx82k8msbmmkd1u8vd:latest/predictions.table.json', 'path': 'media/table/predictions_1_c3de58038722416dffdc.table.json', 'size': 637869, '_type': 'table-file'}",17.873231353059804,,,False,True,dev_r2,False,Yes | Maybe | No,4,CTBase,a1f9951e-2b6b-4530-9636-9cdf4c1658c5,anli,COMPLETION,False,28,bigscience/T0_3B,0,True,more_likely,prompts/general_fixed_choice.yaml,COPA,,3,,,GenFC,,False,['NLI'],,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,more likely,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.super_glue_copa.more_likely.LenNorm,ANLI R2,,,,,,,,,,,,,,,,,,,,,11.0,19.0,19
26.913736669834236,36.585365853658544,0.7099724555634228,2.8983413240760565,1.999,0.6499584833959049,0.0316069612585582,0.0,,,,133.051,2.065857429653406,1.974,44.15584415584416,0.8324838944226504,0.9996619428586848,0.6641581845371917,0.999135125996479,2.027,33.7,"{'artifact_path': 'wandb-client-artifact://wj2e4528kob7qn61v3ow8gpe2igjgk5ilhi41fljyvzx5q6cpan9hd1iwb36zg4kxbe261bc0u8pfaarskemtqwinvtgnxs4i2gnm5xmoins9ccsk8i103k4i9qlmgjj:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://wj2e4528kob7qn61v3ow8gpe2igjgk5ilhi41fljyvzx5q6cpan9hd1iwb36zg4kxbe261bc0u8pfaarskemtqwinvtgnxs4i2gnm5xmoins9ccsk8i103k4i9qlmgjj:latest/predictions.table.json', 'path': 'media/table/predictions_1_1ef061b3c3e705078945.table.json', 'size': 620865, '_type': 'table-file', 'ncols': 11, 'nrows': 1000, 'sha256': '1ef061b3c3e705078945eb0483d22d1f0f1e23f7632baed44432521f7e2bed46'}",17.873231353059804,,,False,True,dev_r2,False,Yes | Maybe | No,4,CTBase,0edd8660-f299-4819-a5ac-633c11177228,anli,COMPLETION,False,28,bigscience/T0_3B,0,True,exercise,prompts/general_fixed_choice.yaml,COPA,,3,,,GenFC,,False,['NLI'],,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,exercise,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.super_glue_copa.exercise.LenNorm,ANLI R2,,,,,,,,,,,,,,,,,,,,,19.5,14.0,13
14.696137913336754,0.0,0.8246589053285763,6.479839041404788,3.018425460636516,0.9637700707405285,0.1464105419324097,33.15217391304348,0.0,0.8318198002762531,3.979899497487437,171.47068676716918,1.8851743918567447,1.1641541038525962,25.632377740303543,3.76284484927179,0.3704153534087745,0.9635803389684848,0.3734028657467211,1.8375209380234503,22.948073701842542,"{'size': 495532, '_type': 'table-file', 'ncols': 13, 'nrows': 597, 'sha256': 'dc6fa2c970825aa392febc49e9d16c3ca1eb01f8285a5e1c6d4e6cda7719d1ef', 'artifact_path': 'wandb-client-artifact://cek3oa43d9dggojq1ipwtyqce2hnshgz552w9z7v6ptce6div09d0a7p8882nztn83dewmwa3t8ze1ffqtooutc9jtjgw27qjhtetg1bthqowm9hjs3z4dx09xx4lkz3:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://cek3oa43d9dggojq1ipwtyqce2hnshgz552w9z7v6ptce6div09d0a7p8882nztn83dewmwa3t8ze1ffqtooutc9jtjgw27qjhtetg1bthqowm9hjs3z4dx09xx4lkz3:latest/predictions.table.json', 'path': 'media/table/predictions_1_dc6fa2c970825aa392fe.table.json'}",78.1171728355754,0.5880765349675268,0.1403441210429039,False,True,validation,False,Seller | Buyer | Neither | Unknown,4,CTBase,f32348cd-d3cb-4619-87b9-e24f99c78567,craigslist_bargains,COMPLETION,False,12,bigscience/T0_3B,0,True,choose,prompts/general_fixed_choice.yaml,COPA,['validation'],4,,,GenFC,,False,['Dialogue'],,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,choose,,cross_task,craigslist,,,,False,,,False,,True,,,False,False,CTBase.GenFC.super_glue_copa.choose.LenNorm,Craigslist,,,,,,,,,,,,,,,,,,,,,24.0,40.0,8
26.715199583176545,38.43575418994413,0.7567732372056285,3.6954894658327104,2.0,0.5657432342558348,0.0,0.0,,,,120.623,2.989072602748871,2.124,41.7098445595855,0.7064168630838394,0.992282217919882,0.7179273002751515,0.992282217919882,1.876,33.300000000000004,"{'_type': 'table-file', 'ncols': 11, 'nrows': 1000, 'sha256': 'f546628a5b3d55315673c505ddd455559fbfe383af26854e51e057fa5798efbc', 'artifact_path': 'wandb-client-artifact://12wiaftsevj8utg5xh7ltrfahvii2k5d1aw9s68qo9t9l8aokv5ucf7nfrbijcmihyzwy73ih6lzb4mu9n24fnynf1oinwucx7t776m3m51ocehe3yqx9sws2vylj1qo:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://12wiaftsevj8utg5xh7ltrfahvii2k5d1aw9s68qo9t9l8aokv5ucf7nfrbijcmihyzwy73ih6lzb4mu9n24fnynf1oinwucx7t776m3m51ocehe3yqx9sws2vylj1qo:latest/predictions.table.json', 'path': 'media/table/predictions_1_f546628a5b3d55315673.table.json', 'size': 574564}",17.855443735735047,,,False,True,dev_r2,False,Yes | Maybe | No,4,CTBase,2d0d63da-ffcf-4f6e-941a-b8da922be43e,anli,ENTAILMENT,False,28,bigscience/T0_3B,0,True,guaranteed_true,prompts/general_fixed_choice.yaml,ANLI,,3,,,GenFC,,True,['NLI'],,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,guaranteed true,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.anli.guaranteed_true.LenNorm,ANLI R2,,,,,,,,,,,,,,,,,,,,,34.0,20.0,12
8.124342016114742,0.0,0.7791127222882975,7.314588383014877,3.0016750418760467,0.8420883889378239,0.0408929836372988,5.653710247349824,0.0,1.2531206176508611,3.9983249581239537,182.4706867671692,2.41767678109046,1.0217755443886096,26.843657817109147,3.643790984273556,0.1459498888495274,0.6517731281109831,0.1459498888495274,1.9782244556113904,16.582914572864322,"{'artifact_path': 'wandb-client-artifact://106uubrmfpl2nia9gdoci2qqqqg61hwlvxyc4ysls0zd3jp26x1n7gpulnn0783rri800wath472q5p36quuqa88o5e4dmhhz4d228bj8t6zz6yh364pu48a1ajm71lz:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://106uubrmfpl2nia9gdoci2qqqqg61hwlvxyc4ysls0zd3jp26x1n7gpulnn0783rri800wath472q5p36quuqa88o5e4dmhhz4d228bj8t6zz6yh364pu48a1ajm71lz:latest/predictions.table.json', 'path': 'media/table/predictions_1_0d4275b7e5a01d709b80.table.json', 'size': 525409, '_type': 'table-file', 'ncols': 13, 'nrows': 597, 'sha256': '0d4275b7e5a01d709b80a1d5577e379000e3e921608640a6916fc3f9681eb3c5'}",78.1171728355754,0.5564355536387677,0.0408929836372988,False,True,validation,False,Seller | Buyer | Neither | Unknown,4,CTBase,a1f9951e-2b6b-4530-9636-9cdf4c1658c5,craigslist_bargains,COMPLETION,False,12,bigscience/T0_3B,0,True,more_likely,prompts/general_fixed_choice.yaml,COPA,['validation'],4,,,GenFC,,False,['Dialogue'],,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,more likely,,cross_task,craigslist,,,,False,,,False,,True,,,False,False,CTBase.GenFC.super_glue_copa.more_likely.LenNorm,Craigslist,,,,,,,,,,,,,,,,,,,,,61.5,74.0,19
27.217291908889766,42.215256008359454,0.7862397735762059,4.175868674755097,2.0,0.6145401682687132,0.0,0.0,,,,133.051,3.4254158072471617,2.248,39.436619718309856,0.7504528675079346,0.9687600322061184,0.7741772736795854,0.9687600322061188,1.752,34.2,"{'_latest_artifact_path': 'wandb-client-artifact://1dlnlbexfbmm9xfta0bpduj5spl9a1358n4em0qx28vdqucxmr6jqk4c12t1w08ondendsbgh3sz4497141cf385o8q9o6d8q5ow0rm1mhy0qnm4iyw6etpm1trab0ny:latest/predictions.table.json', 'path': 'media/table/predictions_1_b1bc73514d562bac0c2c.table.json', 'size': 584812, '_type': 'table-file', 'ncols': 11, 'nrows': 1000, 'sha256': 'b1bc73514d562bac0c2c84f2137f5aca07adabb9ec7902d5669e9ed421fb4d33', 'artifact_path': 'wandb-client-artifact://1dlnlbexfbmm9xfta0bpduj5spl9a1358n4em0qx28vdqucxmr6jqk4c12t1w08ondendsbgh3sz4497141cf385o8q9o6d8q5ow0rm1mhy0qnm4iyw6etpm1trab0ny:latest/predictions.table.json'}",17.873231353059804,,,False,True,dev_r2,False,Yes | Maybe | No,4,CTBase,9e078fb4-505b-413c-bb5e-3cd16ddcf5d7,anli,ENTAILMENT,False,28,bigscience/T0_3B,0,True,does_this_imply,prompts/general_fixed_choice.yaml,ANLI,,3,,,GenFC,,True,['NLI'],,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,does this imply,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.anli.does_this_imply.LenNorm,ANLI R2,,,,,,,,,,,,,,,,,,,,,15.0,12.0,23
10.435359773338892,10.852713178294572,0.7818666301620887,6.642273476475248,2.747068676716918,1.2596145399614658,0.44984153209072,6.36042402826855,0.0,1.01789115032359,3.9949748743718594,176.47068676716918,4.021852880666404,1.1624790619765497,24.52830188679245,1.602529445485254,0.5261018285310456,1.6096756179138298,0.5169777346577561,2.095477386934673,15.745393634840871,"{'path': 'media/table/predictions_1_fc8fbc913a21c805f632.table.json', 'size': 515268, '_type': 'table-file', 'ncols': 13, 'nrows': 597, 'sha256': 'fc8fbc913a21c805f632ad594301b68c64f8850f54bff428ba78bd649b5539df', 'artifact_path': 'wandb-client-artifact://nfivfvszuz50cndq7cuw33txbdwla399dnhwzupqmgk8lmzs3ds8ndihx3k4kcs1az1zneuhurikbfsuvk3aas7humk8ugtt0oscd4u42ggwgmxxeq50xjyqpo0xoc1v:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://nfivfvszuz50cndq7cuw33txbdwla399dnhwzupqmgk8lmzs3ds8ndihx3k4kcs1az1zneuhurikbfsuvk3aas7humk8ugtt0oscd4u42ggwgmxxeq50xjyqpo0xoc1v:latest/predictions.table.json'}",78.1171728355754,0.6105996728767964,0.0707097853239713,False,True,validation,False,Seller | Buyer | Neither | Unknown,4,CTBase,0edd8660-f299-4819-a5ac-633c11177228,craigslist_bargains,COMPLETION,False,12,bigscience/T0_3B,0,True,exercise,prompts/general_fixed_choice.yaml,COPA,['validation'],4,,,GenFC,,False,['Dialogue'],,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,exercise,,cross_task,craigslist,,,,False,,,False,,True,,,False,False,CTBase.GenFC.super_glue_copa.exercise.LenNorm,Craigslist,,,,,,,,,,,,,,,,,,,,,75.5,66.0,13
27.22023537953601,33.80281690140845,0.7476647386024091,3.3056073490977287,2.0,0.5714895499796367,0.0,0.0,,,,122.623,2.55014290189743,1.754,47.85788923719957,0.7554644472002983,0.9692698282728088,0.6637178214363082,0.9692698282728088,2.246,34.9,"{'size': 585065, '_type': 'table-file', 'ncols': 11, 'nrows': 1000, 'sha256': '2abb19ffbb4126a5662f5b7b857654e6d52821c114e2484eddf7052cb253256a', 'artifact_path': 'wandb-client-artifact://nvqisrflhosc0c9x5cr5pmx1m718y9us6wmapedcaipuhp9bin6pzy4yvhwu2f1nvqrk3wwtuy5wk4hkydp4gxws0tkqwqqxa21itfsnui2wk1iu9phz9215ci29jyhu:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://nvqisrflhosc0c9x5cr5pmx1m718y9us6wmapedcaipuhp9bin6pzy4yvhwu2f1nvqrk3wwtuy5wk4hkydp4gxws0tkqwqqxa21itfsnui2wk1iu9phz9215ci29jyhu:latest/predictions.table.json', 'path': 'media/table/predictions_1_2abb19ffbb4126a5662f.table.json'}",17.855443735735047,,,False,True,dev_r2,False,Yes | Maybe | No,4,CTBase,fb4f8144-37f5-4977-88da-37a5d0bfd0e8,anli,ENTAILMENT,False,28,bigscience/T0_3B,0,True,must_be_true,prompts/general_fixed_choice.yaml,ANLI,,3,,,GenFC,,True,['NLI'],,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,must be true,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.anli.must_be_true.LenNorm,ANLI R2,,,,,,,,,,,,,,,,,,,,,5.5,11.0,14
19.02555912313653,29.659318637274552,0.5377480230824383,5.459883680295705,1.865996649916248,0.3319628215613167,0.5977060167012185,30.898876404494377,0.0,0.4949586283621476,4.0,178.5075376884422,4.555508666302091,2.52428810720268,15.544041450777202,0.4094163856314654,0.7622784132492522,0.6235173488307849,0.7851891679500851,1.609715242881072,24.12060301507537,"{'nrows': 597, 'sha256': '3abcc9f66dec8ee5046b9080b422efe82546e077beb911505420ad8b7811ab9e', 'artifact_path': 'wandb-client-artifact://36me4dbzw3i9qi4ybasmnrnfga3yq7t8td7g43ys9iy5coriffzuax6xrtd1860xx27h42l03alhn14k2hynybg0avfh1jcpd1ykgr6z38f1bb4023vc3jxdiiitmth0:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://36me4dbzw3i9qi4ybasmnrnfga3yq7t8td7g43ys9iy5coriffzuax6xrtd1860xx27h42l03alhn14k2hynybg0avfh1jcpd1ykgr6z38f1bb4023vc3jxdiiitmth0:latest/predictions.table.json', 'path': 'media/table/predictions_1_3abcc9f66dec8ee5046b.table.json', 'size': 508193, '_type': 'table-file', 'ncols': 13}",78.326585290588,0.436798456548753,0.0,False,True,validation,False,Seller | Buyer | Neither | Unknown,4,CTBase,2d0d63da-ffcf-4f6e-941a-b8da922be43e,craigslist_bargains,ENTAILMENT,False,12,bigscience/T0_3B,0,True,guaranteed_true,prompts/general_fixed_choice.yaml,ANLI,['validation'],4,,,GenFC,,False,['Dialogue'],,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,guaranteed true,,cross_task,craigslist,,,,False,,,False,,True,,,False,False,CTBase.GenFC.anli.guaranteed_true.LenNorm,Craigslist,,,,,,,,,,,,,,,,,,,,,19.5,12.0,12
27.75959512646448,41.57782515991471,0.8023735869858445,4.184412967205048,2.0,0.6548105639280456,0.0,0.0,,,,125.623,3.3864734196662902,2.21,41.70096021947874,0.7979395475387573,0.9777013859047148,0.800003226730335,0.9777013859047148,1.79,34.7,"{'ncols': 11, 'nrows': 1000, 'sha256': '0e9c6638cf88abc8bda943d8d83bd881928a50e99d63a4a8eff978c9edb45468', 'artifact_path': 'wandb-client-artifact://hnjfsij2d523284551qysmo5g4lyqdc2o1owjosl59amtq8zxtzvlc2pdxm0fg0w0oa3vpnsr5233j363anx6vz60n3vvay5c5c1odbeej37508gd4j4ffd4qg9w7vts:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://hnjfsij2d523284551qysmo5g4lyqdc2o1owjosl59amtq8zxtzvlc2pdxm0fg0w0oa3vpnsr5233j363anx6vz60n3vvay5c5c1odbeej37508gd4j4ffd4qg9w7vts:latest/predictions.table.json', 'path': 'media/table/predictions_1_0e9c6638cf88abc8bda9.table.json', 'size': 602543, '_type': 'table-file'}",17.855443735735047,,,False,True,dev_r2,False,Yes | Maybe | No,4,CTBase,bab86d5a-4f9c-40db-b619-a7b7d5cae681,anli,ENTAILMENT,False,28,bigscience/T0_3B,0,True,take_the_following_as_truth,prompts/general_fixed_choice.yaml,ANLI,,3,,,GenFC,,True,['NLI'],,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,take the following as truth,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.anli.take_the_following_as_truth.LenNorm,ANLI R2,,,,,,,,,,,,,,,,,,,,,9.0,7.0,17
20.641439205955336,26.923076923076923,0.48372925334319,6.194234038118142,1.5159128978224456,0.2707038238193919,0.6459496631221218,47.64267990074442,0.0,0.684545449875108,4.0,190.9614740368509,5.145932547411128,2.6733668341708543,8.0,0.3637560408319061,0.569031226844787,0.6459401176937886,0.7316846744250818,1.8107202680067005,28.643216080402013,"{'_type': 'table-file', 'ncols': 13, 'nrows': 597, 'sha256': '9775190c20f01dcedc947f83e8a558987f011988ef131055edbb61d0d1bbfde9', 'artifact_path': 'wandb-client-artifact://11qbm9glzqgrg3aj4yodd9maw9q76fhyirqnp9upc7s9s7mvzbun54wjty1tc5mtsva178d91wp4xm78073puv8n56ffcjwkjq0x7miz4lmqm2vwyr03ztsqaem8ak9g:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://11qbm9glzqgrg3aj4yodd9maw9q76fhyirqnp9upc7s9s7mvzbun54wjty1tc5mtsva178d91wp4xm78073puv8n56ffcjwkjq0x7miz4lmqm2vwyr03ztsqaem8ak9g:latest/predictions.table.json', 'path': 'media/table/predictions_1_9775190c20f01dcedc94.table.json', 'size': 514056}",78.37238892984527,0.5566618262220877,0.0,False,True,validation,False,Seller | Buyer | Neither | Unknown,4,CTBase,9e078fb4-505b-413c-bb5e-3cd16ddcf5d7,craigslist_bargains,ENTAILMENT,False,12,bigscience/T0_3B,0,True,does_this_imply,prompts/general_fixed_choice.yaml,ANLI,['validation'],4,,,GenFC,,False,['Dialogue'],,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,does this imply,,cross_task,craigslist,,,,False,,,False,,True,,,False,False,CTBase.GenFC.anli.does_this_imply.LenNorm,Craigslist,,,,,,,,,,,,,,,,,,,,,7.0,6.0,23
27.989750347756058,42.038216560509554,0.830599711087285,4.063306883811951,2.0,0.6202056862979634,0.0,0.0,,,,119.623,3.315120492458344,2.218,41.93103448275862,0.7481863913536072,0.9759487691472332,0.7958195093662674,0.9759487691472332,1.782,35.0,"{'sha256': '78c4f3211076ededa758393edf0b19ce9eb4cc3792a42f15bb490b94ab813d3d', 'artifact_path': 'wandb-client-artifact://606dzf5sfg51khzd3efbv3caee5n2i3zj64ywoijq3h5qwmbmunk7vmtmzgrde4b6evobycd125umv0gfw4xalk63kg2uilrb60mzxnd8t7rezh9w7q1yhn8rv08y453:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://606dzf5sfg51khzd3efbv3caee5n2i3zj64ywoijq3h5qwmbmunk7vmtmzgrde4b6evobycd125umv0gfw4xalk63kg2uilrb60mzxnd8t7rezh9w7q1yhn8rv08y453:latest/predictions.table.json', 'path': 'media/table/predictions_1_78c4f3211076ededa758.table.json', 'size': 573453, '_type': 'table-file', 'ncols': 11, 'nrows': 1000}",17.855443735735047,,,False,True,dev_r2,False,Yes | Maybe | No,4,CTBase,a850110d-f1a3-49b4-949a-d3bfe9f81344,anli,ENTAILMENT,False,28,bigscience/T0_3B,0,True,justified_in_saying,prompts/general_fixed_choice.yaml,ANLI,,3,,,GenFC,,True,['NLI'],,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,justified in saying,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.anli.justified_in_saying.LenNorm,ANLI R2,,,,,,,,,,,,,,,,,,,,,3.5,4.0,11
18.06438207193808,31.221719457013577,0.4837825834803812,6.861658825147491,2.080402010050251,0.3965594630732492,0.4879463399624255,16.286644951140065,0.0,0.4329084495403859,4.0,180.5075376884422,5.899056438225598,2.251256281407035,24.749163879598665,0.5296939373815079,0.9353575421408508,0.5868731446117091,0.8410845458207643,1.6683417085427137,21.943048576214405,"{'sha256': 'c98905689a644459c876163f97524714c7545850e6832a70bb029489c3b747db', 'artifact_path': 'wandb-client-artifact://13ra9gctba3ykzs04vqovq04jsafnxhwr34ulwuceh4oi54iai8vb7d8jla4l04tf96x775ookbn8rf0tyyxxflfoimyvx1apfgx5klpqpl9qrno1o43mvvqysk1s7rb:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://13ra9gctba3ykzs04vqovq04jsafnxhwr34ulwuceh4oi54iai8vb7d8jla4l04tf96x775ookbn8rf0tyyxxflfoimyvx1apfgx5klpqpl9qrno1o43mvvqysk1s7rb:latest/predictions.table.json', 'path': 'media/table/predictions_1_c98905689a644459c876.table.json', 'size': 514374, '_type': 'table-file', 'ncols': 13, 'nrows': 597}",78.326585290588,0.3716091152034335,0.0,False,True,validation,False,Seller | Buyer | Neither | Unknown,4,CTBase,fb4f8144-37f5-4977-88da-37a5d0bfd0e8,craigslist_bargains,ENTAILMENT,False,12,bigscience/T0_3B,0,True,must_be_true,prompts/general_fixed_choice.yaml,ANLI,['validation'],4,,,GenFC,,False,['Dialogue'],,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,must be true,,cross_task,craigslist,,,,False,,,False,,True,,,False,False,CTBase.GenFC.anli.must_be_true.LenNorm,Craigslist,,,,,,,,,,,,,,,,,,,,,27.0,19.0,14
28.00558129001116,38.90214797136039,0.7851073957460033,4.400562274098396,2.0,0.6017673428691046,0.0,0.0,,,,123.623,3.636604395866394,2.01,45.1145958986731,0.7639578782320022,0.9999499987499374,0.73312724224944,0.9999499987499374,1.99,35.0,"{'size': 588711, '_type': 'table-file', 'ncols': 11, 'nrows': 1000, 'sha256': 'bd391c67a3d0bcd239be9729da333e609e343addacfdafd4e5521b468c2bf180', 'artifact_path': 'wandb-client-artifact://32nf73q35l5xoexx0bxzchqrfh4lnjxaczhebop59ek3hwl7fvh7chb4z5c211ycqfh8jhfkgs8l3l7tk38qdu1ul46mv7s706x8z6k03883ob00yvjrcsuoyetqrr4k:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://32nf73q35l5xoexx0bxzchqrfh4lnjxaczhebop59ek3hwl7fvh7chb4z5c211ycqfh8jhfkgs8l3l7tk38qdu1ul46mv7s706x8z6k03883ob00yvjrcsuoyetqrr4k:latest/predictions.table.json', 'path': 'media/table/predictions_1_bd391c67a3d0bcd239be.table.json'}",17.855443735735047,,,False,True,dev_r2,False,Yes | Maybe | No,4,CTBase,9b613182-c6ab-4427-9221-3d68f6d62765,anli,ENTAILMENT,False,28,bigscience/T0_3B,0,True,based_on_the_previous_passage,prompts/general_fixed_choice.yaml,ANLI,,3,,,GenFC,,True,['NLI'],,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,based on the previous passage,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.anli.based_on_the_previous_passage.LenNorm,ANLI R2,,,,,,,,,,,,,,,,,,,,,3.5,3.0,15
18.142973668574324,31.79916317991632,0.4200384027259948,6.865379887809306,2.2780569514237854,0.4317617941516842,0.4734890383666265,13.745704467353953,0.0,0.4095908401399801,4.0,183.5075376884422,5.87299873920741,1.5443886097152428,27.027027027027025,0.5827903084619162,0.8701967488136266,0.5286561571924113,0.8379395938546574,2.1775544388609718,21.440536013400337,"{'ncols': 13, 'nrows': 597, 'sha256': 'eebfe2788b42e2da546bee9c9ab08db4fe7ad59f701ebb3176724d1a63a2e9cb', 'artifact_path': 'wandb-client-artifact://958dryw1kzvaq9y0zds2kxtd07cv8ihyhzsuokhkvymn6u5fp91on957tpcewpmfc274c2tk0peps4n42kry49k724w02phwlaonkr7bft9k8pgq5kuik5dbput1xwpc:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://958dryw1kzvaq9y0zds2kxtd07cv8ihyhzsuokhkvymn6u5fp91on957tpcewpmfc274c2tk0peps4n42kry49k724w02phwlaonkr7bft9k8pgq5kuik5dbput1xwpc:latest/predictions.table.json', 'path': 'media/table/predictions_1_eebfe2788b42e2da546b.table.json', 'size': 524880, '_type': 'table-file'}",78.326585290588,0.3025757780822152,0.0,False,True,validation,False,Seller | Buyer | Neither | Unknown,4,CTBase,bab86d5a-4f9c-40db-b619-a7b7d5cae681,craigslist_bargains,ENTAILMENT,False,12,bigscience/T0_3B,0,True,take_the_following_as_truth,prompts/general_fixed_choice.yaml,ANLI,['validation'],4,,,GenFC,,False,['Dialogue'],,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,take the following as truth,,cross_task,craigslist,,,,False,,,False,,True,,,False,False,CTBase.GenFC.anli.take_the_following_as_truth.LenNorm,Craigslist,,,,,,,,,,,,,,,,,,,,,29.0,18.0,17
24.86315000448688,43.31797235023041,0.820755771211805,4.100203725278377,2.0,0.650738454954833,0.0,0.0,,,,112.434,3.269517790555954,2.504,31.27147766323024,0.8306859347224236,0.8637036528810098,0.8400619228445757,0.8637036528810098,1.496,32.6,"{'ncols': 11, 'nrows': 1000, 'sha256': '0530864ddf4c29786ab154a3b9aa4bd76df87d2c78f8226fff1140e2b3641a7e', 'artifact_path': 'wandb-client-artifact://142f635jsm8etgzlp51nrx05ioytxg980fzzwx1lurbmav2y5kxetojr9mcfnh46xcarizbsefv4kpsupmmztupfzjb34vwfad9almmpkml5f9op3sd9fwh14rtxtyvb:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://142f635jsm8etgzlp51nrx05ioytxg980fzzwx1lurbmav2y5kxetojr9mcfnh46xcarizbsefv4kpsupmmztupfzjb34vwfad9almmpkml5f9op3sd9fwh14rtxtyvb:latest/predictions.table.json', 'path': 'media/table/predictions_1_0530864ddf4c29786ab1.table.json', 'size': 546698, '_type': 'table-file'}",17.88970776731694,,,False,True,dev_r2,False,Yes | Maybe | No,4,CTBase,620aa3fc-d5eb-46f5-a1ee-4c754527aa97,anli,ENTAILMENT,False,28,bigscience/T0_3B,0,True,GPT_3_style,prompts/general_fixed_choice.yaml,ANLI,,3,,,GenFC,,True,['NLI'],,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,GPT-3 style,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.anli.GPT_3_style.LenNorm,ANLI R2,,,,,,,,,,,,,,,,,,,,,64.5,42.0,4
27.8976880756511,39.16570104287369,0.8524240079553033,4.482067589282989,2.0,0.6076387408807169,0.0,0.0,,,,121.623,3.737353945016861,2.06,44.5273631840796,0.7447136442661285,0.9981983770774222,0.8035602986714399,0.9981983770774222,1.94,34.8,"{'path': 'media/table/predictions_1_af1fefaee501266881d8.table.json', 'size': 581784, '_type': 'table-file', 'ncols': 11, 'nrows': 1000, 'sha256': 'af1fefaee501266881d81a91af74e82769146a56e251d25a9b8a8dcf5df5554f', 'artifact_path': 'wandb-client-artifact://ljzcc5rzw5nonvy8j1bl6it0im9921pgu85f8m8906blvx9wrf8mi0f7h49855zgp5s2tat0llbcofkcbmhpsu8dk42wfdq6azynaq34z9da4t0uqntdb6sjo2q0e8l5:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://ljzcc5rzw5nonvy8j1bl6it0im9921pgu85f8m8906blvx9wrf8mi0f7h49855zgp5s2tat0llbcofkcbmhpsu8dk42wfdq6azynaq34z9da4t0uqntdb6sjo2q0e8l5:latest/predictions.table.json'}",17.855443735735047,,,False,True,dev_r2,False,Yes | Maybe | No,4,CTBase,ec249357-e672-4e7d-b8b6-d97ed7d090c5,anli,ENTAILMENT,False,28,bigscience/T0_3B,0,True,claim_true_false_inconclusive,prompts/general_fixed_choice.yaml,ANLI,,3,,,GenFC,,True,['NLI'],,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,claim true/false/inconclusive,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.anli.claim_true_false_inconclusive.LenNorm,ANLI R2,,,,,,,,,,,,,,,,,,,,,7.5,5.0,13
10.947918118332018,26.36363636363636,0.576972216559207,6.278112700636463,1.5175879396984924,0.2942859157269071,0.5226291712503416,7.719298245614035,0.0,1.08575609101722,4.0,177.5075376884422,4.799356278462626,2.9447236180904524,9.70873786407767,0.3930003311566172,0.2870046293727364,0.6416289042440425,0.5527485912323057,1.5376884422110553,17.252931323283082,"{'_latest_artifact_path': 'wandb-client-artifact://ffvyj929t17zpe94tv56tbyqzp7d3hnbesxoy9u17c6y1db3lq7b9sn4e0vfhtg84klpoj9brvz3gsr3ffzwap6d6uc3ib085rtzroirzttodczyle2480y4sdkl7i59:latest/predictions.table.json', 'path': 'media/table/predictions_1_e4226c7319a45f96cef7.table.json', 'size': 507780, '_type': 'table-file', 'ncols': 13, 'nrows': 597, 'sha256': 'e4226c7319a45f96cef7697ae67db38a3a19342dd5a530949e5abce6941b8209', 'artifact_path': 'wandb-client-artifact://ffvyj929t17zpe94tv56tbyqzp7d3hnbesxoy9u17c6y1db3lq7b9sn4e0vfhtg84klpoj9brvz3gsr3ffzwap6d6uc3ib085rtzroirzttodczyle2480y4sdkl7i59:latest/predictions.table.json'}",78.326585290588,0.602078463477177,0.0,False,True,validation,False,Seller | Buyer | Neither | Unknown,4,CTBase,a850110d-f1a3-49b4-949a-d3bfe9f81344,craigslist_bargains,ENTAILMENT,False,12,bigscience/T0_3B,0,True,justified_in_saying,prompts/general_fixed_choice.yaml,ANLI,['validation'],4,,,GenFC,,False,['Dialogue'],,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,justified in saying,,cross_task,craigslist,,,,False,,,False,,True,,,False,False,CTBase.GenFC.anli.justified_in_saying.LenNorm,Craigslist,,,,,,,,,,,,,,,,,,,,,52.5,60.0,11
25.87157641249181,42.13592233009709,0.7335413370560974,3.8530987303256974,2.0,0.6839190636816936,0.0,0.0,,,,120.623,3.039880657196045,2.394,35.478806907378335,0.8132180731296539,0.9191104395011516,0.7514095362751847,0.9191104395011516,1.606,33.0,"{'path': 'media/table/predictions_1_1db3b10adb468601f32e.table.json', 'size': 567402, '_type': 'table-file', 'ncols': 11, 'nrows': 1000, 'sha256': '1db3b10adb468601f32e33f0cd75c32c92aae46b7f2f6527d61646765e5268bc', 'artifact_path': 'wandb-client-artifact://15dkhims3ztev18s04mpkju6r9e2eh858kh5vt7vwxxntek0a385flstxljqh2tfyjpmbsukaqkog88u28hyocobjj9ly0ruiwtm6g6bh7qvmrfsquu1nf9k8dj0fete:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://15dkhims3ztev18s04mpkju6r9e2eh858kh5vt7vwxxntek0a385flstxljqh2tfyjpmbsukaqkog88u28hyocobjj9ly0ruiwtm6g6bh7qvmrfsquu1nf9k8dj0fete:latest/predictions.table.json'}",17.855443735735047,,,False,True,dev_r2,False,Yes | Maybe | No,4,CTBase,c4ed37ae-d7d7-4197-a725-ef2152fa3b1f,anli,ENTAILMENT,False,28,bigscience/T0_3B,0,True,can_we_infer,prompts/general_fixed_choice.yaml,ANLI,,3,,,GenFC,,True,['NLI'],,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,can we infer,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.anli.can_we_infer.LenNorm,ANLI R2,,,,,,,,,,,,,,,,,,,,,52.0,34.0,12
12.930062942542827,28.793774319066145,0.5388462258743111,6.582600619525366,1.9363484087102176,0.360863858163499,0.4475528838070428,8.934707903780067,0.0,0.4875376480108929,4.0,181.5075376884422,5.621823050468611,2.4656616415410384,13.9917695473251,0.4732399210458624,0.8648603102237495,0.5688936088994052,0.8180517648756988,1.5979899497487438,17.42043551088777,"{'_type': 'table-file', 'ncols': 13, 'nrows': 597, 'sha256': '85c154bf57050e682652e12fd6118af1f0f7ee684bb58102fe2f868bab70e48e', 'artifact_path': 'wandb-client-artifact://3fxezc26btyt9hw0n3zdx0ue504cdymxezsfk83g4corcm6dwscn7qentb366w9a8x8gy4e7zzm2r065xb08uzzpbmy7hwberlevkikpq9kkn0wafve5bxk86zin8hjh:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://3fxezc26btyt9hw0n3zdx0ue504cdymxezsfk83g4corcm6dwscn7qentb366w9a8x8gy4e7zzm2r065xb08uzzpbmy7hwberlevkikpq9kkn0wafve5bxk86zin8hjh:latest/predictions.table.json', 'path': 'media/table/predictions_1_85c154bf57050e682652.table.json', 'size': 516660}",78.326585290588,0.3974266426793816,0.0,False,True,validation,False,Seller | Buyer | Neither | Unknown,4,CTBase,9b613182-c6ab-4427-9221-3d68f6d62765,craigslist_bargains,ENTAILMENT,False,12,bigscience/T0_3B,0,True,based_on_the_previous_passage,prompts/general_fixed_choice.yaml,ANLI,['validation'],4,,,GenFC,,False,['Dialogue'],,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,based on the previous passage,,cross_task,craigslist,,,,False,,,False,,True,,,False,False,CTBase.GenFC.anli.based_on_the_previous_passage.LenNorm,Craigslist,,,,,,,,,,,,,,,,,,,,,50.5,52.0,15
18.355963250440123,49.46564885496183,1.18577283728629,5.631958151936531,1.997,1.0306210118217425,0.0546900356555012,0.0,,,,126.051,3.4037650775909425,2.954,5.602240896358544,2.228193074345589,0.2998066043301915,1.1490954631947767,0.3043008379876729,1.049,33.4,"{'ncols': 11, 'nrows': 1000, 'sha256': '4e67b8bfa8bca57262e4a1a0911e5afe14a647115a6cf6d2ba2dad4a1dc66e3e', 'artifact_path': 'wandb-client-artifact://m6ii6310frbbvf8j4j6ezhqgv9nxi9mc1j9egm25toc7iyeeddt4cff7x4p78fuea9p2tgq7sifrfvw1rhv5pmk5s9usnor7cyaqskjcvce1mjyei9rfhns0bact5jk3:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://m6ii6310frbbvf8j4j6ezhqgv9nxi9mc1j9egm25toc7iyeeddt4cff7x4p78fuea9p2tgq7sifrfvw1rhv5pmk5s9usnor7cyaqskjcvce1mjyei9rfhns0bact5jk3:latest/predictions.table.json', 'path': 'media/table/predictions_1_4e67b8bfa8bca57262e4.table.json', 'size': 593553, '_type': 'table-file'}",17.873231353059808,,,False,True,dev_r2,False,Yes | Maybe | No,4,CTBase,ed215962-8e51-45e7-b025-6e822f877098,anli,CLASSIFICATION,False,28,bigscience/T0_3B,0,True,sentence_to_concepts,prompts/general_fixed_choice.yaml,CommonGen,,3,,,GenFC,,False,['NLI'],,True,False,GeneralFixedChoice,False,False,False,,,prompts,,,True,sentence to concepts,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.common_gen.sentence_to_concepts.LenNorm,ANLI R2,,,,,,,,,,,,,,,,,,,,,29.0,84.0,13
14.509565745520804,31.011235955056183,0.4647148448722806,7.545029511603478,2.030150753768844,0.505254950324325,0.1710020052982267,0.0,0.0,0.4844555607193478,4.0,171.5075376884422,6.058619626203374,2.1993299832495814,27.027027027027025,1.0019543246807563,0.9799324251078344,0.6108784601939702,0.9576992417082912,1.7705192629815745,19.09547738693467,"{'_latest_artifact_path': 'wandb-client-artifact://aryuejvynx68imglx54m8vru07nuf4d4gpaiyfhgex26v0d2ce9xb4hznird7lmyhax1uo1209i1buaa67syf5bm612pzgqrebrqvyl6zwzwu5mqzz6yhss30dav1w6h:latest/predictions.table.json', 'path': 'media/table/predictions_1_2be9f4afe777d7b6efe9.table.json', 'size': 491696, '_type': 'table-file', 'ncols': 13, 'nrows': 597, 'sha256': '2be9f4afe777d7b6efe9aad588eef16257ef4d7c993b82fbd6957c7856f1f081', 'artifact_path': 'wandb-client-artifact://aryuejvynx68imglx54m8vru07nuf4d4gpaiyfhgex26v0d2ce9xb4hznird7lmyhax1uo1209i1buaa67syf5bm612pzgqrebrqvyl6zwzwu5mqzz6yhss30dav1w6h:latest/predictions.table.json'}",78.326585290588,0.3701825254832753,0.0,False,True,validation,False,Seller | Buyer | Neither | Unknown,4,CTBase,620aa3fc-d5eb-46f5-a1ee-4c754527aa97,craigslist_bargains,ENTAILMENT,False,12,bigscience/T0_3B,0,True,GPT_3_style,prompts/general_fixed_choice.yaml,ANLI,['validation'],4,,,GenFC,,False,['Dialogue'],,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,GPT-3 style,,cross_task,craigslist,,,,False,,,False,,True,,,False,False,CTBase.GenFC.anli.GPT_3_style.LenNorm,Craigslist,,,,,,,,,,,,,,,,,,,,,42.0,42.0,4
18.595596361472413,49.12012241775058,1.2920741599400554,6.572440334796905,1.998,1.229227925111111,0.0446766158073773,0.0,,,,122.051,4.029811894416809,2.948,6.666666666666667,2.5426284403800965,0.3182703253525216,1.283191477384468,0.321066971206943,1.054,33.300000000000004,"{'size': 575986, '_type': 'table-file', 'ncols': 11, 'nrows': 1000, 'sha256': '076f912b5fa2a8a6278785465887f5927e9fb6db07753bf402734a761069e4d8', 'artifact_path': 'wandb-client-artifact://wj4ipwgvwpexfv12vt7b455djl2u0zlhkosjsy4eprbzkol2k1p901vm2we9huxy1mbjkje2i6nfdpnm8k6gl7jj3crhghx5hb20nkmdfaao5fpdtiixunh1h19yrbwc:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://wj4ipwgvwpexfv12vt7b455djl2u0zlhkosjsy4eprbzkol2k1p901vm2we9huxy1mbjkje2i6nfdpnm8k6gl7jj3crhghx5hb20nkmdfaao5fpdtiixunh1h19yrbwc:latest/predictions.table.json', 'path': 'media/table/predictions_1_076f912b5fa2a8a62787.table.json'}",17.873231353059808,,,False,True,dev_r2,False,Yes | Maybe | No,4,CTBase,b7012213-04c4-424d-85fb-39d63d8a0ca2,anli,CLASSIFICATION,False,28,bigscience/T0_3B,0,True,topics_from_the_sentence,prompts/general_fixed_choice.yaml,CommonGen,,3,,,GenFC,,False,['NLI'],,True,False,GeneralFixedChoice,False,False,False,,,prompts,,,True,topics from the sentence,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.common_gen.topics_from_the_sentence.LenNorm,ANLI R2,,,,,,,,,,,,,,,,,,,,,34.0,83.0,8
15.855485160984728,27.257240204429305,0.552506988501501,5.264859096488761,1.6633165829145728,0.3073319115292748,0.5835928589936571,22.424242424242426,0.0,0.6611453101063893,4.0,179.5075376884422,4.200478568947695,2.775544388609715,13.740458015267173,0.403235217434677,0.5459197640067348,0.5959440872279965,0.6737708897146432,1.5611390284757118,21.105527638190956,"{'_type': 'table-file', 'ncols': 13, 'nrows': 597, 'sha256': 'd0ab26515300fa7dfb793fdb50b14ce58f5b1bcad8803227a2f634367332fcdc', 'artifact_path': 'wandb-client-artifact://blmsx8y8tzdareu6zprm5y3miff8zy6kbx5e83rwbw0vvtpdwtvzwl2flz8o9m09d2au2oxe39g98diluosyi6bykli89tspbuxnr2ijlq8pqnuj3q607hihp387fx4s:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://blmsx8y8tzdareu6zprm5y3miff8zy6kbx5e83rwbw0vvtpdwtvzwl2flz8o9m09d2au2oxe39g98diluosyi6bykli89tspbuxnr2ijlq8pqnuj3q607hihp387fx4s:latest/predictions.table.json', 'path': 'media/table/predictions_1_d0ab26515300fa7dfb79.table.json', 'size': 512309}",78.326585290588,0.5030563271082823,0.0,False,True,validation,False,Seller | Buyer | Neither | Unknown,4,CTBase,ec249357-e672-4e7d-b8b6-d97ed7d090c5,craigslist_bargains,ENTAILMENT,False,12,bigscience/T0_3B,0,True,claim_true_false_inconclusive,prompts/general_fixed_choice.yaml,ANLI,['validation'],4,,,GenFC,,False,['Dialogue'],,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,claim true/false/inconclusive,,cross_task,craigslist,,,,False,,,False,,True,,,False,False,CTBase.GenFC.anli.claim_true_false_inconclusive.LenNorm,Craigslist,,,,,,,,,,,,,,,,,,,,,30.5,32.0,13
26.330089176858944,30.49327354260089,0.5898589487354539,1.973273329794407,1.999,0.5119875076402239,0.0547631262803722,0.0,,,,138.051,1.2931263231039047,1.672,48.49699398797595,0.6801470066905022,0.9446777228240328,0.4984655903418362,0.9427401550798608,2.329,34.4,"{'ncols': 11, 'nrows': 1000, 'sha256': '46279d8b1308f2b31b217b4974eba7cf9199ce0157712241c222c6e003e55249', 'artifact_path': 'wandb-client-artifact://ixanlkandld61lvfs36tzng93d3oea17agcbjmr1lve73zc9689ktf2tqdinjl7ae5p1js73kcw63ckbyzexnkm8jdpntiwf9tudnu4jdzuqt4cl3t717xijukhqmrza:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://ixanlkandld61lvfs36tzng93d3oea17agcbjmr1lve73zc9689ktf2tqdinjl7ae5p1js73kcw63ckbyzexnkm8jdpntiwf9tudnu4jdzuqt4cl3t717xijukhqmrza:latest/predictions.table.json', 'path': 'media/table/predictions_1_46279d8b1308f2b31b21.table.json', 'size': 652112, '_type': 'table-file'}",17.873231353059804,,,False,True,dev_r2,False,Yes | Maybe | No,4,CTBase,fc76beb7-c258-412f-a623-42fc8d2331b6,anli,COMPLETION,False,28,bigscience/T0_3B,0,True,fill_in_the_blank_with_instruction_and_choices,prompts/general_fixed_choice.yaml,NumerSense,,3,,,GenFC,,False,['NLI'],,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,fill_in_the_blank_with_instruction_and_choices,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.numer_sense.fill_in_the_blank_with_instruction_and_choices.LenNorm,ANLI R2,,,,,,,,,,,,,,,,,,,,,13.5,25.0,20
27.950628745036965,30.046948356807512,0.5196465313439379,6.149739360489837,1.9112227805695143,0.3053417764924973,0.7616155879462118,52.43619489559166,0.0,0.5394901885858533,4.0,178.5075376884422,5.2370691331387365,2.40536013400335,29.31937172774869,0.3731800387652475,0.752330658498798,0.5911045552241669,0.762572817343786,1.6834170854271358,34.33835845896148,"{'sha256': '782a968111face4f5a01a74ea3bc37c06d65e8df8e7d50e24221f9df6e1e7333', 'artifact_path': 'wandb-client-artifact://1278w6p82hfl4rz2d3auhmdxgi19acgnwj5coknibd75skf59shohw8ysgndplh419g9f79lsckqyq0ck2b656tppg03cl310ytivb06pj74yjqsbo6k9vpg7lmwhe55:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://1278w6p82hfl4rz2d3auhmdxgi19acgnwj5coknibd75skf59shohw8ysgndplh419g9f79lsckqyq0ck2b656tppg03cl310ytivb06pj74yjqsbo6k9vpg7lmwhe55:latest/predictions.table.json', 'path': 'media/table/predictions_1_782a968111face4f5a01.table.json', 'size': 503838, '_type': 'table-file', 'ncols': 13, 'nrows': 597}",78.326585290588,0.4716100878182732,0.0,False,True,validation,False,Seller | Buyer | Neither | Unknown,4,CTBase,c4ed37ae-d7d7-4197-a725-ef2152fa3b1f,craigslist_bargains,ENTAILMENT,False,12,bigscience/T0_3B,0,True,can_we_infer,prompts/general_fixed_choice.yaml,ANLI,['validation'],4,,,GenFC,,False,['Dialogue'],,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,can we infer,,cross_task,craigslist,,,,False,,,False,,True,,,False,False,CTBase.GenFC.anli.can_we_infer.LenNorm,Craigslist,,,,,,,,,,,,,,,,,,,,,4.0,2.0,12
20.37317804781768,46.16626311541566,1.092267363483142,6.388414456129074,2.0,0.9547057309014816,0.0,0.0,,,,125.051,4.926537115097046,2.812,14.95327102803738,1.4618773410320285,0.5836574337742989,1.136088639308562,0.5836574337742988,1.188,31.8,"{'nrows': 1000, 'sha256': '275d0b013159166bbb58dbe8a172c2dfd5261cb639fd5f489894f952ece2b3d6', 'artifact_path': 'wandb-client-artifact://33nomyxdtl11qkqquxjwqkkew9qri6teqbcj7r3ndhsaq67y2g4i662bulurjz11x2lfffqveeppl8rvcjj2m7v1213p05plzrxohjy3451cnn7hug34f16owqkyqfrm:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://33nomyxdtl11qkqquxjwqkkew9qri6teqbcj7r3ndhsaq67y2g4i662bulurjz11x2lfffqveeppl8rvcjj2m7v1213p05plzrxohjy3451cnn7hug34f16owqkyqfrm:latest/predictions.table.json', 'path': 'media/table/predictions_1_275d0b013159166bbb58.table.json', 'size': 580874, '_type': 'table-file', 'ncols': 11}",17.873231353059808,,,False,True,dev_r2,False,Yes | Maybe | No,4,CTBase,cacee36c-e2b7-458e-9d51-6fcfd83842b4,anli,COMPLETION,False,28,bigscience/T0_3B,0,True,fill_in_the_blank_before_sentence,prompts/general_fixed_choice.yaml,NumerSense,,3,,,GenFC,,False,['NLI'],,False,False,GeneralFixedChoice,False,False,False,,,prompts,,,True,fill_in_the_blank_before_sentence,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.numer_sense.fill_in_the_blank_before_sentence.LenNorm,ANLI R2,,,,,,,,,,,,,,,,,,,,,78.0,74.0,11
18.594643789569663,23.326133909287257,1.4298808789604878,2.11491182501392,2.1390284757118927,0.4662697644575204,1.1144404944206507,35.53299492385787,7.582938388625592,0.7448214649954433,2.494137353433836,165.39865996649917,0.8358978122922044,2.7939698492462317,7.936507936507936,0.5341925477262718,0.6989562587796513,1.237585109228435,1.108880252214899,2.57286432160804,22.948073701842542,"{'artifact_path': 'wandb-client-artifact://47vzx9iobblm1vmmfg3yz2sip38faa3dvylmq41i3078rl0armrk6mk74zkcsw2oph4u1qkcf528pqh0gfatom3dw5xx4nilb2ll56aml1vu6s2oy5iipxhfj7e9okoq:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://47vzx9iobblm1vmmfg3yz2sip38faa3dvylmq41i3078rl0armrk6mk74zkcsw2oph4u1qkcf528pqh0gfatom3dw5xx4nilb2ll56aml1vu6s2oy5iipxhfj7e9okoq:latest/predictions.table.json', 'path': 'media/table/predictions_1_5659fda6aca27ce3cbd4.table.json', 'size': 487399, '_type': 'table-file', 'ncols': 13, 'nrows': 597, 'sha256': '5659fda6aca27ce3cbd43291c4134ff994c1a12f4edd9fc687663f6804c44af2'}",78.15334236504172,0.6016787911231573,1.3482599249978249,False,True,validation,False,Seller | Buyer | Neither | Unknown,4,CTBase,ed215962-8e51-45e7-b025-6e822f877098,craigslist_bargains,CLASSIFICATION,False,12,bigscience/T0_3B,0,True,sentence_to_concepts,prompts/general_fixed_choice.yaml,CommonGen,['validation'],4,,,GenFC,,False,['Dialogue'],,True,False,GeneralFixedChoice,False,False,False,,,prompts,,,True,sentence to concepts,,cross_task,craigslist,,,,False,,,False,,True,,,False,False,CTBase.GenFC.common_gen.sentence_to_concepts.LenNorm,Craigslist,,,,,,,,,,,,,,,,,,,,,24.0,13.0,13
26.7143466629768,36.80555555555556,0.66852492603649,3.5619598313868046,2.0,0.6064797778532763,0.0,0.0,,,,142.051,2.8002759841419755,2.062,43.33748443337485,0.761683847244829,0.9980761493994332,0.6629093945888358,0.9980761493994332,1.938,33.300000000000004,"{'nrows': 1000, 'sha256': 'bf32766bcd566b56f59d1a5f37691ca65a124594960df7600e667ae4d6e13be9', 'artifact_path': 'wandb-client-artifact://19qvz22usuavlr2xpz60vsqw656o22f3pora27bvtponeonnlbyicchm5zbmxxbcpllifzcfb4xplxdqm0shusj9kiek0qc8685nn26q51x9i91smc9haypfwhwz14r5:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://19qvz22usuavlr2xpz60vsqw656o22f3pora27bvtponeonnlbyicchm5zbmxxbcpllifzcfb4xplxdqm0shusj9kiek0qc8685nn26q51x9i91smc9haypfwhwz14r5:latest/predictions.table.json', 'path': 'media/table/predictions_1_bf32766bcd566b56f59d.table.json', 'size': 661779, '_type': 'table-file', 'ncols': 11}",17.873231353059804,,,False,True,dev_r2,False,Yes | Maybe | No,4,CTBase,5d8e8d21-8059-4373-bbf2-a25cbe1e6960,anli,COMPLETION,False,28,bigscience/T0_3B,0,True,fill_in_the_blank_with_choices_before,prompts/general_fixed_choice.yaml,NumerSense,,3,,,GenFC,,False,['NLI'],,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,fill_in_the_blank_with_choices_before,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.numer_sense.fill_in_the_blank_with_choices_before.LenNorm,ANLI R2,,,,,,,,,,,,,,,,,,,,,34.0,21.0,24
18.146330891918133,26.08695652173913,1.4172621800315572,2.9683805206912246,2.018425460636516,0.5294807639078417,1.156727695424384,36.45833333333333,1.1904761904761905,1.1328264928143628,2.9045226130653266,160.47068676716918,1.154918167459306,2.782244556113903,8.849557522123893,0.6806358604175561,0.5546994180454058,1.1911233350756103,0.9857560956680336,2.2948073701842544,24.288107202680067,"{'sha256': '509b7da2edf65a86f2e31d210aab713b66de822488d30e987af7888f568588d5', 'artifact_path': 'wandb-client-artifact://y8vi8qm8vkyj6fmyvlwixnc1gxwmpjux7537221qfuc84w7250zwrx3nev5ho46g2ltiyc7qhrguuz5mosamh65oa1zk98qeacfd7p2coz3honma2muz1jcp5xdwzuk4:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://y8vi8qm8vkyj6fmyvlwixnc1gxwmpjux7537221qfuc84w7250zwrx3nev5ho46g2ltiyc7qhrguuz5mosamh65oa1zk98qeacfd7p2coz3honma2muz1jcp5xdwzuk4:latest/predictions.table.json', 'path': 'media/table/predictions_1_509b7da2edf65a86f2e3.table.json', 'size': 474226, '_type': 'table-file', 'ncols': 13, 'nrows': 597}",78.1171728355754,0.849686392636095,1.3657437270149215,False,True,validation,False,Seller | Buyer | Neither | Unknown,4,CTBase,b7012213-04c4-424d-85fb-39d63d8a0ca2,craigslist_bargains,CLASSIFICATION,False,12,bigscience/T0_3B,0,True,topics_from_the_sentence,prompts/general_fixed_choice.yaml,CommonGen,['validation'],4,,,GenFC,,False,['Dialogue'],,True,False,GeneralFixedChoice,False,False,False,,,prompts,,,True,topics from the sentence,,cross_task,craigslist,,,,False,,,False,,True,,,False,False,CTBase.GenFC.common_gen.topics_from_the_sentence.LenNorm,Craigslist,,,,,,,,,,,,,,,,,,,,,18.0,17.0,8
17.534599179967913,49.16540212443096,0.9804099766053386,8.687902332901954,2.0,1.1366916977211825,0.0,0.0,,,,153.051,6.1668949184417725,2.97,3.43839541547278,2.521007414460182,0.2431049156228644,1.1120210255853158,0.2431049156228643,1.03,33.0,"{'artifact_path': 'wandb-client-artifact://wjugssjag98ueik5tvjz177y6q8g6g19yskrh3bd4pic70n228lekyuyzolhd5q1lnpi29u6xfq80fujg3rynfltwjdsmxuh7gg01vr43a4t5w6jxk5bgna0cahic863:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://wjugssjag98ueik5tvjz177y6q8g6g19yskrh3bd4pic70n228lekyuyzolhd5q1lnpi29u6xfq80fujg3rynfltwjdsmxuh7gg01vr43a4t5w6jxk5bgna0cahic863:latest/predictions.table.json', 'path': 'media/table/predictions_1_8d3b66a8228f231bccd0.table.json', 'size': 697857, '_type': 'table-file', 'ncols': 11, 'nrows': 1000, 'sha256': '8d3b66a8228f231bccd0a22af98077a70cb8fdc7bf67f82523e87a1b2ef768b5'}",17.873231353059804,,,False,True,dev_r2,False,Yes | Maybe | No,4,CTBase,4e9da2b8-2502-44a7-a7da-ae62f2d554c9,anli,COMPLETION,False,28,bigscience/T0_3B,0,True,fill_in_the_blank_with_instruction,prompts/general_fixed_choice.yaml,NumerSense,,3,,,GenFC,,False,['NLI'],,False,False,GeneralFixedChoice,False,False,False,,,prompts,,,True,fill_in_the_blank_with_instruction,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.numer_sense.fill_in_the_blank_with_instruction.LenNorm,ANLI R2,,,,,,,,,,,,,,,,,,,,,52.0,86.0,39
6.801736613603474,0.0,0.5939602063003743,7.962894434904932,3.0016750418760467,0.6590948823103518,0.0408929836372988,0.0,0.0,1.227197915365548,3.9983249581239537,180.4706867671692,2.4127760181075564,1.0,27.20694645441389,4.322920501431828,0.0,0.4081106513473838,0.0,2.0,15.745393634840871,"{'path': 'media/table/predictions_1_372f566e91a7cee1e590.table.json', 'size': 532714, '_type': 'table-file', 'ncols': 13, 'nrows': 597, 'sha256': '372f566e91a7cee1e59077924faddde198418088875376239b26f945d0a01b31', 'artifact_path': 'wandb-client-artifact://oyl7ebhtn2gag5wpv5hs5lj0kcr90592m48otntm1tkfzyxo9c3c1ruivx70td946pikyjgrs3ym07l6zty5tec9ecntbdd3sw1ztgnvk53klp0riiz3l0cag6a7bl01:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://oyl7ebhtn2gag5wpv5hs5lj0kcr90592m48otntm1tkfzyxo9c3c1ruivx70td946pikyjgrs3ym07l6zty5tec9ecntbdd3sw1ztgnvk53klp0riiz3l0cag6a7bl01:latest/predictions.table.json'}",78.1171728355754,0.4618488567080585,0.0408929836372988,False,True,validation,False,Seller | Buyer | Neither | Unknown,4,CTBase,fc76beb7-c258-412f-a623-42fc8d2331b6,craigslist_bargains,COMPLETION,False,12,bigscience/T0_3B,0,True,fill_in_the_blank_with_instruction_and_choices,prompts/general_fixed_choice.yaml,NumerSense,['validation'],4,,,GenFC,,False,['Dialogue'],,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,fill_in_the_blank_with_instruction_and_choices,,cross_task,craigslist,,,,False,,,False,,True,,,False,False,CTBase.GenFC.numer_sense.fill_in_the_blank_with_instruction_and_choices.LenNorm,Craigslist,,,,,,,,,,,,,,,,,,,,,75.5,84.0,20
14.98956211887516,26.64576802507837,1.7329436369776416,3.0300892528577066,2.0217755443886096,0.6612561003946529,1.0097654817724473,2.877697841726619,30.434782608695656,1.346977671686329,1.887772194304857,163.47068676716918,0.8780591719513962,3.050251256281407,0.0,0.8050524092199814,0.2729958562694639,1.4426606454409867,1.082087423652914,3.040201005025126,19.597989949748744,"{'_type': 'table-file', 'ncols': 13, 'nrows': 597, 'sha256': '707d634371676bedd4be0da5b640de3cd14b66365af502b3e74f10bcd47a6821', 'artifact_path': 'wandb-client-artifact://aw05rbiqiobrsoo324r174fvxnjzmmzysq04q1ddcjhyy5am9g07p165rw8wqbra7cagrl3sz5c1axbs0ncwxejwzywey6yg79ya0qg00h4kkml2mj22uzsvqoz19gb0:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://aw05rbiqiobrsoo324r174fvxnjzmmzysq04q1ddcjhyy5am9g07p165rw8wqbra7cagrl3sz5c1axbs0ncwxejwzywey6yg79ya0qg00h4kkml2mj22uzsvqoz19gb0:latest/predictions.table.json', 'path': 'media/table/predictions_1_707d634371676bedd4be.table.json', 'size': 480854}",78.1171728355754,0.8386502998904254,1.239684901485953,False,True,validation,False,Seller | Buyer | Neither | Unknown,4,CTBase,cacee36c-e2b7-458e-9d51-6fcfd83842b4,craigslist_bargains,COMPLETION,False,12,bigscience/T0_3B,0,True,fill_in_the_blank_before_sentence,prompts/general_fixed_choice.yaml,NumerSense,['validation'],4,,,GenFC,,False,['Dialogue'],,False,False,GeneralFixedChoice,False,False,False,,,prompts,,,True,fill_in_the_blank_before_sentence,,cross_task,craigslist,,,,False,,,False,,True,,,False,False,CTBase.GenFC.numer_sense.fill_in_the_blank_before_sentence.LenNorm,Craigslist,,,,,,,,,,,,,,,,,,,,,38.0,35.0,11
26.38258434323592,30.67484662576688,0.6085734867153672,2.5456059786975382,2.0,0.5609139549757994,0.0,0.0,,,,138.051,1.7835859560370446,1.638,48.47290640394088,0.7620200226604938,0.9321780945720618,0.525773251996676,0.9321780945720618,2.362,34.599999999999994,"{'_latest_artifact_path': 'wandb-client-artifact://1382o93if9rzfc5grrstccag0g7ydojok7oo361qu1yxmezuip215oc2tewaemudl5rfb5zbzuq4naago0nld2ug58i74qxuxrj15vt0g8kdqyn8vwnue7rl0zoj4qnc:latest/predictions.table.json', 'path': 'media/table/predictions_1_10f2c0f442515138a972.table.json', 'size': 664045, '_type': 'table-file', 'ncols': 11, 'nrows': 1000, 'sha256': '10f2c0f442515138a97241f21f964db446290097d50685593c82e62f3aca3d5f', 'artifact_path': 'wandb-client-artifact://1382o93if9rzfc5grrstccag0g7ydojok7oo361qu1yxmezuip215oc2tewaemudl5rfb5zbzuq4naago0nld2ug58i74qxuxrj15vt0g8kdqyn8vwnue7rl0zoj4qnc:latest/predictions.table.json'}",17.873231353059804,,,False,True,dev_r2,False,Yes | Maybe | No,4,CTBase,1f959d92-dca8-4647-9840-69391dfbd000,anli,COMPLETION,False,28,bigscience/T0_3B,0,True,fill_in_the_blank_with_choices_after,prompts/general_fixed_choice.yaml,NumerSense,,3,,,GenFC,,False,['NLI'],,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,fill_in_the_blank_with_choices_after,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.numer_sense.fill_in_the_blank_with_choices_after.LenNorm,ANLI R2,,,,,,,,,,,,,,,,,,,,,11.0,24.0,20
7.348439375750301,2.0408163265306123,0.7791340733795449,8.424048978679345,2.9447236180904524,1.5646654940374678,0.2285189346914989,0.0,0.0,1.3122494554200164,4.0,184.4706867671692,3.0232666201727274,1.036850921273032,27.35294117647059,4.0885329030866,0.2689681247794847,1.4529395158257925,0.2343861862607946,2.018425460636516,15.745393634840871,"{'size': 535185, '_type': 'table-file', 'ncols': 13, 'nrows': 597, 'sha256': '9f2db3126dc092611edeb084165014356da1cf5a2bc8c3a04391f98facafbe47', 'artifact_path': 'wandb-client-artifact://ib3oh36cip2uyaqpq05ufra3zkk1zuzzwfwoook9d1sz0foysuxjbo1owihd7xzvjfhf81vzf0kqobseomf623zmnv2tmupi7xqetcwfbdjrjz6fglfelq4f2vjspl5r:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://ib3oh36cip2uyaqpq05ufra3zkk1zuzzwfwoook9d1sz0foysuxjbo1owihd7xzvjfhf81vzf0kqobseomf623zmnv2tmupi7xqetcwfbdjrjz6fglfelq4f2vjspl5r:latest/predictions.table.json', 'path': 'media/table/predictions_1_9f2db3126dc092611ede.table.json'}",78.1171728355754,0.4715195188670246,0.0,False,True,validation,False,Seller | Buyer | Neither | Unknown,4,CTBase,5d8e8d21-8059-4373-bbf2-a25cbe1e6960,craigslist_bargains,COMPLETION,False,12,bigscience/T0_3B,0,True,fill_in_the_blank_with_choices_before,prompts/general_fixed_choice.yaml,NumerSense,['validation'],4,,,GenFC,,False,['Dialogue'],,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,fill_in_the_blank_with_choices_before,,cross_task,craigslist,,,,False,,,False,,True,,,False,False,CTBase.GenFC.numer_sense.fill_in_the_blank_with_choices_before.LenNorm,Craigslist,,,,,,,,,,,,,,,,,,,,,75.5,80.0,24
18.164483649648044,47.59689922480621,1.1808541819801217,7.2629879002571105,2.0,1.1175815408519905,0.0,0.0,,,,151.051,5.244249402999878,2.914,6.896551724137931,2.0187384972572326,0.4057141851106515,1.206562820432035,0.4057141851106515,1.086,32.0,"{'ncols': 11, 'nrows': 1000, 'sha256': '6245c3288bda26fccaf442962ce1f46f3fe818b9cf57821e977c218386bc766c', 'artifact_path': 'wandb-client-artifact://183aour3j0foet1v9ydzxuep0nk7po9jw75b8hvfbiehlbemqqbid332e4w30m3mi8z5z7hnxjwppt0w7s00hf04q441l25aknagbos43ge9ebqy4h8j3zgt2l2hpnh6:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://183aour3j0foet1v9ydzxuep0nk7po9jw75b8hvfbiehlbemqqbid332e4w30m3mi8z5z7hnxjwppt0w7s00hf04q441l25aknagbos43ge9ebqy4h8j3zgt2l2hpnh6:latest/predictions.table.json', 'path': 'media/table/predictions_1_6245c3288bda26fccaf4.table.json', 'size': 669930, '_type': 'table-file'}",17.873231353059804,,,False,True,dev_r2,False,Yes | Maybe | No,4,CTBase,c97e7bbf-b7f0-4cee-ada5-431ce7d606cc,anli,CLASSIFICATION,False,28,bigscience/T0_3B,0,True,semantic_relations_nominials_without_options,prompts/general_fixed_choice.yaml,SemEval2010,,3,,,GenFC,,False,['NLI'],,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,semantic relations nominials without options,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.sem_eval_2010_task_8.semantic_relations_nominials_without_options.LenNorm,ANLI R2,,,,,,,,,,,,,,,,,,,,,75.0,85.0,37
8.064426702151252,24.8502994011976,1.5077486153252078,4.754183170583779,2.030150753768844,1.0438760095353476,0.6592433691887729,0.0,7.4074074074074066,2.228374311472703,1.256281407035176,191.4706867671692,1.1202116563691566,3.0268006700167502,0.0,1.40559720274192,0.1615004461399524,0.9683654033813712,0.7303259415943599,3.686767169179229,14.90787269681742,"{'nrows': 597, 'sha256': '69e1854adf859df5714f99fbeaa370851606c27d424106b04b044c567ea84b56', 'artifact_path': 'wandb-client-artifact://z4jruazdd2y507ovtnqsggk4gzhtl3ge1rlr0kw858tost9p7heditwf96f58jlrtrktty7n76nt66vdh4u8lh5g2hte1mm7qwg8ht0bcxqajlvx6ys8nzvwebpmd4fn:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://z4jruazdd2y507ovtnqsggk4gzhtl3ge1rlr0kw858tost9p7heditwf96f58jlrtrktty7n76nt66vdh4u8lh5g2hte1mm7qwg8ht0bcxqajlvx6ys8nzvwebpmd4fn:latest/predictions.table.json', 'path': 'media/table/predictions_1_69e1854adf859df5714f.table.json', 'size': 550612, '_type': 'table-file', 'ncols': 13}",78.1171728355754,0.9490799392744756,0.7432430912355507,False,True,validation,False,Seller | Buyer | Neither | Unknown,4,CTBase,4e9da2b8-2502-44a7-a7da-ae62f2d554c9,craigslist_bargains,COMPLETION,False,12,bigscience/T0_3B,0,True,fill_in_the_blank_with_instruction,prompts/general_fixed_choice.yaml,NumerSense,['validation'],4,,,GenFC,,False,['Dialogue'],,False,False,GeneralFixedChoice,False,False,False,,,prompts,,,True,fill_in_the_blank_with_instruction,,cross_task,craigslist,,,,False,,,False,,True,,,False,False,CTBase.GenFC.numer_sense.fill_in_the_blank_with_instruction.LenNorm,Craigslist,,,,,,,,,,,,,,,,,,,,,80.0,75.0,39
22.3651578757776,43.87755102040816,0.7739711520629029,6.47271477663517,2.0,0.8029474858430243,0.0,0.0,,,,141.051,5.37342434078455,2.686,23.21792260692464,1.0992904358506204,0.7276015393056834,0.8812958026662614,0.7276015393056834,1.314,31.5,"{'size': 645038, '_type': 'table-file', 'ncols': 11, 'nrows': 1000, 'sha256': '33a785769843681f318b7c6e0a773721b52282c14cca20046dc207617cf6e839', 'artifact_path': 'wandb-client-artifact://tql5rsha4w6udld0ym6jodz78tzzt2xk3598xjynrz2bb3heb8ugov2mfithkrkajtax13v1ym21s8qyk1gxk5stdat2cb19q5wbjs56ya1srxs5s84eu7ncdn096t1b:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://tql5rsha4w6udld0ym6jodz78tzzt2xk3598xjynrz2bb3heb8ugov2mfithkrkajtax13v1ym21s8qyk1gxk5stdat2cb19q5wbjs56ya1srxs5s84eu7ncdn096t1b:latest/predictions.table.json', 'path': 'media/table/predictions_1_33a785769843681f318b.table.json'}",17.873231353059804,,,False,True,dev_r2,False,Yes | Maybe | No,4,CTBase,5d7123a8-4ed4-42ce-bcfb-4af415962efc,anli,CLASSIFICATION,False,28,bigscience/T0_3B,0,True,semantically_related_nominials_with_options,prompts/general_fixed_choice.yaml,SemEval2010,,3,,,GenFC,,False,['NLI'],,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,semantically related nominials with options,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.sem_eval_2010_task_8.semantically_related_nominials_with_options.LenNorm,ANLI R2,,,,,,,,,,,,,,,,,,,,,82.5,66.0,17
19.355452333554528,0.0,0.6160777465719259,8.517072120603405,3.0016750418760467,0.5808235369152406,0.0408929836372988,53.0909090909091,0.0,0.4050929993640638,3.9983249581239537,180.4706867671692,1.803392653089872,1.4690117252931325,24.330900243309003,6.308586468149469,0.499038802930886,0.4585080747970644,0.499038802930886,1.5309882747068675,32.83082077051927,"{'artifact_path': 'wandb-client-artifact://vq3xi722pm21kbt0k6fhz72raonn62mez2rbsmjrc5ymm66qom1v2zlvpwpzcm29p4t4pnaqcqiqb33ura76olauuz0knwdgz2p65xawwyf78y39hh56nmqyr076mkba:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://vq3xi722pm21kbt0k6fhz72raonn62mez2rbsmjrc5ymm66qom1v2zlvpwpzcm29p4t4pnaqcqiqb33ura76olauuz0knwdgz2p65xawwyf78y39hh56nmqyr076mkba:latest/predictions.table.json', 'path': 'media/table/predictions_1_faa2aeb2225abfb85aea.table.json', 'size': 539731, '_type': 'table-file', 'ncols': 13, 'nrows': 597, 'sha256': 'faa2aeb2225abfb85aea6db12a3f8a9d763e3893160ca124e516fa2f0349338b'}",78.1171728355754,0.308763096122906,0.0408929836372988,False,True,validation,False,Seller | Buyer | Neither | Unknown,4,CTBase,1f959d92-dca8-4647-9840-69391dfbd000,craigslist_bargains,COMPLETION,False,12,bigscience/T0_3B,0,True,fill_in_the_blank_with_choices_after,prompts/general_fixed_choice.yaml,NumerSense,['validation'],4,,,GenFC,,False,['Dialogue'],,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,fill_in_the_blank_with_choices_after,,cross_task,craigslist,,,,False,,,False,,True,,,False,False,CTBase.GenFC.numer_sense.fill_in_the_blank_with_choices_after.LenNorm,Craigslist,,,,,,,,,,,,,,,,,,,,,5.0,11.0,20
23.11212945072357,44.63519313304721,0.7698507940923408,5.17136946952343,2.0,0.8167696000792826,0.0,0.0,,,,163.051,4.059122041463852,2.664,24.701195219123505,1.112247428059578,0.7477325725150671,0.8460584045912123,0.747732572515067,1.336,32.2,"{'_type': 'table-file', 'ncols': 11, 'nrows': 1000, 'sha256': 'b1e7492d7c0772c2a8002d09c8f0c208c467f6acd211b129d07d4930edcd4156', 'artifact_path': 'wandb-client-artifact://110j6jirj0ocw0e9tggr94bzqz355738bs9axjt6j65qzd64dlruisukc2l4dg0mnziip8ddo1bvx0ryakyq1584pvnvmtmfhx4i62wup1r5aa94k399xjcnx08q3fgr:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://110j6jirj0ocw0e9tggr94bzqz355738bs9axjt6j65qzd64dlruisukc2l4dg0mnziip8ddo1bvx0ryakyq1584pvnvmtmfhx4i62wup1r5aa94k399xjcnx08q3fgr:latest/predictions.table.json', 'path': 'media/table/predictions_1_b1e7492d7c0772c2a800.table.json', 'size': 720501}",17.873231353059804,,,False,True,dev_r2,False,Yes | Maybe | No,4,CTBase,202246b0-3f82-42b9-bc8d-d36997b5f2cb,anli,CLASSIFICATION,False,28,bigscience/T0_3B,0,True,semantic_relations_with_options,prompts/general_fixed_choice.yaml,SemEval2010,,3,,,GenFC,,False,['NLI'],,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,semantic relations with options,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.sem_eval_2010_task_8.semantic_relations_with_options.LenNorm,ANLI R2,,,,,,,,,,,,,,,,,,,,,72.0,57.0,40
14.148102247083632,7.339449541284404,0.9147125040827556,2.699064011949191,1.763819095477387,0.607784812881694,0.7543269848708678,5.673758865248227,39.657631954350926,1.4321069493765008,2.018425460636516,189.4706867671692,0.6409454130048129,3.882747068676717,3.92156862745098,0.6260116495678772,0.473400144164276,0.879646895601289,0.7988667905280472,2.33500837520938,25.628140703517587,"{'ncols': 13, 'nrows': 597, 'sha256': '3136cffde7cb6d56505951ac53dc40060fbbaf736289158fc9f30bd2e6680fd2', 'artifact_path': 'wandb-client-artifact://9lvcw9vdr5mpzd1gi723afm184zfodqnbfgkqmc8gxkvotrj58oxj1icr8fb5ebngobsd90tzaswqjh5m4w5kav1ue0bxpvawxwo24pxv8ct09sh0brpj0mxo285jn71:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://9lvcw9vdr5mpzd1gi723afm184zfodqnbfgkqmc8gxkvotrj58oxj1icr8fb5ebngobsd90tzaswqjh5m4w5kav1ue0bxpvawxwo24pxv8ct09sh0brpj0mxo285jn71:latest/predictions.table.json', 'path': 'media/table/predictions_1_3136cffde7cb6d565059.table.json', 'size': 534352, '_type': 'table-file'}",78.1171728355754,0.7081204497314116,0.9249902167376144,False,True,validation,False,Seller | Buyer | Neither | Unknown,4,CTBase,c97e7bbf-b7f0-4cee-ada5-431ce7d606cc,craigslist_bargains,CLASSIFICATION,False,12,bigscience/T0_3B,0,True,semantic_relations_nominials_without_options,prompts/general_fixed_choice.yaml,SemEval2010,['validation'],4,,,GenFC,,False,['Dialogue'],,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,semantic relations nominials without options,,cross_task,craigslist,,,,False,,,False,,True,,,False,False,CTBase.GenFC.sem_eval_2010_task_8.semantic_relations_nominials_without_options.LenNorm,Craigslist,,,,,,,,,,,,,,,,,,,,,14.0,46.0,37
23.41249801029038,45.33789563729684,1.100364649911323,3.9456193202734,1.99,0.9437617832619593,0.1090871211463571,0.0,,,,123.051,2.637236276626587,2.672,24.899598393574298,1.3083830436468125,0.7405511461067359,1.1223860336207208,0.741455325694003,1.338,32.7,"{'size': 582560, '_type': 'table-file', 'ncols': 11, 'nrows': 1000, 'sha256': 'bc38f7355d9be1759e5a2a398cc01d942fbeaf53f415983ddcbc7a5a9927798f', 'artifact_path': 'wandb-client-artifact://145k0tonu6rt4u0v1i2dnekm5hvrl6a0bbkw2hfin351i3xt4m5kmo74yvaktc8g5fr8zys7e50yanonhm1mwfnhhu7csq33bxx8i5uhf28bp13pcmmoeqx4nbid01jg:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://145k0tonu6rt4u0v1i2dnekm5hvrl6a0bbkw2hfin351i3xt4m5kmo74yvaktc8g5fr8zys7e50yanonhm1mwfnhhu7csq33bxx8i5uhf28bp13pcmmoeqx4nbid01jg:latest/predictions.table.json', 'path': 'media/table/predictions_1_bc38f7355d9be1759e5a.table.json'}",17.873231353059808,,,False,True,dev_r2,False,Yes | Maybe | No,4,CTBase,af4d550e-54b8-471e-97af-2b2c50a1382e,anli,SUMMARIZATION,False,28,bigscience/T0_3B,0,True,relatedwork_abstract,prompts/general_fixed_choice.yaml,Multi-XSci,,3,,,GenFC,,False,['NLI'],,False,False,GeneralFixedChoice,False,False,False,,,prompts,,,True,relatedwork_abstract,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.multi_x_science_sum.relatedwork_abstract.LenNorm,ANLI R2,,,,,,,,,,,,,,,,,,,,,61.5,54.0,9
16.91630178332306,20.45454545454546,0.6144851375635462,8.331176826103249,2.3785594639865995,0.4399062281735486,0.5851964424702013,21.27659574468085,0.0,0.4252628716991175,4.0,184.4706867671692,7.335956795531102,1.6917922948073705,25.93406593406593,0.5699571588730293,0.8978755703175835,0.6637224374350845,0.7798178996841255,1.92964824120603,20.268006700167504,"{'path': 'media/table/predictions_1_9901ee88c36aeaf4c9bf.table.json', 'size': 531427, '_type': 'table-file', 'ncols': 13, 'nrows': 597, 'sha256': '9901ee88c36aeaf4c9bf8a1b13ef11b8000f46cd76bba6baf93ac306c7788e92', 'artifact_path': 'wandb-client-artifact://fkq89eh7tpdl6olihv3tscfncjlm5bmr10dybpww1sornhuskd2jp9vz72mm759u1u3y0bj9vvxvn98v0d3r8g5cyfqzdawdvzi3jcxij3u7o70nr63gszkc79ejqltb:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://fkq89eh7tpdl6olihv3tscfncjlm5bmr10dybpww1sornhuskd2jp9vz72mm759u1u3y0bj9vvxvn98v0d3r8g5cyfqzdawdvzi3jcxij3u7o70nr63gszkc79ejqltb:latest/predictions.table.json'}",78.1171728355754,0.3342534393637363,0.0,False,True,validation,False,Seller | Buyer | Neither | Unknown,4,CTBase,5d7123a8-4ed4-42ce-bcfb-4af415962efc,craigslist_bargains,CLASSIFICATION,False,12,bigscience/T0_3B,0,True,semantically_related_nominials_with_options,prompts/general_fixed_choice.yaml,SemEval2010,['validation'],4,,,GenFC,,False,['Dialogue'],,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,semantically related nominials with options,,cross_task,craigslist,,,,False,,,False,,True,,,False,False,CTBase.GenFC.sem_eval_2010_task_8.semantically_related_nominials_with_options.LenNorm,Craigslist,,,,,,,,,,,,,,,,,,,,,33.5,26.0,17
24.47322907328973,44.52234881682735,1.0576961822485766,4.194849320054054,1.997,0.856937136365034,0.0546900356555012,0.0,,,,131.051,3.041362197160721,2.616,28.89733840304183,1.1534871228933334,0.787746152005835,1.067877396124148,0.788182085561452,1.387,33.0,"{'_type': 'table-file', 'ncols': 11, 'nrows': 1000, 'sha256': '73d691e2a1a52fbf3879b86d5854ef2058df19783d879bfc6d505646c3d36341', 'artifact_path': 'wandb-client-artifact://u612sjz46nbs8x534ro82d11n9bieibf0b2g86sl9x7i5mukvixgmzozjuy3j4ucpt2e0tvgi2gmu45jmeeq0pmcaftxqamyd1xsf1tazpz6tmltzjubel1lim6q8ogo:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://u612sjz46nbs8x534ro82d11n9bieibf0b2g86sl9x7i5mukvixgmzozjuy3j4ucpt2e0tvgi2gmu45jmeeq0pmcaftxqamyd1xsf1tazpz6tmltzjubel1lim6q8ogo:latest/predictions.table.json', 'path': 'media/table/predictions_1_73d691e2a1a52fbf3879.table.json', 'size': 624099}",17.873231353059804,,,False,True,dev_r2,False,Yes | Maybe | No,4,CTBase,3bd082cb-4e28-4eb7-9fa2-dd03f1f86219,anli,SUMMARIZATION,False,28,bigscience/T0_3B,0,True,abstract_relatedwork,prompts/general_fixed_choice.yaml,Multi-XSci,,3,,,GenFC,,False,['NLI'],,False,False,GeneralFixedChoice,False,False,False,,,prompts,,,True,abstract_relatedwork,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.multi_x_science_sum.abstract_relatedwork.LenNorm,ANLI R2,,,,,,,,,,,,,,,,,,,,,52.0,46.0,17
17.516539544547417,4.49438202247191,0.5076875723496416,8.370290489452369,2.9782244556113904,0.8484047774937028,0.1459498888495274,40.38929440389294,0.0,0.4472789305139027,4.0,206.4706867671692,6.049244018855007,1.2428810720268006,25.182481751824813,1.8737675400834584,0.4365661741157923,0.6980273918139741,0.457240412211191,1.778894472361809,25.79564489112228,"{'_latest_artifact_path': 'wandb-client-artifact://16bpwebyrir2bylmxbx9m6ddoucmnpvli2w94hwcwij3jsurecqm1jd4yz3wso47zvu1bjhd89rt1rhq0en75qxsm7wr44ovxbppiyz17r9fmg2gwcw36xu1foqgrzji:latest/predictions.table.json', 'path': 'media/table/predictions_1_a96d9990f3aa9af565e1.table.json', 'size': 576389, '_type': 'table-file', 'ncols': 13, 'nrows': 597, 'sha256': 'a96d9990f3aa9af565e137be4b1a82aadf38df91a5ba2b49792e93556f802357', 'artifact_path': 'wandb-client-artifact://16bpwebyrir2bylmxbx9m6ddoucmnpvli2w94hwcwij3jsurecqm1jd4yz3wso47zvu1bjhd89rt1rhq0en75qxsm7wr44ovxbppiyz17r9fmg2gwcw36xu1foqgrzji:latest/predictions.table.json'}",78.1171728355754,0.3297942665875824,0.0,False,True,validation,False,Seller | Buyer | Neither | Unknown,4,CTBase,202246b0-3f82-42b9-bc8d-d36997b5f2cb,craigslist_bargains,CLASSIFICATION,False,12,bigscience/T0_3B,0,True,semantic_relations_with_options,prompts/general_fixed_choice.yaml,SemEval2010,['validation'],4,,,GenFC,,False,['Dialogue'],,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,semantic relations with options,,cross_task,craigslist,,,,False,,,False,,True,,,False,False,CTBase.GenFC.sem_eval_2010_task_8.semantic_relations_with_options.LenNorm,Craigslist,,,,,,,,,,,,,,,,,,,,,12.5,21.0,40
23.78713602926824,44.54148471615721,1.1243042208698069,4.929611896455288,2.0,0.8733300228158798,0.0,0.0,,,,124.051,3.767031013727188,2.624,26.81992337164751,1.1625808827281,0.781424340547439,1.13467085134827,0.781424340547439,1.376,32.5,"{'_type': 'table-file', 'ncols': 11, 'nrows': 1000, 'sha256': '5499bd08453f64d98eee630a4ae091da6d19bc4ea01a9960ce9de7a9828614d9', 'artifact_path': 'wandb-client-artifact://ags6vihmkpn15yd9g9b6bfeoks852m8yyipvc4xjovsr46tt4et956lk7brbs6thazf5f1d6jrni98fyp0vwibgyxg08sfqr5cx6w4lzka8pm9zlrde3rhryayylolg5:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://ags6vihmkpn15yd9g9b6bfeoks852m8yyipvc4xjovsr46tt4et956lk7brbs6thazf5f1d6jrni98fyp0vwibgyxg08sfqr5cx6w4lzka8pm9zlrde3rhryayylolg5:latest/predictions.table.json', 'path': 'media/table/predictions_1_5499bd08453f64d98eee.table.json', 'size': 592197}",17.873231353059808,,,False,True,dev_r2,False,Yes | Maybe | No,4,CTBase,2bca0197-e3d4-4870-bd95-178411e52e09,anli,SUMMARIZATION,False,28,bigscience/T0_3B,0,True,ref_relatedwork,prompts/general_fixed_choice.yaml,Multi-XSci,,3,,,GenFC,,False,['NLI'],,False,False,GeneralFixedChoice,False,False,False,,,prompts,,,True,ref_relatedwork,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.multi_x_science_sum.ref_relatedwork.LenNorm,ANLI R2,,,,,,,,,,,,,,,,,,,,,66.5,52.0,10
13.801714992927868,25.742574257425744,1.4091234082736734,5.190885017515227,1.4740368509212731,1.3340976282568169,0.5222800983711445,0.0,29.464285714285715,1.4099837831616202,1.6348408710217754,161.47068676716918,0.6346763630009177,3.130653266331658,0.0,3.146224871352689,0.3370207565247681,0.7743228794034065,0.6243885701713836,3.760469011725293,18.592964824120603,"{'nrows': 597, 'sha256': 'ba9b361abd2d244218522f43b153dd1dcd4ffb831107ebc84d8374fa599738e7', 'artifact_path': 'wandb-client-artifact://kvokm4qg3xrw3kl7kfdv2ljj4p0805ol7slt81arulwi46h5jj1us5hbe9vcaqab7yu4pt62apeglnh10bkitd7tlmhwkw7ptse4resff695tl01868nf8do4swh444y:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://kvokm4qg3xrw3kl7kfdv2ljj4p0805ol7slt81arulwi46h5jj1us5hbe9vcaqab7yu4pt62apeglnh10bkitd7tlmhwkw7ptse4resff695tl01868nf8do4swh444y:latest/predictions.table.json', 'path': 'media/table/predictions_1_ba9b361abd2d24421852.table.json', 'size': 477835, '_type': 'table-file', 'ncols': 13}",78.1171728355754,1.041782236666957,0.6604339848764681,False,True,validation,False,Seller | Buyer | Neither | Unknown,4,CTBase,af4d550e-54b8-471e-97af-2b2c50a1382e,craigslist_bargains,SUMMARIZATION,False,12,bigscience/T0_3B,0,True,relatedwork_abstract,prompts/general_fixed_choice.yaml,Multi-XSci,['validation'],4,,,GenFC,,False,['Dialogue'],,False,False,GeneralFixedChoice,False,False,False,,,prompts,,,True,relatedwork_abstract,,cross_task,craigslist,,,,False,,,False,,True,,,False,False,CTBase.GenFC.multi_x_science_sum.relatedwork_abstract.LenNorm,Craigslist,,,,,,,,,,,,,,,,,,,,,45.0,48.0,9
21.16568744447791,46.86998394863564,0.9815913773690844,3.680980126440525,1.988,0.8394262297805987,0.1088852607105296,0.0,,,,124.051,2.324010491371155,2.826,16.627078384798097,1.3569696350693703,0.5636701162914352,1.0220377795926727,0.5704419339424478,1.186,32.7,"{'_latest_artifact_path': 'wandb-client-artifact://j6kdnm70zh3nojer7ywsuhdh5amdwxdz84q7tyzeow9djot8zvyrhr96jl58dxpkvxl6z6ijpueb19u9x2w4gvjwd0mau0e7vur5ytz7um7lffrmxu1kti5zya9r5id8:latest/predictions.table.json', 'path': 'media/table/predictions_1_bc28cb27a550ac974dde.table.json', 'size': 580427, '_type': 'table-file', 'ncols': 11, 'nrows': 1000, 'sha256': 'bc28cb27a550ac974dde074a9b261bcf0426538f219e21079bb75579e271cb12', 'artifact_path': 'wandb-client-artifact://j6kdnm70zh3nojer7ywsuhdh5amdwxdz84q7tyzeow9djot8zvyrhr96jl58dxpkvxl6z6ijpueb19u9x2w4gvjwd0mau0e7vur5ytz7um7lffrmxu1kti5zya9r5id8:latest/predictions.table.json'}",17.873231353059808,,,False,True,dev_r2,False,Yes | Maybe | No,4,CTBase,774b4349-0524-4a34-881b-b344f8f5c34e,anli,COMPLETION,False,28,bigscience/T0_3B,0,True,what_comes_next,prompts/general_fixed_choice.yaml,LAMBADA,,3,,,GenFC,,False,['NLI'],,False,False,GeneralFixedChoice,False,False,False,,,prompts,,,True,what comes next,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.craffel_openai_lambada.what_comes_next.LenNorm,ANLI R2,,,,,,,,,,,,,,,,,,,,,61.5,72.0,10
19.627117380690606,28.023032629558536,1.3456430973947715,4.687295326785226,1.743718592964824,1.2566009380876573,0.4662637852760997,0.0,50.48543689320388,1.1261637987104094,1.3500837520938025,169.47068676716918,0.6472511463229181,3.273031825795645,0.0,2.9138803817518992,0.4455170567984367,0.7165848823309849,0.6188866057624384,3.633165829145729,25.29313232830821,"{'nrows': 597, 'sha256': 'a6dfaf3be4aed27a0963f389255a361a79859e09d62015fd1cd2b09cb85f540c', 'artifact_path': 'wandb-client-artifact://rnmrh3rs2si37yepgxy89byweqvzakajoe3jhkbyqq2v4etyycxv4e2s1nysom4snfu25ejq5vhubvfe8389mnb39yys7y6zireztvtdw3ouzxpowjmyl6thijfwdxp5:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://rnmrh3rs2si37yepgxy89byweqvzakajoe3jhkbyqq2v4etyycxv4e2s1nysom4snfu25ejq5vhubvfe8389mnb39yys7y6zireztvtdw3ouzxpowjmyl6thijfwdxp5:latest/predictions.table.json', 'path': 'media/table/predictions_1_a6dfaf3be4aed27a0963.table.json', 'size': 502882, '_type': 'table-file', 'ncols': 13}",78.1171728355754,0.9693286297356076,0.6520583256022898,False,True,validation,False,Seller | Buyer | Neither | Unknown,4,CTBase,3bd082cb-4e28-4eb7-9fa2-dd03f1f86219,craigslist_bargains,SUMMARIZATION,False,12,bigscience/T0_3B,0,True,abstract_relatedwork,prompts/general_fixed_choice.yaml,Multi-XSci,['validation'],4,,,GenFC,,False,['Dialogue'],,False,False,GeneralFixedChoice,False,False,False,,,prompts,,,True,abstract_relatedwork,,cross_task,craigslist,,,,False,,,False,,True,,,False,False,CTBase.GenFC.multi_x_science_sum.abstract_relatedwork.LenNorm,Craigslist,,,,,,,,,,,,,,,,,,,,,15.5,10.0,17
22.58948023653906,45.54621848739496,1.1441501754345984,4.774720290541649,1.998,0.9313793929300273,0.0446766158073773,0.0,,,,125.051,3.4505273306369784,2.714,22.22222222222222,1.324192959904671,0.7001456991226898,1.1593626670381327,0.7007538797609328,1.288,32.4,"{'ncols': 11, 'nrows': 1000, 'sha256': '6c22c1cee7832c8c2fea1abb30bf10cf9bb8352228ca98ebb87ad40f482cb181', 'artifact_path': 'wandb-client-artifact://khu1qc09ysfgro8ifeazvm4sbb6l64szt5vuca0ljft9j3esz8fdfyyi8a3znobcsd4vo5fuxsyqtorywl8l1o0j4mfkfoqhgtyieurs2dn6ngh925nilfbwz1wj5agc:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://khu1qc09ysfgro8ifeazvm4sbb6l64szt5vuca0ljft9j3esz8fdfyyi8a3znobcsd4vo5fuxsyqtorywl8l1o0j4mfkfoqhgtyieurs2dn6ngh925nilfbwz1wj5agc:latest/predictions.table.json', 'path': 'media/table/predictions_1_6c22c1cee7832c8c2fea.table.json', 'size': 563077, '_type': 'table-file'}",17.873231353059808,,,False,True,dev_r2,False,Yes | Maybe | No,4,CTBase,4f08e9d4-bcff-4bc0-9902-87c497625d17,anli,COMPLETION,False,28,bigscience/T0_3B,0,True,GPT_3_style,prompts/general_fixed_choice.yaml,LAMBADA,,3,,,GenFC,,False,['NLI'],,False,False,GeneralFixedChoice,False,False,False,,,prompts,,,True,GPT-3 style,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.craffel_openai_lambada.GPT_3_style.LenNorm,ANLI R2,,,,,,,,,,,,,,,,,,,,,68.0,63.0,11
14.744193345888265,25.92592592592593,1.4124285138031438,4.37321558350095,1.5963149078726968,1.1829475387261292,0.5517019392853864,0.0,33.05084745762713,1.437177720381387,1.5544388609715245,162.47068676716918,0.6166384815171336,3.150753768844221,0.0,2.3193993816024294,0.3578087059078975,0.8625721433220224,0.6796006355298161,3.698492462311558,19.43048576214405,"{'_type': 'table-file', 'ncols': 13, 'nrows': 597, 'sha256': '13c4c5c644bde24cbc7eb0bd85f403936cd87bc2f2c2dbb6c78ccd1224f497dc', 'artifact_path': 'wandb-client-artifact://p6bu87buu5suhksytr6vftlclbgi75t6ubwyac7yoylapeoodpwu0lcntwwf5xzyydoecbny1bwjuw35kcvdbt6i20z1ytok8oslaj7q8utkmclydalgtnoiosb7kcvj:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://p6bu87buu5suhksytr6vftlclbgi75t6ubwyac7yoylapeoodpwu0lcntwwf5xzyydoecbny1bwjuw35kcvdbt6i20z1ytok8oslaj7q8utkmclydalgtnoiosb7kcvj:latest/predictions.table.json', 'path': 'media/table/predictions_1_13c4c5c644bde24cbc7e.table.json', 'size': 483879}",78.1171728355754,1.0456385783158777,0.7315351072205557,False,True,validation,False,Seller | Buyer | Neither | Unknown,4,CTBase,2bca0197-e3d4-4870-bd95-178411e52e09,craigslist_bargains,SUMMARIZATION,False,12,bigscience/T0_3B,0,True,ref_relatedwork,prompts/general_fixed_choice.yaml,Multi-XSci,['validation'],4,,,GenFC,,False,['Dialogue'],,False,False,GeneralFixedChoice,False,False,False,,,prompts,,,True,ref_relatedwork,,cross_task,craigslist,,,,False,,,False,,True,,,False,False,CTBase.GenFC.multi_x_science_sum.ref_relatedwork.LenNorm,Craigslist,,,,,,,,,,,,,,,,,,,,,39.0,38.0,10
23.32618411645767,43.26241134751773,1.202196666330296,4.900608245372772,1.999,0.9257333190672746,0.0316069612585582,0.0,,,,123.051,3.670700690031051,2.59,26.716141001855288,1.2299075553417205,0.807403244977378,1.2380768365303838,0.8075140865644388,1.411,31.6,"{'artifact_path': 'wandb-client-artifact://18vhqcfab3pj3cqhx810jflpbinoaiq4z3edg4v69vr6fgzp7bbmmq69yjpb3ktwnlu2ua3gxeh8fi896u6mfbfdjjsdl127hvndjidx0pqywbbj8gw3ffol8kwj7cdj:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://18vhqcfab3pj3cqhx810jflpbinoaiq4z3edg4v69vr6fgzp7bbmmq69yjpb3ktwnlu2ua3gxeh8fi896u6mfbfdjjsdl127hvndjidx0pqywbbj8gw3ffol8kwj7cdj:latest/predictions.table.json', 'path': 'media/table/predictions_1_6902620a3bd089d558b2.table.json', 'size': 572452, '_type': 'table-file', 'ncols': 11, 'nrows': 1000, 'sha256': '6902620a3bd089d558b2cbce56146721fb436ca2937bb49b6b277cc433b6dc9d'}",17.873231353059808,,,False,True,dev_r2,False,Yes | Maybe | No,4,CTBase,1ee5ddef-fffb-4b73-a2f7-f600ffac63cb,anli,COMPLETION,False,28,bigscience/T0_3B,0,True,ellipses,prompts/general_fixed_choice.yaml,LAMBADA,,3,,,GenFC,,False,['NLI'],,False,False,GeneralFixedChoice,False,False,False,,,prompts,,,True,ellipses,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.craffel_openai_lambada.ellipses.LenNorm,ANLI R2,,,,,,,,,,,,,,,,,,,,,80.5,55.0,11
10.870826709062005,24.48330683624801,1.3430702958623435,3.8935525364412538,1.4706867671691792,1.0531691488505597,0.5562753292378645,0.0,19.0,1.5564266008947365,1.6649916247906198,162.47068676716918,0.5097456741173263,3.087102177554439,0.0,1.8273802614291907,0.2992751902112757,0.6554926279531483,0.6358499557722892,3.777219430485762,16.08040201005025,"{'sha256': '6b1ed76c7f0765c00e588d0a884a637c3c37921764452c1e4f3d7874c1582d40', 'artifact_path': 'wandb-client-artifact://uv463wjjx8en6spri2h62pf9nlwjyq4exs081lv2f44spn8tchrra684gexrwigzgruzy5bs5lpl4u1mgb31j3k5r18t20l4bf1zxskkqvjy44gdzihknrhbp7lrggtb:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://uv463wjjx8en6spri2h62pf9nlwjyq4exs081lv2f44spn8tchrra684gexrwigzgruzy5bs5lpl4u1mgb31j3k5r18t20l4bf1zxskkqvjy44gdzihknrhbp7lrggtb:latest/predictions.table.json', 'path': 'media/table/predictions_1_6b1ed76c7f0765c00e58.table.json', 'size': 477138, '_type': 'table-file', 'ncols': 13, 'nrows': 597}",78.1171728355754,0.945552823553131,0.6811635588459685,False,True,validation,False,Seller | Buyer | Neither | Unknown,4,CTBase,774b4349-0524-4a34-881b-b344f8f5c34e,craigslist_bargains,COMPLETION,False,12,bigscience/T0_3B,0,True,what_comes_next,prompts/general_fixed_choice.yaml,LAMBADA,['validation'],4,,,GenFC,,False,['Dialogue'],,False,False,GeneralFixedChoice,False,False,False,,,prompts,,,True,what comes next,,cross_task,craigslist,,,,False,,,False,,True,,,False,False,CTBase.GenFC.craffel_openai_lambada.what_comes_next.LenNorm,Craigslist,,,,,,,,,,,,,,,,,,,,,69.5,61.0,10
24.0098138689688,45.47008547008547,1.0202540696630902,4.011652813017369,1.997,0.7926073121345719,0.0546900356555012,0.0,,,,135.051,2.9193677830696108,2.674,26.559356136820927,1.0922850299477578,0.7387313449421244,1.0188703478282246,0.7394315384131244,1.329,33.2,"{'sha256': 'aef58e0ecf272db7deceb526c0247b872fae98b347bf6e80825be23704d4ed77', 'artifact_path': 'wandb-client-artifact://125pt0cb8yc2rr3hqtho2p03eanjjxiyn6lx72vpbsep0ptojierhaqfpnlx1lucn4et9kc9m3tozv3w34ifsnh7ks00dh5c9svwg7r6bm1w9mbfdu6wl8b9uh3gk8ze:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://125pt0cb8yc2rr3hqtho2p03eanjjxiyn6lx72vpbsep0ptojierhaqfpnlx1lucn4et9kc9m3tozv3w34ifsnh7ks00dh5c9svwg7r6bm1w9mbfdu6wl8b9uh3gk8ze:latest/predictions.table.json', 'path': 'media/table/predictions_1_aef58e0ecf272db7dece.table.json', 'size': 633614, '_type': 'table-file', 'ncols': 11, 'nrows': 1000}",17.873231353059804,,,False,True,dev_r2,False,Yes | Maybe | No,4,CTBase,9a3f617f-628f-4fa5-9b74-47d0b166a487,anli,SUMMARIZATION,False,28,bigscience/T0_3B,0,True,read_below_DOC_write_abstract,prompts/general_fixed_choice.yaml,XSum,,3,,,GenFC,,False,['NLI'],,True,False,GeneralFixedChoice,False,False,False,,,prompts,,,True,read_below_DOC_write_abstract,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.xsum.read_below_DOC_write_abstract.LenNorm,ANLI R2,,,,,,,,,,,,,,,,,,,,,40.5,50.0,21
19.684034298553563,30.64516129032258,1.5980958724687375,2.2685281567437765,2.030150753768844,0.5721066185612952,1.0251913139529736,17.76504297994269,27.58620689655172,0.836229181369545,2.582914572864321,163.47068676716918,0.8429330413665005,2.78894472361809,2.73972602739726,0.589365934007731,0.7291570994453046,1.293845162627112,1.2233884815476297,2.597989949748744,22.948073701842542,"{'_latest_artifact_path': 'wandb-client-artifact://11c0qr7cqkkra2pgwkyzu3ru8267go7ejwnceej8xo8ezycentfb3bbza7h7w17ndmt82isojxt4d05rw5ig4nnfs4c2e3ryfzyp3ga9fq8p9zkkpn4vmit4a4qewq52:latest/predictions.table.json', 'path': 'media/table/predictions_1_daf7b2c6807661e2374b.table.json', 'size': 469710, '_type': 'table-file', 'ncols': 13, 'nrows': 597, 'sha256': 'daf7b2c6807661e2374be37e0b073b062755355b439c96845cff1d0be52b00ee', 'artifact_path': 'wandb-client-artifact://11c0qr7cqkkra2pgwkyzu3ru8267go7ejwnceej8xo8ezycentfb3bbza7h7w17ndmt82isojxt4d05rw5ig4nnfs4c2e3ryfzyp3ga9fq8p9zkkpn4vmit4a4qewq52:latest/predictions.table.json'}",78.1171728355754,0.7288829758882831,1.264875129490938,False,True,validation,False,Seller | Buyer | Neither | Unknown,4,CTBase,4f08e9d4-bcff-4bc0-9902-87c497625d17,craigslist_bargains,COMPLETION,False,12,bigscience/T0_3B,0,True,GPT_3_style,prompts/general_fixed_choice.yaml,LAMBADA,['validation'],4,,,GenFC,,False,['Dialogue'],,False,False,GeneralFixedChoice,False,False,False,,,prompts,,,True,GPT-3 style,,cross_task,craigslist,,,,False,,,False,,True,,,False,False,CTBase.GenFC.craffel_openai_lambada.GPT_3_style.LenNorm,Craigslist,,,,,,,,,,,,,,,,,,,,,24.0,9.0,11
21.401564364311284,44.83627204030227,0.9749033528885788,2.9785492304563523,1.971,0.7180560130050065,0.1736634676608756,0.0,,,,138.051,1.9340654833316804,2.717,19.368421052631582,1.044483747124672,0.6963555126514043,0.9524956781827209,0.7047382492812491,1.312,31.3,"{'ncols': 11, 'nrows': 1000, 'sha256': 'b47d82a3b1eeee704c411ab7cba3598151ddc452eb24900e030ca75f18af7c7a', 'artifact_path': 'wandb-client-artifact://uahqzongaf6mfl0n4tyxrv7n7p7p87pbf9glbx322e2z9av18efiawaa3f1z5a7j2c0o47z6hshbzbk0nbc7q98tdbyfbg9j1lh7llvxxs7w9qk3p22cy7plxvqqsbob:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://uahqzongaf6mfl0n4tyxrv7n7p7p87pbf9glbx322e2z9av18efiawaa3f1z5a7j2c0o47z6hshbzbk0nbc7q98tdbyfbg9j1lh7llvxxs7w9qk3p22cy7plxvqqsbob:latest/predictions.table.json', 'path': 'media/table/predictions_1_b47d82a3b1eeee704c41.table.json', 'size': 627273, '_type': 'table-file'}",17.873231353059804,,,False,True,dev_r2,False,Yes | Maybe | No,4,CTBase,4cfe4126-b9f5-44eb-8a98-973987c5f32e,anli,SUMMARIZATION,False,28,bigscience/T0_3B,0,True,college_roommate_asked_DOC_so_I_recap,prompts/general_fixed_choice.yaml,XSum,,3,,,GenFC,,False,['NLI'],,True,False,GeneralFixedChoice,False,False,False,,,prompts,,,True,college_roommate_asked_DOC_so_I_recap,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.xsum.college_roommate_asked_DOC_so_I_recap.LenNorm,ANLI R2,,,,,,,,,,,,,,,,,,,,,86.0,70.0,24
7.984323368938753,25.44378698224852,1.4209597682362278,5.756021949913434,1.849246231155779,1.2106440860042411,0.4222301816603016,0.0,6.493506493506493,2.2064025905264084,1.256281407035176,163.36683417085428,1.0109191651719698,3.013400335008375,0.0,2.538700194215056,0.1149815899613434,0.7523138595463106,0.505507546169442,3.88107202680067,15.2428810720268,"{'path': 'media/table/predictions_1_8ffb9dd0ca11fd1af59e.table.json', 'size': 475802, '_type': 'table-file', 'ncols': 13, 'nrows': 597, 'sha256': '8ffb9dd0ca11fd1af59e22a5de50eed5e412b95427cbe977c70e1db559a2ce89', 'artifact_path': 'wandb-client-artifact://gvo8gswdslgh88qnjuu0t9cfhjyng8djxku2a4fsjazls2j7wptr6b36gjewbacyezb92k84cu8z1fj6p6k3rq2tik6cimkylmtefhyh0whoaaz622y94w95z452mi4t:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://gvo8gswdslgh88qnjuu0t9cfhjyng8djxku2a4fsjazls2j7wptr6b36gjewbacyezb92k84cu8z1fj6p6k3rq2tik6cimkylmtefhyh0whoaaz622y94w95z452mi4t:latest/predictions.table.json'}",78.16068857415623,1.0495340054088411,0.6416438070155726,False,True,validation,False,Seller | Buyer | Neither | Unknown,4,CTBase,1ee5ddef-fffb-4b73-a2f7-f600ffac63cb,craigslist_bargains,COMPLETION,False,12,bigscience/T0_3B,0,True,ellipses,prompts/general_fixed_choice.yaml,LAMBADA,['validation'],4,,,GenFC,,False,['Dialogue'],,False,False,GeneralFixedChoice,False,False,False,,,prompts,,,True,ellipses,,cross_task,craigslist,,,,False,,,False,,True,,,False,False,CTBase.GenFC.craffel_openai_lambada.ellipses.LenNorm,Craigslist,,,,,,,,,,,,,,,,,,,,,78.0,76.0,11
22.85502151997123,44.74576271186441,1.1116313979573282,4.7763094419837,1.998,0.9239212822250452,0.0446766158073773,0.0,,,,127.051,3.48057048368454,2.694,23.81930184804928,1.29573895829916,0.7199749995659572,1.1355363090079595,0.7205109298268833,1.308,32.2,"{'_latest_artifact_path': 'wandb-client-artifact://pskstc9vh5ryt08galbdaxo3j8tc75hlhmlkqrsd5mw32b5fq23tz081wmhsidog80mqnzoco9opi0r8h0s4ffmmwouhvurqn0wefp612792c5ggqm4uimqe1u2gf8m6:latest/predictions.table.json', 'path': 'media/table/predictions_1_79baadcd86319e30dfb5.table.json', 'size': 581829, '_type': 'table-file', 'ncols': 11, 'nrows': 1000, 'sha256': '79baadcd86319e30dfb515193fc22a20e0f131dc692b4a77f4bf1c4daa05dbc8', 'artifact_path': 'wandb-client-artifact://pskstc9vh5ryt08galbdaxo3j8tc75hlhmlkqrsd5mw32b5fq23tz081wmhsidog80mqnzoco9opi0r8h0s4ffmmwouhvurqn0wefp612792c5ggqm4uimqe1u2gf8m6:latest/predictions.table.json'}",17.873231353059808,,,False,True,dev_r2,False,Yes | Maybe | No,4,CTBase,3d388a1e-3361-407b-baa7-61397cc58382,anli,SUMMARIZATION,False,28,bigscience/T0_3B,0,True,DOC_how_would_you_rephrase_few_words,prompts/general_fixed_choice.yaml,XSum,,3,,,GenFC,,False,['NLI'],,True,False,GeneralFixedChoice,False,False,False,,,prompts,,,True,DOC_how_would_you_rephrase_few_words,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.xsum.DOC_how_would_you_rephrase_few_words.LenNorm,ANLI R2,,,,,,,,,,,,,,,,,,,,,72.0,59.0,13
17.402173913043477,27.0,1.2928878664178074,3.5502029680327154,1.6030150753768844,1.0085617748994389,0.5654996943370934,0.0,42.60869565217392,1.0165096811912766,1.5309882747068675,173.47068676716918,0.5228844863086489,3.14070351758794,0.0,2.0108088005327898,0.3477154551157024,0.6823611698612976,0.6509213592408718,3.725293132328308,21.77554438860972,"{'_type': 'table-file', 'ncols': 13, 'nrows': 597, 'sha256': '0d057584460379c64d7fe44b9db1e1b36a4184b7d181e90a1aea55341ab52b86', 'artifact_path': 'wandb-client-artifact://99cl75y2fpyympbbsxqywnbxw96qpqz5oaedhmr916gor4p3v4ww14akqmdo0chk8jn2iyjkpgyl2g8nzahhunko9uqxrxskudi3r7ksnhgl9x9hrr37crsb7t4858ct:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://99cl75y2fpyympbbsxqywnbxw96qpqz5oaedhmr916gor4p3v4ww14akqmdo0chk8jn2iyjkpgyl2g8nzahhunko9uqxrxskudi3r7ksnhgl9x9hrr37crsb7t4858ct:latest/predictions.table.json', 'path': 'media/table/predictions_1_0d057584460379c64d7f.table.json', 'size': 512434}",78.1171728355754,0.7862568402551228,0.6929614027672566,False,True,validation,False,Seller | Buyer | Neither | Unknown,4,CTBase,9a3f617f-628f-4fa5-9b74-47d0b166a487,craigslist_bargains,SUMMARIZATION,False,12,bigscience/T0_3B,0,True,read_below_DOC_write_abstract,prompts/general_fixed_choice.yaml,XSum,['validation'],4,,,GenFC,,False,['Dialogue'],,True,False,GeneralFixedChoice,False,False,False,,,prompts,,,True,read_below_DOC_write_abstract,,cross_task,craigslist,,,,False,,,False,,True,,,False,False,CTBase.GenFC.xsum.read_below_DOC_write_abstract.LenNorm,Craigslist,,,,,,,,,,,,,,,,,,,,,28.0,22.0,21
22.785146578625618,44.38687392055268,1.1473729824436574,4.585782790780067,1.998,0.8904898862171098,0.0446766158073773,0.0,,,,127.051,3.348082782745361,2.65,23.968565815324165,1.237700008034706,0.7599342076785333,1.154639312060001,0.7603262457655924,1.352,31.8,"{'sha256': '865671ff9212cc25998083bf379485b4fd3911d5de993d7e650260e63d913b66', 'artifact_path': 'wandb-client-artifact://hn5soxpz51o2r8ysvrxj7mmt5ztye479umqfx8fsahfpbhmnr7xosuovsqoc34fqi7mbtotlr5hcfv6tlsh4r11xbsija0hckug2miac890ubtxgg3tuxu1fjkgjybud:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://hn5soxpz51o2r8ysvrxj7mmt5ztye479umqfx8fsahfpbhmnr7xosuovsqoc34fqi7mbtotlr5hcfv6tlsh4r11xbsija0hckug2miac890ubtxgg3tuxu1fjkgjybud:latest/predictions.table.json', 'path': 'media/table/predictions_1_865671ff9212cc259980.table.json', 'size': 578258, '_type': 'table-file', 'ncols': 11, 'nrows': 1000}",17.873231353059808,,,False,True,dev_r2,False,Yes | Maybe | No,4,CTBase,13c02904-e4e2-4b4f-b115-44b437d22041,anli,SUMMARIZATION,False,28,bigscience/T0_3B,0,True,DOC_write_summary_of_above,prompts/general_fixed_choice.yaml,XSum,,3,,,GenFC,,False,['NLI'],,True,False,GeneralFixedChoice,False,False,False,,,prompts,,,True,DOC_write_summary_of_above,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.xsum.DOC_write_summary_of_above.LenNorm,ANLI R2,,,,,,,,,,,,,,,,,,,,,78.0,61.0,13
16.65202782902692,27.5092936802974,1.188634275068862,2.002094197512871,2.257956448911223,0.5801616368089234,1.0388393108085543,28.818443804034583,10.2803738317757,0.6334868495787808,1.6314907872696818,176.47068676716918,0.7445921045252226,2.9815745393634843,0.0,0.6240152434088677,0.4992411661024364,0.8911517805899267,0.9484790581841714,3.1289782244556115,22.61306532663317,"{'sha256': 'a30fa11f987d6d848b91dd783a9df1535e590aeb586c9202a506fbb5639522be', 'artifact_path': 'wandb-client-artifact://139jvg83s70296v8zy8wip1hfy5xnosldqvz3r4rbdvaqewqb9yrl43vijj9o2l0diu63joohjwe29mri7j5ryhu42qpqptdcqqt3jmicvtd7t51n00uplqzi2ptt4x8:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://139jvg83s70296v8zy8wip1hfy5xnosldqvz3r4rbdvaqewqb9yrl43vijj9o2l0diu63joohjwe29mri7j5ryhu42qpqptdcqqt3jmicvtd7t51n00uplqzi2ptt4x8:latest/predictions.table.json', 'path': 'media/table/predictions_1_a30fa11f987d6d848b91.table.json', 'size': 508988, '_type': 'table-file', 'ncols': 13, 'nrows': 597}",78.1171728355754,0.517389812979701,1.1539227199210382,False,True,validation,False,Seller | Buyer | Neither | Unknown,4,CTBase,4cfe4126-b9f5-44eb-8a98-973987c5f32e,craigslist_bargains,SUMMARIZATION,False,12,bigscience/T0_3B,0,True,college_roommate_asked_DOC_so_I_recap,prompts/general_fixed_choice.yaml,XSum,['validation'],4,,,GenFC,,False,['Dialogue'],,True,False,GeneralFixedChoice,False,False,False,,,prompts,,,True,college_roommate_asked_DOC_so_I_recap,,cross_task,craigslist,,,,False,,,False,,True,,,False,False,CTBase.GenFC.xsum.college_roommate_asked_DOC_so_I_recap.LenNorm,Craigslist,,,,,,,,,,,,,,,,,,,,,26.0,28.0,24
19.98401217137921,47.33067729083665,0.7644762773849434,4.539563452720642,2.0,0.8202568317600991,0.0,0.0,,,,134.051,3.210093939781189,2.844,12.62135922330097,1.3294695129394531,0.5363431737236897,0.9029090752361424,0.5363431737236897,1.156,32.300000000000004,"{'size': 614376, '_type': 'table-file', 'ncols': 11, 'nrows': 1000, 'sha256': 'c501190b20ac16a1c3966261e71392b7d8b9f7e2896f7fcd1d8778f6dcfbc29a', 'artifact_path': 'wandb-client-artifact://3lcvzj5by3i48vpeifg9vr5huk2pd3b6vat277lus5fz0fmk4oazh2zn0rfrty0866qnlizb9of7cumzjmehoizy2mrrfkdgwvelcujvk9ecylw87oyzd72lqfwv3eee:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://3lcvzj5by3i48vpeifg9vr5huk2pd3b6vat277lus5fz0fmk4oazh2zn0rfrty0866qnlizb9of7cumzjmehoizy2mrrfkdgwvelcujvk9ecylw87oyzd72lqfwv3eee:latest/predictions.table.json', 'path': 'media/table/predictions_1_c501190b20ac16a1c396.table.json'}",17.873231353059804,,,False,True,dev_r2,False,Yes | Maybe | No,4,CTBase,5fa16d31-b513-480d-bd1b-1fa8c182fb76,anli,SENTIMENT,False,28,bigscience/T0_3B,0,True,bullish_neutral_bearish,prompts/general_fixed_choice.yaml,FinNews,,3,,,GenFC,,False,['NLI'],,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,bullish_neutral_bearish,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.financial_phrasebank_sentences_allagree.bullish_neutral_bearish.LenNorm,ANLI R2,,,,,,,,,,,,,,,,,,,,,69.5,76.0,9
10.591143840015484,26.17960426179604,1.5313901887899852,4.41818210717222,1.5343383584589614,1.080684273758569,0.6160147266664996,0.0,16.184971098265894,1.8819829623902864,1.6867671691792294,165.47068676716918,0.6549116718509489,3.0452261306532664,0.0,1.881287472930985,0.2077997299310084,0.9448783861617456,0.7464637642305957,3.733668341708543,16.750418760469014,"{'ncols': 13, 'nrows': 597, 'sha256': 'ab8b0622c26ed202e138af94ccd7d7d6c8d78347224fd4888cd5e1b170fc6dfc', 'artifact_path': 'wandb-client-artifact://6j7t7ibjt9nvgb5p299ooq36vqhre2cw6illmcgniykb9n38tebutl0lwdpwcygyasfp19eb4olp1sbl6d1dzjkcdom5ux2j5ymyymlmt1yl4nid39msovxqu3wz54ee:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://6j7t7ibjt9nvgb5p299ooq36vqhre2cw6illmcgniykb9n38tebutl0lwdpwcygyasfp19eb4olp1sbl6d1dzjkcdom5ux2j5ymyymlmt1yl4nid39msovxqu3wz54ee:latest/predictions.table.json', 'path': 'media/table/predictions_1_ab8b0622c26ed202e138.table.json', 'size': 481441, '_type': 'table-file'}",78.1171728355754,1.0954873739603708,0.7791519899940909,False,True,validation,False,Seller | Buyer | Neither | Unknown,4,CTBase,3d388a1e-3361-407b-baa7-61397cc58382,craigslist_bargains,SUMMARIZATION,False,12,bigscience/T0_3B,0,True,DOC_how_would_you_rephrase_few_words,prompts/general_fixed_choice.yaml,XSum,['validation'],4,,,GenFC,,False,['Dialogue'],,True,False,GeneralFixedChoice,False,False,False,,,prompts,,,True,DOC_how_would_you_rephrase_few_words,,cross_task,craigslist,,,,False,,,False,,True,,,False,False,CTBase.GenFC.xsum.DOC_how_would_you_rephrase_few_words.LenNorm,Craigslist,,,,,,,,,,,,,,,,,,,,,58.5,64.0,13
19.58203964652496,48.11320754716981,1.089921710968024,4.993654658079147,1.998,0.9645305312375266,0.0446766158073773,0.0,,,,125.051,3.329732228755951,2.878,10.63291139240506,1.6639224293231965,0.4786606313454241,1.158210472873512,0.4802332766479223,1.124,32.7,"{'ncols': 11, 'nrows': 1000, 'sha256': '69fa502c0454eb084ee974b8d64946b26f922786b8a2efba95c171d83ae1e410', 'artifact_path': 'wandb-client-artifact://gxy64v3t91ijn4hah3toygwuype3kybvk615fq0uobr9v1kyw6x5oz7un3bitax1gx601dxo0eleunhxqn0mowur3pttqzra31cdnj6y2uajh7innvof1622ic05ofai:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://gxy64v3t91ijn4hah3toygwuype3kybvk615fq0uobr9v1kyw6x5oz7un3bitax1gx601dxo0eleunhxqn0mowur3pttqzra31cdnj6y2uajh7innvof1622ic05ofai:latest/predictions.table.json', 'path': 'media/table/predictions_1_69fa502c0454eb084ee9.table.json', 'size': 609856, '_type': 'table-file'}",17.873231353059808,,,False,True,dev_r2,False,Yes | Maybe | No,4,CTBase,461efe04-6883-41e8-80f0-e722a75260fe,anli,SENTIMENT,False,28,bigscience/T0_3B,0,True,complementary_industries,prompts/general_fixed_choice.yaml,FinNews,,3,,,GenFC,,False,['NLI'],,False,False,GeneralFixedChoice,False,False,False,,,prompts,,,True,complementary_industries,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.financial_phrasebank_sentences_allagree.complementary_industries.LenNorm,ANLI R2,,,,,,,,,,,,,,,,,,,,,61.5,77.0,11
10.640812467396971,25.665101721439747,1.5168491707312108,3.466358451188309,1.559463986599665,0.9507250847598964,0.865434340150508,0.0,14.814814814814811,1.3953524065177445,1.9614740368509216,165.47068676716918,0.7230040563810212,3.0653266331658293,2.083333333333333,1.348001988289544,0.2848851815690124,1.0790914838629058,1.081911090778182,3.4137353433835846,16.24790619765494,"{'ncols': 13, 'nrows': 597, 'sha256': 'b5613c51565b75f0ce5666d1e38791ab4b12aa04c8e1854d20522e62738f04d6', 'artifact_path': 'wandb-client-artifact://13ib6xo6rfqbc3cqsh8otres1ybwpbtsp5lg18m3raary3cmwbdux9zqn6mfqatjsu7a0ajudg6xlsu0v6grvmd7q11tlpmxlvydqjp33ie8o47ornn7w0e44226d3g9:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://13ib6xo6rfqbc3cqsh8otres1ybwpbtsp5lg18m3raary3cmwbdux9zqn6mfqatjsu7a0ajudg6xlsu0v6grvmd7q11tlpmxlvydqjp33ie8o47ornn7w0e44226d3g9:latest/predictions.table.json', 'path': 'media/table/predictions_1_b5613c51565b75f0ce56.table.json', 'size': 478941, '_type': 'table-file'}",78.1171728355754,0.9137324509087202,0.8186620441050405,False,True,validation,False,Seller | Buyer | Neither | Unknown,4,CTBase,13c02904-e4e2-4b4f-b115-44b437d22041,craigslist_bargains,SUMMARIZATION,False,12,bigscience/T0_3B,0,True,DOC_write_summary_of_above,prompts/general_fixed_choice.yaml,XSum,['validation'],4,,,GenFC,,False,['Dialogue'],,True,False,GeneralFixedChoice,False,False,False,,,prompts,,,True,DOC_write_summary_of_above,,cross_task,craigslist,,,,False,,,False,,True,,,False,False,CTBase.GenFC.xsum.DOC_write_summary_of_above.LenNorm,Craigslist,,,,,,,,,,,,,,,,,,,,,66.0,63.0,13
24.04484121067542,40.22662889518414,1.11722863543369,4.2592645292282105,1.999,0.8956129907296546,0.0316069612585582,0.0,,,,122.051,3.0920589752197265,2.452,31.907894736842117,1.1672055540084838,0.8920179370393849,1.0637858611319722,0.8919635642782726,1.549,31.0,"{'size': 578244, '_type': 'table-file', 'ncols': 11, 'nrows': 1000, 'sha256': '914f95bb4eb354d8f552fa507b7bd2b0178013bc37d39f397171fb869256a123', 'artifact_path': 'wandb-client-artifact://pnfmmr2nbrvtlgjc77qwdzbc8i7wasyvn9703eregje77im4smi19hx5vswxu90rawzrrhrjgzyx612rmbxs9es7wp6j9ovxut03v4hz36m36vr8t72x1c3vyt13lxmi:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://pnfmmr2nbrvtlgjc77qwdzbc8i7wasyvn9703eregje77im4smi19hx5vswxu90rawzrrhrjgzyx612rmbxs9es7wp6j9ovxut03v4hz36m36vr8t72x1c3vyt13lxmi:latest/predictions.table.json', 'path': 'media/table/predictions_1_914f95bb4eb354d8f552.table.json'}",17.873231353059808,,,False,True,dev_r2,False,Yes | Maybe | No,4,CTBase,0beba048-f949-4034-83b6-a3e0e7363f46,anli,SENTIMENT,False,28,bigscience/T0_3B,0,True,sentiment,prompts/general_fixed_choice.yaml,FinNews,,3,,,GenFC,,False,['NLI'],,False,False,GeneralFixedChoice,False,False,False,,,prompts,,,True,sentiment,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.financial_phrasebank_sentences_allagree.sentiment.LenNorm,ANLI R2,,,,,,,,,,,,,,,,,,,,,88.0,49.0,8
17.20417845087127,26.548672566371685,0.8419564835344246,4.810100895675583,1.3098827470686767,0.365611088465296,0.5926287741695413,42.2680412371134,0.0,1.2301417627126927,3.9949748743718594,177.47068676716918,3.0648686793980686,2.798994974874372,0.0,0.5150904535648212,0.4049099761082301,0.8372354083944029,0.6091996273614637,1.896147403685092,26.298157453936348,"{'size': 509855, '_type': 'table-file', 'ncols': 13, 'nrows': 597, 'sha256': '81856c73f6a23148c57b793d174b48adb3dc64c15fbbf037b1d99d7192e7b828', 'artifact_path': 'wandb-client-artifact://o8bwfnquujh2pjbcb4d9gixb51t8892y7ldtiaqpau15kor4aff22xmibm0o5khn8husxhu44jcoz3470j1tqc4rx0i83qomq2q6uv5s5d2o6t6jkhxfewxueg5vl8ex:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://o8bwfnquujh2pjbcb4d9gixb51t8892y7ldtiaqpau15kor4aff22xmibm0o5khn8husxhu44jcoz3470j1tqc4rx0i83qomq2q6uv5s5d2o6t6jkhxfewxueg5vl8ex:latest/predictions.table.json', 'path': 'media/table/predictions_1_81856c73f6a23148c57b.table.json'}",78.1171728355754,1.0659491511614465,0.0913781018223508,False,True,validation,False,Seller | Buyer | Neither | Unknown,4,CTBase,5fa16d31-b513-480d-bd1b-1fa8c182fb76,craigslist_bargains,SENTIMENT,False,12,bigscience/T0_3B,0,True,bullish_neutral_bearish,prompts/general_fixed_choice.yaml,FinNews,['validation'],4,,,GenFC,,False,['Dialogue'],,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,bullish_neutral_bearish,,cross_task,craigslist,,,,False,,,False,,True,,,False,False,CTBase.GenFC.financial_phrasebank_sentences_allagree.bullish_neutral_bearish.LenNorm,Craigslist,,,,,,,,,,,,,,,,,,,,,11.0,23.0,9
22.30239346176299,42.90718038528897,0.5146416615770597,2.637069499731064,2.0,0.5610138910394356,0.0,0.0,,,,145.051,1.9107536871433253,2.618,24.000000000000004,0.726315812587738,0.7861780968711861,0.5995111160987739,0.7861780968711861,1.382,30.8,"{'ncols': 11, 'nrows': 1000, 'sha256': '268f4434ce58f96a34c81d28c1f27950c2491578b54386cd5e1ab6d2e573dd19', 'artifact_path': 'wandb-client-artifact://ghdm9haoq0ck12rphcfvt0uiuafchp56c17oymch4w3kyklv7k48np1h8od94a1arbcf5w780jj0kbkq5g32w3hzzg114hsal1nhecz2z5lja24ybr65q81bwf248pam:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://ghdm9haoq0ck12rphcfvt0uiuafchp56c17oymch4w3kyklv7k48np1h8od94a1arbcf5w780jj0kbkq5g32w3hzzg114hsal1nhecz2z5lja24ybr65q81bwf248pam:latest/predictions.table.json', 'path': 'media/table/predictions_1_268f4434ce58f96a34c8.table.json', 'size': 673171, '_type': 'table-file'}",17.873231353059804,,,False,True,dev_r2,False,Yes | Maybe | No,4,CTBase,06719321-62e7-4f6e-8f95-464cd2b5ca5c,anli,SENTIMENT,False,28,bigscience/T0_3B,0,True,share_price_option,prompts/general_fixed_choice.yaml,FinNews,,3,,,GenFC,,False,['NLI'],,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,share_price_option,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.financial_phrasebank_sentences_allagree.share_price_option.LenNorm,ANLI R2,,,,,,,,,,,,,,,,,,,,,89.0,67.0,20
6.833333333333334,24.000000000000004,1.299098265690621,4.895867897937047,1.5360134003350083,1.1908514696187862,0.5558817702839326,0.0,3.333333333333333,1.849386434758728,1.5829145728643217,163.47068676716918,0.5815102606762195,3.056951423785595,0.0,2.464971202502099,0.2317497769457141,0.7007009824648316,0.5994590852052768,3.8241206030150754,13.5678391959799,"{'_type': 'table-file', 'ncols': 13, 'nrows': 597, 'sha256': '9685975c8af5d466abf835f4f9a2ba4d3475e65f8088eb1649f22e2dbb50577d', 'artifact_path': 'wandb-client-artifact://yaoqrahm78dql8ew699w05vgovu9pagc4d6tir0ic1tps3niqkyloiu3fdqxya25kefhsyolsdyqndaqmykmj87c866td3v7pjg8i36u565s9glyaz2b1w0tskaz4ghw:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://yaoqrahm78dql8ew699w05vgovu9pagc4d6tir0ic1tps3niqkyloiu3fdqxya25kefhsyolsdyqndaqmykmj87c866td3v7pjg8i36u565s9glyaz2b1w0tskaz4ghw:latest/predictions.table.json', 'path': 'media/table/predictions_1_9685975c8af5d466abf8.table.json', 'size': 494622}",78.1171728355754,0.9985713643262828,0.6664309407075539,False,True,validation,False,Seller | Buyer | Neither | Unknown,4,CTBase,461efe04-6883-41e8-80f0-e722a75260fe,craigslist_bargains,SENTIMENT,False,12,bigscience/T0_3B,0,True,complementary_industries,prompts/general_fixed_choice.yaml,FinNews,['validation'],4,,,GenFC,,False,['Dialogue'],,False,False,GeneralFixedChoice,False,False,False,,,prompts,,,True,complementary_industries,,cross_task,craigslist,,,,False,,,False,,True,,,False,False,CTBase.GenFC.financial_phrasebank_sentences_allagree.complementary_industries.LenNorm,Craigslist,,,,,,,,,,,,,,,,,,,,,90.0,83.0,11
6.250000000000002,25.000000000000007,1.4399168104659346,6.687588678133149,1.3752093802345058,1.2827217086244442,0.8286667652025193,0.0,0.0,4.1633362019281694,2.013400335008375,160.47068676716918,0.7004397885883273,3.006700167504188,0.0,1.823812687616652,0.0815798704313964,0.5161704291001363,1.0047682530470108,3.604690117252931,14.23785594639866,"{'sha256': 'cb1e6eef3a6bec7f856112b69d31cf9f35800ce6802ce4d0e1490d5810b323f1', 'artifact_path': 'wandb-client-artifact://6ehmttudj33jhs1dt62fh5yssv3ny74r49t0eoqoq41cefpr5xk17gagij4j41ny9lcklwqh0tpgfj3wqm9p1i2mq7um5jbc3scox68vqy4mb16mzbvy7zavwu1nydpb:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://6ehmttudj33jhs1dt62fh5yssv3ny74r49t0eoqoq41cefpr5xk17gagij4j41ny9lcklwqh0tpgfj3wqm9p1i2mq7um5jbc3scox68vqy4mb16mzbvy7zavwu1nydpb:latest/predictions.table.json', 'path': 'media/table/predictions_1_cb1e6eef3a6bec7f8561.table.json', 'size': 476025, '_type': 'table-file', 'ncols': 13, 'nrows': 597}",78.1171728355754,1.1879610402989689,0.5639843858393373,False,True,validation,False,Seller | Buyer | Neither | Unknown,4,CTBase,0beba048-f949-4034-83b6-a3e0e7363f46,craigslist_bargains,SENTIMENT,False,12,bigscience/T0_3B,0,True,sentiment,prompts/general_fixed_choice.yaml,FinNews,['validation'],4,,,GenFC,,False,['Dialogue'],,False,False,GeneralFixedChoice,False,False,False,,,prompts,,,True,sentiment,,cross_task,craigslist,,,,False,,,False,,True,,,False,False,CTBase.GenFC.financial_phrasebank_sentences_allagree.sentiment.LenNorm,Craigslist,,,,,,,,,,,,,,,,,,,,,88.0,90.0,8
18.57195708880638,24.184261036468328,0.7527478639678321,5.012447585612286,1.5561139028475712,0.3153674889622975,0.7128518517690263,41.01265822784811,0.0,1.045572142704847,4.0,188.4706867671692,3.597655226836852,2.663316582914573,9.09090909090909,0.3692202160705873,0.5921409260680027,0.7668019045565283,0.6753057578669878,1.780569514237856,25.125628140703515,"{'nrows': 597, 'sha256': '1ed4eb476d14ef000410325997e74299159cfb78bddd6747179aa5930d043b22', 'artifact_path': 'wandb-client-artifact://95dn8soictlvgeoznzs7y0cq4f979qsisut599ez776o4ft6igmbk3ljax5ly50nbmr97ysm0zstn8eqkt300o0d3vbkcwlrz2d7mwtmi4scx1cxro38qe1bbfkrlf10:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://95dn8soictlvgeoznzs7y0cq4f979qsisut599ez776o4ft6igmbk3ljax5ly50nbmr97ysm0zstn8eqkt300o0d3vbkcwlrz2d7mwtmi4scx1cxro38qe1bbfkrlf10:latest/predictions.table.json', 'path': 'media/table/predictions_1_1ed4eb476d14ef000410.table.json', 'size': 545055, '_type': 'table-file', 'ncols': 13}",78.1171728355754,0.9074247410297392,0.0,False,True,validation,False,Seller | Buyer | Neither | Unknown,4,CTBase,06719321-62e7-4f6e-8f95-464cd2b5ca5c,craigslist_bargains,SENTIMENT,False,12,bigscience/T0_3B,0,True,share_price_option,prompts/general_fixed_choice.yaml,FinNews,['validation'],4,,,GenFC,,False,['Dialogue'],,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,share_price_option,,cross_task,craigslist,,,,False,,,False,,True,,,False,False,CTBase.GenFC.financial_phrasebank_sentences_allagree.share_price_option.LenNorm,Craigslist,,,,,,,,,,,,,,,,,,,,,17.0,14.0,20
30.909972380560617,40.83916083916084,0.7682811590865047,3.3328665062114595,2.0,0.7175857774507292,0.0,0.0,,,,130.056,2.3997503194212912,1.764,51.89075630252101,0.9331161867901684,0.97175305505051,0.6619350470343874,0.9717530550505102,2.236,39.3,"{'sha256': 'b3c81892366f257d7c07f5c62cc34763582689e482c669311568470a7cbc6e47', 'artifact_path': 'wandb-client-artifact://o3tq5a9acozqn4hxh787fjg9cr4bmalvufj8eizsu77q8xlo7839bq8lqcyik3yaa8kka1zcvocxapdjsc5cq9fdk8651re0cjm89ccddjaqauyrmnmoe7kzu70a86do:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://o3tq5a9acozqn4hxh787fjg9cr4bmalvufj8eizsu77q8xlo7839bq8lqcyik3yaa8kka1zcvocxapdjsc5cq9fdk8651re0cjm89ccddjaqauyrmnmoe7kzu70a86do:latest/predictions.table.json', 'path': 'media/table/predictions_1_b3c81892366f257d7c07.table.json', 'size': 592849, '_type': 'table-file', 'ncols': 11, 'nrows': 1000}",18.09101611297718,,,False,True,dev_r1,False,Yes | Maybe | No,4,CTBase,f32348cd-d3cb-4619-87b9-e24f99c78567,anli,COMPLETION,False,28,bigscience/T0_3B,0,True,choose,prompts/general_fixed_choice.yaml,COPA,,3,,,GenFC,,False,['NLI'],,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,choose,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.super_glue_copa.choose.LenNorm,ANLI R1,,,,,,,,,,,,,,,,,,,,,4.0,1.0,8
27.264819085390585,43.321917808219176,0.8491553531655981,2.4514183960234126,1.9883333333333333,0.6370102007191821,0.1679202853208099,0.9876543209876544,,,,122.23583333333332,1.6271012215316296,2.2891666666666666,37.48488512696493,0.824317174491783,0.9559720910617052,0.7959956014339089,0.9471855238899434,1.7225,34.166666666666664,"{'ncols': 11, 'nrows': 1200, 'sha256': '6f17a65d0126ae2cf93ceca5d8161979bfd63b5af3ef7fcbe427b0d6ca79146e', 'artifact_path': 'wandb-client-artifact://kclidprlrce2jguuvxcayfyvprjqv6l9jc6y3rsaynwgwz1pijsorced4odpzpcnoupiaxpqg20uzadajgipa0wua9rzie6nmb4ud0u2u8u9gvkf2v1fa6ie2kmep9nf:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://kclidprlrce2jguuvxcayfyvprjqv6l9jc6y3rsaynwgwz1pijsorced4odpzpcnoupiaxpqg20uzadajgipa0wua9rzie6nmb4ud0u2u8u9gvkf2v1fa6ie2kmep9nf:latest/predictions.table.json', 'path': 'media/table/predictions_1_6f17a65d0126ae2cf93c.table.json', 'size': 689048, '_type': 'table-file'}",32.01257902719214,,,False,True,dev_r3,False,Yes | Maybe | No,4,CTBase,f32348cd-d3cb-4619-87b9-e24f99c78567,anli,COMPLETION,False,28,bigscience/T0_3B,0,True,choose,prompts/general_fixed_choice.yaml,COPA,,3,,,GenFC,,False,['NLI'],,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,choose,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.super_glue_copa.choose.LenNorm,ANLI R3,,,,,,,,,,,,,,,,,,,,,17.0,14.0,8
30.621681829029264,39.76083707025411,0.7688518871156794,2.564335973359644,1.993,0.7731405415093053,0.1046470257580214,0.0,,,,141.056,1.5497239193320274,1.672,52.104208416833664,1.014612054027617,0.9446777228240328,0.6013057044254484,0.9363626434240102,2.335,39.3,"{'nrows': 1000, 'sha256': '4bd89c7b2c2c69e30a101cf5584d93fc69686158d3a1c8644a85b089ae768598', 'artifact_path': 'wandb-client-artifact://6u9g87qupmc6uome0v86416t00s3nvqm30r81vibj1e0q5c04xv0n1tf8wuex6k7687srarllsxe0v6vxd3h5viyjpb4545654cbzeisvjbjnu54k83y4kaeu9bcsre1:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://6u9g87qupmc6uome0v86416t00s3nvqm30r81vibj1e0q5c04xv0n1tf8wuex6k7687srarllsxe0v6vxd3h5viyjpb4545654cbzeisvjbjnu54k83y4kaeu9bcsre1:latest/predictions.table.json', 'path': 'media/table/predictions_1_4bd89c7b2c2c69e30a10.table.json', 'size': 643038, '_type': 'table-file', 'ncols': 11}",18.09101611297718,,,False,True,dev_r1,False,Yes | Maybe | No,4,CTBase,a1f9951e-2b6b-4530-9636-9cdf4c1658c5,anli,COMPLETION,False,28,bigscience/T0_3B,0,True,more_likely,prompts/general_fixed_choice.yaml,COPA,,3,,,GenFC,,False,['NLI'],,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,more likely,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.super_glue_copa.more_likely.LenNorm,ANLI R1,,,,,,,,,,,,,,,,,,,,,4.0,5.0,19
27.54048059576673,38.60329776915616,0.7168425165338704,1.923177639382581,1.9733333333333336,0.6074033784778039,0.2220110107379561,0.9828009828009828,,,,133.23583333333335,1.130381067097187,2.0625,43.03534303534304,0.7927965722853939,0.995955362118872,0.6378992425099387,0.9761570769547744,1.9641666666666664,34.0,"{'ncols': 11, 'nrows': 1200, 'sha256': '2d02b3e65d1b0913cf41c2b7069b23d67086639193885804b353c61249b31b6d', 'artifact_path': 'wandb-client-artifact://xt0gou0g4p0i9msl0ko9opu1zs1dgvj9licmox1v9nzsfanw3imtphjqpklg3sbqrcmppauhw0z2e570oshmcfwd4giktoxz6pgb6ck0gi4v8gybii2na5ea5yuv9kus:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://xt0gou0g4p0i9msl0ko9opu1zs1dgvj9licmox1v9nzsfanw3imtphjqpklg3sbqrcmppauhw0z2e570oshmcfwd4giktoxz6pgb6ck0gi4v8gybii2na5ea5yuv9kus:latest/predictions.table.json', 'path': 'media/table/predictions_1_2d02b3e65d1b0913cf41.table.json', 'size': 749520, '_type': 'table-file'}",32.01257902719214,,,False,True,dev_r3,False,Yes | Maybe | No,4,CTBase,a1f9951e-2b6b-4530-9636-9cdf4c1658c5,anli,COMPLETION,False,28,bigscience/T0_3B,0,True,more_likely,prompts/general_fixed_choice.yaml,COPA,,3,,,GenFC,,False,['NLI'],,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,more likely,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.super_glue_copa.more_likely.LenNorm,ANLI R3,,,,,,,,,,,,,,,,,,,,,19.5,8.0,19
29.575124248853733,41.51898734177215,0.7278236119726107,3.001433532983065,1.998,0.7315769897255395,0.0446766158073773,0.0,,,,135.056,2.0815003336071967,1.914,47.20638540478906,0.9199331993758678,0.9962951369950572,0.6618876884558488,0.9951160736316144,2.088,37.1,"{'_type': 'table-file', 'ncols': 11, 'nrows': 1000, 'sha256': '42d84bcb77d3088e9b1540878e5e3c05e30fea1f503d196bdf62106b0c024990', 'artifact_path': 'wandb-client-artifact://i47yn3f3mo0x0nmwj4xnbyex2g5p81b2559p3g31aectwb5r96xxf4snt7h8e1tpp09ag0g3dwvidi4lass6wu5cjuwydih3nn6a6xc2u0ioyqeozkmx4dmshx3xbk87:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://i47yn3f3mo0x0nmwj4xnbyex2g5p81b2559p3g31aectwb5r96xxf4snt7h8e1tpp09ag0g3dwvidi4lass6wu5cjuwydih3nn6a6xc2u0ioyqeozkmx4dmshx3xbk87:latest/predictions.table.json', 'path': 'media/table/predictions_1_42d84bcb77d3088e9b15.table.json', 'size': 626059}",18.09101611297718,,,False,True,dev_r1,False,Yes | Maybe | No,4,CTBase,0edd8660-f299-4819-a5ac-633c11177228,anli,COMPLETION,False,28,bigscience/T0_3B,0,True,exercise,prompts/general_fixed_choice.yaml,COPA,,3,,,GenFC,,False,['NLI'],,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,exercise,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.super_glue_copa.exercise.LenNorm,ANLI R1,,,,,,,,,,,,,,,,,,,,,19.5,18.0,13
25.55651697383981,44.25196850393701,0.7546767889504845,2.302151678365966,1.965833333333333,0.6815273182560345,0.1906112244567168,0.0,,,,127.23583333333332,1.3806447427968185,2.4566666666666666,32.417582417582416,0.9215069355691472,0.8896378788898074,0.7320043957922626,0.8854342155123666,1.5775,33.25,"{'size': 728922, '_type': 'table-file', 'ncols': 11, 'nrows': 1200, 'sha256': 'd9cb80d89620b03e7410f30941d4d7dae0b7a22867bd2a52960e7a18c77c7e6a', 'artifact_path': 'wandb-client-artifact://l8l6anbdq81x288uoytfc6t83emjug6kk8fbqfxlfiwbj4c82iac392138ahiowvjadnp1m2e978ivbyd8hxkdk49xscvgoymgimrw16ttwldbi0z64x3ojrvn9gtgh9:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://l8l6anbdq81x288uoytfc6t83emjug6kk8fbqfxlfiwbj4c82iac392138ahiowvjadnp1m2e978ivbyd8hxkdk49xscvgoymgimrw16ttwldbi0z64x3ojrvn9gtgh9:latest/predictions.table.json', 'path': 'media/table/predictions_1_d9cb80d89620b03e7410.table.json'}",32.01257902719214,,,False,True,dev_r3,False,Yes | Maybe | No,4,CTBase,0edd8660-f299-4819-a5ac-633c11177228,anli,COMPLETION,False,28,bigscience/T0_3B,0,True,exercise,prompts/general_fixed_choice.yaml,COPA,,3,,,GenFC,,False,['NLI'],,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,exercise,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.super_glue_copa.exercise.LenNorm,ANLI R3,,,,,,,,,,,,,,,,,,,,,42.0,26.0,13
29.04497180085849,40.5727923627685,0.7617179038524088,3.809571369469166,2.0,0.6636006247906245,0.0,0.0,,,,122.549,3.032253194093704,2.01,46.562123039807,0.7773181753754616,0.9999499987499374,0.6842857655986896,0.9999499987499376,1.99,36.3,"{'artifact_path': 'wandb-client-artifact://13spoa9tgzlyt1g0e4dutg9mb8h8gfa48s0j6s32pq236p1ygwg9fw7qr9l9dvkoyphybqmrs4622sskz4dlh078yciol3dj2vvi4banouaq02avpakeeh8mu5iuwz18:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://13spoa9tgzlyt1g0e4dutg9mb8h8gfa48s0j6s32pq236p1ygwg9fw7qr9l9dvkoyphybqmrs4622sskz4dlh078yciol3dj2vvi4banouaq02avpakeeh8mu5iuwz18:latest/predictions.table.json', 'path': 'media/table/predictions_1_a3838f1940152092ee08.table.json', 'size': 579810, '_type': 'table-file', 'ncols': 11, 'nrows': 1000, 'sha256': 'a3838f1940152092ee08c10148dbdc23310b13b34ffee035d35d96e49332f50b'}",18.070517397130608,,,False,True,dev_r1,False,Yes | Maybe | No,4,CTBase,2d0d63da-ffcf-4f6e-941a-b8da922be43e,anli,ENTAILMENT,False,28,bigscience/T0_3B,0,True,guaranteed_true,prompts/general_fixed_choice.yaml,ANLI,,3,,,GenFC,,True,['NLI'],,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,guaranteed true,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.anli.guaranteed_true.LenNorm,ANLI R1,,,,,,,,,,,,,,,,,,,,,25.0,24.0,12
26.831961538788235,44.01294498381878,0.8765756883448365,3.061638572116693,2.0,0.6686019135805767,0.0,0.0,,,,115.1,2.223181192378203,2.4,36.482939632545936,0.8384573797384898,0.916515138991168,0.807558838301961,0.916515138991168,1.6,34.25,"{'size': 673509, '_type': 'table-file', 'ncols': 11, 'nrows': 1200, 'sha256': '50a557e2efa165404bbec9909fce17c9924871ba9b0a16c865be2108fbcd9146', 'artifact_path': 'wandb-client-artifact://47vhphoocp5ml5uj3cxh2n10u3o4yvd6x6j18rsq4ab4gi1ffo6wt0r36gbwrapyok5938kfdmpbd9p1yjeh8qv74pzimdd6gzqzbcr5tq8w2vb0skhqsw5w4lf3mk7w:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://47vhphoocp5ml5uj3cxh2n10u3o4yvd6x6j18rsq4ab4gi1ffo6wt0r36gbwrapyok5938kfdmpbd9p1yjeh8qv74pzimdd6gzqzbcr5tq8w2vb0skhqsw5w4lf3mk7w:latest/predictions.table.json', 'path': 'media/table/predictions_1_50a557e2efa165404bbe.table.json'}",32.020462207782074,,,False,True,dev_r3,False,Yes | Maybe | No,4,CTBase,2d0d63da-ffcf-4f6e-941a-b8da922be43e,anli,ENTAILMENT,False,28,bigscience/T0_3B,0,True,guaranteed_true,prompts/general_fixed_choice.yaml,ANLI,,3,,,GenFC,,True,['NLI'],,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,guaranteed true,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.anli.guaranteed_true.LenNorm,ANLI R3,,,,,,,,,,,,,,,,,,,,,13.0,18.0,12
30.798447909803063,45.22292993630573,0.8180659936904205,4.300271931886673,2.0,0.724792634872059,0.0,0.0,,,,135.054,3.481600151538849,2.218,47.17241379310345,0.8186717803478241,0.9759487691472332,0.7287803751078772,0.9759487691472332,1.782,38.4,"{'artifact_path': 'wandb-client-artifact://qciamyoqzcyc8zhx595bvc60e9m2pdqzp8xvb5jje6160ff0f55svwujxwph8pxajmnl17dyuno6uz6d2ckvterfo7z4p8mbbdqzbulg5vnn27al0adovoclwv4dslpc:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://qciamyoqzcyc8zhx595bvc60e9m2pdqzp8xvb5jje6160ff0f55svwujxwph8pxajmnl17dyuno6uz6d2ckvterfo7z4p8mbbdqzbulg5vnn27al0adovoclwv4dslpc:latest/predictions.table.json', 'path': 'media/table/predictions_1_941ab8c3abd304fcd2d9.table.json', 'size': 589972, '_type': 'table-file', 'ncols': 11, 'nrows': 1000, 'sha256': '941ab8c3abd304fcd2d98bc04afc30f8c3120ef43d17df6c0c24791aed257c3d'}",18.092680398437377,,,False,True,dev_r1,False,Yes | Maybe | No,4,CTBase,9e078fb4-505b-413c-bb5e-3cd16ddcf5d7,anli,ENTAILMENT,False,28,bigscience/T0_3B,0,True,does_this_imply,prompts/general_fixed_choice.yaml,ANLI,,3,,,GenFC,,True,['NLI'],,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,does this imply,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.anli.does_this_imply.LenNorm,ANLI R1,,,,,,,,,,,,,,,,,,,,,6.0,4.0,23
25.213076241387096,46.54275092936803,0.9076576124032506,3.5665987956523897,2.0,0.7741756051601071,0.0,0.0,,,,127.235,2.547071061929067,2.5816666666666666,29.096477794793262,1.0195277337233226,0.8134272486761732,0.8592361563301805,0.8134272486761732,1.4183333333333332,34.0,"{'size': 685597, '_type': 'table-file', 'ncols': 11, 'nrows': 1200, 'sha256': 'e2ff1bb592b0f7a1ca0e73d06f320a41c707b24bba496709dc97a1cde07b581a', 'artifact_path': 'wandb-client-artifact://3j0qnljyr6086mmubu11qwdzg7uos49bnp1apmp0mkkrmbdnsak96w391rneob9tc2dhe3680tp0gl9czn45vx6nl3kwjc8o63gssmofhpvf8isfmjf91qakwyazdfoe:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://3j0qnljyr6086mmubu11qwdzg7uos49bnp1apmp0mkkrmbdnsak96w391rneob9tc2dhe3680tp0gl9czn45vx6nl3kwjc8o63gssmofhpvf8isfmjf91qakwyazdfoe:latest/predictions.table.json', 'path': 'media/table/predictions_1_e2ff1bb592b0f7a1ca0e.table.json'}",32.01259817113673,,,False,True,dev_r3,False,Yes | Maybe | No,4,CTBase,9e078fb4-505b-413c-bb5e-3cd16ddcf5d7,anli,ENTAILMENT,False,28,bigscience/T0_3B,0,True,does_this_imply,prompts/general_fixed_choice.yaml,ANLI,,3,,,GenFC,,True,['NLI'],,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,does this imply,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.anli.does_this_imply.LenNorm,ANLI R3,,,,,,,,,,,,,,,,,,,,,19.5,29.0,23
30.8934902304587,41.4985590778098,0.7622392363505976,3.4262529420256613,2.0,0.6558190180362593,0.0,0.0,,,,124.549,2.583307632684708,1.722,51.181911613566285,0.8429453093409538,0.9605810741421048,0.679450644634903,0.9605810741421048,2.278,39.3,"{'artifact_path': 'wandb-client-artifact://11nsm7v349b956n977erthxa8yjqp09st0gy2ziml74ui5kpbbdnq7v551qznvogvkdiazc306v85trfs8rlxee9h6dja1vsfcn8s9i2brmjk59m5ed258utytcn25ke:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://11nsm7v349b956n977erthxa8yjqp09st0gy2ziml74ui5kpbbdnq7v551qznvogvkdiazc306v85trfs8rlxee9h6dja1vsfcn8s9i2brmjk59m5ed258utytcn25ke:latest/predictions.table.json', 'path': 'media/table/predictions_1_34539e0827430ee27d5c.table.json', 'size': 590220, '_type': 'table-file', 'ncols': 11, 'nrows': 1000, 'sha256': '34539e0827430ee27d5c3d9785881883c6f9189fb219a55970660925b53f1ab6'}",18.070517397130608,,,False,True,dev_r1,False,Yes | Maybe | No,4,CTBase,fb4f8144-37f5-4977-88da-37a5d0bfd0e8,anli,ENTAILMENT,False,28,bigscience/T0_3B,0,True,must_be_true,prompts/general_fixed_choice.yaml,ANLI,,3,,,GenFC,,True,['NLI'],,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,must be true,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.anli.must_be_true.LenNorm,ANLI R1,,,,,,,,,,,,,,,,,,,,,4.0,2.0,14
27.429326068236065,41.11812443642921,0.7802783391710717,2.716478366777301,1.995,0.6019771246682625,0.0705336798983294,0.0,,,,117.1,1.955511792500814,2.188333333333333,41.16985376827897,0.7609665742764871,0.9821051652219102,0.7576067066828197,0.9805044053388484,1.8166666666666669,34.25,"{'sha256': '0e5450e00b6dc72457a051e49d966e71b0117fcc3f88f6621101961b3dda163e', 'artifact_path': 'wandb-client-artifact://4e5vpoqallesx1hm9kf6wn9deui407nvekdtasfm0n9qba633j4cwim36aet417ukbkiiyignzl5db61u3i9euwar0u20ug8vzibcifycoxjx68jrgol9f9pjej7oe9b:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://4e5vpoqallesx1hm9kf6wn9deui407nvekdtasfm0n9qba633j4cwim36aet417ukbkiiyignzl5db61u3i9euwar0u20ug8vzibcifycoxjx68jrgol9f9pjej7oe9b:latest/predictions.table.json', 'path': 'media/table/predictions_1_0e5450e00b6dc72457a0.table.json', 'size': 685962, '_type': 'table-file', 'ncols': 11, 'nrows': 1200}",32.020462207782074,,,False,True,dev_r3,False,Yes | Maybe | No,4,CTBase,fb4f8144-37f5-4977-88da-37a5d0bfd0e8,anli,ENTAILMENT,False,28,bigscience/T0_3B,0,True,must_be_true,prompts/general_fixed_choice.yaml,ANLI,,3,,,GenFC,,True,['NLI'],,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,must be true,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.anli.must_be_true.LenNorm,ANLI R3,,,,,,,,,,,,,,,,,,,,,13.0,10.0,14
29.30793875996488,43.44978165938864,0.7909295436246183,4.367279089808464,2.0,0.7617114234406325,0.0,0.0,,,,127.549,3.483410464763641,2.166,44.474034620506,0.8838686250448227,0.9861257526299574,0.7528250047672321,0.9861257526299574,1.834,36.6,"{'artifact_path': 'wandb-client-artifact://9al5raubu43j9bigvo9fqkr0mgwbh9tn9kh907d8m1i3mlitef4p6lv2sli43f72795etzweavaiofd3jt4rd38p916ncz1pwij8mwqhufwuoankoqoo0gaop70be7ji:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://9al5raubu43j9bigvo9fqkr0mgwbh9tn9kh907d8m1i3mlitef4p6lv2sli43f72795etzweavaiofd3jt4rd38p916ncz1pwij8mwqhufwuoankoqoo0gaop70be7ji:latest/predictions.table.json', 'path': 'media/table/predictions_1_eac513d9a033115de0b4.table.json', 'size': 607673, '_type': 'table-file', 'ncols': 11, 'nrows': 1000, 'sha256': 'eac513d9a033115de0b40361d976b37412083f44757a3cf7550c8a2b5d5fdd02'}",18.070517397130608,,,False,True,dev_r1,False,Yes | Maybe | No,4,CTBase,bab86d5a-4f9c-40db-b619-a7b7d5cae681,anli,ENTAILMENT,False,28,bigscience/T0_3B,0,True,take_the_following_as_truth,prompts/general_fixed_choice.yaml,ANLI,,3,,,GenFC,,True,['NLI'],,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,take the following as truth,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.anli.take_the_following_as_truth.LenNorm,ANLI R1,,,,,,,,,,,,,,,,,,,,,24.0,20.0,17
26.581771515193275,44.69096671949287,0.8541328149226945,3.589363123178482,2.0,0.6693106783428088,0.0,0.0,,,,120.1,2.7170051381985347,2.443333333333334,35.05434782608695,0.8723579849799474,0.8963568237903673,0.8370241180432155,0.8963568237903673,1.5566666666666666,34.25,"{'artifact_path': 'wandb-client-artifact://193cxlyg0v4dw9ztre4gjiv2bdiq7vz34mux1edp7j1h5qlpj7mct1l5zjp8q3qdhgudjsxt92yhy26fxfla87x71odysesl24vrzfg2zf8cvow129gwfkerwxaykfyd:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://193cxlyg0v4dw9ztre4gjiv2bdiq7vz34mux1edp7j1h5qlpj7mct1l5zjp8q3qdhgudjsxt92yhy26fxfla87x71odysesl24vrzfg2zf8cvow129gwfkerwxaykfyd:latest/predictions.table.json', 'path': 'media/table/predictions_1_66689193903537edda70.table.json', 'size': 707010, '_type': 'table-file', 'ncols': 11, 'nrows': 1200, 'sha256': '66689193903537edda70f69584ca9c32d2b8a2222071ee5a203ae3722ffd1f84'}",32.020462207782074,,,False,True,dev_r3,False,Yes | Maybe | No,4,CTBase,bab86d5a-4f9c-40db-b619-a7b7d5cae681,anli,ENTAILMENT,False,28,bigscience/T0_3B,0,True,take_the_following_as_truth,prompts/general_fixed_choice.yaml,ANLI,,3,,,GenFC,,True,['NLI'],,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,take the following as truth,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.anli.take_the_following_as_truth.LenNorm,ANLI R3,,,,,,,,,,,,,,,,,,,,,13.0,19.0,17
30.0241291096252,43.326039387308526,0.8409018197017559,4.198587336659432,2.0,0.710327549710966,0.0,0.0,,,,121.549,3.3847524540424345,2.162,46.746347941567066,0.8138348826169968,0.986790757962396,0.7613927000097518,0.986790757962396,1.838,37.4,"{'sha256': 'c26121117a0333f2b6c5cc2ab39b329f78b1bf834ae23a0095bf1ce10c3d810c', 'artifact_path': 'wandb-client-artifact://172vctilw0x9tsez0z379abtucdwhqdmoi7fk0oyxsw6u7czqquazlbai4wv8hdlxxt5zd03kwdw9zz75ek8y5qax9shyt8nzp0bu0kfalybsuxsecteag3ks10ho2nv:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://172vctilw0x9tsez0z379abtucdwhqdmoi7fk0oyxsw6u7czqquazlbai4wv8hdlxxt5zd03kwdw9zz75ek8y5qax9shyt8nzp0bu0kfalybsuxsecteag3ks10ho2nv:latest/predictions.table.json', 'path': 'media/table/predictions_1_c26121117a0333f2b6c5.table.json', 'size': 578755, '_type': 'table-file', 'ncols': 11, 'nrows': 1000}",18.070517397130608,,,False,True,dev_r1,False,Yes | Maybe | No,4,CTBase,a850110d-f1a3-49b4-949a-d3bfe9f81344,anli,ENTAILMENT,False,28,bigscience/T0_3B,0,True,justified_in_saying,prompts/general_fixed_choice.yaml,ANLI,,3,,,GenFC,,True,['NLI'],,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,justified in saying,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.anli.justified_in_saying.LenNorm,ANLI R1,,,,,,,,,,,,,,,,,,,,,14.0,10.0,11
25.51190888955833,46.6120625465376,0.9365706410553076,3.370790904462337,1.9991666666666668,0.7399621579037972,0.0288554828219679,0.0,,,,114.1,2.40573574701945,2.578333333333333,29.923664122137406,0.9650551574428876,0.8158005611395199,0.8992206339428256,0.8158801484695326,1.4225,34.25,"{'size': 672224, '_type': 'table-file', 'ncols': 11, 'nrows': 1200, 'sha256': '5395e550e60aecd07f90cdfc213806434ef02410784f6505ded913545d12acc7', 'artifact_path': 'wandb-client-artifact://x2fhh6f5shuzpt7qlmkf4atr1xpos0vv8m2nr7t6qmotyzvmf7bxk86aeicx3xijg9jfwoe5d2ydm3ns55uwjejzoe624urw94surlzhfyzzic7uytz9x5zu3y2suhzy:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://x2fhh6f5shuzpt7qlmkf4atr1xpos0vv8m2nr7t6qmotyzvmf7bxk86aeicx3xijg9jfwoe5d2ydm3ns55uwjejzoe624urw94surlzhfyzzic7uytz9x5zu3y2suhzy:latest/predictions.table.json', 'path': 'media/table/predictions_1_5395e550e60aecd07f90.table.json'}",32.020462207782074,,,False,True,dev_r3,False,Yes | Maybe | No,4,CTBase,a850110d-f1a3-49b4-949a-d3bfe9f81344,anli,ENTAILMENT,False,28,bigscience/T0_3B,0,True,justified_in_saying,prompts/general_fixed_choice.yaml,ANLI,,3,,,GenFC,,True,['NLI'],,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,justified in saying,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.anli.justified_in_saying.LenNorm,ANLI R3,,,,,,,,,,,,,,,,,,,,,13.0,27.0,11
30.038443268774028,41.20603015075377,0.7793164423498781,4.545169539570808,2.0,0.7155386700613963,0.0,0.0,,,,125.549,3.698423160791397,1.926,48.90929965556831,0.8467463787794113,0.9972582413798344,0.6940773955465017,0.9972582413798344,2.074,37.7,"{'sha256': '1532a54427d699a51ad0ccd6ff3c69bbd1feae8552fe07f3ab7d1455c5d287d4', 'artifact_path': 'wandb-client-artifact://1d8jzakev42huf8dnu4payrpw5jpg966glbajb3u09h87exn53en79it42p4ta4l68hkzhihac471n8fn3xa3cpn9a916e3t1gpp07gzfwxrusrdmmzca7q7nqeiq1ag:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://1d8jzakev42huf8dnu4payrpw5jpg966glbajb3u09h87exn53en79it42p4ta4l68hkzhihac471n8fn3xa3cpn9a916e3t1gpp07gzfwxrusrdmmzca7q7nqeiq1ag:latest/predictions.table.json', 'path': 'media/table/predictions_1_1532a54427d699a51ad0.table.json', 'size': 593972, '_type': 'table-file', 'ncols': 11, 'nrows': 1000}",18.070517397130608,,,False,True,dev_r1,False,Yes | Maybe | No,4,CTBase,9b613182-c6ab-4427-9221-3d68f6d62765,anli,ENTAILMENT,False,28,bigscience/T0_3B,0,True,based_on_the_previous_passage,prompts/general_fixed_choice.yaml,ANLI,,3,,,GenFC,,True,['NLI'],,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,based on the previous passage,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.anli.based_on_the_previous_passage.LenNorm,ANLI R1,,,,,,,,,,,,,,,,,,,,,10.0,9.0,15
27.059938928289995,42.88194444444445,0.8735641968464626,3.712124339938163,2.0,0.6807803254019194,0.0,0.0,,,,118.1,2.889235234856605,2.26,38.297872340425535,0.8228891050815582,0.9656086163658648,0.8178878687866407,0.9656086163658648,1.74,34.08333333333333,"{'artifact_path': 'wandb-client-artifact://6zjede7fpput37xj0lzledqiwv7wn7wfnjddxs2xk8jqsrh6zmfth59u5jiooum96ilrf9x86xuft5i2ylqyrk4yezbn7fa3nk9snrho3uqj8d9ypn9hqma048eyqt6g:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://6zjede7fpput37xj0lzledqiwv7wn7wfnjddxs2xk8jqsrh6zmfth59u5jiooum96ilrf9x86xuft5i2ylqyrk4yezbn7fa3nk9snrho3uqj8d9ypn9hqma048eyqt6g:latest/predictions.table.json', 'path': 'media/table/predictions_1_46d8e11fb7bea1b6553b.table.json', 'size': 690508, '_type': 'table-file', 'ncols': 11, 'nrows': 1200, 'sha256': '46d8e11fb7bea1b6553b612b116a1ab4776449ae5de38d45fb73ce57b0947687'}",32.020462207782074,,,False,True,dev_r3,False,Yes | Maybe | No,4,CTBase,9b613182-c6ab-4427-9221-3d68f6d62765,anli,ENTAILMENT,False,28,bigscience/T0_3B,0,True,based_on_the_previous_passage,prompts/general_fixed_choice.yaml,ANLI,,3,,,GenFC,,True,['NLI'],,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,based on the previous passage,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.anli.based_on_the_previous_passage.LenNorm,ANLI R3,,,,,,,,,,,,,,,,,,,,,18.0,15.0,15
27.6731893837157,44.42307692307693,0.8408869686865289,4.19211004281044,2.0,0.6968018634749196,0.0,0.0,,,,114.428,3.3288897565603257,2.414,38.59649122807017,0.8632202862501145,0.9102768809543612,0.8227669516769983,0.9102768809543612,1.586,35.2,"{'path': 'media/table/predictions_1_83a82f6d064b9cd0c02c.table.json', 'size': 551857, '_type': 'table-file', 'ncols': 11, 'nrows': 1000, 'sha256': '83a82f6d064b9cd0c02ce56735766350d3ff069eb94be021ec6d078fcaafc0df', 'artifact_path': 'wandb-client-artifact://15pgsgf1wmtgl4l9wo8blit858kt0a3snhx1r9oxcgu521tvpwvbyh18mbx3i0adjer4rtdxsxwgz9frricaumdd1w8w0lttbm2d22iodcn278omtywkfif8ua0r6aka:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://15pgsgf1wmtgl4l9wo8blit858kt0a3snhx1r9oxcgu521tvpwvbyh18mbx3i0adjer4rtdxsxwgz9frricaumdd1w8w0lttbm2d22iodcn278omtywkfif8ua0r6aka:latest/predictions.table.json'}",18.13314137153295,,,False,True,dev_r1,False,Yes | Maybe | No,4,CTBase,620aa3fc-d5eb-46f5-a1ee-4c754527aa97,anli,ENTAILMENT,False,28,bigscience/T0_3B,0,True,GPT_3_style,prompts/general_fixed_choice.yaml,ANLI,,3,,,GenFC,,True,['NLI'],,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,GPT-3 style,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.anli.GPT_3_style.LenNorm,ANLI R1,,,,,,,,,,,,,,,,,,,,,36.5,36.0,4
23.519272936764075,45.84237165582068,0.9574971645426118,3.4452676376203697,1.9966666666666664,0.7811115041822794,0.0576387215526352,0.0,,,,107.10583333333334,2.366980142990748,2.645,24.715447154471548,1.0782874946296217,0.7641825698090738,0.9162213682529708,0.764807528438074,1.3583333333333334,32.75,"{'size': 640051, '_type': 'table-file', 'ncols': 11, 'nrows': 1200, 'sha256': '5384d39a984c4f90851d2257fc2055be9e778478a2b969f5e93f207a2c921a1f', 'artifact_path': 'wandb-client-artifact://14qb9o3saecsgxmedupfh1njym1p2lticiu3soucln92odrjg9v0qe250xoiz64tfczwijqyrocobkh2aan0frjwg0mlnn2q60h18u0v8gt6e7j40urkwaogqya9lwgk:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://14qb9o3saecsgxmedupfh1njym1p2lticiu3soucln92odrjg9v0qe250xoiz64tfczwijqyrocobkh2aan0frjwg0mlnn2q60h18u0v8gt6e7j40urkwaogqya9lwgk:latest/predictions.table.json', 'path': 'media/table/predictions_1_5384d39a984c4f90851d.table.json'}",31.96711277712699,,,False,True,dev_r3,False,Yes | Maybe | No,4,CTBase,620aa3fc-d5eb-46f5-a1ee-4c754527aa97,anli,ENTAILMENT,False,28,bigscience/T0_3B,0,True,GPT_3_style,prompts/general_fixed_choice.yaml,ANLI,,3,,,GenFC,,True,['NLI'],,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,GPT-3 style,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.anli.GPT_3_style.LenNorm,ANLI R3,,,,,,,,,,,,,,,,,,,,,67.5,45.0,4
30.509756001494782,44.13472706155633,0.8471986947364679,4.651279646635055,2.0,0.723105868720089,0.0,0.0,,,,123.549,3.826854870796203,2.056,47.39454094292803,0.8244247758388519,0.9984307687566524,0.7735345174986866,0.9984307687566524,1.944,38.1,"{'artifact_path': 'wandb-client-artifact://6sn5cqqfeg60nlfx7z3vvpui05c7m0hung43qajvvdtpyk9knmiezze5qonc982oonm1xsgwzc5ypuy2x7egpjw8i7ohiwnyyjj9pkecf2cbevjfk0ahpzl8jqhnir5k:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://6sn5cqqfeg60nlfx7z3vvpui05c7m0hung43qajvvdtpyk9knmiezze5qonc982oonm1xsgwzc5ypuy2x7egpjw8i7ohiwnyyjj9pkecf2cbevjfk0ahpzl8jqhnir5k:latest/predictions.table.json', 'path': 'media/table/predictions_1_ae98d2746b432bb28f36.table.json', 'size': 586988, '_type': 'table-file', 'ncols': 11, 'nrows': 1000, 'sha256': 'ae98d2746b432bb28f36d1978b10d74a84ad137e3dcc6b78de3e84bc1310d05d'}",18.070517397130608,,,False,True,dev_r1,False,Yes | Maybe | No,4,CTBase,ec249357-e672-4e7d-b8b6-d97ed7d090c5,anli,ENTAILMENT,False,28,bigscience/T0_3B,0,True,claim_true_false_inconclusive,prompts/general_fixed_choice.yaml,ANLI,,3,,,GenFC,,True,['NLI'],,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,claim true/false/inconclusive,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.anli.claim_true_false_inconclusive.LenNorm,ANLI R1,,,,,,,,,,,,,,,,,,,,,7.0,7.0,13
25.466211865798822,43.55484387510008,0.910175700066336,3.9199699015418688,2.0,0.7150628694358141,0.0,0.0,,,,116.1,3.0439543213446933,2.421666666666667,32.843791722296395,0.8760155801971753,0.9067509152034104,0.8511127139937075,0.9067509152034102,1.5783333333333334,32.916666666666664,"{'path': 'media/table/predictions_1_587ccb0a6c78d44a83e9.table.json', 'size': 682124, '_type': 'table-file', 'ncols': 11, 'nrows': 1200, 'sha256': '587ccb0a6c78d44a83e9d75320947a28593a99939cc81fc1b28715b51c93e7a0', 'artifact_path': 'wandb-client-artifact://wbui60arkim4v02m37akdrnd067nux17957bwvzohdfh73y0iv161tytwekzfe7khqm3mzg71po44g8mvxa4dha3aleij4de9d0uf9gsuziboocmjohji67to9cjmogi:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://wbui60arkim4v02m37akdrnd067nux17957bwvzohdfh73y0iv161tytwekzfe7khqm3mzg71po44g8mvxa4dha3aleij4de9d0uf9gsuziboocmjohji67to9cjmogi:latest/predictions.table.json'}",32.020462207782074,,,False,True,dev_r3,False,Yes | Maybe | No,4,CTBase,ec249357-e672-4e7d-b8b6-d97ed7d090c5,anli,ENTAILMENT,False,28,bigscience/T0_3B,0,True,claim_true_false_inconclusive,prompts/general_fixed_choice.yaml,ANLI,,3,,,GenFC,,True,['NLI'],,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,claim true/false/inconclusive,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.anli.claim_true_false_inconclusive.LenNorm,ANLI R3,,,,,,,,,,,,,,,,,,,,,58.5,28.0,13
29.99639755830084,45.61049445005045,0.7525202519312064,3.982730323791504,2.0,0.778056036204748,0.0,0.0,,,,122.549,3.0916377568244933,2.316,44.37869822485207,0.8910925669670104,0.948759189678814,0.7259966411855803,0.948759189678814,1.684,37.6,"{'sha256': 'a8b0e8360359d7497ce7986cc9bcbe6ce40d2d9377d7858d842a6c3a9c0f32cb', 'artifact_path': 'wandb-client-artifact://5dnz06m2fo9ajp8w65omua8ked2nldvmc4u9opetsq4xw2em7ffidzg34yfpq36nhh8e26jwtwtmbv8kg2cgkxnuyt3tjukhdfnizizihfdbss8xko0eqx1iwl96ptgr:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://5dnz06m2fo9ajp8w65omua8ked2nldvmc4u9opetsq4xw2em7ffidzg34yfpq36nhh8e26jwtwtmbv8kg2cgkxnuyt3tjukhdfnizizihfdbss8xko0eqx1iwl96ptgr:latest/predictions.table.json', 'path': 'media/table/predictions_1_a8b0e8360359d7497ce7.table.json', 'size': 572606, '_type': 'table-file', 'ncols': 11, 'nrows': 1000}",18.070517397130608,,,False,True,dev_r1,False,Yes | Maybe | No,4,CTBase,c4ed37ae-d7d7-4197-a725-ef2152fa3b1f,anli,ENTAILMENT,False,28,bigscience/T0_3B,0,True,can_we_infer,prompts/general_fixed_choice.yaml,ANLI,,3,,,GenFC,,True,['NLI'],,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,can we infer,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.anli.can_we_infer.LenNorm,ANLI R1,,,,,,,,,,,,,,,,,,,,,12.5,11.0,12
24.024931885193897,46.43377001455604,0.8370671361021812,3.3159245679775875,1.995833333333333,0.758166537018444,0.0644151034739179,0.0,,,,115.1,2.2883097406228385,2.63,25.64102564102565,1.027614827354749,0.7765951326141569,0.8424043257814005,0.7772811410437166,1.3741666666666668,33.25,"{'_type': 'table-file', 'ncols': 11, 'nrows': 1200, 'sha256': '0ca8043eea3e7f0db9b4b88bbb900764034bb6894bd24284c27b5cf2b9f73430', 'artifact_path': 'wandb-client-artifact://7qo7rl0pxszx9eoqi3q1m5fmvbkx2havt2d9ywymepj76ekgikecusq4cqwpr8mb082yicay9keqx4a5k2i7p4zod4oq4rrjs5j20gaivfxyu7tqx5aqbaykjogmqtfi:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://7qo7rl0pxszx9eoqi3q1m5fmvbkx2havt2d9ywymepj76ekgikecusq4cqwpr8mb082yicay9keqx4a5k2i7p4zod4oq4rrjs5j20gaivfxyu7tqx5aqbaykjogmqtfi:latest/predictions.table.json', 'path': 'media/table/predictions_1_0ca8043eea3e7f0db9b4.table.json', 'size': 664942}",32.020462207782074,,,False,True,dev_r3,False,Yes | Maybe | No,4,CTBase,c4ed37ae-d7d7-4197-a725-ef2152fa3b1f,anli,ENTAILMENT,False,28,bigscience/T0_3B,0,True,can_we_infer,prompts/general_fixed_choice.yaml,ANLI,,3,,,GenFC,,True,['NLI'],,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,can we infer,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.anli.can_we_infer.LenNorm,ANLI R3,,,,,,,,,,,,,,,,,,,,,42.0,40.0,12
20.029417066815256,49.53416149068323,1.1670910895202755,5.648851633071899,1.998,1.1571098160298487,0.0446766158073773,0.0,,,,128.056,3.531204288482666,2.91,10.554089709762533,2.117647344589233,0.4146082488325575,1.12781509017783,0.4165765235824025,1.092,33.900000000000006,"{'ncols': 11, 'nrows': 1000, 'sha256': 'd4afd3b8512e0e4519f8ce0b8e093271c35edf4e311d3d7fc4952125a59efff4', 'artifact_path': 'wandb-client-artifact://14rsozpjnql4iu6glqjf2k8s5zt43l9f7hhrkckrbkvznfvgi9d8gs39se6ymw4nf64egq48gsd89449nddqk642u17ltk38oxzpobbj40aknx5habvigji34rumnq0q:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://14rsozpjnql4iu6glqjf2k8s5zt43l9f7hhrkckrbkvznfvgi9d8gs39se6ymw4nf64egq48gsd89449nddqk642u17ltk38oxzpobbj40aknx5habvigji34rumnq0q:latest/predictions.table.json', 'path': 'media/table/predictions_1_d4afd3b8512e0e4519f8.table.json', 'size': 598747, '_type': 'table-file'}",18.09101611297718,,,False,True,dev_r1,False,Yes | Maybe | No,4,CTBase,ed215962-8e51-45e7-b025-6e822f877098,anli,CLASSIFICATION,False,28,bigscience/T0_3B,0,True,sentence_to_concepts,prompts/general_fixed_choice.yaml,CommonGen,,3,,,GenFC,,False,['NLI'],,True,False,GeneralFixedChoice,False,False,False,,,prompts,,,True,sentence to concepts,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.common_gen.sentence_to_concepts.LenNorm,ANLI R1,,,,,,,,,,,,,,,,,,,,,56.5,79.0,13
18.58973171999744,48.73622812702528,1.486236118263562,4.51194572031498,1.961666666666667,1.1816476301684422,0.1919997106479301,0.0,,,,120.23583333333332,2.279096927642822,2.911666666666666,7.032967032967033,2.2328487926721574,0.4109305158891085,1.2617359686548597,0.4460443425888906,1.1266666666666667,32.666666666666664,"{'ncols': 11, 'nrows': 1200, 'sha256': 'b771da03923351e1654c12211bf46c4ffc4b5f9c4ea9743ff7084d6798036f5e', 'artifact_path': 'wandb-client-artifact://izpm0nolh5z9d007rpl3x0tat4eym5fp9wihe5oyk8yfljedf34lqij1nba44hdxg33xqlzf8mlcd3fedftt2dbnvrcvx3j07dt9jktb0ypslgjskt63a6j9yhozyere:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://izpm0nolh5z9d007rpl3x0tat4eym5fp9wihe5oyk8yfljedf34lqij1nba44hdxg33xqlzf8mlcd3fedftt2dbnvrcvx3j07dt9jktb0ypslgjskt63a6j9yhozyere:latest/predictions.table.json', 'path': 'media/table/predictions_1_b771da03923351e1654c.table.json', 'size': 696530, '_type': 'table-file'}",32.01257902719214,,,False,True,dev_r3,False,Yes | Maybe | No,4,CTBase,ed215962-8e51-45e7-b025-6e822f877098,anli,CLASSIFICATION,False,28,bigscience/T0_3B,0,True,sentence_to_concepts,prompts/general_fixed_choice.yaml,CommonGen,,3,,,GenFC,,False,['NLI'],,True,False,GeneralFixedChoice,False,False,False,,,prompts,,,True,sentence to concepts,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.common_gen.sentence_to_concepts.LenNorm,ANLI R3,,,,,,,,,,,,,,,,,,,,,71.5,80.0,13
20.266719328083312,48.94448788115716,1.2786908747028345,6.589644417524338,1.998,1.3540971037520095,0.0446766158073773,0.0,,,,124.056,4.161655097007752,2.892,11.855670103092784,2.4279893205165863,0.4520353968440967,1.2949245342949112,0.4537620521815371,1.11,33.6,"{'path': 'media/table/predictions_1_beeaac8fb616198bcd5a.table.json', 'size': 581177, '_type': 'table-file', 'ncols': 11, 'nrows': 1000, 'sha256': 'beeaac8fb616198bcd5a6c07b27532b8a459a7aec31945049f9612502bf7e6af', 'artifact_path': 'wandb-client-artifact://17xs13hz86lnztmik5z77ohqvkl2rp3fc53pghn36bbuzbs0ehspg2f48q97aipomfkvkv47k3faejtneacjy5poqomdf9kpw4lvmva1vwjb1nokn5yt1qfnfjuhe33o:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://17xs13hz86lnztmik5z77ohqvkl2rp3fc53pghn36bbuzbs0ehspg2f48q97aipomfkvkv47k3faejtneacjy5poqomdf9kpw4lvmva1vwjb1nokn5yt1qfnfjuhe33o:latest/predictions.table.json'}",18.09101611297718,,,False,True,dev_r1,False,Yes | Maybe | No,4,CTBase,b7012213-04c4-424d-85fb-39d63d8a0ca2,anli,CLASSIFICATION,False,28,bigscience/T0_3B,0,True,topics_from_the_sentence,prompts/general_fixed_choice.yaml,CommonGen,,3,,,GenFC,,False,['NLI'],,True,False,GeneralFixedChoice,False,False,False,,,prompts,,,True,topics from the sentence,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.common_gen.topics_from_the_sentence.LenNorm,ANLI R1,,,,,,,,,,,,,,,,,,,,,61.0,78.0,8
18.29690856983671,48.25355756791721,1.575190887511429,5.332891062696775,1.9691666666666667,1.3642825911043794,0.1728659564196747,0.0,,,,116.23583333333332,2.6771211604277294,2.9166666666666665,6.63716814159292,2.655769902269045,0.3996526269427266,1.4087918007575948,0.4294950200202817,1.1141666666666667,32.33333333333333,"{'nrows': 1200, 'sha256': '49ab7026661efa2fb93966dc25c61090889ff2044243f66cdc66b5032372af7f', 'artifact_path': 'wandb-client-artifact://sx2u5n112crirq1t8wx5sz5vryl7vbk64qjliwf34j9ci4qa8ys2zc7no1atrlsnkcphas6ev8l3wa88ufmmuzbjv3a4sov3kafakdzgt4ueusy1x3sk1983r2ho67at:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://sx2u5n112crirq1t8wx5sz5vryl7vbk64qjliwf34j9ci4qa8ys2zc7no1atrlsnkcphas6ev8l3wa88ufmmuzbjv3a4sov3kafakdzgt4ueusy1x3sk1983r2ho67at:latest/predictions.table.json', 'path': 'media/table/predictions_1_49ab7026661efa2fb939.table.json', 'size': 675466, '_type': 'table-file', 'ncols': 11}",32.01257902719214,,,False,True,dev_r3,False,Yes | Maybe | No,4,CTBase,b7012213-04c4-424d-85fb-39d63d8a0ca2,anli,CLASSIFICATION,False,28,bigscience/T0_3B,0,True,topics_from_the_sentence,prompts/general_fixed_choice.yaml,CommonGen,,3,,,GenFC,,False,['NLI'],,True,False,GeneralFixedChoice,False,False,False,,,prompts,,,True,topics from the sentence,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.common_gen.topics_from_the_sentence.LenNorm,ANLI R3,,,,,,,,,,,,,,,,,,,,,83.0,81.0,8
30.593651514005497,39.07692307692307,0.6287521516962618,2.110924087792635,1.996,0.6018765791965148,0.063118935352238,0.0,,,,140.056,1.3302238820791243,1.634,52.704031465093415,0.7807002057135105,0.9306148505155074,0.5203453119432155,0.9268764750493996,2.37,39.5,"{'ncols': 11, 'nrows': 1000, 'sha256': 'd6681ef91cd14d00d8d9c11872753ccc5964284ef009345d02751bc85b3d3ad6', 'artifact_path': 'wandb-client-artifact://nrtgxki1jdf04kkhvbl46zyfw60zckmpacsdekw6ielnlr6mykxs2ownege89xfelppgtzv663pxcg8708d2rse58sb20pk1hdc5ipmcdcjrnfzvoaxc07vuhbtrxezo:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://nrtgxki1jdf04kkhvbl46zyfw60zckmpacsdekw6ielnlr6mykxs2ownege89xfelppgtzv663pxcg8708d2rse58sb20pk1hdc5ipmcdcjrnfzvoaxc07vuhbtrxezo:latest/predictions.table.json', 'path': 'media/table/predictions_1_d6681ef91cd14d00d8d9.table.json', 'size': 657254, '_type': 'table-file'}",18.09101611297718,,,False,True,dev_r1,False,Yes | Maybe | No,4,CTBase,fc76beb7-c258-412f-a623-42fc8d2331b6,anli,COMPLETION,False,28,bigscience/T0_3B,0,True,fill_in_the_blank_with_instruction_and_choices,prompts/general_fixed_choice.yaml,NumerSense,,3,,,GenFC,,False,['NLI'],,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,fill_in_the_blank_with_instruction_and_choices,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.numer_sense.fill_in_the_blank_with_instruction_and_choices.LenNorm,ANLI R1,,,,,,,,,,,,,,,,,,,,,2.0,6.0,20
27.452072623313423,39.31947069943289,0.6131959776644559,1.687854891270399,1.9875,0.5245364263188361,0.1844191331360894,0.9876543209876544,,,,132.23583333333335,1.0387767362842957,2.105833333333333,42.04909284951974,0.6490781549861033,0.9931260270255512,0.5490108114061102,0.9796030942285872,1.9066666666666667,33.916666666666664,"{'ncols': 11, 'nrows': 1200, 'sha256': '211f2190032f8ccd9ea9e5763c9121a8e1d58870541fb0941b396e13946b64d4', 'artifact_path': 'wandb-client-artifact://4igr2cfqnrg98d5mlnptpav1srrvo6dmfn1xriq7nx6ncy00rs6t507k7j048oc6e5dwehnccurxbs5f7dm5ght7yjoy5941pkxy08detw6pmsmvvkv8d6i1efh6wzke:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://4igr2cfqnrg98d5mlnptpav1srrvo6dmfn1xriq7nx6ncy00rs6t507k7j048oc6e5dwehnccurxbs5f7dm5ght7yjoy5941pkxy08detw6pmsmvvkv8d6i1efh6wzke:latest/predictions.table.json', 'path': 'media/table/predictions_1_211f2190032f8ccd9ea9.table.json', 'size': 766331, '_type': 'table-file'}",32.01257902719214,,,False,True,dev_r3,False,Yes | Maybe | No,4,CTBase,fc76beb7-c258-412f-a623-42fc8d2331b6,anli,COMPLETION,False,28,bigscience/T0_3B,0,True,fill_in_the_blank_with_instruction_and_choices,prompts/general_fixed_choice.yaml,NumerSense,,3,,,GenFC,,False,['NLI'],,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,fill_in_the_blank_with_instruction_and_choices,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.numer_sense.fill_in_the_blank_with_instruction_and_choices.LenNorm,ANLI R3,,,,,,,,,,,,,,,,,,,,,21.5,9.0,20
23.627781508216287,46.452702702702695,1.1296443493726498,6.44066028547287,2.0,1.0108581219606585,0.0,0.0,,,,127.056,5.016725029230118,2.702,24.43064182194617,1.423935256242752,0.7121769443052758,1.086478249720888,0.7121769443052758,1.298,33.4,"{'artifact_path': 'wandb-client-artifact://19g0evphmjdhynr820exfk5lt5rg2sshmlby565zemcd0nqwm2c90ogoatfucgltltzxpxmjimfxtpmjtsakko6pylu6rq9j8um8bzw181yhkoarbow8c7md4p62bgwi:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://19g0evphmjdhynr820exfk5lt5rg2sshmlby565zemcd0nqwm2c90ogoatfucgltltzxpxmjimfxtpmjtsakko6pylu6rq9j8um8bzw181yhkoarbow8c7md4p62bgwi:latest/predictions.table.json', 'path': 'media/table/predictions_1_4f8cad5e12c308e73b6a.table.json', 'size': 586082, '_type': 'table-file', 'ncols': 11, 'nrows': 1000, 'sha256': '4f8cad5e12c308e73b6ad4d6955ca2b4ed7f90756afdc4459c2e858852921a6a'}",18.09101611297718,,,False,True,dev_r1,False,Yes | Maybe | No,4,CTBase,cacee36c-e2b7-458e-9d51-6fcfd83842b4,anli,COMPLETION,False,28,bigscience/T0_3B,0,True,fill_in_the_blank_before_sentence,prompts/general_fixed_choice.yaml,NumerSense,,3,,,GenFC,,False,['NLI'],,False,False,GeneralFixedChoice,False,False,False,,,prompts,,,True,fill_in_the_blank_before_sentence,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.numer_sense.fill_in_the_blank_before_sentence.LenNorm,ANLI R1,,,,,,,,,,,,,,,,,,,,,64.5,69.0,11
21.44485044619666,48.49296718017415,1.3867327963758838,5.308427155489723,1.9991666666666668,1.0487237297194254,0.0288554828219679,0.0,,,,119.23583333333332,3.602755768398444,2.828333333333333,15.84158415841584,1.705671387091279,0.5602355655337217,1.311679814521384,0.5607231194329931,1.1725,33.5,"{'ncols': 11, 'nrows': 1200, 'sha256': '9a009da3eb8af06f11ef45484fa3c8391af47ab951450e4918e569e329e6f48b', 'artifact_path': 'wandb-client-artifact://19wn8tge1nlb33lnetlans9ej2kdb3z3tu9t8x73ytbjs8ju86fpu8sgl7iixdfdxmx5hbeqxy7rf97tmtwgxhc2g77txljb1arldt9zj4a7rvfsr59ycdxqicqfy12v:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://19wn8tge1nlb33lnetlans9ej2kdb3z3tu9t8x73ytbjs8ju86fpu8sgl7iixdfdxmx5hbeqxy7rf97tmtwgxhc2g77txljb1arldt9zj4a7rvfsr59ycdxqicqfy12v:latest/predictions.table.json', 'path': 'media/table/predictions_1_9a009da3eb8af06f11ef.table.json', 'size': 681113, '_type': 'table-file'}",32.01257902719214,,,False,True,dev_r3,False,Yes | Maybe | No,4,CTBase,cacee36c-e2b7-458e-9d51-6fcfd83842b4,anli,COMPLETION,False,28,bigscience/T0_3B,0,True,fill_in_the_blank_before_sentence,prompts/general_fixed_choice.yaml,NumerSense,,3,,,GenFC,,False,['NLI'],,False,False,GeneralFixedChoice,False,False,False,,,prompts,,,True,fill_in_the_blank_before_sentence,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.numer_sense.fill_in_the_blank_before_sentence.LenNorm,ANLI R3,,,,,,,,,,,,,,,,,,,,,33.0,66.0,11
30.078862217304746,41.28553770086526,0.7071364159013025,3.688163681533187,2.0,0.7088453053627466,0.0,0.0,,,,144.056,2.8314721905887126,1.952,48.95104895104895,0.8566914909444749,0.9988473356824856,0.6385637276112294,0.9988473356824856,2.048,37.7,"{'size': 666987, '_type': 'table-file', 'ncols': 11, 'nrows': 1000, 'sha256': '0b9e0a089661fb1f412d785576a7d85b850b211fe140b9c32674dc8d354ae958', 'artifact_path': 'wandb-client-artifact://kv06bpa51ifu7oqjmq9b26b0gllqv541zyyhc6qbuqc6ii6yd09xvic4g0btzuf8zf574m9utrt9q3eavjzds7s2aodka1ixrbj2kvbpju7x1faofwpt5zqd26tz9svi:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://kv06bpa51ifu7oqjmq9b26b0gllqv541zyyhc6qbuqc6ii6yd09xvic4g0btzuf8zf574m9utrt9q3eavjzds7s2aodka1ixrbj2kvbpju7x1faofwpt5zqd26tz9svi:latest/predictions.table.json', 'path': 'media/table/predictions_1_0b9e0a089661fb1f412d.table.json'}",18.09101611297718,,,False,True,dev_r1,False,Yes | Maybe | No,4,CTBase,5d8e8d21-8059-4373-bbf2-a25cbe1e6960,anli,COMPLETION,False,28,bigscience/T0_3B,0,True,fill_in_the_blank_with_choices_before,prompts/general_fixed_choice.yaml,NumerSense,,3,,,GenFC,,False,['NLI'],,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,fill_in_the_blank_with_choices_before,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.numer_sense.fill_in_the_blank_with_choices_before.LenNorm,ANLI R1,,,,,,,,,,,,,,,,,,,,,10.0,8.0,24
24.868831140739207,43.79336931380107,0.7659903818630978,2.922003448509301,1.995833333333333,0.6931559122240347,0.0644151034739179,0.0,,,,136.23583333333335,1.9888671037725485,2.5016666666666665,30.813124108416552,0.9331363447367524,0.8650610126202404,0.7934839239953745,0.8650590056946019,1.5025,32.666666666666664,"{'ncols': 11, 'nrows': 1200, 'sha256': 'ebd9b4293f39f49e66752fd02924452e4eed3b5e108683958a87876412c5c6f0', 'artifact_path': 'wandb-client-artifact://183jt21y4r0q6yewyiclt3l936tf4a4xiix6ma3ko92wq6qcymhvw61yl84o07ar3nymc958v5f8ou91n9gfcazhfyvhps65vlsyah449tsg9d6dlikg6a3gsgrg1sz6:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://183jt21y4r0q6yewyiclt3l936tf4a4xiix6ma3ko92wq6qcymhvw61yl84o07ar3nymc958v5f8ou91n9gfcazhfyvhps65vlsyah449tsg9d6dlikg6a3gsgrg1sz6:latest/predictions.table.json', 'path': 'media/table/predictions_1_ebd9b4293f39f49e6675.table.json', 'size': 777986, '_type': 'table-file'}",32.01257902719214,,,False,True,dev_r3,False,Yes | Maybe | No,4,CTBase,5d8e8d21-8059-4373-bbf2-a25cbe1e6960,anli,COMPLETION,False,28,bigscience/T0_3B,0,True,fill_in_the_blank_with_choices_before,prompts/general_fixed_choice.yaml,NumerSense,,3,,,GenFC,,False,['NLI'],,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,fill_in_the_blank_with_choices_before,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.numer_sense.fill_in_the_blank_with_choices_before.LenNorm,ANLI R3,,,,,,,,,,,,,,,,,,,,,71.5,32.0,24
18.79955285404877,48.76923076923077,0.9669642839020376,8.726096525132656,2.0,1.2587017808779248,0.0,0.0,,,,155.056,6.296561801433564,2.934,7.62942779291553,2.429534723699093,0.3572730048576298,1.125825238479396,0.3572730048576298,1.066,33.1,"{'artifact_path': 'wandb-client-artifact://k6b3pjvt42uqfkj3az5zx679s5xxt068h9madhxix92dg8azzd1ypzdnh7mm7sgscuvot28xhpgtxi0jw8m4bsm2fxp3szk1uw11mqwe6b62s231qgfzh2qy3pwp1hkx:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://k6b3pjvt42uqfkj3az5zx679s5xxt068h9madhxix92dg8azzd1ypzdnh7mm7sgscuvot28xhpgtxi0jw8m4bsm2fxp3szk1uw11mqwe6b62s231qgfzh2qy3pwp1hkx:latest/predictions.table.json', 'path': 'media/table/predictions_1_8780887aeb6fc6cfe963.table.json', 'size': 703115, '_type': 'table-file', 'ncols': 11, 'nrows': 1000, 'sha256': '8780887aeb6fc6cfe9639a57e2709b0100a8f0f8cb36019290fd600b862c0a68'}",18.09101611297718,,,False,True,dev_r1,False,Yes | Maybe | No,4,CTBase,4e9da2b8-2502-44a7-a7da-ae62f2d554c9,anli,COMPLETION,False,28,bigscience/T0_3B,0,True,fill_in_the_blank_with_instruction,prompts/general_fixed_choice.yaml,NumerSense,,3,,,GenFC,,False,['NLI'],,False,False,GeneralFixedChoice,False,False,False,,,prompts,,,True,fill_in_the_blank_with_instruction,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.numer_sense.fill_in_the_blank_with_instruction.LenNorm,ANLI R1,,,,,,,,,,,,,,,,,,,,,69.0,85.0,39
17.456430468246754,49.463722397476346,1.139703890616739,7.597611987491448,2.0,1.0516899805656548,0.0,0.0,,,,147.23583333333335,4.978140213688215,2.9816666666666665,2.905569007263922,2.6194717738032343,0.1906057595025805,1.1243186225828927,0.1906057595025805,1.018333333333333,33.166666666666664,"{'artifact_path': 'wandb-client-artifact://187u2cv0x6554u79nmwxeby3m04gt0ar42gn0q5lvy2pvyuefv0j4tjaas5tn7jtz98m6t90j4tuvjs6zur8uf5we7pxvegbvxsv8cxxbsw1byt1qdfsjvxxm9o85fjw:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://187u2cv0x6554u79nmwxeby3m04gt0ar42gn0q5lvy2pvyuefv0j4tjaas5tn7jtz98m6t90j4tuvjs6zur8uf5we7pxvegbvxsv8cxxbsw1byt1qdfsjvxxm9o85fjw:latest/predictions.table.json', 'path': 'media/table/predictions_1_50f3866352d5ec6bfff5.table.json', 'size': 821666, '_type': 'table-file', 'ncols': 11, 'nrows': 1200, 'sha256': '50f3866352d5ec6bfff5e2059844482692ec98e3d848f6f64fe65cf961d140bb'}",32.01257902719214,,,False,True,dev_r3,False,Yes | Maybe | No,4,CTBase,4e9da2b8-2502-44a7-a7da-ae62f2d554c9,anli,COMPLETION,False,28,bigscience/T0_3B,0,True,fill_in_the_blank_with_instruction,prompts/general_fixed_choice.yaml,NumerSense,,3,,,GenFC,,False,['NLI'],,False,False,GeneralFixedChoice,False,False,False,,,prompts,,,True,fill_in_the_blank_with_instruction,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.numer_sense.fill_in_the_blank_with_instruction.LenNorm,ANLI R3,,,,,,,,,,,,,,,,,,,,,44.5,88.0,39
30.83016236757372,39.44530046224962,0.6457958880355011,2.680119732543826,1.999,0.658651618999094,0.0316069612585582,0.0,,,,140.056,1.8085108734369275,1.632,53.04518664047152,0.8716088591068983,0.9298257901349049,0.5280333249927037,0.9288912745849216,2.369,39.8,"{'_type': 'table-file', 'ncols': 11, 'nrows': 1000, 'sha256': '466fe13f5ecfbd0300ec85f45a5c0462f9418460554595f5b511957b43253062', 'artifact_path': 'wandb-client-artifact://oey92yphth9x2so049ph1uoyx0m8pufiecjfhfc2wrfowou83rb7bw7ca66j4pebfeshxbsw5kcepci7nqrqeqh4cy9c2dlf7esmo09nq4rjfw5lhhjyk4vug6j8cpsz:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://oey92yphth9x2so049ph1uoyx0m8pufiecjfhfc2wrfowou83rb7bw7ca66j4pebfeshxbsw5kcepci7nqrqeqh4cy9c2dlf7esmo09nq4rjfw5lhhjyk4vug6j8cpsz:latest/predictions.table.json', 'path': 'media/table/predictions_1_466fe13f5ecfbd0300ec.table.json', 'size': 669206}",18.09101611297718,,,False,True,dev_r1,False,Yes | Maybe | No,4,CTBase,1f959d92-dca8-4647-9840-69391dfbd000,anli,COMPLETION,False,28,bigscience/T0_3B,0,True,fill_in_the_blank_with_choices_after,prompts/general_fixed_choice.yaml,NumerSense,,3,,,GenFC,,False,['NLI'],,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,fill_in_the_blank_with_choices_after,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.numer_sense.fill_in_the_blank_with_choices_after.LenNorm,ANLI R1,,,,,,,,,,,,,,,,,,,,,1.0,3.0,20
26.080369700622867,37.523809523809526,0.644019340339167,2.0956343099226555,1.9933333333333336,0.5531402511465788,0.0997775303139717,0.0,,,,132.23583333333335,1.3961226812501748,2.09,40.71729957805908,0.6995116286724806,0.995941765365827,0.6017150413236394,0.99149158118239,1.9166666666666667,32.5,"{'_latest_artifact_path': 'wandb-client-artifact://c7o3iy5qlgwmg63mnwus9hzvu86bscojh63czhxwn9wldjfzlz953d2zuu3yz1mqeqayy9sgz6du370dc4sl5t7v6zi94xtaus3qpljuduydj76gklxqwn1jnc3uxqoi:latest/predictions.table.json', 'path': 'media/table/predictions_1_d838f9ba213396a05c3a.table.json', 'size': 780817, '_type': 'table-file', 'ncols': 11, 'nrows': 1200, 'sha256': 'd838f9ba213396a05c3aa0594222d0a8e5147ac81a95b7d801f8fe1b9ff0975d', 'artifact_path': 'wandb-client-artifact://c7o3iy5qlgwmg63mnwus9hzvu86bscojh63czhxwn9wldjfzlz953d2zuu3yz1mqeqayy9sgz6du370dc4sl5t7v6zi94xtaus3qpljuduydj76gklxqwn1jnc3uxqoi:latest/predictions.table.json'}",32.01257902719214,,,False,True,dev_r3,False,Yes | Maybe | No,4,CTBase,1f959d92-dca8-4647-9840-69391dfbd000,anli,COMPLETION,False,28,bigscience/T0_3B,0,True,fill_in_the_blank_with_choices_after,prompts/general_fixed_choice.yaml,NumerSense,,3,,,GenFC,,False,['NLI'],,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,fill_in_the_blank_with_choices_after,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.numer_sense.fill_in_the_blank_with_choices_after.LenNorm,ANLI R3,,,,,,,,,,,,,,,,,,,,,76.5,23.0,20
19.300457070241244,46.36290967226218,1.159375505760978,7.386638494491577,2.0,1.2190993652800397,0.0,0.0,,,,153.056,5.436709082603454,2.836,11.538461538461538,1.9499294118881223,0.5487294415283365,1.1689228895815886,0.5487294415283364,1.164,31.4,"{'_type': 'table-file', 'ncols': 11, 'nrows': 1000, 'sha256': '5daf683ef31c871c03808555e79b45d60d8ba9e1dc1c3a826afb5602120ac2f9', 'artifact_path': 'wandb-client-artifact://9k819lfycwe4u62la47fd5sj5dcfdj40gkrrqswcqvkf3b59bbd8x04fsqovdvyr9nfgbubmpt4lhzoxzmhxr1w9w6obw0pmi1l4gdtchp62hvfa0okoqcyjfe10p33h:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://9k819lfycwe4u62la47fd5sj5dcfdj40gkrrqswcqvkf3b59bbd8x04fsqovdvyr9nfgbubmpt4lhzoxzmhxr1w9w6obw0pmi1l4gdtchp62hvfa0okoqcyjfe10p33h:latest/predictions.table.json', 'path': 'media/table/predictions_1_5daf683ef31c871c0380.table.json', 'size': 675164}",18.09101611297718,,,False,True,dev_r1,False,Yes | Maybe | No,4,CTBase,c97e7bbf-b7f0-4cee-ada5-431ce7d606cc,anli,CLASSIFICATION,False,28,bigscience/T0_3B,0,True,semantic_relations_nominials_without_options,prompts/general_fixed_choice.yaml,SemEval2010,,3,,,GenFC,,False,['NLI'],,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,semantic relations nominials without options,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.sem_eval_2010_task_8.semantic_relations_nominials_without_options.LenNorm,ANLI R1,,,,,,,,,,,,,,,,,,,,,88.0,82.0,37
18.223944875107662,48.44961240310077,1.4594828618705753,5.953739303350448,1.9975,1.1328101739373435,0.0499374608885954,0.0,,,,145.23583333333335,3.7640752402941375,2.92,6.222222222222222,2.18966406305631,0.3919183588453085,1.4047984153828952,0.3945804734144861,1.0825,32.416666666666664,"{'_type': 'table-file', 'ncols': 11, 'nrows': 1200, 'sha256': '3622fcca09f10b52fbb5d5c546e03241734fa6ca18dad19f4bc31a1950f1e26b', 'artifact_path': 'wandb-client-artifact://blovj0li1csf6azfsu8rlzc0we29tmi7fq8bea2od3y9w49z25idwxai2whkgg35osrssytwvfpm3hahrz4emn9rpq8tht5y5yrztktvhv6rfnjw45rmnew1tqrhvwu1:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://blovj0li1csf6azfsu8rlzc0we29tmi7fq8bea2od3y9w49z25idwxai2whkgg35osrssytwvfpm3hahrz4emn9rpq8tht5y5yrztktvhv6rfnjw45rmnew1tqrhvwu1:latest/predictions.table.json', 'path': 'media/table/predictions_1_3622fcca09f10b52fbb5.table.json', 'size': 787965}",32.01257902719214,,,False,True,dev_r3,False,Yes | Maybe | No,4,CTBase,c97e7bbf-b7f0-4cee-ada5-431ce7d606cc,anli,CLASSIFICATION,False,28,bigscience/T0_3B,0,True,semantic_relations_nominials_without_options,prompts/general_fixed_choice.yaml,SemEval2010,,3,,,GenFC,,False,['NLI'],,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,semantic relations nominials without options,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.sem_eval_2010_task_8.semantic_relations_nominials_without_options.LenNorm,ANLI R3,,,,,,,,,,,,,,,,,,,,,80.5,84.0,37
25.118229910699725,43.96782841823057,0.7898159225882969,6.598732908084989,2.0,0.8723722215799276,0.0,0.0,,,,143.056,5.483266613602639,2.572,31.38686131386861,1.1154662944823504,0.8202536193153921,0.847500248401664,0.8202536193153921,1.428,33.2,"{'nrows': 1000, 'sha256': 'e591ba73217802373dbd65fbac92696e022ad1da25431fa9858a8bde22438599', 'artifact_path': 'wandb-client-artifact://181m6dsaetj0ubis7npqcmqxzcdcghp30vatgw5rnfhppcosaazp1wdey2u9jie0ww5b4sa6jnvgdurm8n1kbq6d0f4uwez5axlwwq0qu48k6hxoh0vj044ygjptfkim:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://181m6dsaetj0ubis7npqcmqxzcdcghp30vatgw5rnfhppcosaazp1wdey2u9jie0ww5b4sa6jnvgdurm8n1kbq6d0f4uwez5axlwwq0qu48k6hxoh0vj044ygjptfkim:latest/predictions.table.json', 'path': 'media/table/predictions_1_e591ba73217802373dbd.table.json', 'size': 650355, '_type': 'table-file', 'ncols': 11}",18.09101611297718,,,False,True,dev_r1,False,Yes | Maybe | No,4,CTBase,5d7123a8-4ed4-42ce-bcfb-4af415962efc,anli,CLASSIFICATION,False,28,bigscience/T0_3B,0,True,semantically_related_nominials_with_options,prompts/general_fixed_choice.yaml,SemEval2010,,3,,,GenFC,,False,['NLI'],,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,semantically related nominials with options,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.sem_eval_2010_task_8.semantically_related_nominials_with_options.LenNorm,ANLI R1,,,,,,,,,,,,,,,,,,,,,67.0,58.0,17
20.04793577414928,47.97342192691031,0.9244583918966816,5.716412095005314,2.0,0.8636065085499951,0.0,0.0,,,,135.23583333333335,4.261160405178865,2.848333333333333,12.170385395537524,1.4552516898264487,0.5294625157228371,1.0050664080046423,0.5294625157228371,1.1516666666666666,32.58333333333333,"{'sha256': 'bbdcc21304da0ce730a536bb4ebc3700223a8ffe4c347feea66ce93302af4085', 'artifact_path': 'wandb-client-artifact://crc0blake0lgi3uc3hgi0lgicrgj6br7y9gznn70axko8yp8yw60hmqpga7o03vc2x5dmb7sakvanon495tbx1suinyg7wtep9888phytmihib2k6023bzh09i90d2d2:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://crc0blake0lgi3uc3hgi0lgicrgj6br7y9gznn70axko8yp8yw60hmqpga7o03vc2x5dmb7sakvanon495tbx1suinyg7wtep9888phytmihib2k6023bzh09i90d2d2:latest/predictions.table.json', 'path': 'media/table/predictions_1_bbdcc21304da0ce730a5.table.json', 'size': 758078, '_type': 'table-file', 'ncols': 11, 'nrows': 1200}",32.01257902719214,,,False,True,dev_r3,False,Yes | Maybe | No,4,CTBase,5d7123a8-4ed4-42ce-bcfb-4af415962efc,anli,CLASSIFICATION,False,28,bigscience/T0_3B,0,True,semantically_related_nominials_with_options,prompts/general_fixed_choice.yaml,SemEval2010,,3,,,GenFC,,False,['NLI'],,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,semantically related nominials with options,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.sem_eval_2010_task_8.semantically_related_nominials_with_options.LenNorm,ANLI R3,,,,,,,,,,,,,,,,,,,,,74.0,74.0,17
24.614548829680068,44.73916887709992,0.8069182722192163,5.314150097966194,2.0,0.8919102448365451,0.0,0.0,,,,165.056,4.189303236722946,2.596,29.1044776119403,1.124846861243248,0.8029844332239574,0.8418587280062619,0.8029844332239574,1.404,33.1,"{'path': 'media/table/predictions_1_caf7c8363825cb4fb36c.table.json', 'size': 725760, '_type': 'table-file', 'ncols': 11, 'nrows': 1000, 'sha256': 'caf7c8363825cb4fb36c958d386a96252480d183bd4636e01bb1dec68d6b8ba4', 'artifact_path': 'wandb-client-artifact://zg4l3b0xftxfd5ik5dyhkjexmr3lqmp1u59byfg0chpbtl3hi21m95ljd8rk4bxjfavha7gz3omdowbyinb91rba2kx6cq67lnn90esdioem8xhxwb2ypbrvvioe7oiz:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://zg4l3b0xftxfd5ik5dyhkjexmr3lqmp1u59byfg0chpbtl3hi21m95ljd8rk4bxjfavha7gz3omdowbyinb91rba2kx6cq67lnn90esdioem8xhxwb2ypbrvvioe7oiz:latest/predictions.table.json'}",18.09101611297718,,,False,True,dev_r1,False,Yes | Maybe | No,4,CTBase,202246b0-3f82-42b9-bc8d-d36997b5f2cb,anli,CLASSIFICATION,False,28,bigscience/T0_3B,0,True,semantic_relations_with_options,prompts/general_fixed_choice.yaml,SemEval2010,,3,,,GenFC,,False,['NLI'],,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,semantic relations with options,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.sem_eval_2010_task_8.semantic_relations_with_options.LenNorm,ANLI R1,,,,,,,,,,,,,,,,,,,,,69.0,64.0,40
20.92147629186025,47.97843665768194,0.9301042939219156,4.439609325826168,1.9983333333333333,0.8619620163414231,0.0407907941684013,0.0,,,,157.23583333333335,3.0500913800795875,2.813333333333333,14.78599221789883,1.3895179457465807,0.5817979794472381,0.9942431940702332,0.5826925051479173,1.1883333333333332,32.83333333333333,"{'nrows': 1200, 'sha256': '6ecd37e464423b80ef0623af75e5bff12f036b88cb2df409f5a45228b43a18cd', 'artifact_path': 'wandb-client-artifact://4849zg1p5pveg9t1qdq5mslfef0zc2lfxxle27pnqtcdnjtyzoojdpof93yywvshu2s7694g1h5r1zyj2g59osu4y1iyu2kimufxbprv1m2wquiawfibtsms7iat6eqz:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://4849zg1p5pveg9t1qdq5mslfef0zc2lfxxle27pnqtcdnjtyzoojdpof93yywvshu2s7694g1h5r1zyj2g59osu4y1iyu2kimufxbprv1m2wquiawfibtsms7iat6eqz:latest/predictions.table.json', 'path': 'media/table/predictions_1_6ecd37e464423b80ef06.table.json', 'size': 848679, '_type': 'table-file', 'ncols': 11}",32.01257902719214,,,False,True,dev_r3,False,Yes | Maybe | No,4,CTBase,202246b0-3f82-42b9-bc8d-d36997b5f2cb,anli,CLASSIFICATION,False,28,bigscience/T0_3B,0,True,semantic_relations_with_options,prompts/general_fixed_choice.yaml,SemEval2010,,3,,,GenFC,,False,['NLI'],,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,semantic relations with options,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.sem_eval_2010_task_8.semantic_relations_with_options.LenNorm,ANLI R3,,,,,,,,,,,,,,,,,,,,,63.0,72.0,40
25.8799031695532,44.48462929475588,1.1533634972264624,4.020703989028931,1.99,0.9492247994944012,0.099498743710662,0.0,,,,125.056,2.7503878445625305,2.546,33.155080213903744,1.2703161444664002,0.8377851753283773,1.094490420487005,0.8382744180756085,1.464,33.900000000000006,"{'nrows': 1000, 'sha256': 'bbcfc244e60bba88c4c2ee0108da8d5a9bea69df7bc50cbeca9370c3c0e81f76', 'artifact_path': 'wandb-client-artifact://desjbey5mp81gelni9dxb236yuef1uissy0ks8jkrx24m1goqkkrva6gz36nxsyayldv0ftheo9dpyicrd6rwtehq8v1b88jshg8o3wkz2f6v18cinz2b9lq78irq9w6:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://desjbey5mp81gelni9dxb236yuef1uissy0ks8jkrx24m1goqkkrva6gz36nxsyayldv0ftheo9dpyicrd6rwtehq8v1b88jshg8o3wkz2f6v18cinz2b9lq78irq9w6:latest/predictions.table.json', 'path': 'media/table/predictions_1_bbcfc244e60bba88c4c2.table.json', 'size': 587748, '_type': 'table-file', 'ncols': 11}",18.09101611297718,,,False,True,dev_r1,False,Yes | Maybe | No,4,CTBase,af4d550e-54b8-471e-97af-2b2c50a1382e,anli,SUMMARIZATION,False,28,bigscience/T0_3B,0,True,relatedwork_abstract,prompts/general_fixed_choice.yaml,Multi-XSci,,3,,,GenFC,,False,['NLI'],,False,False,GeneralFixedChoice,False,False,False,,,prompts,,,True,relatedwork_abstract,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.multi_x_science_sum.relatedwork_abstract.LenNorm,ANLI R1,,,,,,,,,,,,,,,,,,,,,56.5,53.0,9
20.998704433818936,47.25274725274725,1.304275767170543,2.992771198352178,1.8266666666666669,1.0300180664853382,0.3978553617696875,0.4761904761904761,,,,117.23583333333332,1.4158281672000883,2.7816666666666667,15.267175572519085,1.5769430311520891,0.6115531229764282,1.0486027589645548,0.6757197808427856,1.3916666666666666,32.083333333333336,"{'ncols': 11, 'nrows': 1200, 'sha256': '4d180738cbed553a5b4fb2dcd0dea572bce254d1eea3ffc24d083d680906b04e', 'artifact_path': 'wandb-client-artifact://y1i584h3ci22dhkc50ekpeoveo8ert728flptiq2kidr9rjszux7yo652q1yexszfx2nz4pcqlz7oyveei6f9gzto2cvpglx06y6swq9w7tuoho3wmr7rhlnsme1hrc0:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://y1i584h3ci22dhkc50ekpeoveo8ert728flptiq2kidr9rjszux7yo652q1yexszfx2nz4pcqlz7oyveei6f9gzto2cvpglx06y6swq9w7tuoho3wmr7rhlnsme1hrc0:latest/predictions.table.json', 'path': 'media/table/predictions_1_4d180738cbed553a5b4f.table.json', 'size': 682802, '_type': 'table-file'}",32.01257902719214,,,False,True,dev_r3,False,Yes | Maybe | No,4,CTBase,af4d550e-54b8-471e-97af-2b2c50a1382e,anli,SUMMARIZATION,False,28,bigscience/T0_3B,0,True,relatedwork_abstract,prompts/general_fixed_choice.yaml,Multi-XSci,,3,,,GenFC,,False,['NLI'],,False,False,GeneralFixedChoice,False,False,False,,,prompts,,,True,relatedwork_abstract,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.multi_x_science_sum.relatedwork_abstract.LenNorm,ANLI R3,,,,,,,,,,,,,,,,,,,,,87.5,70.0,9
26.879313966205306,43.85633270321361,1.087343194673109,4.26540853881836,1.997,0.898359093020163,0.0546900356555012,0.0,,,,133.056,3.126672523021698,2.45,36.7816091954023,1.1387360157966613,0.8930285549745877,1.0272761707321991,0.8928555314271173,1.553,34.4,"{'artifact_path': 'wandb-client-artifact://su5jmk35cajnhlg5dfaql5zezys4jwsukkeqetunhjle0gf4tfmjg4d0wq2otygkjj7jnbo51vrgjyxfm6opzs3ge93ocfb73eptf20w25df7fidj93rdkvuihvsql9e:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://su5jmk35cajnhlg5dfaql5zezys4jwsukkeqetunhjle0gf4tfmjg4d0wq2otygkjj7jnbo51vrgjyxfm6opzs3ge93ocfb73eptf20w25df7fidj93rdkvuihvsql9e:latest/predictions.table.json', 'path': 'media/table/predictions_1_1b666bc9345a66b7670f.table.json', 'size': 629380, '_type': 'table-file', 'ncols': 11, 'nrows': 1000, 'sha256': '1b666bc9345a66b7670f31d371403a7ca3f3cac1de0755f7d189eab18c0d207a'}",18.09101611297718,,,False,True,dev_r1,False,Yes | Maybe | No,4,CTBase,3bd082cb-4e28-4eb7-9fa2-dd03f1f86219,anli,SUMMARIZATION,False,28,bigscience/T0_3B,0,True,abstract_relatedwork,prompts/general_fixed_choice.yaml,Multi-XSci,,3,,,GenFC,,False,['NLI'],,False,False,GeneralFixedChoice,False,False,False,,,prompts,,,True,abstract_relatedwork,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.multi_x_science_sum.abstract_relatedwork.LenNorm,ANLI R1,,,,,,,,,,,,,,,,,,,,,45.0,45.0,17
22.13054391914356,47.36111111111112,1.3265682305934712,3.233143801341454,1.9283333333333328,1.0040865589552437,0.2674519686888761,0.0,,,,125.23583333333332,1.7171042017141978,2.740833333333333,19.03052064631957,1.5160395996272564,0.6710682818379131,1.1233357683236664,0.6902047804013595,1.330833333333333,32.83333333333333,"{'sha256': 'b4da303b553417a7f7d1743e1b7764e4528c1fd38eec830b3ff230c9b5a486e3', 'artifact_path': 'wandb-client-artifact://grheb5q90ys26m273t4s50n7sen84dw2a8x5yxgiw8hygt8ypiefctvjwenwrg46ev3bnkgb7qcd0ogvf1viag7eqsk6qh7mqrgh1tkxscx31ip8hjdqizphs43wi07u:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://grheb5q90ys26m273t4s50n7sen84dw2a8x5yxgiw8hygt8ypiefctvjwenwrg46ev3bnkgb7qcd0ogvf1viag7eqsk6qh7mqrgh1tkxscx31ip8hjdqizphs43wi07u:latest/predictions.table.json', 'path': 'media/table/predictions_1_b4da303b553417a7f7d1.table.json', 'size': 732684, '_type': 'table-file', 'ncols': 11, 'nrows': 1200}",32.01257902719214,,,False,True,dev_r3,False,Yes | Maybe | No,4,CTBase,3bd082cb-4e28-4eb7-9fa2-dd03f1f86219,anli,SUMMARIZATION,False,28,bigscience/T0_3B,0,True,abstract_relatedwork,prompts/general_fixed_choice.yaml,Multi-XSci,,3,,,GenFC,,False,['NLI'],,False,False,GeneralFixedChoice,False,False,False,,,prompts,,,True,abstract_relatedwork,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.multi_x_science_sum.abstract_relatedwork.LenNorm,ANLI R3,,,,,,,,,,,,,,,,,,,,,63.0,56.0,17
26.554050964891506,44.17293233082707,1.1450923551671088,4.993648736238479,2.0,0.9173426432623092,0.0,0.0,,,,126.056,3.849050092697144,2.462,35.48922056384743,1.144598643541336,0.8868799242287536,1.0845201939388076,0.8868799242287537,1.538,34.2,"{'nrows': 1000, 'sha256': '1400432c8bd5d88d583ff08c89cf70295edcd79766add201f94c022166e3de95', 'artifact_path': 'wandb-client-artifact://mg1ashutwptixmg3ic6bgf4w9t1m1rrnxzremprypzg82qrzvlvok96q3haigzual1zbz4qw2mycd5s1ouwfpdo6p36au2hx088avaydl3juec5z8m4p5uua6bdfdqm6:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://mg1ashutwptixmg3ic6bgf4w9t1m1rrnxzremprypzg82qrzvlvok96q3haigzual1zbz4qw2mycd5s1ouwfpdo6p36au2hx088avaydl3juec5z8m4p5uua6bdfdqm6:latest/predictions.table.json', 'path': 'media/table/predictions_1_1400432c8bd5d88d583f.table.json', 'size': 597425, '_type': 'table-file', 'ncols': 11}",18.09101611297718,,,False,True,dev_r1,False,Yes | Maybe | No,4,CTBase,2bca0197-e3d4-4870-bd95-178411e52e09,anli,SUMMARIZATION,False,28,bigscience/T0_3B,0,True,ref_relatedwork,prompts/general_fixed_choice.yaml,Multi-XSci,,3,,,GenFC,,False,['NLI'],,False,False,GeneralFixedChoice,False,False,False,,,prompts,,,True,ref_relatedwork,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.multi_x_science_sum.ref_relatedwork.LenNorm,ANLI R1,,,,,,,,,,,,,,,,,,,,,48.5,48.0,10
22.61646419045036,46.95898161244696,1.431261196529358,3.6688169379035633,1.9625,1.011028633635316,0.2027159342528357,0.0,,,,118.23583333333332,2.175181238452593,2.6966666666666668,20.89041095890411,1.4936356994509696,0.7173949787638296,1.2646955247312344,0.723186909142827,1.340833333333333,32.75,"{'_type': 'table-file', 'ncols': 11, 'nrows': 1200, 'sha256': '68f2b914991f4861b62fe4191e5e645268bc8da70d1ea7b8039921d806781cb6', 'artifact_path': 'wandb-client-artifact://167p4o02es68xl95xl6qbc8gen2ptkhz7tqpjbx8wmkz7jj4nh0ar6n14mdrm2rblnt41an6zkbgxmzw25lz8445im7q5hcsajhgvmfynwzdzcaprgjup3owir25t337:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://167p4o02es68xl95xl6qbc8gen2ptkhz7tqpjbx8wmkz7jj4nh0ar6n14mdrm2rblnt41an6zkbgxmzw25lz8445im7q5hcsajhgvmfynwzdzcaprgjup3owir25t337:latest/predictions.table.json', 'path': 'media/table/predictions_1_68f2b914991f4861b62f.table.json', 'size': 694517}",32.01257902719214,,,False,True,dev_r3,False,Yes | Maybe | No,4,CTBase,2bca0197-e3d4-4870-bd95-178411e52e09,anli,SUMMARIZATION,False,28,bigscience/T0_3B,0,True,ref_relatedwork,prompts/general_fixed_choice.yaml,Multi-XSci,,3,,,GenFC,,False,['NLI'],,False,False,GeneralFixedChoice,False,False,False,,,prompts,,,True,ref_relatedwork,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.multi_x_science_sum.ref_relatedwork.LenNorm,ANLI R3,,,,,,,,,,,,,,,,,,,,,67.5,54.0,10
24.234469151790066,46.76198486122792,1.0286997513519265,3.721050186395645,1.989,0.8978464091381431,0.1043024448419115,0.0,,,,126.056,2.4446744294166565,2.712,25.94142259414226,1.2763757569789886,0.702179464239734,0.9944552848290398,0.7054069747316084,1.299,34.0,"{'sha256': 'c86d679f4cf42d0cd2f820dbc1fffa7295491eeed967acc757efb0346821fcd2', 'artifact_path': 'wandb-client-artifact://13de1bcvvzito49hm499kyjegfod4j9s7xvm4sas7375uzdujagb625uvx1ae3t266a5gegb5dc2ptwm9gzuu3t0v6nn5n17k0bat9zgq4mpe5qv21ta47pmhm6ckkdg:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://13de1bcvvzito49hm499kyjegfod4j9s7xvm4sas7375uzdujagb625uvx1ae3t266a5gegb5dc2ptwm9gzuu3t0v6nn5n17k0bat9zgq4mpe5qv21ta47pmhm6ckkdg:latest/predictions.table.json', 'path': 'media/table/predictions_1_c86d679f4cf42d0cd2f8.table.json', 'size': 585646, '_type': 'table-file', 'ncols': 11, 'nrows': 1000}",18.09101611297718,,,False,True,dev_r1,False,Yes | Maybe | No,4,CTBase,774b4349-0524-4a34-881b-b344f8f5c34e,anli,COMPLETION,False,28,bigscience/T0_3B,0,True,what_comes_next,prompts/general_fixed_choice.yaml,LAMBADA,,3,,,GenFC,,False,['NLI'],,False,False,GeneralFixedChoice,False,False,False,,,prompts,,,True,what comes next,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.craffel_openai_lambada.what_comes_next.LenNorm,ANLI R1,,,,,,,,,,,,,,,,,,,,,53.0,65.0,10
21.54069823073064,47.37916950306331,1.1757029737389744,2.8347760604818664,1.83,0.9695048697098536,0.3908537663457609,0.9638554216867468,,,,118.23583333333332,1.2765214480956395,2.799166666666667,16.279069767441857,1.5582546123862266,0.5920298181304346,0.9508887191337198,0.6582674017617933,1.3708333333333331,32.666666666666664,"{'sha256': '1f807645c656caf1d9b6ff83a17792ac19ea75ba134d19fb6142d22216d9d553', 'artifact_path': 'wandb-client-artifact://6v3woqqytcbysexk9py01m7sqi58utb6lv5ubl10ggig9eybc9dgdbgqt3cfzv7vc0dhmevmmz5kra7su4xh1j3ygb32l2yeouxc3est6v9as854w8ayi1p4w33py9rk:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://6v3woqqytcbysexk9py01m7sqi58utb6lv5ubl10ggig9eybc9dgdbgqt3cfzv7vc0dhmevmmz5kra7su4xh1j3ygb32l2yeouxc3est6v9as854w8ayi1p4w33py9rk:latest/predictions.table.json', 'path': 'media/table/predictions_1_1f807645c656caf1d9b6.table.json', 'size': 680723, '_type': 'table-file', 'ncols': 11, 'nrows': 1200}",32.01257902719214,,,False,True,dev_r3,False,Yes | Maybe | No,4,CTBase,774b4349-0524-4a34-881b-b344f8f5c34e,anli,COMPLETION,False,28,bigscience/T0_3B,0,True,what_comes_next,prompts/general_fixed_choice.yaml,LAMBADA,,3,,,GenFC,,False,['NLI'],,False,False,GeneralFixedChoice,False,False,False,,,prompts,,,True,what comes next,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.craffel_openai_lambada.what_comes_next.LenNorm,ANLI R3,,,,,,,,,,,,,,,,,,,,,71.5,65.0,10
25.33534802105673,44.48430493273543,1.172894528012958,4.835631020009518,1.999,0.9924919513724796,0.0316069612585582,0.0,,,,127.056,3.5254751749038697,2.564,31.52173913043477,1.310155845105648,0.8257747876994066,1.1152036712093207,0.825851681599063,1.437,33.5,"{'_latest_artifact_path': 'wandb-client-artifact://54pwuk7z81co4z25jkmjawhbbi41g6c89i3s3i473wk5dk4wvky3mnp4hpvjxgop795aa7x9hf4sbgt3mlexdtomdi0b04l1miftmpkn404of5zu8noi66y20qkidcho:latest/predictions.table.json', 'path': 'media/table/predictions_1_4e210cd81d863e5d9d04.table.json', 'size': 568266, '_type': 'table-file', 'ncols': 11, 'nrows': 1000, 'sha256': '4e210cd81d863e5d9d04a7a389f2251876866ec50750de428ce13b85a1024d2c', 'artifact_path': 'wandb-client-artifact://54pwuk7z81co4z25jkmjawhbbi41g6c89i3s3i473wk5dk4wvky3mnp4hpvjxgop795aa7x9hf4sbgt3mlexdtomdi0b04l1miftmpkn404of5zu8noi66y20qkidcho:latest/predictions.table.json'}",18.09101611297718,,,False,True,dev_r1,False,Yes | Maybe | No,4,CTBase,4f08e9d4-bcff-4bc0-9902-87c497625d17,anli,COMPLETION,False,28,bigscience/T0_3B,0,True,GPT_3_style,prompts/general_fixed_choice.yaml,LAMBADA,,3,,,GenFC,,False,['NLI'],,False,False,GeneralFixedChoice,False,False,False,,,prompts,,,True,GPT-3 style,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.craffel_openai_lambada.GPT_3_style.LenNorm,ANLI R1,,,,,,,,,,,,,,,,,,,,,62.5,57.0,11
20.933104424565528,47.61904761904762,1.4019504651176689,3.712420100470384,1.9416666666666669,1.0767560023949183,0.2379017070603366,0.0,,,,119.23583333333332,2.0284277985493344,2.790833333333333,15.180265654648958,1.6839923019210497,0.6113503950727075,1.2514977695641512,0.6358278724099262,1.2675,32.5,"{'path': 'media/table/predictions_1_2835bd77148cdd825d5c.table.json', 'size': 659287, '_type': 'table-file', 'ncols': 11, 'nrows': 1200, 'sha256': '2835bd77148cdd825d5c979d60f29b9d9bd8d961b0ea576c029cd3b52cc9d873', 'artifact_path': 'wandb-client-artifact://11oym0nvulz9yn40qm00g9c5swpqiih7bp2dzrf7qc6o107k8c96q23c3w108nehjotcdgmjg6oq7itw021d7twdlb5vzefhm9pfbkp4xe9g1u7mbphfc2mq62bqdkox:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://11oym0nvulz9yn40qm00g9c5swpqiih7bp2dzrf7qc6o107k8c96q23c3w108nehjotcdgmjg6oq7itw021d7twdlb5vzefhm9pfbkp4xe9g1u7mbphfc2mq62bqdkox:latest/predictions.table.json'}",32.01257902719214,,,False,True,dev_r3,False,Yes | Maybe | No,4,CTBase,4f08e9d4-bcff-4bc0-9902-87c497625d17,anli,COMPLETION,False,28,bigscience/T0_3B,0,True,GPT_3_style,prompts/general_fixed_choice.yaml,LAMBADA,,3,,,GenFC,,False,['NLI'],,False,False,GeneralFixedChoice,False,False,False,,,prompts,,,True,GPT-3 style,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.craffel_openai_lambada.GPT_3_style.LenNorm,ANLI R3,,,,,,,,,,,,,,,,,,,,,76.5,71.0,11
27.18792520152754,44.083969465648856,1.2186727138436924,5.057691715955734,1.997,1.0004268304982449,0.0546900356555012,0.0,,,,125.056,3.804813648223877,2.43,37.47980613893376,1.2528780677318574,0.9028288874421332,1.1764637423989626,0.9025912696231888,1.573,34.7,"{'path': 'media/table/predictions_1_f6f282a0ceff029e8dc1.table.json', 'size': 577731, '_type': 'table-file', 'ncols': 11, 'nrows': 1000, 'sha256': 'f6f282a0ceff029e8dc1bb33a9244fed9350ed6b2bd06aedd5aaaec98792607a', 'artifact_path': 'wandb-client-artifact://7rzhgpyj7pzw51syw08vlvnttdu9p0skqmvbpklnduw3u20q2091p2xfl4e1bmauffrmzi6vzcyi4x07g3aqpzl9bqfzwudeeuwo3znlu8g816rh8ixpmuu1wgpwccjq:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://7rzhgpyj7pzw51syw08vlvnttdu9p0skqmvbpklnduw3u20q2091p2xfl4e1bmauffrmzi6vzcyi4x07g3aqpzl9bqfzwudeeuwo3znlu8g816rh8ixpmuu1wgpwccjq:latest/predictions.table.json'}",18.09101611297718,,,False,True,dev_r1,False,Yes | Maybe | No,4,CTBase,1ee5ddef-fffb-4b73-a2f7-f600ffac63cb,anli,COMPLETION,False,28,bigscience/T0_3B,0,True,ellipses,prompts/general_fixed_choice.yaml,LAMBADA,,3,,,GenFC,,False,['NLI'],,False,False,GeneralFixedChoice,False,False,False,,,prompts,,,True,ellipses,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.craffel_openai_lambada.ellipses.LenNorm,ANLI R1,,,,,,,,,,,,,,,,,,,,,42.5,41.0,11
21.6916731474866,46.72639558924879,1.4060886814677107,3.769279015759627,1.9341666666666664,1.06412045082893,0.2513284150712414,0.0,,,,117.23583333333332,2.1391321539878847,2.76,18.34862385321101,1.6301468617717425,0.6486396020390163,1.3182248294394945,0.6725320108036164,1.3058333333333334,32.416666666666664,"{'artifact_path': 'wandb-client-artifact://li4by1vbe0uq5phsq15kf17mggj0kzsd5edernp562ii6um5t0w35osk7p6fiss7l018yq186giz00rd2rrai2edroio1kgrw8dt9sw7cjyxsl8byrag04zrppkyaues:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://li4by1vbe0uq5phsq15kf17mggj0kzsd5edernp562ii6um5t0w35osk7p6fiss7l018yq186giz00rd2rrai2edroio1kgrw8dt9sw7cjyxsl8byrag04zrppkyaues:latest/predictions.table.json', 'path': 'media/table/predictions_1_fdc6a854023647a696ef.table.json', 'size': 670956, '_type': 'table-file', 'ncols': 11, 'nrows': 1200, 'sha256': 'fdc6a854023647a696ef345f257d52e019a183bae1415291bf66f8c1dd683480'}",32.01257902719214,,,False,True,dev_r3,False,Yes | Maybe | No,4,CTBase,1ee5ddef-fffb-4b73-a2f7-f600ffac63cb,anli,COMPLETION,False,28,bigscience/T0_3B,0,True,ellipses,prompts/general_fixed_choice.yaml,LAMBADA,,3,,,GenFC,,False,['NLI'],,False,False,GeneralFixedChoice,False,False,False,,,prompts,,,True,ellipses,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.craffel_openai_lambada.ellipses.LenNorm,ANLI R3,,,,,,,,,,,,,,,,,,,,,80.5,62.0,11
25.094280124591343,44.02173913043478,1.0660284261001691,4.105375951051712,1.998,0.8287866368448508,0.0446766158073773,0.0,,,,137.056,3.039138222694397,2.542,31.26110124333925,1.066237728357315,0.8403784861596588,0.9944397547156152,0.8404760555780278,1.46,33.1,"{'_latest_artifact_path': 'wandb-client-artifact://175bte57jtnt7da9l3jpeto6e0dmpemogxcyju4fp8izehg1g86r1zghskervgvp7ktvvj9vpbcgbbpja5w222cfcb1logxgqyk8ypkvk31dsfjdt5e67cac2slbvdiy:latest/predictions.table.json', 'path': 'media/table/predictions_1_06ba51e41ae2a0c7a43a.table.json', 'size': 638970, '_type': 'table-file', 'ncols': 11, 'nrows': 1000, 'sha256': '06ba51e41ae2a0c7a43a332296dd7e4b0b34b5a151e82ab0517e3d23915fd86c', 'artifact_path': 'wandb-client-artifact://175bte57jtnt7da9l3jpeto6e0dmpemogxcyju4fp8izehg1g86r1zghskervgvp7ktvvj9vpbcgbbpja5w222cfcb1logxgqyk8ypkvk31dsfjdt5e67cac2slbvdiy:latest/predictions.table.json'}",18.09101611297718,,,False,True,dev_r1,False,Yes | Maybe | No,4,CTBase,9a3f617f-628f-4fa5-9b74-47d0b166a487,anli,SUMMARIZATION,False,28,bigscience/T0_3B,0,True,read_below_DOC_write_abstract,prompts/general_fixed_choice.yaml,XSum,,3,,,GenFC,,False,['NLI'],,True,False,GeneralFixedChoice,False,False,False,,,prompts,,,True,read_below_DOC_write_abstract,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.xsum.read_below_DOC_write_abstract.LenNorm,ANLI R1,,,,,,,,,,,,,,,,,,,,,69.0,59.0,21
21.65631469979296,47.82608695652174,1.2181177764830722,3.11761548747619,1.9266666666666667,0.957294367567402,0.2669997919266771,0.0,,,,129.23583333333335,1.6355752207835514,2.7941666666666665,17.142857142857142,1.4820402666926384,0.6070139802526975,1.0543115117599096,0.6360550072298954,1.2791666666666666,33.08333333333333,"{'nrows': 1200, 'sha256': '74701424b90a8235159ffa23189f56fa9c2865f7165f8799183bf35002d8554d', 'artifact_path': 'wandb-client-artifact://15azbryb9hen5i62jbxhouto03fjudtle6at6hvfk34anm3h0xlq8z0wnybm5o90e5yj1ewcaxmsq910w0jnkjjr5ry8bsv87svvqkljszaird43gss6u3guwhb72sq6:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://15azbryb9hen5i62jbxhouto03fjudtle6at6hvfk34anm3h0xlq8z0wnybm5o90e5yj1ewcaxmsq910w0jnkjjr5ry8bsv87svvqkljszaird43gss6u3guwhb72sq6:latest/predictions.table.json', 'path': 'media/table/predictions_1_74701424b90a8235159f.table.json', 'size': 744373, '_type': 'table-file', 'ncols': 11}",32.01257902719214,,,False,True,dev_r3,False,Yes | Maybe | No,4,CTBase,9a3f617f-628f-4fa5-9b74-47d0b166a487,anli,SUMMARIZATION,False,28,bigscience/T0_3B,0,True,read_below_DOC_write_abstract,prompts/general_fixed_choice.yaml,XSum,,3,,,GenFC,,False,['NLI'],,True,False,GeneralFixedChoice,False,False,False,,,prompts,,,True,read_below_DOC_write_abstract,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.xsum.read_below_DOC_write_abstract.LenNorm,ANLI R3,,,,,,,,,,,,,,,,,,,,,48.5,63.0,21
24.85156623770485,44.28442844284428,1.0225408819332713,3.04571433365345,1.986,0.7589982887217613,0.1174904251417961,0.0,,,,140.056,2.0279394121170045,2.557,30.270270270270277,1.0177749215364456,0.829910236109906,0.9112618758232214,0.8319561286510245,1.457,33.0,"{'_type': 'table-file', 'ncols': 11, 'nrows': 1000, 'sha256': '4859b71870b709415f23f903a0ab3e125f481fd180e1f7d4447061b1d5b3f444', 'artifact_path': 'wandb-client-artifact://czhzhs2r4fsnj0065kqs1s06m4wzyry5103zpgb23rf7mebb7j2txnsygz9q0cwsff8f1ld2y4xk97ozzjtmz59kyvtq5a32nqo2ku1awbxdkudwo7puqv960qmvg5zq:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://czhzhs2r4fsnj0065kqs1s06m4wzyry5103zpgb23rf7mebb7j2txnsygz9q0cwsff8f1ld2y4xk97ozzjtmz59kyvtq5a32nqo2ku1awbxdkudwo7puqv960qmvg5zq:latest/predictions.table.json', 'path': 'media/table/predictions_1_4859b71870b709415f23.table.json', 'size': 632548}",18.09101611297718,,,False,True,dev_r1,False,Yes | Maybe | No,4,CTBase,4cfe4126-b9f5-44eb-8a98-973987c5f32e,anli,SUMMARIZATION,False,28,bigscience/T0_3B,0,True,college_roommate_asked_DOC_so_I_recap,prompts/general_fixed_choice.yaml,XSum,,3,,,GenFC,,False,['NLI'],,True,False,GeneralFixedChoice,False,False,False,,,prompts,,,True,college_roommate_asked_DOC_so_I_recap,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.xsum.college_roommate_asked_DOC_so_I_recap.LenNorm,ANLI R1,,,,,,,,,,,,,,,,,,,,,72.0,62.0,24
22.010984236880077,47.97806716929403,1.1234706400294925,2.3647209462026755,1.7433333333333334,0.9189853886304814,0.4627334245785819,2.790697674418605,,,,132.23583333333335,1.0098694787422815,2.795,15.264187866927594,1.354851467460394,0.587061893386606,0.795279344130598,0.6734467726224216,1.461666666666667,32.916666666666664,"{'sha256': 'f9dab32290e81e95404e7447d596fc5fb978df4cae26c3de8a08003e0be5886a', 'artifact_path': 'wandb-client-artifact://6qpw90pg0hbycdocymivdnxqw17xni7yjhk0wkmcgbznghy2z05wclzc745r2kp4bqdbso7tu6zet61ddk32hmf4agqwsbiq4zcq6rfpm7h1g7o3tmc97abw5x00p9hm:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://6qpw90pg0hbycdocymivdnxqw17xni7yjhk0wkmcgbznghy2z05wclzc745r2kp4bqdbso7tu6zet61ddk32hmf4agqwsbiq4zcq6rfpm7h1g7o3tmc97abw5x00p9hm:latest/predictions.table.json', 'path': 'media/table/predictions_1_f9dab32290e81e95404e.table.json', 'size': 737037, '_type': 'table-file', 'ncols': 11, 'nrows': 1200}",32.01257902719214,,,False,True,dev_r3,False,Yes | Maybe | No,4,CTBase,4cfe4126-b9f5-44eb-8a98-973987c5f32e,anli,SUMMARIZATION,False,28,bigscience/T0_3B,0,True,college_roommate_asked_DOC_so_I_recap,prompts/general_fixed_choice.yaml,XSum,,3,,,GenFC,,False,['NLI'],,True,False,GeneralFixedChoice,False,False,False,,,prompts,,,True,college_roommate_asked_DOC_so_I_recap,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.xsum.college_roommate_asked_DOC_so_I_recap.LenNorm,ANLI R3,,,,,,,,,,,,,,,,,,,,,58.5,57.0,24
25.7725598556708,45.25939177101967,1.1463174697309413,4.876543049156666,1.997,0.9982743771032452,0.0546900356555012,0.0,,,,129.056,3.5918606734275818,2.57,32.05828779599272,1.284682375729084,0.8216446920658589,1.0775363814537178,0.8218947621198227,1.433,34.1,"{'nrows': 1000, 'sha256': '754e27a8e3025e854c3abfd28c974799ba30d583ce1f4366fcbd476e5e6e6438', 'artifact_path': 'wandb-client-artifact://hpeawy3g4fcux0s11shza2p6izd98j3x4a408xgcqli6uwn2h05af3cca3zl88pzpkx0fc84eotp3v3yl1oaxr6h8vh9uiyoa13ptpmz9ivtotha5rzmg6sa0wxqnizi:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://hpeawy3g4fcux0s11shza2p6izd98j3x4a408xgcqli6uwn2h05af3cca3zl88pzpkx0fc84eotp3v3yl1oaxr6h8vh9uiyoa13ptpmz9ivtotha5rzmg6sa0wxqnizi:latest/predictions.table.json', 'path': 'media/table/predictions_1_754e27a8e3025e854c3a.table.json', 'size': 587071, '_type': 'table-file', 'ncols': 11}",18.09101611297718,,,False,True,dev_r1,False,Yes | Maybe | No,4,CTBase,3d388a1e-3361-407b-baa7-61397cc58382,anli,SUMMARIZATION,False,28,bigscience/T0_3B,0,True,DOC_how_would_you_rephrase_few_words,prompts/general_fixed_choice.yaml,XSum,,3,,,GenFC,,False,['NLI'],,True,False,GeneralFixedChoice,False,False,False,,,prompts,,,True,DOC_how_would_you_rephrase_few_words,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.xsum.DOC_how_would_you_rephrase_few_words.LenNorm,ANLI R1,,,,,,,,,,,,,,,,,,,,,50.5,54.0,13
21.571976123932817,47.94058068872384,1.3827361989991398,3.6613271452486513,1.9441666666666664,1.0551508104330516,0.2402414873043834,0.4962779156327544,,,,121.23583333333332,2.0039568626880646,2.8091666666666666,16.279069767441857,1.657370282560587,0.5868696381840026,1.2391353747663485,0.6103186781419104,1.2466666666666666,33.166666666666664,"{'_type': 'table-file', 'ncols': 11, 'nrows': 1200, 'sha256': '9f14d88ce5ffc3a2a505494de77bb6414d7807e7ec6028d317e53c598e6c11da', 'artifact_path': 'wandb-client-artifact://iye8m3bw7c0zc28p13cwjcnmtkxtf0yfj1rw551atq9ntr77831jh3nt1wxcjekhj8rct6c8d0o90fl5lvqpzazz7xrbztx48gn3gy0w1axyde6ppnzjd4v1348upvs8:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://iye8m3bw7c0zc28p13cwjcnmtkxtf0yfj1rw551atq9ntr77831jh3nt1wxcjekhj8rct6c8d0o90fl5lvqpzazz7xrbztx48gn3gy0w1axyde6ppnzjd4v1348upvs8:latest/predictions.table.json', 'path': 'media/table/predictions_1_9f14d88ce5ffc3a2a505.table.json', 'size': 682178}",32.01257902719214,,,False,True,dev_r3,False,Yes | Maybe | No,4,CTBase,3d388a1e-3361-407b-baa7-61397cc58382,anli,SUMMARIZATION,False,28,bigscience/T0_3B,0,True,DOC_how_would_you_rephrase_few_words,prompts/general_fixed_choice.yaml,XSum,,3,,,GenFC,,False,['NLI'],,True,False,GeneralFixedChoice,False,False,False,,,prompts,,,True,DOC_how_would_you_rephrase_few_words,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.xsum.DOC_how_would_you_rephrase_few_words.LenNorm,ANLI R3,,,,,,,,,,,,,,,,,,,,,44.5,64.0,13
26.002819428424967,44.44444444444444,1.1877090743370176,4.658176629543305,1.996,0.9402908679849942,0.063118935352238,0.0,,,,129.056,3.443718576908112,2.512,33.564013840830455,1.214458052635193,0.8589854480723176,1.1124191269373802,0.8590320133731919,1.492,33.900000000000006,"{'_latest_artifact_path': 'wandb-client-artifact://xlaq9b17tyggc9vedkscrvtflvg08xfbe4h7ytn2yj6qzzx7d8zq0chr5owd1s2jbbk76axbimv2lojd5qimxrxqidsx8wp5wmz2gtq6cavi6e0l7ac88p3jq9eti9q6:latest/predictions.table.json', 'path': 'media/table/predictions_1_1a144ab9b12bc93f1dc8.table.json', 'size': 583417, '_type': 'table-file', 'ncols': 11, 'nrows': 1000, 'sha256': '1a144ab9b12bc93f1dc852f28142569e8165e4eee7f27ee49eb9caeb0c316b64', 'artifact_path': 'wandb-client-artifact://xlaq9b17tyggc9vedkscrvtflvg08xfbe4h7ytn2yj6qzzx7d8zq0chr5owd1s2jbbk76axbimv2lojd5qimxrxqidsx8wp5wmz2gtq6cavi6e0l7ac88p3jq9eti9q6:latest/predictions.table.json'}",18.09101611297718,,,False,True,dev_r1,False,Yes | Maybe | No,4,CTBase,13c02904-e4e2-4b4f-b115-44b437d22041,anli,SUMMARIZATION,False,28,bigscience/T0_3B,0,True,DOC_write_summary_of_above,prompts/general_fixed_choice.yaml,XSum,,3,,,GenFC,,False,['NLI'],,True,False,GeneralFixedChoice,False,False,False,,,prompts,,,True,DOC_write_summary_of_above,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.xsum.DOC_write_summary_of_above.LenNorm,ANLI R1,,,,,,,,,,,,,,,,,,,,,56.5,52.0,13
21.765304823724065,47.14776632302405,1.4521800969790934,3.5645385897159576,1.933333333333333,1.074002755215295,0.2560381915956203,0.0,,,,121.23583333333332,1.9382925498485568,2.7675,18.14814814814815,1.626246039867401,0.6390960412958291,1.2327004479768633,0.6643287129794172,1.2991666666666666,32.666666666666664,"{'_latest_artifact_path': 'wandb-client-artifact://a1lsiolxp3xxisf4419ar183400tanfjgykf26ta0ba13o3rdrexnu9zn30rjo0ppgqfr1nuok30m39roj4m7jmgmlpd416prk3rc9v6o6xacsj30itly1fm52shmgms:latest/predictions.table.json', 'path': 'media/table/predictions_1_c2c52b5dd0bf9d668169.table.json', 'size': 677716, '_type': 'table-file', 'ncols': 11, 'nrows': 1200, 'sha256': 'c2c52b5dd0bf9d668169125b0b19160aff53bf7b9af3e68124971b233e9900b5', 'artifact_path': 'wandb-client-artifact://a1lsiolxp3xxisf4419ar183400tanfjgykf26ta0ba13o3rdrexnu9zn30rjo0ppgqfr1nuok30m39roj4m7jmgmlpd416prk3rc9v6o6xacsj30itly1fm52shmgms:latest/predictions.table.json'}",32.01257902719214,,,False,True,dev_r3,False,Yes | Maybe | No,4,CTBase,13c02904-e4e2-4b4f-b115-44b437d22041,anli,SUMMARIZATION,False,28,bigscience/T0_3B,0,True,DOC_write_summary_of_above,prompts/general_fixed_choice.yaml,XSum,,3,,,GenFC,,False,['NLI'],,True,False,GeneralFixedChoice,False,False,False,,,prompts,,,True,DOC_write_summary_of_above,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.xsum.DOC_write_summary_of_above.LenNorm,ANLI R3,,,,,,,,,,,,,,,,,,,,,71.5,60.0,13
21.6177878042111,46.1033634126333,0.7903078031444934,4.624852410495281,2.0,0.8987764535086495,0.0,0.0,,,,136.056,3.3430729410648348,2.772,18.75,1.2817794694304463,0.635622529493724,0.8535944801340917,0.635622529493724,1.228,32.300000000000004,"{'_type': 'table-file', 'ncols': 11, 'nrows': 1000, 'sha256': '891c9c7582943ce069d6555fce2c6ebad09091b86d95759a57fb383b73f0385f', 'artifact_path': 'wandb-client-artifact://194zriyyd419ds0lpkekcfkduqynb0qfxlekkfemyt65181wsw5jr6t1maqwd019r5qkw23qmpbkoa5a4tuq2tkblryshlpbv5vaofho1sheuhvdf30r4w9x2c82pwgh:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://194zriyyd419ds0lpkekcfkduqynb0qfxlekkfemyt65181wsw5jr6t1maqwd019r5qkw23qmpbkoa5a4tuq2tkblryshlpbv5vaofho1sheuhvdf30r4w9x2c82pwgh:latest/predictions.table.json', 'path': 'media/table/predictions_1_891c9c7582943ce069d6.table.json', 'size': 619623}",18.09101611297718,,,False,True,dev_r1,False,Yes | Maybe | No,4,CTBase,5fa16d31-b513-480d-bd1b-1fa8c182fb76,anli,SENTIMENT,False,28,bigscience/T0_3B,0,True,bullish_neutral_bearish,prompts/general_fixed_choice.yaml,FinNews,,3,,,GenFC,,False,['NLI'],,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,bullish_neutral_bearish,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.financial_phrasebank_sentences_allagree.bullish_neutral_bearish.LenNorm,ANLI R1,,,,,,,,,,,,,,,,,,,,,80.0,74.0,9
19.73107758348589,48.01043705153295,0.909376501235504,3.847040063291788,1.9966666666666664,0.871869483896098,0.0576387215526352,0.0,,,,128.23583333333335,2.277084065079689,2.895,11.182795698924732,1.569955998212099,0.4460661385938189,0.9384618958186712,0.4489957931008065,1.1083333333333334,32.83333333333333,"{'size': 721335, '_type': 'table-file', 'ncols': 11, 'nrows': 1200, 'sha256': 'a1463267efef8fc6ff0382131c04e3ab93f11ad67ec297457a45c483a8b67fd2', 'artifact_path': 'wandb-client-artifact://pz0jco54qobdvduoannwpiubjwe3fqkgmgjrjplskwp8pxbm6f8k2xs8j6b81t6v523lmmrop401sc84ytfxhlnzo163738nl2fsqd72ymhceamk2xiqphypdhexn9cd:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://pz0jco54qobdvduoannwpiubjwe3fqkgmgjrjplskwp8pxbm6f8k2xs8j6b81t6v523lmmrop401sc84ytfxhlnzo163738nl2fsqd72ymhceamk2xiqphypdhexn9cd:latest/predictions.table.json', 'path': 'media/table/predictions_1_a1463267efef8fc6ff03.table.json'}",32.01257902719214,,,False,True,dev_r3,False,Yes | Maybe | No,4,CTBase,5fa16d31-b513-480d-bd1b-1fa8c182fb76,anli,SENTIMENT,False,28,bigscience/T0_3B,0,True,bullish_neutral_bearish,prompts/general_fixed_choice.yaml,FinNews,,3,,,GenFC,,False,['NLI'],,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,bullish_neutral_bearish,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.financial_phrasebank_sentences_allagree.bullish_neutral_bearish.LenNorm,ANLI R3,,,,,,,,,,,,,,,,,,,,,63.0,75.0,9
20.58879059564711,46.62875710804224,1.1047714374594697,5.036795592427254,1.998,1.033310616180371,0.0446766158073773,0.0,,,,127.056,3.4914379086494445,2.796,15.137614678899084,1.5453576837778091,0.6052966215005664,1.1361964372670046,0.6062705666614535,1.206,32.0,"{'path': 'media/table/predictions_1_d1af3972fb42b12ba308.table.json', 'size': 615135, '_type': 'table-file', 'ncols': 11, 'nrows': 1000, 'sha256': 'd1af3972fb42b12ba308873badf8d8944774643604ecf12d7c6b00bd4a745142', 'artifact_path': 'wandb-client-artifact://149wuvsuyhcm2kchcdrm1x8vtxxz5xy6ictylnfez0rmeequmzp22d1tsj2b49fij2ya7yuabekp8h26f9qfv4bz5x3b2fivdr980h9kp5vnzxl70so9zlwws3vh1xro:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://149wuvsuyhcm2kchcdrm1x8vtxxz5xy6ictylnfez0rmeequmzp22d1tsj2b49fij2ya7yuabekp8h26f9qfv4bz5x3b2fivdr980h9kp5vnzxl70so9zlwws3vh1xro:latest/predictions.table.json'}",18.09101611297718,,,False,True,dev_r1,False,Yes | Maybe | No,4,CTBase,461efe04-6883-41e8-80f0-e722a75260fe,anli,SENTIMENT,False,28,bigscience/T0_3B,0,True,complementary_industries,prompts/general_fixed_choice.yaml,FinNews,,3,,,GenFC,,False,['NLI'],,False,False,GeneralFixedChoice,False,False,False,,,prompts,,,True,complementary_industries,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.financial_phrasebank_sentences_allagree.complementary_industries.LenNorm,ANLI R1,,,,,,,,,,,,,,,,,,,,,83.0,77.0,11
19.09754812655399,48.53990914990266,1.2762718874658503,4.002967844183246,1.9258333333333333,1.0852451757086845,0.2620419283668593,0.0,,,,119.23583333333332,1.943904424905777,2.908333333333333,8.752735229759299,2.0590634192774693,0.4182470030443202,1.1979528962356574,0.4795824283223433,1.1658333333333333,32.83333333333333,"{'nrows': 1200, 'sha256': '6e6f985f85f2a781727a5ea611e04c532a8e542effb74e3eb379f6cb94f17b3c', 'artifact_path': 'wandb-client-artifact://4qbqn0cshp7sdjrc8fh56v1n25fjsbh3uoa0tawqiczc6e7x8yyx00zytkiqswm4wmtqh2gigdyeqp0bnpzsrvclxqlca2ibm95i2zy1lxdhnlfr3dy2kjlelxsc8yx9:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://4qbqn0cshp7sdjrc8fh56v1n25fjsbh3uoa0tawqiczc6e7x8yyx00zytkiqswm4wmtqh2gigdyeqp0bnpzsrvclxqlca2ibm95i2zy1lxdhnlfr3dy2kjlelxsc8yx9:latest/predictions.table.json', 'path': 'media/table/predictions_1_6e6f985f85f2a781727a.table.json', 'size': 715833, '_type': 'table-file', 'ncols': 11}",32.01257902719214,,,False,True,dev_r3,False,Yes | Maybe | No,4,CTBase,461efe04-6883-41e8-80f0-e722a75260fe,anli,SENTIMENT,False,28,bigscience/T0_3B,0,True,complementary_industries,prompts/general_fixed_choice.yaml,FinNews,,3,,,GenFC,,False,['NLI'],,False,False,GeneralFixedChoice,False,False,False,,,prompts,,,True,complementary_industries,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.financial_phrasebank_sentences_allagree.complementary_industries.LenNorm,ANLI R3,,,,,,,,,,,,,,,,,,,,,63.0,78.0,11
27.935985816805797,43.37585868498528,1.1401794307158015,4.4480017395019535,1.999,0.9856864926043104,0.0316069612585582,0.0,,,,124.056,3.226669534683228,2.372,40.4320987654321,1.2213322048187256,0.9282327294380436,1.0308629665653672,0.9280942840035163,1.629,35.2,"{'sha256': 'e35b584c13c42d0dcfec225a7b1d3c5d829c4e89122c2e9fa93e56e54b4c4321', 'artifact_path': 'wandb-client-artifact://x26ng613lafz29j70jca3c2kqp2z9gjfxjkrbuqlq7s39h8t8koglgi4cjyoj8s0ho98t5c70f1b1zkxmskmbkvf6sx5bwhnwkeu77y3vyqjng6uw6tlpxvbzlx7ycs2:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://x26ng613lafz29j70jca3c2kqp2z9gjfxjkrbuqlq7s39h8t8koglgi4cjyoj8s0ho98t5c70f1b1zkxmskmbkvf6sx5bwhnwkeu77y3vyqjng6uw6tlpxvbzlx7ycs2:latest/predictions.table.json', 'path': 'media/table/predictions_1_e35b584c13c42d0dcfec.table.json', 'size': 583419, '_type': 'table-file', 'ncols': 11, 'nrows': 1000}",18.09101611297718,,,False,True,dev_r1,False,Yes | Maybe | No,4,CTBase,0beba048-f949-4034-83b6-a3e0e7363f46,anli,SENTIMENT,False,28,bigscience/T0_3B,0,True,sentiment,prompts/general_fixed_choice.yaml,FinNews,,3,,,GenFC,,False,['NLI'],,False,False,GeneralFixedChoice,False,False,False,,,prompts,,,True,sentiment,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.financial_phrasebank_sentences_allagree.sentiment.LenNorm,ANLI R1,,,,,,,,,,,,,,,,,,,,,36.5,34.0,8
24.72511464476603,46.12005856515374,1.2402844880301622,3.27218233982722,1.9741666666666664,0.8744340221182568,0.1736835404470505,0.9852216748768472,,,,116.23583333333332,2.0469218921661376,2.62,27.07006369426751,1.225260447661082,0.7824747067264646,1.117919049657604,0.787061606370316,1.4058333333333333,33.5,"{'sha256': 'd2f32fd6186827f5d23264b0f2fbd83f0c8f49f13405aea3630f15bdbab95992', 'artifact_path': 'wandb-client-artifact://orsryxz57gdglndy2kp698skurewsxfogxle3gzfolh1gxfs7hfztc7osmwtcrpyrzfag3u6fpc5wg91360lwc03mcew0ti6leaqcqaptleqxp1jvz7zdz7kr0x2nk35:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://orsryxz57gdglndy2kp698skurewsxfogxle3gzfolh1gxfs7hfztc7osmwtcrpyrzfag3u6fpc5wg91360lwc03mcew0ti6leaqcqaptleqxp1jvz7zdz7kr0x2nk35:latest/predictions.table.json', 'path': 'media/table/predictions_1_d2f32fd6186827f5d232.table.json', 'size': 678222, '_type': 'table-file', 'ncols': 11, 'nrows': 1200}",32.01257902719214,,,False,True,dev_r3,False,Yes | Maybe | No,4,CTBase,0beba048-f949-4034-83b6-a3e0e7363f46,anli,SENTIMENT,False,28,bigscience/T0_3B,0,True,sentiment,prompts/general_fixed_choice.yaml,FinNews,,3,,,GenFC,,False,['NLI'],,False,False,GeneralFixedChoice,False,False,False,,,prompts,,,True,sentiment,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.financial_phrasebank_sentences_allagree.sentiment.LenNorm,ANLI R3,,,,,,,,,,,,,,,,,,,,,33.0,34.0,8
26.11640251517026,43.94785847299814,0.5533254086049472,2.686186188340187,1.997,0.6112950341947494,0.0546900356555012,0.0,,,,147.056,1.969230204343796,2.482,34.40134907251265,0.7169559839963913,0.8761712161444245,0.5725512372899682,0.8761044458282357,1.521,33.800000000000004,"{'artifact_path': 'wandb-client-artifact://191wtom21599mtlg5choe894csig1nsyzjxpn7zmdl1z1spqwvfcfc1fc4hgl12oyfxnuwuq70c6x0zmmefki2l2x6vvh2pvdyl6ull64plrdjelfc97qq1is1rzuks6:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://191wtom21599mtlg5choe894csig1nsyzjxpn7zmdl1z1spqwvfcfc1fc4hgl12oyfxnuwuq70c6x0zmmefki2l2x6vvh2pvdyl6ull64plrdjelfc97qq1is1rzuks6:latest/predictions.table.json', 'path': 'media/table/predictions_1_1b2352a09dd96674a2b8.table.json', 'size': 678380, '_type': 'table-file', 'ncols': 11, 'nrows': 1000, 'sha256': '1b2352a09dd96674a2b89477f7ad633010fcf59c8b51763c4e74bd4a0b2efcec'}",18.09101611297718,,,False,True,dev_r1,False,Yes | Maybe | No,4,CTBase,06719321-62e7-4f6e-8f95-464cd2b5ca5c,anli,SENTIMENT,False,28,bigscience/T0_3B,0,True,share_price_option,prompts/general_fixed_choice.yaml,FinNews,,3,,,GenFC,,False,['NLI'],,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,share_price_option,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.financial_phrasebank_sentences_allagree.share_price_option.LenNorm,ANLI R1,,,,,,,,,,,,,,,,,,,,,59.0,50.0,20
21.11285009465039,46.889952153110045,0.5834821083809111,2.3739120165507,1.975833333333333,0.644148548437166,0.1535663989578738,0.0,,,,139.23583333333335,1.3559332478046418,2.7783333333333333,16.448598130841123,1.0179787687460582,0.627851273967189,0.645626100539163,0.6380172193775198,1.2458333333333331,32.25,"{'path': 'media/table/predictions_1_4faf7227d755a3bea08b.table.json', 'size': 791987, '_type': 'table-file', 'ncols': 11, 'nrows': 1200, 'sha256': '4faf7227d755a3bea08b4a0a24fc3df08331302297ca5db35f2537e683226991', 'artifact_path': 'wandb-client-artifact://16792kjglimqonigbmibdzg4w1otm37rlfhn4yd8br7uyup26vxezzmokg8om0yl6snv5ppt543ebsc1pw7r1kbe6uedy9mbl5tvmbrzq6cgempowkqya60upk7bcbbx:latest/predictions.table.json', '_latest_artifact_path': 'wandb-client-artifact://16792kjglimqonigbmibdzg4w1otm37rlfhn4yd8br7uyup26vxezzmokg8om0yl6snv5ppt543ebsc1pw7r1kbe6uedy9mbl5tvmbrzq6cgempowkqya60upk7bcbbx:latest/predictions.table.json'}",32.01257902719214,,,False,True,dev_r3,False,Yes | Maybe | No,4,CTBase,06719321-62e7-4f6e-8f95-464cd2b5ca5c,anli,SENTIMENT,False,28,bigscience/T0_3B,0,True,share_price_option,prompts/general_fixed_choice.yaml,FinNews,,3,,,GenFC,,False,['NLI'],,False,False,GeneralFixedChoice,False,False,True,,,prompts,,,True,share_price_option,,cross_task,three_choice_entailment,,,,False,,,False,,True,,,False,,CTBase.GenFC.financial_phrasebank_sentences_allagree.share_price_option.LenNorm,ANLI R3,,,,,,,,,,,,,,,,,,,,,84.0,69.0,20
