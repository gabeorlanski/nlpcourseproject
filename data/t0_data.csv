,runs,prompt,metric_name,dataset_name,score,step
66,xxl-lm-d4-091621-512,_GPT_3_Style,accuracy (Rank),super_glue_wsc.fixed,60.57692337036133,1112200
67,xxl-lm-d4-091621-512,_I_think_they_mean,accuracy (Rank),super_glue_wsc.fixed,69.23076629638672,1112200
68,xxl-lm-d4-091621-512,_Who_is_are,accuracy (Rank),super_glue_wsc.fixed,65.38461303710939,1112200
69,xxl-lm-d4-091621-512,_Who_or_what_is_are,accuracy (Rank),super_glue_wsc.fixed,66.34615325927734,1112200
70,xxl-lm-d4-091621-512,_by_p_they_mean,accuracy (Rank),super_glue_wsc.fixed,60.57692337036133,1112200
71,xxl-lm-d4-091621-512,_does_p_stand_for,accuracy (Rank),super_glue_wsc.fixed,64.42308044433594,1112200
72,xxl-lm-d4-091621-512,_does_the_pronoun_refer_to,accuracy (Rank),super_glue_wsc.fixed,64.42308044433594,1112200
73,xxl-lm-d4-091621-512,_in_other_words,accuracy (Rank),super_glue_wsc.fixed,67.30769348144531,1112200
74,xxl-lm-d4-091621-512,_p_is_are_r,accuracy (Rank),super_glue_wsc.fixed,49.03845977783203,1112200
75,xxl-lm-d4-091621-512,_replaced_with,accuracy (Rank),super_glue_wsc.fixed,50.96154022216797,1112200
76,xxl-lm-d4-091621-512,_the_pronoun_refers_to,accuracy (Rank),super_glue_wsc.fixed,57.69230651855469,1112200
77,xxl-lm-d4-gpt-091621,_GPT_3_Style,accuracy (Rank),super_glue_wsc.fixed,66.34615325927734,1112200
78,xxl-lm-d4-gpt-091621,_I_think_they_mean,accuracy (Rank),super_glue_wsc.fixed,63.46154022216797,1112200
79,xxl-lm-d4-gpt-091621,_Who_is_are,accuracy (Rank),super_glue_wsc.fixed,56.73077011108398,1112200
80,xxl-lm-d4-gpt-091621,_Who_or_what_is_are,accuracy (Rank),super_glue_wsc.fixed,58.653846740722656,1112200
81,xxl-lm-d4-gpt-091621,_by_p_they_mean,accuracy (Rank),super_glue_wsc.fixed,64.42308044433594,1112200
82,xxl-lm-d4-gpt-091621,_does_p_stand_for,accuracy (Rank),super_glue_wsc.fixed,64.42308044433594,1112200
83,xxl-lm-d4-gpt-091621,_does_the_pronoun_refer_to,accuracy (Rank),super_glue_wsc.fixed,67.30769348144531,1112200
84,xxl-lm-d4-gpt-091621,_in_other_words,accuracy (Rank),super_glue_wsc.fixed,67.30769348144531,1112200
85,xxl-lm-d4-gpt-091621,_p_is_are_r,accuracy (Rank),super_glue_wsc.fixed,49.03845977783203,1112200
86,xxl-lm-d4-gpt-091621,_replaced_with,accuracy (Rank),super_glue_wsc.fixed,66.34615325927734,1112200
87,xxl-lm-d4-gpt-091621,_the_pronoun_refers_to,accuracy (Rank),super_glue_wsc.fixed,60.57692337036133,1112200
88,xxl-lm-d4-all-091621,_GPT_3_Style,accuracy (Rank),super_glue_wsc.fixed,69.23076629638672,1112000
89,xxl-lm-d4-all-091621,_I_think_they_mean,accuracy (Rank),super_glue_wsc.fixed,70.19230651855469,1112000
90,xxl-lm-d4-all-091621,_Who_is_are,accuracy (Rank),super_glue_wsc.fixed,,1112000
91,xxl-lm-d4-all-091621,_Who_or_what_is_are,accuracy (Rank),super_glue_wsc.fixed,73.07691955566406,1112000
92,xxl-lm-d4-all-091621,_by_p_they_mean,accuracy (Rank),super_glue_wsc.fixed,73.07691955566406,1112000
93,xxl-lm-d4-all-091621,_does_p_stand_for,accuracy (Rank),super_glue_wsc.fixed,68.26923370361328,1112000
94,xxl-lm-d4-all-091621,_does_the_pronoun_refer_to,accuracy (Rank),super_glue_wsc.fixed,73.07691955566406,1112000
95,xxl-lm-d4-all-091621,_in_other_words,accuracy (Rank),super_glue_wsc.fixed,74.03845977783203,1112000
96,xxl-lm-d4-all-091621,_p_is_are_r,accuracy (Rank),super_glue_wsc.fixed,66.34615325927734,1112000
97,xxl-lm-d4-all-091621,_replaced_with,accuracy (Rank),super_glue_wsc.fixed,68.26923370361328,1112000
98,xxl-lm-d4-all-091621,_the_pronoun_refers_to,accuracy (Rank),super_glue_wsc.fixed,67.30769348144531,1112000
99,xxl-lm-d4-og-091621,_GPT_3_Style,accuracy (Rank),super_glue_wsc.fixed,,1112000
100,xxl-lm-d4-og-091621,_I_think_they_mean,accuracy (Rank),super_glue_wsc.fixed,60.57692337036133,1112000
101,xxl-lm-d4-og-091621,_Who_is_are,accuracy (Rank),super_glue_wsc.fixed,,1112000
102,xxl-lm-d4-og-091621,_Who_or_what_is_are,accuracy (Rank),super_glue_wsc.fixed,61.53845977783203,1112000
103,xxl-lm-d4-og-091621,_by_p_they_mean,accuracy (Rank),super_glue_wsc.fixed,55.76922988891602,1112000
104,xxl-lm-d4-og-091621,_does_p_stand_for,accuracy (Rank),super_glue_wsc.fixed,56.73077011108398,1112000
105,xxl-lm-d4-og-091621,_does_the_pronoun_refer_to,accuracy (Rank),super_glue_wsc.fixed,54.80769348144531,1112000
106,xxl-lm-d4-og-091621,_in_other_words,accuracy (Rank),super_glue_wsc.fixed,36.53845977783203,1112000
107,xxl-lm-d4-og-091621,_p_is_are_r,accuracy (Rank),super_glue_wsc.fixed,,1112000
108,xxl-lm-d4-og-091621,_replaced_with,accuracy (Rank),super_glue_wsc.fixed,56.73077011108398,1112000
109,xxl-lm-d4-og-091621,_the_pronoun_refers_to,accuracy (Rank),super_glue_wsc.fixed,36.53845977783203,1112000
110,xxl-lm-d4-all-og-091621,_GPT_3_Style,accuracy (Rank),super_glue_wsc.fixed,62.5,1112000
111,xxl-lm-d4-all-og-091621,_I_think_they_mean,accuracy (Rank),super_glue_wsc.fixed,67.30769348144531,1112000
112,xxl-lm-d4-all-og-091621,_Who_or_what_is_are,accuracy (Rank),super_glue_wsc.fixed,69.23076629638672,1112000
113,xxl-lm-d4-all-og-091621,_by_p_they_mean,accuracy (Rank),super_glue_wsc.fixed,64.42308044433594,1112000
114,xxl-lm-d4-all-og-091621,_does_p_stand_for,accuracy (Rank),super_glue_wsc.fixed,68.26923370361328,1112000
115,xxl-lm-d4-all-og-091621,_does_the_pronoun_refer_to,accuracy (Rank),super_glue_wsc.fixed,67.30769348144531,1112000
116,xxl-lm-d4-all-og-091621,_in_other_words,accuracy (Rank),super_glue_wsc.fixed,58.653846740722656,1112000
117,xxl-lm-d4-all-og-091621,_p_is_are_r,accuracy (Rank),super_glue_wsc.fixed,41.346153259277344,1112000
118,xxl-lm-d4-all-og-091621,_replaced_with,accuracy (Rank),super_glue_wsc.fixed,56.73077011108398,1112000
119,xxl-lm-d4-all-og-091621,_the_pronoun_refers_to,accuracy (Rank),super_glue_wsc.fixed,44.230770111083984,1112000
120,xxl-lm-d4-091621,_GPT_3_Style,accuracy (Rank),super_glue_wsc.fixed,63.46154022216797,1100000
121,xxl-lm-d4-091621,_I_think_they_mean,accuracy (Rank),super_glue_wsc.fixed,55.76922988891602,1100000
122,xxl-lm-d4-091621,_Who_is_are,accuracy (Rank),super_glue_wsc.fixed,,1100000
123,xxl-lm-d4-091621,_Who_or_what_is_are,accuracy (Rank),super_glue_wsc.fixed,63.46154022216797,1100000
124,xxl-lm-d4-091621,_by_p_they_mean,accuracy (Rank),super_glue_wsc.fixed,59.61538314819336,1100000
125,xxl-lm-d4-091621,_does_p_stand_for,accuracy (Rank),super_glue_wsc.fixed,52.88461685180664,1100000
126,xxl-lm-d4-091621,_does_the_pronoun_refer_to,accuracy (Rank),super_glue_wsc.fixed,,1100000
127,xxl-lm-d4-091621,_in_other_words,accuracy (Rank),super_glue_wsc.fixed,37.5,1100000
128,xxl-lm-d4-091621,_p_is_are_r,accuracy (Rank),super_glue_wsc.fixed,,1100000
129,xxl-lm-d4-091621,_replaced_with,accuracy (Rank),super_glue_wsc.fixed,61.53845977783203,1100000
130,xxl-lm-d4-091621,_the_pronoun_refers_to,accuracy (Rank),super_glue_wsc.fixed,38.46154022216797,1100000
131,xl-lm-d4-091621,_GPT_3_Style,accuracy (Rank),super_glue_wsc.fixed,60.57692337036133,1112000
132,xl-lm-d4-091621,_I_think_they_mean,accuracy (Rank),super_glue_wsc.fixed,69.23076629638672,1112000
133,xl-lm-d4-091621,_Who_is_are,accuracy (Rank),super_glue_wsc.fixed,,1112000
134,xl-lm-d4-091621,_Who_or_what_is_are,accuracy (Rank),super_glue_wsc.fixed,64.42308044433594,1112000
135,xl-lm-d4-091621,_by_p_they_mean,accuracy (Rank),super_glue_wsc.fixed,62.5,1112000
136,xl-lm-d4-091621,_does_p_stand_for,accuracy (Rank),super_glue_wsc.fixed,67.30769348144531,1112000
137,xl-lm-d4-091621,_does_the_pronoun_refer_to,accuracy (Rank),super_glue_wsc.fixed,68.26923370361328,1112000
138,xl-lm-d4-091621,_in_other_words,accuracy (Rank),super_glue_wsc.fixed,67.30769348144531,1112000
139,xl-lm-d4-091621,_p_is_are_r,accuracy (Rank),super_glue_wsc.fixed,62.5,1112000
140,xl-lm-d4-091621,_replaced_with,accuracy (Rank),super_glue_wsc.fixed,64.42308044433594,1112000
141,xl-lm-d4-091621,_the_pronoun_refers_to,accuracy (Rank),super_glue_wsc.fixed,64.42308044433594,1112000
400,xxl-lm-d4-091621-512,_Replace,accuracy (Rank),winogrande_winogrande_xl,56.1168098449707,1112200
401,xxl-lm-d4-091621-512,_does_underscore_refer_to,accuracy (Rank),winogrande_winogrande_xl,60.4577751159668,1112200
402,xxl-lm-d4-091621-512,_fill_in_the_blank,accuracy (Rank),winogrande_winogrande_xl,58.72138977050781,1112200
403,xxl-lm-d4-091621-512,_stand_for,accuracy (Rank),winogrande_winogrande_xl,60.77347946166992,1112200
404,xxl-lm-d4-091621-512,_underscore_refer_to,accuracy (Rank),winogrande_winogrande_xl,63.61483764648438,1112200
405,xxl-lm-d4-gpt-091621,_Replace,accuracy (Rank),winogrande_winogrande_xl,60.93133544921875,1112200
406,xxl-lm-d4-gpt-091621,_does_underscore_refer_to,accuracy (Rank),winogrande_winogrande_xl,61.72060012817383,1112200
407,xxl-lm-d4-gpt-091621,_fill_in_the_blank,accuracy (Rank),winogrande_winogrande_xl,60.69455337524414,1112200
408,xxl-lm-d4-gpt-091621,_stand_for,accuracy (Rank),winogrande_winogrande_xl,64.24625396728516,1112200
409,xxl-lm-d4-gpt-091621,_underscore_refer_to,accuracy (Rank),winogrande_winogrande_xl,65.11444091796875,1112200
410,xxl-lm-d4-all-091621,_Replace,accuracy (Rank),winogrande_winogrande_xl,64.40410614013672,1112000
411,xxl-lm-d4-all-091621,_does_underscore_refer_to,accuracy (Rank),winogrande_winogrande_xl,66.53512573242189,1112000
412,xxl-lm-d4-all-091621,_fill_in_the_blank,accuracy (Rank),winogrande_winogrande_xl,64.95658874511719,1112000
413,xxl-lm-d4-all-091621,_stand_for,accuracy (Rank),winogrande_winogrande_xl,66.69297790527344,1112000
414,xxl-lm-d4-all-091621,_underscore_refer_to,accuracy (Rank),winogrande_winogrande_xl,69.53433227539061,1112000
415,xxl-lm-d4-og-091621,_Replace,accuracy (Rank),winogrande_winogrande_xl,57.22178268432617,1112000
416,xxl-lm-d4-og-091621,_does_underscore_refer_to,accuracy (Rank),winogrande_winogrande_xl,56.03788375854492,1112000
417,xxl-lm-d4-og-091621,_fill_in_the_blank,accuracy (Rank),winogrande_winogrande_xl,62.98342514038086,1112000
418,xxl-lm-d4-og-091621,_stand_for,accuracy (Rank),winogrande_winogrande_xl,57.616416931152344,1112000
419,xxl-lm-d4-og-091621,_underscore_refer_to,accuracy (Rank),winogrande_winogrande_xl,56.66929626464844,1112000
420,xxl-lm-d4-all-og-091621,_Replace,accuracy (Rank),winogrande_winogrande_xl,59.98421478271485,1112000
421,xxl-lm-d4-all-og-091621,_does_underscore_refer_to,accuracy (Rank),winogrande_winogrande_xl,58.72138977050781,1112000
422,xxl-lm-d4-all-og-091621,_fill_in_the_blank,accuracy (Rank),winogrande_winogrande_xl,58.8003158569336,1112000
423,xxl-lm-d4-all-og-091621,_stand_for,accuracy (Rank),winogrande_winogrande_xl,58.16890335083008,1112000
424,xxl-lm-d4-all-og-091621,_underscore_refer_to,accuracy (Rank),winogrande_winogrande_xl,61.08918762207031,1112000
425,xxl-lm-d4-091621,_Replace,accuracy (Rank),winogrande_winogrande_xl,52.09155654907226,1100000
426,xxl-lm-d4-091621,_does_underscore_refer_to,accuracy (Rank),winogrande_winogrande_xl,49.40805053710938,1100000
427,xxl-lm-d4-091621,_fill_in_the_blank,accuracy (Rank),winogrande_winogrande_xl,,1100000
428,xxl-lm-d4-091621,_stand_for,accuracy (Rank),winogrande_winogrande_xl,49.09234237670898,1100000
429,xxl-lm-d4-091621,_underscore_refer_to,accuracy (Rank),winogrande_winogrande_xl,52.01262664794922,1100000
430,xl-lm-d4-091621,_Replace,accuracy (Rank),winogrande_winogrande_xl,52.48618698120117,1112000
431,xl-lm-d4-091621,_does_underscore_refer_to,accuracy (Rank),winogrande_winogrande_xl,49.25019836425781,1112000
432,xl-lm-d4-091621,_fill_in_the_blank,accuracy (Rank),winogrande_winogrande_xl,52.17048263549805,1112000
433,xl-lm-d4-091621,_stand_for,accuracy (Rank),winogrande_winogrande_xl,50.51302337646485,1112000
434,xl-lm-d4-091621,_underscore_refer_to,accuracy (Rank),winogrande_winogrande_xl,50.43409729003906,1112000
540,xxl-lm-d4-091621-512,_Replace,accuracy (Rank),winogrande_winogrande_debiased,56.1168098449707,1112200
541,xxl-lm-d4-091621-512,_does_underscore_refer_to,accuracy (Rank),winogrande_winogrande_debiased,60.4577751159668,1112200
542,xxl-lm-d4-091621-512,_fill_in_the_blank,accuracy (Rank),winogrande_winogrande_debiased,58.72138977050781,1112200
543,xxl-lm-d4-091621-512,_stand_for,accuracy (Rank),winogrande_winogrande_debiased,60.77347946166992,1112200
544,xxl-lm-d4-091621-512,_underscore_refer_to,accuracy (Rank),winogrande_winogrande_debiased,,1112200
545,xxl-lm-d4-gpt-091621,_Replace,accuracy (Rank),winogrande_winogrande_debiased,60.93133544921875,1112200
546,xxl-lm-d4-gpt-091621,_does_underscore_refer_to,accuracy (Rank),winogrande_winogrande_debiased,61.72060012817383,1112200
547,xxl-lm-d4-gpt-091621,_fill_in_the_blank,accuracy (Rank),winogrande_winogrande_debiased,60.69455337524414,1112200
548,xxl-lm-d4-gpt-091621,_stand_for,accuracy (Rank),winogrande_winogrande_debiased,64.24625396728516,1112200
549,xxl-lm-d4-gpt-091621,_underscore_refer_to,accuracy (Rank),winogrande_winogrande_debiased,65.11444091796875,1112200
550,xxl-lm-d4-all-091621,_Replace,accuracy (Rank),winogrande_winogrande_debiased,64.40410614013672,1112000
551,xxl-lm-d4-all-091621,_does_underscore_refer_to,accuracy (Rank),winogrande_winogrande_debiased,66.53512573242189,1112000
552,xxl-lm-d4-all-091621,_fill_in_the_blank,accuracy (Rank),winogrande_winogrande_debiased,64.95658874511719,1112000
553,xxl-lm-d4-all-091621,_stand_for,accuracy (Rank),winogrande_winogrande_debiased,66.69297790527344,1112000
554,xxl-lm-d4-all-091621,_underscore_refer_to,accuracy (Rank),winogrande_winogrande_debiased,69.53433227539061,1112000
555,xxl-lm-d4-og-091621,_Replace,accuracy (Rank),winogrande_winogrande_debiased,57.22178268432617,1112000
556,xxl-lm-d4-og-091621,_does_underscore_refer_to,accuracy (Rank),winogrande_winogrande_debiased,56.03788375854492,1112000
557,xxl-lm-d4-og-091621,_fill_in_the_blank,accuracy (Rank),winogrande_winogrande_debiased,62.98342514038086,1112000
558,xxl-lm-d4-og-091621,_stand_for,accuracy (Rank),winogrande_winogrande_debiased,57.616416931152344,1112000
559,xxl-lm-d4-og-091621,_underscore_refer_to,accuracy (Rank),winogrande_winogrande_debiased,56.66929626464844,1112000
560,xxl-lm-d4-all-og-091621,_Replace,accuracy (Rank),winogrande_winogrande_debiased,59.98421478271485,1112000
561,xxl-lm-d4-all-og-091621,_does_underscore_refer_to,accuracy (Rank),winogrande_winogrande_debiased,58.72138977050781,1112000
562,xxl-lm-d4-all-og-091621,_fill_in_the_blank,accuracy (Rank),winogrande_winogrande_debiased,58.8003158569336,1112000
563,xxl-lm-d4-all-og-091621,_stand_for,accuracy (Rank),winogrande_winogrande_debiased,58.16890335083008,1112000
564,xxl-lm-d4-all-og-091621,_underscore_refer_to,accuracy (Rank),winogrande_winogrande_debiased,61.08918762207031,1112000
565,xxl-lm-d4-091621,_Replace,accuracy (Rank),winogrande_winogrande_debiased,52.09155654907226,1100000
566,xxl-lm-d4-091621,_does_underscore_refer_to,accuracy (Rank),winogrande_winogrande_debiased,49.40805053710938,1100000
567,xxl-lm-d4-091621,_fill_in_the_blank,accuracy (Rank),winogrande_winogrande_debiased,,1100000
568,xxl-lm-d4-091621,_stand_for,accuracy (Rank),winogrande_winogrande_debiased,49.09234237670898,1100000
569,xxl-lm-d4-091621,_underscore_refer_to,accuracy (Rank),winogrande_winogrande_debiased,52.01262664794922,1100000
570,xl-lm-d4-091621,_Replace,accuracy (Rank),winogrande_winogrande_debiased,52.48618698120117,1112000
571,xl-lm-d4-091621,_does_underscore_refer_to,accuracy (Rank),winogrande_winogrande_debiased,49.25019836425781,1112000
572,xl-lm-d4-091621,_fill_in_the_blank,accuracy (Rank),winogrande_winogrande_debiased,52.17048263549805,1112000
573,xl-lm-d4-091621,_stand_for,accuracy (Rank),winogrande_winogrande_debiased,50.51302337646485,1112000
574,xl-lm-d4-091621,_underscore_refer_to,accuracy (Rank),winogrande_winogrande_debiased,50.43409729003906,1112000
650,xxl-lm-d4-091621-512,_Following_sentence_acceptable,accuracy (Rank),glue_cola,48.609779357910156,1112200
651,xxl-lm-d4-091621-512,_Make_sense_yes_no,accuracy (Rank),glue_cola,32.790027618408196,1112200
652,xxl-lm-d4-091621-512,_Previous_sentence_acceptable,accuracy (Rank),glue_cola,31.06423759460449,1112200
653,xxl-lm-d4-091621-512,_editing,accuracy (Rank),glue_cola,30.968360900878906,1112200
654,xxl-lm-d4-091621-512,_is_this_correct,accuracy (Rank),glue_cola,43.24065017700195,1112200
655,xxl-lm-d4-gpt-091621,_Following_sentence_acceptable,accuracy (Rank),glue_cola,43.33652877807617,1112200
656,xxl-lm-d4-gpt-091621,_Make_sense_yes_no,accuracy (Rank),glue_cola,31.351869583129886,1112200
657,xxl-lm-d4-gpt-091621,_Previous_sentence_acceptable,accuracy (Rank),glue_cola,31.160114288330078,1112200
658,xxl-lm-d4-gpt-091621,_editing,accuracy (Rank),glue_cola,31.160114288330078,1112200
659,xxl-lm-d4-gpt-091621,_is_this_correct,accuracy (Rank),glue_cola,47.65100860595703,1112200
660,xxl-lm-d4-all-091621,_Following_sentence_acceptable,accuracy (Rank),glue_cola,45.92521667480469,1112000
661,xxl-lm-d4-all-091621,_Make_sense_yes_no,accuracy (Rank),glue_cola,34.32406616210937,1112000
662,xxl-lm-d4-all-091621,_Previous_sentence_acceptable,accuracy (Rank),glue_cola,31.06423759460449,1112000
663,xxl-lm-d4-all-091621,_editing,accuracy (Rank),glue_cola,34.89933013916016,1112000
664,xxl-lm-d4-all-091621,_is_this_correct,accuracy (Rank),glue_cola,56.95110321044922,1112000
665,xxl-lm-d4-og-091621,_Following_sentence_acceptable,accuracy (Rank),glue_cola,38.54266357421875,1112000
666,xxl-lm-d4-og-091621,_Make_sense_yes_no,accuracy (Rank),glue_cola,30.968360900878906,1112000
667,xxl-lm-d4-og-091621,_Previous_sentence_acceptable,accuracy (Rank),glue_cola,30.968360900878906,1112000
668,xxl-lm-d4-og-091621,_editing,accuracy (Rank),glue_cola,31.06423759460449,1112000
669,xxl-lm-d4-og-091621,_is_this_correct,accuracy (Rank),glue_cola,33.65292358398437,1112000
670,xxl-lm-d4-all-og-091621,_Following_sentence_acceptable,accuracy (Rank),glue_cola,35.66634750366211,1112000
671,xxl-lm-d4-all-og-091621,_Make_sense_yes_no,accuracy (Rank),glue_cola,31.06423759460449,1112000
672,xxl-lm-d4-all-og-091621,_Previous_sentence_acceptable,accuracy (Rank),glue_cola,31.160114288330078,1112000
673,xxl-lm-d4-all-og-091621,_editing,accuracy (Rank),glue_cola,30.968360900878906,1112000
674,xxl-lm-d4-all-og-091621,_is_this_correct,accuracy (Rank),glue_cola,31.927133560180664,1112000
675,xxl-lm-d4-091621,_Following_sentence_acceptable,accuracy (Rank),glue_cola,66.15531921386719,1100000
676,xxl-lm-d4-091621,_Make_sense_yes_no,accuracy (Rank),glue_cola,31.255992889404297,1100000
677,xxl-lm-d4-091621,_Previous_sentence_acceptable,accuracy (Rank),glue_cola,38.4467887878418,1100000
678,xxl-lm-d4-091621,_editing,accuracy (Rank),glue_cola,60.59444046020508,1100000
679,xxl-lm-d4-091621,_is_this_correct,accuracy (Rank),glue_cola,41.03547286987305,1100000
680,xl-lm-d4-091621,_Following_sentence_acceptable,accuracy (Rank),glue_cola,60.88207244873047,1112000
681,xl-lm-d4-091621,_Make_sense_yes_no,accuracy (Rank),glue_cola,30.968360900878906,1112000
682,xl-lm-d4-091621,_Previous_sentence_acceptable,accuracy (Rank),glue_cola,31.255992889404297,1112000
683,xl-lm-d4-091621,_editing,accuracy (Rank),glue_cola,31.351869583129886,1112000
684,xl-lm-d4-091621,_is_this_correct,accuracy (Rank),glue_cola,31.639501571655273,1112000
910,xxl-lm-d4-091621-512,_GPT_3_style,accuracy (Rank),super_glue_cb,76.78571319580078,1112200
911,xxl-lm-d4-091621-512,_MNLI_crowdsource,accuracy (Rank),super_glue_cb,60.71428680419922,1112200
912,xxl-lm-d4-091621-512,_always_sometimes_never,accuracy (Rank),super_glue_cb,58.92856979370117,1112200
913,xxl-lm-d4-091621-512,_based_on_the_previous_passage,accuracy (Rank),super_glue_cb,80.35713958740234,1112200
914,xxl-lm-d4-091621-512,_can_we_infer,accuracy (Rank),super_glue_cb,78.57142639160156,1112200
915,xxl-lm-d4-091621-512,_claim_true_false_inconclusive,accuracy (Rank),super_glue_cb,80.35713958740234,1112200
916,xxl-lm-d4-091621-512,_consider_always_sometimes_never,accuracy (Rank),super_glue_cb,53.57143020629883,1112200
917,xxl-lm-d4-091621-512,_does_it_follow_that,accuracy (Rank),super_glue_cb,80.35713958740234,1112200
918,xxl-lm-d4-091621-512,_does_this_imply,accuracy (Rank),super_glue_cb,80.35713958740234,1112200
919,xxl-lm-d4-091621-512,_guaranteed_possible_impossible,accuracy (Rank),super_glue_cb,8.928571701049805,1112200
920,xxl-lm-d4-091621-512,_guaranteed_true,accuracy (Rank),super_glue_cb,75.0,1112200
921,xxl-lm-d4-091621-512,_justified_in_saying,accuracy (Rank),super_glue_cb,78.57142639160156,1112200
922,xxl-lm-d4-091621-512,_must_be_true,accuracy (Rank),super_glue_cb,80.35713958740234,1112200
923,xxl-lm-d4-091621-512,_should_assume,accuracy (Rank),super_glue_cb,78.57142639160156,1112200
924,xxl-lm-d4-091621-512,_take_the_following_as_truth,accuracy (Rank),super_glue_cb,80.35713958740234,1112200
925,xxl-lm-d4-gpt-091621,_GPT_3_style,accuracy (Rank),super_glue_cb,82.14286041259766,1112200
926,xxl-lm-d4-gpt-091621,_MNLI_crowdsource,accuracy (Rank),super_glue_cb,35.71428680419922,1112200
927,xxl-lm-d4-gpt-091621,_always_sometimes_never,accuracy (Rank),super_glue_cb,25.0,1112200
928,xxl-lm-d4-gpt-091621,_based_on_the_previous_passage,accuracy (Rank),super_glue_cb,73.21428680419922,1112200
929,xxl-lm-d4-gpt-091621,_can_we_infer,accuracy (Rank),super_glue_cb,69.64286041259766,1112200
930,xxl-lm-d4-gpt-091621,_claim_true_false_inconclusive,accuracy (Rank),super_glue_cb,85.71428680419922,1112200
931,xxl-lm-d4-gpt-091621,_consider_always_sometimes_never,accuracy (Rank),super_glue_cb,17.85714340209961,1112200
932,xxl-lm-d4-gpt-091621,_does_it_follow_that,accuracy (Rank),super_glue_cb,,1112200
933,xxl-lm-d4-gpt-091621,_does_this_imply,accuracy (Rank),super_glue_cb,71.42857360839844,1112200
934,xxl-lm-d4-gpt-091621,_guaranteed_possible_impossible,accuracy (Rank),super_glue_cb,8.928571701049805,1112200
935,xxl-lm-d4-gpt-091621,_guaranteed_true,accuracy (Rank),super_glue_cb,73.21428680419922,1112200
936,xxl-lm-d4-gpt-091621,_justified_in_saying,accuracy (Rank),super_glue_cb,75.0,1112200
937,xxl-lm-d4-gpt-091621,_must_be_true,accuracy (Rank),super_glue_cb,69.64286041259766,1112200
938,xxl-lm-d4-gpt-091621,_should_assume,accuracy (Rank),super_glue_cb,,1112200
939,xxl-lm-d4-gpt-091621,_take_the_following_as_truth,accuracy (Rank),super_glue_cb,82.14286041259766,1112200
940,xxl-lm-d4-all-091621,_GPT_3_style,accuracy (Rank),super_glue_cb,85.71428680419922,1112000
941,xxl-lm-d4-all-091621,_MNLI_crowdsource,accuracy (Rank),super_glue_cb,33.92856979370117,1112000
942,xxl-lm-d4-all-091621,_always_sometimes_never,accuracy (Rank),super_glue_cb,,1112000
943,xxl-lm-d4-all-091621,_based_on_the_previous_passage,accuracy (Rank),super_glue_cb,83.92857360839844,1112000
944,xxl-lm-d4-all-091621,_can_we_infer,accuracy (Rank),super_glue_cb,85.71428680419922,1112000
945,xxl-lm-d4-all-091621,_claim_true_false_inconclusive,accuracy (Rank),super_glue_cb,83.92857360839844,1112000
946,xxl-lm-d4-all-091621,_consider_always_sometimes_never,accuracy (Rank),super_glue_cb,46.42856979370117,1112000
947,xxl-lm-d4-all-091621,_does_it_follow_that,accuracy (Rank),super_glue_cb,73.21428680419922,1112000
948,xxl-lm-d4-all-091621,_does_this_imply,accuracy (Rank),super_glue_cb,82.14286041259766,1112000
949,xxl-lm-d4-all-091621,_guaranteed_possible_impossible,accuracy (Rank),super_glue_cb,,1112000
950,xxl-lm-d4-all-091621,_guaranteed_true,accuracy (Rank),super_glue_cb,76.78571319580078,1112000
951,xxl-lm-d4-all-091621,_justified_in_saying,accuracy (Rank),super_glue_cb,83.92857360839844,1112000
952,xxl-lm-d4-all-091621,_must_be_true,accuracy (Rank),super_glue_cb,80.35713958740234,1112000
953,xxl-lm-d4-all-091621,_should_assume,accuracy (Rank),super_glue_cb,83.92857360839844,1112000
954,xxl-lm-d4-all-091621,_take_the_following_as_truth,accuracy (Rank),super_glue_cb,83.92857360839844,1112000
955,xxl-lm-d4-og-091621,_GPT_3_style,accuracy (Rank),super_glue_cb,41.07143020629883,1112000
956,xxl-lm-d4-og-091621,_MNLI_crowdsource,accuracy (Rank),super_glue_cb,21.428571701049805,1112000
957,xxl-lm-d4-og-091621,_always_sometimes_never,accuracy (Rank),super_glue_cb,50.0,1112000
958,xxl-lm-d4-og-091621,_based_on_the_previous_passage,accuracy (Rank),super_glue_cb,64.28571319580078,1112000
959,xxl-lm-d4-og-091621,_can_we_infer,accuracy (Rank),super_glue_cb,60.71428680419922,1112000
960,xxl-lm-d4-og-091621,_claim_true_false_inconclusive,accuracy (Rank),super_glue_cb,41.07143020629883,1112000
961,xxl-lm-d4-og-091621,_consider_always_sometimes_never,accuracy (Rank),super_glue_cb,32.14285659790039,1112000
962,xxl-lm-d4-og-091621,_does_it_follow_that,accuracy (Rank),super_glue_cb,51.78571319580078,1112000
963,xxl-lm-d4-og-091621,_does_this_imply,accuracy (Rank),super_glue_cb,73.21428680419922,1112000
964,xxl-lm-d4-og-091621,_guaranteed_possible_impossible,accuracy (Rank),super_glue_cb,8.928571701049805,1112000
965,xxl-lm-d4-og-091621,_guaranteed_true,accuracy (Rank),super_glue_cb,64.28571319580078,1112000
966,xxl-lm-d4-og-091621,_justified_in_saying,accuracy (Rank),super_glue_cb,,1112000
967,xxl-lm-d4-og-091621,_must_be_true,accuracy (Rank),super_glue_cb,64.28571319580078,1112000
968,xxl-lm-d4-og-091621,_should_assume,accuracy (Rank),super_glue_cb,66.07142639160156,1112000
969,xxl-lm-d4-og-091621,_take_the_following_as_truth,accuracy (Rank),super_glue_cb,44.64285659790039,1112000
970,xxl-lm-d4-all-og-091621,_GPT_3_style,accuracy (Rank),super_glue_cb,55.35714340209961,1112000
971,xxl-lm-d4-all-og-091621,_MNLI_crowdsource,accuracy (Rank),super_glue_cb,17.85714340209961,1112000
972,xxl-lm-d4-all-og-091621,_always_sometimes_never,accuracy (Rank),super_glue_cb,26.78571510314941,1112000
973,xxl-lm-d4-all-og-091621,_based_on_the_previous_passage,accuracy (Rank),super_glue_cb,75.0,1112000
974,xxl-lm-d4-all-og-091621,_can_we_infer,accuracy (Rank),super_glue_cb,67.85713958740234,1112000
975,xxl-lm-d4-all-og-091621,_claim_true_false_inconclusive,accuracy (Rank),super_glue_cb,67.85713958740234,1112000
976,xxl-lm-d4-all-og-091621,_consider_always_sometimes_never,accuracy (Rank),super_glue_cb,35.71428680419922,1112000
977,xxl-lm-d4-all-og-091621,_does_it_follow_that,accuracy (Rank),super_glue_cb,62.5,1112000
978,xxl-lm-d4-all-og-091621,_does_this_imply,accuracy (Rank),super_glue_cb,75.0,1112000
979,xxl-lm-d4-all-og-091621,_guaranteed_possible_impossible,accuracy (Rank),super_glue_cb,8.928571701049805,1112000
980,xxl-lm-d4-all-og-091621,_guaranteed_true,accuracy (Rank),super_glue_cb,67.85713958740234,1112000
981,xxl-lm-d4-all-og-091621,_justified_in_saying,accuracy (Rank),super_glue_cb,64.28571319580078,1112000
982,xxl-lm-d4-all-og-091621,_must_be_true,accuracy (Rank),super_glue_cb,64.28571319580078,1112000
983,xxl-lm-d4-all-og-091621,_should_assume,accuracy (Rank),super_glue_cb,66.07142639160156,1112000
984,xxl-lm-d4-all-og-091621,_take_the_following_as_truth,accuracy (Rank),super_glue_cb,60.71428680419922,1112000
985,xxl-lm-d4-091621,_GPT_3_style,accuracy (Rank),super_glue_cb,26.78571510314941,1100000
986,xxl-lm-d4-091621,_MNLI_crowdsource,accuracy (Rank),super_glue_cb,,1100000
987,xxl-lm-d4-091621,_always_sometimes_never,accuracy (Rank),super_glue_cb,42.85714340209961,1100000
988,xxl-lm-d4-091621,_based_on_the_previous_passage,accuracy (Rank),super_glue_cb,39.28571319580078,1100000
989,xxl-lm-d4-091621,_can_we_infer,accuracy (Rank),super_glue_cb,16.071428298950195,1100000
990,xxl-lm-d4-091621,_claim_true_false_inconclusive,accuracy (Rank),super_glue_cb,41.07143020629883,1100000
991,xxl-lm-d4-091621,_consider_always_sometimes_never,accuracy (Rank),super_glue_cb,44.64285659790039,1100000
992,xxl-lm-d4-091621,_does_it_follow_that,accuracy (Rank),super_glue_cb,32.14285659790039,1100000
993,xxl-lm-d4-091621,_does_this_imply,accuracy (Rank),super_glue_cb,30.35714340209961,1100000
994,xxl-lm-d4-091621,_guaranteed_possible_impossible,accuracy (Rank),super_glue_cb,,1100000
995,xxl-lm-d4-091621,_guaranteed_true,accuracy (Rank),super_glue_cb,37.5,1100000
996,xxl-lm-d4-091621,_justified_in_saying,accuracy (Rank),super_glue_cb,33.92856979370117,1100000
997,xxl-lm-d4-091621,_must_be_true,accuracy (Rank),super_glue_cb,33.92856979370117,1100000
998,xxl-lm-d4-091621,_should_assume,accuracy (Rank),super_glue_cb,28.571428298950195,1100000
999,xxl-lm-d4-091621,_take_the_following_as_truth,accuracy (Rank),super_glue_cb,39.28571319580078,1100000
1000,xl-lm-d4-091621,_GPT_3_style,accuracy (Rank),super_glue_cb,51.78571319580078,1112000
1001,xl-lm-d4-091621,_MNLI_crowdsource,accuracy (Rank),super_glue_cb,8.928571701049805,1112000
1002,xl-lm-d4-091621,_always_sometimes_never,accuracy (Rank),super_glue_cb,39.28571319580078,1112000
1003,xl-lm-d4-091621,_based_on_the_previous_passage,accuracy (Rank),super_glue_cb,44.64285659790039,1112000
1004,xl-lm-d4-091621,_can_we_infer,accuracy (Rank),super_glue_cb,55.35714340209961,1112000
1005,xl-lm-d4-091621,_claim_true_false_inconclusive,accuracy (Rank),super_glue_cb,50.0,1112000
1006,xl-lm-d4-091621,_consider_always_sometimes_never,accuracy (Rank),super_glue_cb,35.71428680419922,1112000
1007,xl-lm-d4-091621,_does_it_follow_that,accuracy (Rank),super_glue_cb,64.28571319580078,1112000
1008,xl-lm-d4-091621,_does_this_imply,accuracy (Rank),super_glue_cb,58.92856979370117,1112000
1009,xl-lm-d4-091621,_guaranteed_possible_impossible,accuracy (Rank),super_glue_cb,8.928571701049805,1112000
1010,xl-lm-d4-091621,_guaranteed_true,accuracy (Rank),super_glue_cb,48.21428680419922,1112000
1011,xl-lm-d4-091621,_justified_in_saying,accuracy (Rank),super_glue_cb,53.57143020629883,1112000
1012,xl-lm-d4-091621,_must_be_true,accuracy (Rank),super_glue_cb,53.57143020629883,1112000
1013,xl-lm-d4-091621,_should_assume,accuracy (Rank),super_glue_cb,57.14285659790039,1112000
1014,xl-lm-d4-091621,_take_the_following_as_truth,accuracy (Rank),super_glue_cb,50.0,1112000
1270,xxl-lm-d4-091621-512,_GPT_3_style,accuracy (Rank),super_glue_rte,83.75450897216797,1112200
1271,xxl-lm-d4-091621-512,_MNLI_crowdsource,accuracy (Rank),super_glue_rte,84.8375473022461,1112200
1272,xxl-lm-d4-091621-512,_based_on_the_previous_passage,accuracy (Rank),super_glue_rte,84.47653198242188,1112200
1273,xxl-lm-d4-091621-512,_can_we_infer,accuracy (Rank),super_glue_rte,80.86642456054688,1112200
1274,xxl-lm-d4-091621-512,_does_it_follow_that,accuracy (Rank),super_glue_rte,74.00721740722656,1112200
1275,xxl-lm-d4-091621-512,_does_this_imply,accuracy (Rank),super_glue_rte,,1112200
1276,xxl-lm-d4-091621-512,_guaranteed_true,accuracy (Rank),super_glue_rte,79.78339385986328,1112200
1277,xxl-lm-d4-091621-512,_justified_in_saying,accuracy (Rank),super_glue_rte,75.09025573730469,1112200
1278,xxl-lm-d4-091621-512,_must_be_true,accuracy (Rank),super_glue_rte,81.2274398803711,1112200
1279,xxl-lm-d4-091621-512,_should_assume,accuracy (Rank),super_glue_rte,83.39350128173828,1112200
1280,xxl-lm-d4-gpt-091621,_GPT_3_style,accuracy (Rank),super_glue_rte,80.14440155029297,1112200
1281,xxl-lm-d4-gpt-091621,_MNLI_crowdsource,accuracy (Rank),super_glue_rte,75.45126342773438,1112200
1282,xxl-lm-d4-gpt-091621,_based_on_the_previous_passage,accuracy (Rank),super_glue_rte,64.98194885253906,1112200
1283,xxl-lm-d4-gpt-091621,_can_we_infer,accuracy (Rank),super_glue_rte,70.75812530517578,1112200
1284,xxl-lm-d4-gpt-091621,_does_it_follow_that,accuracy (Rank),super_glue_rte,64.62094116210939,1112200
1285,xxl-lm-d4-gpt-091621,_does_this_imply,accuracy (Rank),super_glue_rte,59.20577621459961,1112200
1286,xxl-lm-d4-gpt-091621,_guaranteed_true,accuracy (Rank),super_glue_rte,63.17689514160156,1112200
1287,xxl-lm-d4-gpt-091621,_justified_in_saying,accuracy (Rank),super_glue_rte,64.98194885253906,1112200
1288,xxl-lm-d4-gpt-091621,_must_be_true,accuracy (Rank),super_glue_rte,66.78700256347656,1112200
1289,xxl-lm-d4-gpt-091621,_should_assume,accuracy (Rank),super_glue_rte,64.62094116210939,1112200
1290,xxl-lm-d4-all-091621,_GPT_3_style,accuracy (Rank),super_glue_rte,83.75450897216797,1112000
1291,xxl-lm-d4-all-091621,_MNLI_crowdsource,accuracy (Rank),super_glue_rte,85.19855499267578,1112000
1292,xxl-lm-d4-all-091621,_based_on_the_previous_passage,accuracy (Rank),super_glue_rte,87.3646240234375,1112000
1293,xxl-lm-d4-all-091621,_can_we_infer,accuracy (Rank),super_glue_rte,87.00360870361328,1112000
1294,xxl-lm-d4-all-091621,_does_it_follow_that,accuracy (Rank),super_glue_rte,83.0324935913086,1112000
1295,xxl-lm-d4-all-091621,_does_this_imply,accuracy (Rank),super_glue_rte,90.2527084350586,1112000
1296,xxl-lm-d4-all-091621,_guaranteed_true,accuracy (Rank),super_glue_rte,86.6426010131836,1112000
1297,xxl-lm-d4-all-091621,_justified_in_saying,accuracy (Rank),super_glue_rte,84.47653198242188,1112000
1298,xxl-lm-d4-all-091621,_must_be_true,accuracy (Rank),super_glue_rte,81.94945526123047,1112000
1299,xxl-lm-d4-all-091621,_should_assume,accuracy (Rank),super_glue_rte,83.39350128173828,1112000
1300,xxl-lm-d4-og-091621,_GPT_3_style,accuracy (Rank),super_glue_rte,57.76173400878906,1112000
1301,xxl-lm-d4-og-091621,_MNLI_crowdsource,accuracy (Rank),super_glue_rte,79.06137084960938,1112000
1302,xxl-lm-d4-og-091621,_based_on_the_previous_passage,accuracy (Rank),super_glue_rte,83.39350128173828,1112000
1303,xxl-lm-d4-og-091621,_can_we_infer,accuracy (Rank),super_glue_rte,79.4223861694336,1112000
1304,xxl-lm-d4-og-091621,_does_it_follow_that,accuracy (Rank),super_glue_rte,66.42599487304689,1112000
1305,xxl-lm-d4-og-091621,_does_this_imply,accuracy (Rank),super_glue_rte,82.31047058105469,1112000
1306,xxl-lm-d4-og-091621,_guaranteed_true,accuracy (Rank),super_glue_rte,79.4223861694336,1112000
1307,xxl-lm-d4-og-091621,_justified_in_saying,accuracy (Rank),super_glue_rte,76.53429412841797,1112000
1308,xxl-lm-d4-og-091621,_must_be_true,accuracy (Rank),super_glue_rte,79.06137084960938,1112000
1309,xxl-lm-d4-og-091621,_should_assume,accuracy (Rank),super_glue_rte,80.86642456054688,1112000
1310,xxl-lm-d4-all-og-091621,_GPT_3_style,accuracy (Rank),super_glue_rte,81.58844757080078,1112000
1311,xxl-lm-d4-all-og-091621,_MNLI_crowdsource,accuracy (Rank),super_glue_rte,78.70036315917969,1112000
1312,xxl-lm-d4-all-og-091621,_based_on_the_previous_passage,accuracy (Rank),super_glue_rte,81.58844757080078,1112000
1313,xxl-lm-d4-all-og-091621,_can_we_infer,accuracy (Rank),super_glue_rte,71.11913299560547,1112000
1314,xxl-lm-d4-all-og-091621,_does_it_follow_that,accuracy (Rank),super_glue_rte,65.70397186279297,1112000
1315,xxl-lm-d4-all-og-091621,_does_this_imply,accuracy (Rank),super_glue_rte,81.94945526123047,1112000
1316,xxl-lm-d4-all-og-091621,_guaranteed_true,accuracy (Rank),super_glue_rte,75.09025573730469,1112000
1317,xxl-lm-d4-all-og-091621,_justified_in_saying,accuracy (Rank),super_glue_rte,74.00721740722656,1112000
1318,xxl-lm-d4-all-og-091621,_must_be_true,accuracy (Rank),super_glue_rte,74.72924041748047,1112000
1319,xxl-lm-d4-all-og-091621,_should_assume,accuracy (Rank),super_glue_rte,72.20216369628906,1112000
1320,xxl-lm-d4-091621,_GPT_3_style,accuracy (Rank),super_glue_rte,53.79061508178711,1100000
1321,xxl-lm-d4-091621,_MNLI_crowdsource,accuracy (Rank),super_glue_rte,51.2635383605957,1100000
1322,xxl-lm-d4-091621,_based_on_the_previous_passage,accuracy (Rank),super_glue_rte,50.5415153503418,1100000
1323,xxl-lm-d4-091621,_can_we_infer,accuracy (Rank),super_glue_rte,51.2635383605957,1100000
1324,xxl-lm-d4-091621,_does_it_follow_that,accuracy (Rank),super_glue_rte,51.2635383605957,1100000
1325,xxl-lm-d4-091621,_does_this_imply,accuracy (Rank),super_glue_rte,57.40072250366211,1100000
1326,xxl-lm-d4-091621,_guaranteed_true,accuracy (Rank),super_glue_rte,58.844764709472656,1100000
1327,xxl-lm-d4-091621,_justified_in_saying,accuracy (Rank),super_glue_rte,53.79061508178711,1100000
1328,xxl-lm-d4-091621,_must_be_true,accuracy (Rank),super_glue_rte,49.819496154785156,1100000
1329,xxl-lm-d4-091621,_should_assume,accuracy (Rank),super_glue_rte,52.3465690612793,1100000
1330,xl-lm-d4-091621,_GPT_3_style,accuracy (Rank),super_glue_rte,61.37184143066406,1112000
1331,xl-lm-d4-091621,_MNLI_crowdsource,accuracy (Rank),super_glue_rte,63.53790664672852,1112000
1332,xl-lm-d4-091621,_based_on_the_previous_passage,accuracy (Rank),super_glue_rte,68.23104858398439,1112000
1333,xl-lm-d4-091621,_can_we_infer,accuracy (Rank),super_glue_rte,59.56678771972656,1112000
1334,xl-lm-d4-091621,_does_it_follow_that,accuracy (Rank),super_glue_rte,61.73285293579102,1112000
1335,xl-lm-d4-091621,_does_this_imply,accuracy (Rank),super_glue_rte,64.62094116210939,1112000
1336,xl-lm-d4-091621,_guaranteed_true,accuracy (Rank),super_glue_rte,68.95307159423828,1112000
1337,xl-lm-d4-091621,_justified_in_saying,accuracy (Rank),super_glue_rte,61.01082992553711,1112000
1338,xl-lm-d4-091621,_must_be_true,accuracy (Rank),super_glue_rte,70.03610229492189,1112000
1339,xl-lm-d4-091621,_should_assume,accuracy (Rank),super_glue_rte,66.42599487304689,1112000
1640,xxl-lm-d4-091621-512,_GPT_3_style,accuracy (Rank),anli_r1,45.0,1112200
1641,xxl-lm-d4-091621-512,_MNLI_crowdsource,accuracy (Rank),anli_r1,42.79999923706055,1112200
1642,xxl-lm-d4-091621-512,_always_sometimes_never,accuracy (Rank),anli_r1,37.400001525878906,1112200
1643,xxl-lm-d4-091621-512,_based_on_the_previous_passage,accuracy (Rank),anli_r1,45.4000015258789,1112200
1644,xxl-lm-d4-091621-512,_can_we_infer,accuracy (Rank),anli_r1,44.79999923706055,1112200
1645,xxl-lm-d4-091621-512,_claim_true_false_inconclusive,accuracy (Rank),anli_r1,46.4000015258789,1112200
1646,xxl-lm-d4-091621-512,_consider_always_sometimes_never,accuracy (Rank),anli_r1,,1112200
1647,xxl-lm-d4-091621-512,_does_it_follow_that,accuracy (Rank),anli_r1,44.599998474121094,1112200
1648,xxl-lm-d4-091621-512,_does_this_imply,accuracy (Rank),anli_r1,45.099998474121094,1112200
1649,xxl-lm-d4-091621-512,_guaranteed_possible_impossible,accuracy (Rank),anli_r1,33.299999237060554,1112200
1650,xxl-lm-d4-091621-512,_guaranteed_true,accuracy (Rank),anli_r1,44.20000076293945,1112200
1651,xxl-lm-d4-091621-512,_justified_in_saying,accuracy (Rank),anli_r1,44.5,1112200
1652,xxl-lm-d4-091621-512,_must_be_true,accuracy (Rank),anli_r1,45.70000076293945,1112200
1653,xxl-lm-d4-091621-512,_should_assume,accuracy (Rank),anli_r1,44.099998474121094,1112200
1654,xxl-lm-d4-091621-512,_take_the_following_as_truth,accuracy (Rank),anli_r1,46.599998474121094,1112200
1655,xxl-lm-d4-gpt-091621,_GPT_3_style,accuracy (Rank),anli_r1,47.5,1112200
1656,xxl-lm-d4-gpt-091621,_MNLI_crowdsource,accuracy (Rank),anli_r1,34.799999237060554,1112200
1657,xxl-lm-d4-gpt-091621,_always_sometimes_never,accuracy (Rank),anli_r1,35.0,1112200
1658,xxl-lm-d4-gpt-091621,_based_on_the_previous_passage,accuracy (Rank),anli_r1,44.900001525878906,1112200
1659,xxl-lm-d4-gpt-091621,_can_we_infer,accuracy (Rank),anli_r1,46.099998474121094,1112200
1660,xxl-lm-d4-gpt-091621,_claim_true_false_inconclusive,accuracy (Rank),anli_r1,48.4000015258789,1112200
1661,xxl-lm-d4-gpt-091621,_consider_always_sometimes_never,accuracy (Rank),anli_r1,36.400001525878906,1112200
1662,xxl-lm-d4-gpt-091621,_does_it_follow_that,accuracy (Rank),anli_r1,47.29999923706055,1112200
1663,xxl-lm-d4-gpt-091621,_does_this_imply,accuracy (Rank),anli_r1,46.4000015258789,1112200
1664,xxl-lm-d4-gpt-091621,_guaranteed_possible_impossible,accuracy (Rank),anli_r1,34.400001525878906,1112200
1665,xxl-lm-d4-gpt-091621,_guaranteed_true,accuracy (Rank),anli_r1,44.099998474121094,1112200
1666,xxl-lm-d4-gpt-091621,_justified_in_saying,accuracy (Rank),anli_r1,44.900001525878906,1112200
1667,xxl-lm-d4-gpt-091621,_must_be_true,accuracy (Rank),anli_r1,47.20000076293945,1112200
1668,xxl-lm-d4-gpt-091621,_should_assume,accuracy (Rank),anli_r1,45.79999923706055,1112200
1669,xxl-lm-d4-gpt-091621,_take_the_following_as_truth,accuracy (Rank),anli_r1,48.5,1112200
1670,xxl-lm-d4-all-091621,_GPT_3_style,accuracy (Rank),anli_r1,52.29999923706055,1112000
1671,xxl-lm-d4-all-091621,_MNLI_crowdsource,accuracy (Rank),anli_r1,36.599998474121094,1112000
1672,xxl-lm-d4-all-091621,_always_sometimes_never,accuracy (Rank),anli_r1,37.5,1112000
1673,xxl-lm-d4-all-091621,_based_on_the_previous_passage,accuracy (Rank),anli_r1,49.79999923706055,1112000
1674,xxl-lm-d4-all-091621,_can_we_infer,accuracy (Rank),anli_r1,50.29999923706055,1112000
1675,xxl-lm-d4-all-091621,_claim_true_false_inconclusive,accuracy (Rank),anli_r1,51.099998474121094,1112000
1676,xxl-lm-d4-all-091621,_consider_always_sometimes_never,accuracy (Rank),anli_r1,42.70000076293945,1112000
1677,xxl-lm-d4-all-091621,_does_it_follow_that,accuracy (Rank),anli_r1,50.20000076293945,1112000
1678,xxl-lm-d4-all-091621,_does_this_imply,accuracy (Rank),anli_r1,48.599998474121094,1112000
1679,xxl-lm-d4-all-091621,_guaranteed_possible_impossible,accuracy (Rank),anli_r1,33.299999237060554,1112000
1680,xxl-lm-d4-all-091621,_guaranteed_true,accuracy (Rank),anli_r1,48.70000076293945,1112000
1681,xxl-lm-d4-all-091621,_justified_in_saying,accuracy (Rank),anli_r1,49.099998474121094,1112000
1682,xxl-lm-d4-all-091621,_must_be_true,accuracy (Rank),anli_r1,52.0,1112000
1683,xxl-lm-d4-all-091621,_should_assume,accuracy (Rank),anli_r1,51.5,1112000
1684,xxl-lm-d4-all-091621,_take_the_following_as_truth,accuracy (Rank),anli_r1,52.4000015258789,1112000
1685,xxl-lm-d4-og-091621,_GPT_3_style,accuracy (Rank),anli_r1,34.200000762939446,1112000
1686,xxl-lm-d4-og-091621,_MNLI_crowdsource,accuracy (Rank),anli_r1,36.70000076293945,1112000
1687,xxl-lm-d4-og-091621,_always_sometimes_never,accuracy (Rank),anli_r1,38.599998474121094,1112000
1688,xxl-lm-d4-og-091621,_based_on_the_previous_passage,accuracy (Rank),anli_r1,42.5,1112000
1689,xxl-lm-d4-og-091621,_can_we_infer,accuracy (Rank),anli_r1,42.099998474121094,1112000
1690,xxl-lm-d4-og-091621,_claim_true_false_inconclusive,accuracy (Rank),anli_r1,35.70000076293945,1112000
1691,xxl-lm-d4-og-091621,_consider_always_sometimes_never,accuracy (Rank),anli_r1,34.799999237060554,1112000
1692,xxl-lm-d4-og-091621,_does_it_follow_that,accuracy (Rank),anli_r1,42.099998474121094,1112000
1693,xxl-lm-d4-og-091621,_does_this_imply,accuracy (Rank),anli_r1,43.70000076293945,1112000
1694,xxl-lm-d4-og-091621,_guaranteed_possible_impossible,accuracy (Rank),anli_r1,33.200000762939446,1112000
1695,xxl-lm-d4-og-091621,_guaranteed_true,accuracy (Rank),anli_r1,41.5,1112000
1696,xxl-lm-d4-og-091621,_justified_in_saying,accuracy (Rank),anli_r1,,1112000
1697,xxl-lm-d4-og-091621,_must_be_true,accuracy (Rank),anli_r1,43.900001525878906,1112000
1698,xxl-lm-d4-og-091621,_should_assume,accuracy (Rank),anli_r1,42.599998474121094,1112000
1699,xxl-lm-d4-og-091621,_take_the_following_as_truth,accuracy (Rank),anli_r1,34.700000762939446,1112000
1700,xxl-lm-d4-all-og-091621,_GPT_3_style,accuracy (Rank),anli_r1,43.20000076293945,1112000
1701,xxl-lm-d4-all-og-091621,_MNLI_crowdsource,accuracy (Rank),anli_r1,33.900001525878906,1112000
1702,xxl-lm-d4-all-og-091621,_always_sometimes_never,accuracy (Rank),anli_r1,39.0,1112000
1703,xxl-lm-d4-all-og-091621,_based_on_the_previous_passage,accuracy (Rank),anli_r1,43.70000076293945,1112000
1704,xxl-lm-d4-all-og-091621,_can_we_infer,accuracy (Rank),anli_r1,43.599998474121094,1112000
1705,xxl-lm-d4-all-og-091621,_claim_true_false_inconclusive,accuracy (Rank),anli_r1,42.29999923706055,1112000
1706,xxl-lm-d4-all-og-091621,_consider_always_sometimes_never,accuracy (Rank),anli_r1,36.29999923706055,1112000
1707,xxl-lm-d4-all-og-091621,_does_it_follow_that,accuracy (Rank),anli_r1,42.900001525878906,1112000
1708,xxl-lm-d4-all-og-091621,_does_this_imply,accuracy (Rank),anli_r1,44.599998474121094,1112000
1709,xxl-lm-d4-all-og-091621,_guaranteed_possible_impossible,accuracy (Rank),anli_r1,33.299999237060554,1112000
1710,xxl-lm-d4-all-og-091621,_guaranteed_true,accuracy (Rank),anli_r1,43.29999923706055,1112000
1711,xxl-lm-d4-all-og-091621,_justified_in_saying,accuracy (Rank),anli_r1,43.29999923706055,1112000
1712,xxl-lm-d4-all-og-091621,_must_be_true,accuracy (Rank),anli_r1,44.099998474121094,1112000
1713,xxl-lm-d4-all-og-091621,_should_assume,accuracy (Rank),anli_r1,44.0,1112000
1714,xxl-lm-d4-all-og-091621,_take_the_following_as_truth,accuracy (Rank),anli_r1,41.70000076293945,1112000
1715,xxl-lm-d4-091621,_GPT_3_style,accuracy (Rank),anli_r1,32.799999237060554,1100000
1716,xxl-lm-d4-091621,_MNLI_crowdsource,accuracy (Rank),anli_r1,33.59999847412109,1100000
1717,xxl-lm-d4-091621,_always_sometimes_never,accuracy (Rank),anli_r1,31.20000076293945,1100000
1718,xxl-lm-d4-091621,_based_on_the_previous_passage,accuracy (Rank),anli_r1,32.700000762939446,1100000
1719,xxl-lm-d4-091621,_can_we_infer,accuracy (Rank),anli_r1,32.59999847412109,1100000
1720,xxl-lm-d4-091621,_claim_true_false_inconclusive,accuracy (Rank),anli_r1,33.799999237060554,1100000
1721,xxl-lm-d4-091621,_consider_always_sometimes_never,accuracy (Rank),anli_r1,29.70000076293945,1100000
1722,xxl-lm-d4-091621,_does_it_follow_that,accuracy (Rank),anli_r1,34.0,1100000
1723,xxl-lm-d4-091621,_does_this_imply,accuracy (Rank),anli_r1,34.5,1100000
1724,xxl-lm-d4-091621,_guaranteed_possible_impossible,accuracy (Rank),anli_r1,32.799999237060554,1100000
1725,xxl-lm-d4-091621,_guaranteed_true,accuracy (Rank),anli_r1,32.700000762939446,1100000
1726,xxl-lm-d4-091621,_justified_in_saying,accuracy (Rank),anli_r1,34.0,1100000
1727,xxl-lm-d4-091621,_must_be_true,accuracy (Rank),anli_r1,32.900001525878906,1100000
1728,xxl-lm-d4-091621,_should_assume,accuracy (Rank),anli_r1,33.09999847412109,1100000
1729,xxl-lm-d4-091621,_take_the_following_as_truth,accuracy (Rank),anli_r1,,1100000
1730,xl-lm-d4-091621,_GPT_3_style,accuracy (Rank),anli_r1,33.799999237060554,1112000
1731,xl-lm-d4-091621,_MNLI_crowdsource,accuracy (Rank),anli_r1,33.59999847412109,1112000
1732,xl-lm-d4-091621,_always_sometimes_never,accuracy (Rank),anli_r1,,1112000
1733,xl-lm-d4-091621,_based_on_the_previous_passage,accuracy (Rank),anli_r1,33.900001525878906,1112000
1734,xl-lm-d4-091621,_can_we_infer,accuracy (Rank),anli_r1,33.900001525878906,1112000
1735,xl-lm-d4-091621,_claim_true_false_inconclusive,accuracy (Rank),anli_r1,35.599998474121094,1112000
1736,xl-lm-d4-091621,_consider_always_sometimes_never,accuracy (Rank),anli_r1,33.200000762939446,1112000
1737,xl-lm-d4-091621,_does_it_follow_that,accuracy (Rank),anli_r1,36.0,1112000
1738,xl-lm-d4-091621,_does_this_imply,accuracy (Rank),anli_r1,33.59999847412109,1112000
1739,xl-lm-d4-091621,_guaranteed_possible_impossible,accuracy (Rank),anli_r1,33.299999237060554,1112000
1740,xl-lm-d4-091621,_guaranteed_true,accuracy (Rank),anli_r1,33.700000762939446,1112000
1741,xl-lm-d4-091621,_justified_in_saying,accuracy (Rank),anli_r1,33.09999847412109,1112000
1742,xl-lm-d4-091621,_must_be_true,accuracy (Rank),anli_r1,34.400001525878906,1112000
1743,xl-lm-d4-091621,_should_assume,accuracy (Rank),anli_r1,33.200000762939446,1112000
1744,xl-lm-d4-091621,_take_the_following_as_truth,accuracy (Rank),anli_r1,32.400001525878906,1112000
1940,xxl-lm-d4-091621-512,_GPT_3_style,accuracy (Rank),anli_r2,39.400001525878906,1112200
1941,xxl-lm-d4-091621-512,_MNLI_crowdsource,accuracy (Rank),anli_r2,39.29999923706055,1112200
1942,xxl-lm-d4-091621-512,_always_sometimes_never,accuracy (Rank),anli_r2,35.0,1112200
1943,xxl-lm-d4-091621-512,_based_on_the_previous_passage,accuracy (Rank),anli_r2,39.900001525878906,1112200
1944,xxl-lm-d4-091621-512,_can_we_infer,accuracy (Rank),anli_r2,39.29999923706055,1112200
1945,xxl-lm-d4-091621-512,_claim_true_false_inconclusive,accuracy (Rank),anli_r2,40.70000076293945,1112200
1946,xxl-lm-d4-091621-512,_consider_always_sometimes_never,accuracy (Rank),anli_r2,34.799999237060554,1112200
1947,xxl-lm-d4-091621-512,_does_it_follow_that,accuracy (Rank),anli_r2,40.5,1112200
1948,xxl-lm-d4-091621-512,_does_this_imply,accuracy (Rank),anli_r2,40.70000076293945,1112200
1949,xxl-lm-d4-091621-512,_guaranteed_possible_impossible,accuracy (Rank),anli_r2,33.5,1112200
1950,xxl-lm-d4-091621-512,_guaranteed_true,accuracy (Rank),anli_r2,39.0,1112200
1951,xxl-lm-d4-091621-512,_justified_in_saying,accuracy (Rank),anli_r2,39.599998474121094,1112200
1952,xxl-lm-d4-091621-512,_must_be_true,accuracy (Rank),anli_r2,40.0,1112200
1953,xxl-lm-d4-091621-512,_should_assume,accuracy (Rank),anli_r2,38.79999923706055,1112200
1954,xxl-lm-d4-091621-512,_take_the_following_as_truth,accuracy (Rank),anli_r2,39.70000076293945,1112200
1955,xxl-lm-d4-gpt-091621,_GPT_3_style,accuracy (Rank),anli_r2,41.400001525878906,1112200
1956,xxl-lm-d4-gpt-091621,_MNLI_crowdsource,accuracy (Rank),anli_r2,35.0,1112200
1957,xxl-lm-d4-gpt-091621,_always_sometimes_never,accuracy (Rank),anli_r2,34.59999847412109,1112200
1958,xxl-lm-d4-gpt-091621,_based_on_the_previous_passage,accuracy (Rank),anli_r2,40.099998474121094,1112200
1959,xxl-lm-d4-gpt-091621,_can_we_infer,accuracy (Rank),anli_r2,42.70000076293945,1112200
1960,xxl-lm-d4-gpt-091621,_claim_true_false_inconclusive,accuracy (Rank),anli_r2,42.5,1112200
1961,xxl-lm-d4-gpt-091621,_consider_always_sometimes_never,accuracy (Rank),anli_r2,35.70000076293945,1112200
1962,xxl-lm-d4-gpt-091621,_does_it_follow_that,accuracy (Rank),anli_r2,43.70000076293945,1112200
1963,xxl-lm-d4-gpt-091621,_does_this_imply,accuracy (Rank),anli_r2,42.400001525878906,1112200
1964,xxl-lm-d4-gpt-091621,_guaranteed_possible_impossible,accuracy (Rank),anli_r2,34.0,1112200
1965,xxl-lm-d4-gpt-091621,_guaranteed_true,accuracy (Rank),anli_r2,39.5,1112200
1966,xxl-lm-d4-gpt-091621,_justified_in_saying,accuracy (Rank),anli_r2,41.599998474121094,1112200
1967,xxl-lm-d4-gpt-091621,_must_be_true,accuracy (Rank),anli_r2,42.5,1112200
1968,xxl-lm-d4-gpt-091621,_should_assume,accuracy (Rank),anli_r2,39.70000076293945,1112200
1969,xxl-lm-d4-gpt-091621,_take_the_following_as_truth,accuracy (Rank),anli_r2,41.099998474121094,1112200
1970,xxl-lm-d4-all-091621,_GPT_3_style,accuracy (Rank),anli_r2,44.599998474121094,1112000
1971,xxl-lm-d4-all-091621,_MNLI_crowdsource,accuracy (Rank),anli_r2,35.70000076293945,1112000
1972,xxl-lm-d4-all-091621,_always_sometimes_never,accuracy (Rank),anli_r2,38.29999923706055,1112000
1973,xxl-lm-d4-all-091621,_based_on_the_previous_passage,accuracy (Rank),anli_r2,43.0,1112000
1974,xxl-lm-d4-all-091621,_can_we_infer,accuracy (Rank),anli_r2,45.5,1112000
1975,xxl-lm-d4-all-091621,_claim_true_false_inconclusive,accuracy (Rank),anli_r2,44.5,1112000
1976,xxl-lm-d4-all-091621,_consider_always_sometimes_never,accuracy (Rank),anli_r2,37.599998474121094,1112000
1977,xxl-lm-d4-all-091621,_does_it_follow_that,accuracy (Rank),anli_r2,44.900001525878906,1112000
1978,xxl-lm-d4-all-091621,_does_this_imply,accuracy (Rank),anli_r2,44.5,1112000
1979,xxl-lm-d4-all-091621,_guaranteed_possible_impossible,accuracy (Rank),anli_r2,33.400001525878906,1112000
1980,xxl-lm-d4-all-091621,_guaranteed_true,accuracy (Rank),anli_r2,43.599998474121094,1112000
1981,xxl-lm-d4-all-091621,_justified_in_saying,accuracy (Rank),anli_r2,44.5,1112000
1982,xxl-lm-d4-all-091621,_must_be_true,accuracy (Rank),anli_r2,45.29999923706055,1112000
1983,xxl-lm-d4-all-091621,_should_assume,accuracy (Rank),anli_r2,44.5,1112000
1984,xxl-lm-d4-all-091621,_take_the_following_as_truth,accuracy (Rank),anli_r2,42.79999923706055,1112000
1985,xxl-lm-d4-og-091621,_GPT_3_style,accuracy (Rank),anli_r2,34.0,1112000
1986,xxl-lm-d4-og-091621,_MNLI_crowdsource,accuracy (Rank),anli_r2,37.20000076293945,1112000
1987,xxl-lm-d4-og-091621,_always_sometimes_never,accuracy (Rank),anli_r2,36.0,1112000
1988,xxl-lm-d4-og-091621,_based_on_the_previous_passage,accuracy (Rank),anli_r2,38.70000076293945,1112000
1989,xxl-lm-d4-og-091621,_can_we_infer,accuracy (Rank),anli_r2,38.79999923706055,1112000
1990,xxl-lm-d4-og-091621,_claim_true_false_inconclusive,accuracy (Rank),anli_r2,33.799999237060554,1112000
1991,xxl-lm-d4-og-091621,_consider_always_sometimes_never,accuracy (Rank),anli_r2,34.0,1112000
1992,xxl-lm-d4-og-091621,_does_it_follow_that,accuracy (Rank),anli_r2,39.599998474121094,1112000
1993,xxl-lm-d4-og-091621,_does_this_imply,accuracy (Rank),anli_r2,39.29999923706055,1112000
1994,xxl-lm-d4-og-091621,_guaranteed_possible_impossible,accuracy (Rank),anli_r2,33.299999237060554,1112000
1995,xxl-lm-d4-og-091621,_guaranteed_true,accuracy (Rank),anli_r2,38.20000076293945,1112000
1996,xxl-lm-d4-og-091621,_justified_in_saying,accuracy (Rank),anli_r2,38.79999923706055,1112000
1997,xxl-lm-d4-og-091621,_must_be_true,accuracy (Rank),anli_r2,39.599998474121094,1112000
1998,xxl-lm-d4-og-091621,_should_assume,accuracy (Rank),anli_r2,39.29999923706055,1112000
1999,xxl-lm-d4-og-091621,_take_the_following_as_truth,accuracy (Rank),anli_r2,33.799999237060554,1112000
2000,xxl-lm-d4-all-og-091621,_GPT_3_style,accuracy (Rank),anli_r2,38.099998474121094,1112000
2001,xxl-lm-d4-all-og-091621,_MNLI_crowdsource,accuracy (Rank),anli_r2,34.700000762939446,1112000
2002,xxl-lm-d4-all-og-091621,_always_sometimes_never,accuracy (Rank),anli_r2,36.70000076293945,1112000
2003,xxl-lm-d4-all-og-091621,_based_on_the_previous_passage,accuracy (Rank),anli_r2,39.599998474121094,1112000
2004,xxl-lm-d4-all-og-091621,_can_we_infer,accuracy (Rank),anli_r2,38.599998474121094,1112000
2005,xxl-lm-d4-all-og-091621,_claim_true_false_inconclusive,accuracy (Rank),anli_r2,38.599998474121094,1112000
2006,xxl-lm-d4-all-og-091621,_consider_always_sometimes_never,accuracy (Rank),anli_r2,35.400001525878906,1112000
2007,xxl-lm-d4-all-og-091621,_does_it_follow_that,accuracy (Rank),anli_r2,39.0,1112000
2008,xxl-lm-d4-all-og-091621,_does_this_imply,accuracy (Rank),anli_r2,40.20000076293945,1112000
2009,xxl-lm-d4-all-og-091621,_guaranteed_possible_impossible,accuracy (Rank),anli_r2,33.59999847412109,1112000
2010,xxl-lm-d4-all-og-091621,_guaranteed_true,accuracy (Rank),anli_r2,39.5,1112000
2011,xxl-lm-d4-all-og-091621,_justified_in_saying,accuracy (Rank),anli_r2,37.400001525878906,1112000
2012,xxl-lm-d4-all-og-091621,_must_be_true,accuracy (Rank),anli_r2,39.20000076293945,1112000
2013,xxl-lm-d4-all-og-091621,_should_assume,accuracy (Rank),anli_r2,39.5,1112000
2014,xxl-lm-d4-all-og-091621,_take_the_following_as_truth,accuracy (Rank),anli_r2,36.70000076293945,1112000
2015,xxl-lm-d4-091621,_GPT_3_style,accuracy (Rank),anli_r2,36.900001525878906,1100000
2016,xxl-lm-d4-091621,_MNLI_crowdsource,accuracy (Rank),anli_r2,36.599998474121094,1100000
2017,xxl-lm-d4-091621,_always_sometimes_never,accuracy (Rank),anli_r2,32.400001525878906,1100000
2018,xxl-lm-d4-091621,_based_on_the_previous_passage,accuracy (Rank),anli_r2,32.59999847412109,1100000
2019,xxl-lm-d4-091621,_can_we_infer,accuracy (Rank),anli_r2,32.900001525878906,1100000
2020,xxl-lm-d4-091621,_claim_true_false_inconclusive,accuracy (Rank),anli_r2,35.70000076293945,1100000
2021,xxl-lm-d4-091621,_consider_always_sometimes_never,accuracy (Rank),anli_r2,31.79999923706055,1100000
2022,xxl-lm-d4-091621,_does_it_follow_that,accuracy (Rank),anli_r2,32.700000762939446,1100000
2023,xxl-lm-d4-091621,_does_this_imply,accuracy (Rank),anli_r2,32.799999237060554,1100000
2024,xxl-lm-d4-091621,_guaranteed_possible_impossible,accuracy (Rank),anli_r2,34.5,1100000
2025,xxl-lm-d4-091621,_guaranteed_true,accuracy (Rank),anli_r2,32.799999237060554,1100000
2026,xxl-lm-d4-091621,_justified_in_saying,accuracy (Rank),anli_r2,32.400001525878906,1100000
2027,xxl-lm-d4-091621,_must_be_true,accuracy (Rank),anli_r2,34.299999237060554,1100000
2028,xxl-lm-d4-091621,_should_assume,accuracy (Rank),anli_r2,33.900001525878906,1100000
2029,xxl-lm-d4-091621,_take_the_following_as_truth,accuracy (Rank),anli_r2,34.09999847412109,1100000
2030,xl-lm-d4-091621,_GPT_3_style,accuracy (Rank),anli_r2,33.5,1112000
2031,xl-lm-d4-091621,_MNLI_crowdsource,accuracy (Rank),anli_r2,33.400001525878906,1112000
2032,xl-lm-d4-091621,_always_sometimes_never,accuracy (Rank),anli_r2,33.400001525878906,1112000
2033,xl-lm-d4-091621,_based_on_the_previous_passage,accuracy (Rank),anli_r2,31.399999618530273,1112000
2034,xl-lm-d4-091621,_can_we_infer,accuracy (Rank),anli_r2,30.399999618530273,1112000
2035,xl-lm-d4-091621,_claim_true_false_inconclusive,accuracy (Rank),anli_r2,34.900001525878906,1112000
2036,xl-lm-d4-091621,_consider_always_sometimes_never,accuracy (Rank),anli_r2,33.700000762939446,1112000
2037,xl-lm-d4-091621,_does_it_follow_that,accuracy (Rank),anli_r2,34.5,1112000
2038,xl-lm-d4-091621,_does_this_imply,accuracy (Rank),anli_r2,32.700000762939446,1112000
2039,xl-lm-d4-091621,_guaranteed_possible_impossible,accuracy (Rank),anli_r2,33.299999237060554,1112000
2040,xl-lm-d4-091621,_guaranteed_true,accuracy (Rank),anli_r2,32.900001525878906,1112000
2041,xl-lm-d4-091621,_justified_in_saying,accuracy (Rank),anli_r2,33.5,1112000
2042,xl-lm-d4-091621,_must_be_true,accuracy (Rank),anli_r2,35.09999847412109,1112000
2043,xl-lm-d4-091621,_should_assume,accuracy (Rank),anli_r2,32.400001525878906,1112000
2044,xl-lm-d4-091621,_take_the_following_as_truth,accuracy (Rank),anli_r2,31.60000038146973,1112000
2240,xxl-lm-d4-091621-512,_GPT_3_style,accuracy (Rank),anli_r3,41.33333206176758,1112200
2241,xxl-lm-d4-091621-512,_MNLI_crowdsource,accuracy (Rank),anli_r3,40.83333206176758,1112200
2242,xxl-lm-d4-091621-512,_always_sometimes_never,accuracy (Rank),anli_r3,36.91666793823242,1112200
2243,xxl-lm-d4-091621-512,_based_on_the_previous_passage,accuracy (Rank),anli_r3,44.08333206176758,1112200
2244,xxl-lm-d4-091621-512,_can_we_infer,accuracy (Rank),anli_r3,43.75,1112200
2245,xxl-lm-d4-091621-512,_claim_true_false_inconclusive,accuracy (Rank),anli_r3,43.0,1112200
2246,xxl-lm-d4-091621-512,_consider_always_sometimes_never,accuracy (Rank),anli_r3,36.08333206176758,1112200
2247,xxl-lm-d4-091621-512,_does_it_follow_that,accuracy (Rank),anli_r3,42.41666793823242,1112200
2248,xxl-lm-d4-091621-512,_does_this_imply,accuracy (Rank),anli_r3,43.16666793823242,1112200
2249,xxl-lm-d4-091621-512,_guaranteed_possible_impossible,accuracy (Rank),anli_r3,33.83333206176758,1112200
2250,xxl-lm-d4-091621-512,_guaranteed_true,accuracy (Rank),anli_r3,42.16666793823242,1112200
2251,xxl-lm-d4-091621-512,_justified_in_saying,accuracy (Rank),anli_r3,42.25,1112200
2252,xxl-lm-d4-091621-512,_must_be_true,accuracy (Rank),anli_r3,42.91666793823242,1112200
2253,xxl-lm-d4-091621-512,_should_assume,accuracy (Rank),anli_r3,43.16666793823242,1112200
2254,xxl-lm-d4-091621-512,_take_the_following_as_truth,accuracy (Rank),anli_r3,42.91666793823242,1112200
2255,xxl-lm-d4-gpt-091621,_GPT_3_style,accuracy (Rank),anli_r3,45.08333206176758,1112200
2256,xxl-lm-d4-gpt-091621,_MNLI_crowdsource,accuracy (Rank),anli_r3,38.75,1112200
2257,xxl-lm-d4-gpt-091621,_always_sometimes_never,accuracy (Rank),anli_r3,35.08333206176758,1112200
2258,xxl-lm-d4-gpt-091621,_based_on_the_previous_passage,accuracy (Rank),anli_r3,41.16666793823242,1112200
2259,xxl-lm-d4-gpt-091621,_can_we_infer,accuracy (Rank),anli_r3,42.0,1112200
2260,xxl-lm-d4-gpt-091621,_claim_true_false_inconclusive,accuracy (Rank),anli_r3,46.0,1112200
2261,xxl-lm-d4-gpt-091621,_consider_always_sometimes_never,accuracy (Rank),anli_r3,33.41666793823242,1112200
2262,xxl-lm-d4-gpt-091621,_does_it_follow_that,accuracy (Rank),anli_r3,43.08333206176758,1112200
2263,xxl-lm-d4-gpt-091621,_does_this_imply,accuracy (Rank),anli_r3,42.33333206176758,1112200
2264,xxl-lm-d4-gpt-091621,_guaranteed_possible_impossible,accuracy (Rank),anli_r3,34.58333206176758,1112200
2265,xxl-lm-d4-gpt-091621,_guaranteed_true,accuracy (Rank),anli_r3,40.58333206176758,1112200
2266,xxl-lm-d4-gpt-091621,_justified_in_saying,accuracy (Rank),anli_r3,40.33333206176758,1112200
2267,xxl-lm-d4-gpt-091621,_must_be_true,accuracy (Rank),anli_r3,41.66666793823242,1112200
2268,xxl-lm-d4-gpt-091621,_should_assume,accuracy (Rank),anli_r3,40.5,1112200
2269,xxl-lm-d4-gpt-091621,_take_the_following_as_truth,accuracy (Rank),anli_r3,46.83333206176758,1112200
2270,xxl-lm-d4-all-091621,_GPT_3_style,accuracy (Rank),anli_r3,49.5,1112000
2271,xxl-lm-d4-all-091621,_MNLI_crowdsource,accuracy (Rank),anli_r3,36.5,1112000
2272,xxl-lm-d4-all-091621,_always_sometimes_never,accuracy (Rank),anli_r3,35.91666793823242,1112000
2273,xxl-lm-d4-all-091621,_based_on_the_previous_passage,accuracy (Rank),anli_r3,46.5,1112000
2274,xxl-lm-d4-all-091621,_can_we_infer,accuracy (Rank),anli_r3,47.16666793823242,1112000
2275,xxl-lm-d4-all-091621,_claim_true_false_inconclusive,accuracy (Rank),anli_r3,48.25,1112000
2276,xxl-lm-d4-all-091621,_consider_always_sometimes_never,accuracy (Rank),anli_r3,37.91666793823242,1112000
2277,xxl-lm-d4-all-091621,_does_it_follow_that,accuracy (Rank),anli_r3,45.33333206176758,1112000
2278,xxl-lm-d4-all-091621,_does_this_imply,accuracy (Rank),anli_r3,46.41666793823242,1112000
2279,xxl-lm-d4-all-091621,_guaranteed_possible_impossible,accuracy (Rank),anli_r3,33.75,1112000
2280,xxl-lm-d4-all-091621,_guaranteed_true,accuracy (Rank),anli_r3,44.41666793823242,1112000
2281,xxl-lm-d4-all-091621,_justified_in_saying,accuracy (Rank),anli_r3,46.16666793823242,1112000
2282,xxl-lm-d4-all-091621,_must_be_true,accuracy (Rank),anli_r3,48.25,1112000
2283,xxl-lm-d4-all-091621,_should_assume,accuracy (Rank),anli_r3,47.41666793823242,1112000
2284,xxl-lm-d4-all-091621,_take_the_following_as_truth,accuracy (Rank),anli_r3,47.91666793823242,1112000
2285,xxl-lm-d4-og-091621,_GPT_3_style,accuracy (Rank),anli_r3,34.16666793823242,1112000
2286,xxl-lm-d4-og-091621,_MNLI_crowdsource,accuracy (Rank),anli_r3,40.66666793823242,1112000
2287,xxl-lm-d4-og-091621,_always_sometimes_never,accuracy (Rank),anli_r3,35.25,1112000
2288,xxl-lm-d4-og-091621,_based_on_the_previous_passage,accuracy (Rank),anli_r3,41.41666793823242,1112000
2289,xxl-lm-d4-og-091621,_can_we_infer,accuracy (Rank),anli_r3,39.83333206176758,1112000
2290,xxl-lm-d4-og-091621,_claim_true_false_inconclusive,accuracy (Rank),anli_r3,34.83333206176758,1112000
2291,xxl-lm-d4-og-091621,_consider_always_sometimes_never,accuracy (Rank),anli_r3,36.66666793823242,1112000
2292,xxl-lm-d4-og-091621,_does_it_follow_that,accuracy (Rank),anli_r3,38.83333206176758,1112000
2293,xxl-lm-d4-og-091621,_does_this_imply,accuracy (Rank),anli_r3,41.83333206176758,1112000
2294,xxl-lm-d4-og-091621,_guaranteed_possible_impossible,accuracy (Rank),anli_r3,33.41666793823242,1112000
2295,xxl-lm-d4-og-091621,_guaranteed_true,accuracy (Rank),anli_r3,39.33333206176758,1112000
2296,xxl-lm-d4-og-091621,_justified_in_saying,accuracy (Rank),anli_r3,40.0,1112000
2297,xxl-lm-d4-og-091621,_must_be_true,accuracy (Rank),anli_r3,40.5,1112000
2298,xxl-lm-d4-og-091621,_should_assume,accuracy (Rank),anli_r3,39.83333206176758,1112000
2299,xxl-lm-d4-og-091621,_take_the_following_as_truth,accuracy (Rank),anli_r3,34.75,1112000
2300,xxl-lm-d4-all-og-091621,_GPT_3_style,accuracy (Rank),anli_r3,43.0,1112000
2301,xxl-lm-d4-all-og-091621,_MNLI_crowdsource,accuracy (Rank),anli_r3,36.41666793823242,1112000
2302,xxl-lm-d4-all-og-091621,_always_sometimes_never,accuracy (Rank),anli_r3,35.75,1112000
2303,xxl-lm-d4-all-og-091621,_based_on_the_previous_passage,accuracy (Rank),anli_r3,40.91666793823242,1112000
2304,xxl-lm-d4-all-og-091621,_can_we_infer,accuracy (Rank),anli_r3,38.75,1112000
2305,xxl-lm-d4-all-og-091621,_claim_true_false_inconclusive,accuracy (Rank),anli_r3,41.5,1112000
2306,xxl-lm-d4-all-og-091621,_consider_always_sometimes_never,accuracy (Rank),anli_r3,34.33333206176758,1112000
2307,xxl-lm-d4-all-og-091621,_does_it_follow_that,accuracy (Rank),anli_r3,38.08333206176758,1112000
2308,xxl-lm-d4-all-og-091621,_does_this_imply,accuracy (Rank),anli_r3,39.58333206176758,1112000
2309,xxl-lm-d4-all-og-091621,_guaranteed_possible_impossible,accuracy (Rank),anli_r3,33.5,1112000
2310,xxl-lm-d4-all-og-091621,_guaranteed_true,accuracy (Rank),anli_r3,37.5,1112000
2311,xxl-lm-d4-all-og-091621,_justified_in_saying,accuracy (Rank),anli_r3,37.08333206176758,1112000
2312,xxl-lm-d4-all-og-091621,_must_be_true,accuracy (Rank),anli_r3,38.58333206176758,1112000
2313,xxl-lm-d4-all-og-091621,_should_assume,accuracy (Rank),anli_r3,39.08333206176758,1112000
2314,xxl-lm-d4-all-og-091621,_take_the_following_as_truth,accuracy (Rank),anli_r3,40.83333206176758,1112000
2315,xxl-lm-d4-091621,_GPT_3_style,accuracy (Rank),anli_r3,34.91666793823242,1100000
2316,xxl-lm-d4-091621,_MNLI_crowdsource,accuracy (Rank),anli_r3,33.91666793823242,1100000
2317,xxl-lm-d4-091621,_always_sometimes_never,accuracy (Rank),anli_r3,32.33333206176758,1100000
2318,xxl-lm-d4-091621,_based_on_the_previous_passage,accuracy (Rank),anli_r3,32.91666793823242,1100000
2319,xxl-lm-d4-091621,_can_we_infer,accuracy (Rank),anli_r3,33.25,1100000
2320,xxl-lm-d4-091621,_claim_true_false_inconclusive,accuracy (Rank),anli_r3,33.25,1100000
2321,xxl-lm-d4-091621,_consider_always_sometimes_never,accuracy (Rank),anli_r3,33.25,1100000
2322,xxl-lm-d4-091621,_does_it_follow_that,accuracy (Rank),anli_r3,35.58333206176758,1100000
2323,xxl-lm-d4-091621,_does_this_imply,accuracy (Rank),anli_r3,34.5,1100000
2324,xxl-lm-d4-091621,_guaranteed_possible_impossible,accuracy (Rank),anli_r3,33.83333206176758,1100000
2325,xxl-lm-d4-091621,_guaranteed_true,accuracy (Rank),anli_r3,32.75,1100000
2326,xxl-lm-d4-091621,_justified_in_saying,accuracy (Rank),anli_r3,34.08333206176758,1100000
2327,xxl-lm-d4-091621,_must_be_true,accuracy (Rank),anli_r3,33.41666793823242,1100000
2328,xxl-lm-d4-091621,_should_assume,accuracy (Rank),anli_r3,33.75,1100000
2329,xxl-lm-d4-091621,_take_the_following_as_truth,accuracy (Rank),anli_r3,35.5,1100000
2330,xl-lm-d4-091621,_GPT_3_style,accuracy (Rank),anli_r3,33.33333206176758,1112000
2331,xl-lm-d4-091621,_MNLI_crowdsource,accuracy (Rank),anli_r3,33.75,1112000
2332,xl-lm-d4-091621,_always_sometimes_never,accuracy (Rank),anli_r3,33.41666793823242,1112000
2333,xl-lm-d4-091621,_based_on_the_previous_passage,accuracy (Rank),anli_r3,33.33333206176758,1112000
2334,xl-lm-d4-091621,_can_we_infer,accuracy (Rank),anli_r3,33.0,1112000
2335,xl-lm-d4-091621,_claim_true_false_inconclusive,accuracy (Rank),anli_r3,32.83333206176758,1112000
2336,xl-lm-d4-091621,_consider_always_sometimes_never,accuracy (Rank),anli_r3,33.08333206176758,1112000
2337,xl-lm-d4-091621,_does_it_follow_that,accuracy (Rank),anli_r3,34.08333206176758,1112000
2338,xl-lm-d4-091621,_does_this_imply,accuracy (Rank),anli_r3,32.91666793823242,1112000
2339,xl-lm-d4-091621,_guaranteed_possible_impossible,accuracy (Rank),anli_r3,33.5,1112000
2340,xl-lm-d4-091621,_guaranteed_true,accuracy (Rank),anli_r3,32.58333206176758,1112000
2341,xl-lm-d4-091621,_justified_in_saying,accuracy (Rank),anli_r3,33.58333206176758,1112000
2342,xl-lm-d4-091621,_must_be_true,accuracy (Rank),anli_r3,33.83333206176758,1112000
2343,xl-lm-d4-091621,_should_assume,accuracy (Rank),anli_r3,33.25,1112000
2344,xl-lm-d4-091621,_take_the_following_as_truth,accuracy (Rank),anli_r3,33.41666793823242,1112000
2510,xxl-lm-d4-091621-512,_GPT_3_style,accuracy (Rank),hans,70.52666473388672,1112200
2511,xxl-lm-d4-091621-512,_MNLI_crowdsource,accuracy (Rank),hans,68.90666961669922,1112200
2512,xxl-lm-d4-091621-512,_based_on_the_previous_passage,accuracy (Rank),hans,71.24333190917969,1112200
2513,xxl-lm-d4-091621-512,_can_we_infer,accuracy (Rank),hans,70.77666473388672,1112200
2514,xxl-lm-d4-091621-512,_does_it_follow_that,accuracy (Rank),hans,69.84333038330078,1112200
2515,xxl-lm-d4-091621-512,_does_this_imply,accuracy (Rank),hans,72.74333190917969,1112200
2516,xxl-lm-d4-091621-512,_guaranteed_true,accuracy (Rank),hans,69.44666290283203,1112200
2517,xxl-lm-d4-091621-512,_justified_in_saying,accuracy (Rank),hans,71.51333618164062,1112200
2518,xxl-lm-d4-091621-512,_must_be_true,accuracy (Rank),hans,71.60333251953125,1112200
2519,xxl-lm-d4-091621-512,_should_assume,accuracy (Rank),hans,70.88333129882812,1112200
2520,xxl-lm-d4-gpt-091621,_GPT_3_style,accuracy (Rank),hans,73.24666595458984,1112200
2521,xxl-lm-d4-gpt-091621,_MNLI_crowdsource,accuracy (Rank),hans,72.4000015258789,1112200
2522,xxl-lm-d4-gpt-091621,_based_on_the_previous_passage,accuracy (Rank),hans,72.26333618164062,1112200
2523,xxl-lm-d4-gpt-091621,_can_we_infer,accuracy (Rank),hans,69.32333374023439,1112200
2524,xxl-lm-d4-gpt-091621,_does_it_follow_that,accuracy (Rank),hans,60.45000076293945,1112200
2525,xxl-lm-d4-gpt-091621,_does_this_imply,accuracy (Rank),hans,69.17666625976561,1112200
2526,xxl-lm-d4-gpt-091621,_guaranteed_true,accuracy (Rank),hans,72.58999633789062,1112200
2527,xxl-lm-d4-gpt-091621,_justified_in_saying,accuracy (Rank),hans,71.50666809082031,1112200
2528,xxl-lm-d4-gpt-091621,_must_be_true,accuracy (Rank),hans,70.60333251953125,1112200
2529,xxl-lm-d4-gpt-091621,_should_assume,accuracy (Rank),hans,70.38999938964844,1112200
2530,xxl-lm-d4-all-091621,_GPT_3_style,accuracy (Rank),hans,73.586669921875,1112000
2531,xxl-lm-d4-all-091621,_MNLI_crowdsource,accuracy (Rank),hans,72.09666442871094,1112000
2532,xxl-lm-d4-all-091621,_based_on_the_previous_passage,accuracy (Rank),hans,74.5,1112000
2533,xxl-lm-d4-all-091621,_can_we_infer,accuracy (Rank),hans,71.55000305175781,1112000
2534,xxl-lm-d4-all-091621,_does_it_follow_that,accuracy (Rank),hans,65.66999816894531,1112000
2535,xxl-lm-d4-all-091621,_does_this_imply,accuracy (Rank),hans,75.38666534423828,1112000
2536,xxl-lm-d4-all-091621,_guaranteed_true,accuracy (Rank),hans,72.76000213623047,1112000
2537,xxl-lm-d4-all-091621,_justified_in_saying,accuracy (Rank),hans,75.3066635131836,1112000
2538,xxl-lm-d4-all-091621,_must_be_true,accuracy (Rank),hans,71.3566665649414,1112000
2539,xxl-lm-d4-all-091621,_should_assume,accuracy (Rank),hans,71.47333526611328,1112000
2540,xxl-lm-d4-og-091621,_GPT_3_style,accuracy (Rank),hans,52.31666564941406,1112000
2541,xxl-lm-d4-og-091621,_MNLI_crowdsource,accuracy (Rank),hans,72.22333526611328,1112000
2542,xxl-lm-d4-og-091621,_based_on_the_previous_passage,accuracy (Rank),hans,72.44000244140625,1112000
2543,xxl-lm-d4-og-091621,_can_we_infer,accuracy (Rank),hans,65.51999664306639,1112000
2544,xxl-lm-d4-og-091621,_does_it_follow_that,accuracy (Rank),hans,65.73000335693361,1112000
2545,xxl-lm-d4-og-091621,_does_this_imply,accuracy (Rank),hans,71.73332977294922,1112000
2546,xxl-lm-d4-og-091621,_guaranteed_true,accuracy (Rank),hans,67.92666625976561,1112000
2547,xxl-lm-d4-og-091621,_justified_in_saying,accuracy (Rank),hans,71.92666625976562,1112000
2548,xxl-lm-d4-og-091621,_must_be_true,accuracy (Rank),hans,67.42333221435547,1112000
2549,xxl-lm-d4-og-091621,_should_assume,accuracy (Rank),hans,64.37999725341797,1112000
2550,xxl-lm-d4-all-og-091621,_GPT_3_style,accuracy (Rank),hans,67.86000061035156,1112000
2551,xxl-lm-d4-all-og-091621,_MNLI_crowdsource,accuracy (Rank),hans,71.93333435058594,1112000
2552,xxl-lm-d4-all-og-091621,_based_on_the_previous_passage,accuracy (Rank),hans,70.2933349609375,1112000
2553,xxl-lm-d4-all-og-091621,_can_we_infer,accuracy (Rank),hans,66.69999694824219,1112000
2554,xxl-lm-d4-all-og-091621,_does_it_follow_that,accuracy (Rank),hans,62.36000061035156,1112000
2555,xxl-lm-d4-all-og-091621,_does_this_imply,accuracy (Rank),hans,72.43000030517578,1112000
2556,xxl-lm-d4-all-og-091621,_guaranteed_true,accuracy (Rank),hans,69.43333435058594,1112000
2557,xxl-lm-d4-all-og-091621,_justified_in_saying,accuracy (Rank),hans,71.8066635131836,1112000
2558,xxl-lm-d4-all-og-091621,_must_be_true,accuracy (Rank),hans,69.52666473388672,1112000
2559,xxl-lm-d4-all-og-091621,_should_assume,accuracy (Rank),hans,68.68333435058594,1112000
2560,xxl-lm-d4-091621,_GPT_3_style,accuracy (Rank),hans,51.22333145141602,1100000
2561,xxl-lm-d4-091621,_MNLI_crowdsource,accuracy (Rank),hans,50.01333236694336,1100000
2562,xxl-lm-d4-091621,_based_on_the_previous_passage,accuracy (Rank),hans,50.563331604003906,1100000
2563,xxl-lm-d4-091621,_can_we_infer,accuracy (Rank),hans,53.13999938964844,1100000
2564,xxl-lm-d4-091621,_does_it_follow_that,accuracy (Rank),hans,50.40999984741211,1100000
2565,xxl-lm-d4-091621,_does_this_imply,accuracy (Rank),hans,49.8033332824707,1100000
2566,xxl-lm-d4-091621,_guaranteed_true,accuracy (Rank),hans,51.63000106811523,1100000
2567,xxl-lm-d4-091621,_justified_in_saying,accuracy (Rank),hans,50.33666610717773,1100000
2568,xxl-lm-d4-091621,_must_be_true,accuracy (Rank),hans,51.6533317565918,1100000
2569,xxl-lm-d4-091621,_should_assume,accuracy (Rank),hans,50.84000015258789,1100000
2570,xl-lm-d4-091621,_GPT_3_style,accuracy (Rank),hans,65.81666564941406,1112000
2571,xl-lm-d4-091621,_MNLI_crowdsource,accuracy (Rank),hans,63.93000030517578,1112000
2572,xl-lm-d4-091621,_based_on_the_previous_passage,accuracy (Rank),hans,65.86333465576172,1112000
2573,xl-lm-d4-091621,_can_we_infer,accuracy (Rank),hans,63.1533317565918,1112000
2574,xl-lm-d4-091621,_does_it_follow_that,accuracy (Rank),hans,55.65999984741211,1112000
2575,xl-lm-d4-091621,_does_this_imply,accuracy (Rank),hans,60.7066650390625,1112000
2576,xl-lm-d4-091621,_guaranteed_true,accuracy (Rank),hans,64.06333160400389,1112000
2577,xl-lm-d4-091621,_justified_in_saying,accuracy (Rank),hans,63.68333435058594,1112000
2578,xl-lm-d4-091621,_must_be_true,accuracy (Rank),hans,65.84333038330078,1112000
2579,xl-lm-d4-091621,_should_assume,accuracy (Rank),hans,64.01333618164061,1112000
2820,xxl-lm-d4-091621-512,_equivalent,accuracy (Rank),glue_mrpc,75.2450942993164,1112200
2821,xxl-lm-d4-091621-512,_paraphrase,accuracy (Rank),glue_mrpc,76.71568298339844,1112200
2822,xxl-lm-d4-091621-512,_replace,accuracy (Rank),glue_mrpc,78.4313735961914,1112200
2823,xxl-lm-d4-091621-512,_same_thing,accuracy (Rank),glue_mrpc,79.16666412353516,1112200
2824,xxl-lm-d4-091621-512,_want_to_know,accuracy (Rank),glue_mrpc,77.94117736816406,1112200
2825,xxl-lm-d4-gpt-091621,_equivalent,accuracy (Rank),glue_mrpc,70.3431396484375,1112200
2826,xxl-lm-d4-gpt-091621,_paraphrase,accuracy (Rank),glue_mrpc,78.18627166748047,1112200
2827,xxl-lm-d4-gpt-091621,_replace,accuracy (Rank),glue_mrpc,80.14705657958984,1112200
2828,xxl-lm-d4-gpt-091621,_same_thing,accuracy (Rank),glue_mrpc,78.67646789550781,1112200
2829,xxl-lm-d4-gpt-091621,_want_to_know,accuracy (Rank),glue_mrpc,79.90196228027344,1112200
2830,xxl-lm-d4-all-091621,_equivalent,accuracy (Rank),glue_mrpc,70.09803771972656,1112000
2831,xxl-lm-d4-all-091621,_paraphrase,accuracy (Rank),glue_mrpc,79.16666412353516,1112000
2832,xxl-lm-d4-all-091621,_replace,accuracy (Rank),glue_mrpc,81.37255096435547,1112000
2833,xxl-lm-d4-all-091621,_same_thing,accuracy (Rank),glue_mrpc,76.96078491210938,1112000
2834,xxl-lm-d4-all-091621,_want_to_know,accuracy (Rank),glue_mrpc,79.4117660522461,1112000
2835,xxl-lm-d4-og-091621,_equivalent,accuracy (Rank),glue_mrpc,78.4313735961914,1112000
2836,xxl-lm-d4-og-091621,_paraphrase,accuracy (Rank),glue_mrpc,68.87255096435547,1112000
2837,xxl-lm-d4-og-091621,_replace,accuracy (Rank),glue_mrpc,70.5882339477539,1112000
2838,xxl-lm-d4-og-091621,_same_thing,accuracy (Rank),glue_mrpc,73.52941131591797,1112000
2839,xxl-lm-d4-og-091621,_want_to_know,accuracy (Rank),glue_mrpc,75.98039245605469,1112000
2840,xxl-lm-d4-all-og-091621,_equivalent,accuracy (Rank),glue_mrpc,73.28431701660156,1112000
2841,xxl-lm-d4-all-og-091621,_paraphrase,accuracy (Rank),glue_mrpc,75.0,1112000
2842,xxl-lm-d4-all-og-091621,_replace,accuracy (Rank),glue_mrpc,75.98039245605469,1112000
2843,xxl-lm-d4-all-og-091621,_same_thing,accuracy (Rank),glue_mrpc,74.50980377197266,1112000
2844,xxl-lm-d4-all-og-091621,_want_to_know,accuracy (Rank),glue_mrpc,74.7549057006836,1112000
2845,xxl-lm-d4-091621,_equivalent,accuracy (Rank),glue_mrpc,47.05882263183594,1100000
2846,xxl-lm-d4-091621,_paraphrase,accuracy (Rank),glue_mrpc,33.33333206176758,1100000
2847,xxl-lm-d4-091621,_replace,accuracy (Rank),glue_mrpc,31.61764717102051,1100000
2848,xxl-lm-d4-091621,_same_thing,accuracy (Rank),glue_mrpc,31.37254905700684,1100000
2849,xxl-lm-d4-091621,_want_to_know,accuracy (Rank),glue_mrpc,33.33333206176758,1100000
2850,xl-lm-d4-091621,_equivalent,accuracy (Rank),glue_mrpc,70.09803771972656,1112000
2851,xl-lm-d4-091621,_paraphrase,accuracy (Rank),glue_mrpc,75.2450942993164,1112000
2852,xl-lm-d4-091621,_replace,accuracy (Rank),glue_mrpc,,1112000
2853,xl-lm-d4-091621,_same_thing,accuracy (Rank),glue_mrpc,75.0,1112000
2854,xl-lm-d4-091621,_want_to_know,accuracy (Rank),glue_mrpc,74.01960754394531,1112000
3021,xxl-lm-d4-091621-512,_answer,accuracy (Rank),glue_qqp,82.55999755859375,1112200
3022,xxl-lm-d4-091621-512,_duplicate,accuracy (Rank),glue_qqp,89.6809310913086,1112200
3023,xxl-lm-d4-091621-512,_duplicate_or_not,accuracy (Rank),glue_qqp,88.69898223876953,1112200
3024,xxl-lm-d4-091621-512,_meaning,accuracy (Rank),glue_qqp,36.866188049316406,1112200
3025,xxl-lm-d4-091621-512,_quora,accuracy (Rank),glue_qqp,89.74276733398438,1112200
3026,xxl-lm-d4-091621-512,_same_thing,accuracy (Rank),glue_qqp,89.54489135742188,1112200
3027,xxl-lm-d4-gpt-091621,_duplicate,accuracy (Rank),glue_qqp,89.33712768554688,1112200
3028,xxl-lm-d4-gpt-091621,_duplicate_or_not,accuracy (Rank),glue_qqp,88.67425537109375,1112200
3029,xxl-lm-d4-gpt-091621,_meaning,accuracy (Rank),glue_qqp,36.83650588989258,1112200
3030,xxl-lm-d4-gpt-091621,_quora,accuracy (Rank),glue_qqp,89.51521301269531,1112200
3031,xxl-lm-d4-gpt-091621,_same_thing,accuracy (Rank),glue_qqp,89.23076629638672,1112200
3032,xxl-lm-d4-all-091621,_duplicate,accuracy (Rank),glue_qqp,89.23324584960938,1112000
3033,xxl-lm-d4-all-091621,_duplicate_or_not,accuracy (Rank),glue_qqp,88.75834655761719,1112000
3034,xxl-lm-d4-all-091621,_meaning,accuracy (Rank),glue_qqp,36.82908630371094,1112000
3035,xxl-lm-d4-all-091621,_quora,accuracy (Rank),glue_qqp,89.3222885131836,1112000
3036,xxl-lm-d4-all-091621,_same_thing,accuracy (Rank),glue_qqp,89.01063537597656,1112000
3037,xxl-lm-d4-og-091621,_duplicate,accuracy (Rank),glue_qqp,90.24981689453124,1112000
3038,xxl-lm-d4-og-091621,_duplicate_or_not,accuracy (Rank),glue_qqp,63.16843795776367,1112000
3039,xxl-lm-d4-og-091621,_meaning,accuracy (Rank),glue_qqp,82.83452606201172,1112000
3040,xxl-lm-d4-og-091621,_quora,accuracy (Rank),glue_qqp,88.61736297607422,1112000
3041,xxl-lm-d4-og-091621,_same_thing,accuracy (Rank),glue_qqp,89.47563934326172,1112000
3042,xxl-lm-d4-all-og-091621,_duplicate,accuracy (Rank),glue_qqp,88.9908447265625,1112000
3043,xxl-lm-d4-all-og-091621,_duplicate_or_not,accuracy (Rank),glue_qqp,89.0205307006836,1112000
3044,xxl-lm-d4-all-og-091621,_meaning,accuracy (Rank),glue_qqp,66.73014831542969,1112000
3045,xxl-lm-d4-all-og-091621,_quora,accuracy (Rank),glue_qqp,88.77566528320312,1112000
3046,xxl-lm-d4-all-og-091621,_same_thing,accuracy (Rank),glue_qqp,89.09473419189453,1112000
3047,xxl-lm-d4-091621,_duplicate,accuracy (Rank),glue_qqp,59.25055694580078,1100000
3048,xxl-lm-d4-091621,_duplicate_or_not,accuracy (Rank),glue_qqp,46.7623062133789,1100000
3049,xxl-lm-d4-091621,_meaning,accuracy (Rank),glue_qqp,55.77046585083008,1100000
3050,xxl-lm-d4-091621,_quora,accuracy (Rank),glue_qqp,51.93915557861328,1100000
3051,xxl-lm-d4-091621,_same_thing,accuracy (Rank),glue_qqp,60.6406135559082,1100000
3052,xl-lm-d4-091621,_duplicate,accuracy (Rank),glue_qqp,85.35740661621094,1112000
3053,xl-lm-d4-091621,_duplicate_or_not,accuracy (Rank),glue_qqp,84.53128814697266,1112000
3054,xl-lm-d4-091621,_meaning,accuracy (Rank),glue_qqp,79.62403869628906,1112000
3055,xl-lm-d4-091621,_quora,accuracy (Rank),glue_qqp,87.25203704833984,1112000
3056,xl-lm-d4-091621,_same_thing,accuracy (Rank),glue_qqp,85.4167709350586,1112000
3226,xxl-lm-d4-091621-512,_heres_a_problem,accuracy (Rank),ai2_arc_ARC_Challenge,,1112200
3227,xxl-lm-d4-091621-512,_i_am_hesitating,accuracy (Rank),ai2_arc_ARC_Challenge,59.8662223815918,1112200
3228,xxl-lm-d4-091621-512,_multiple_choice,accuracy (Rank),ai2_arc_ARC_Challenge,58.1939811706543,1112200
3229,xxl-lm-d4-091621-512,_pick_the_most_correct_option,accuracy (Rank),ai2_arc_ARC_Challenge,53.846153259277344,1112200
3230,xxl-lm-d4-091621-512,_qa_options,accuracy (Rank),ai2_arc_ARC_Challenge,,1112200
3231,xxl-lm-d4-gpt-091621,_heres_a_problem,accuracy (Rank),ai2_arc_ARC_Challenge,64.54849243164061,1112200
3232,xxl-lm-d4-gpt-091621,_i_am_hesitating,accuracy (Rank),ai2_arc_ARC_Challenge,66.88963317871094,1112200
3233,xxl-lm-d4-gpt-091621,_multiple_choice,accuracy (Rank),ai2_arc_ARC_Challenge,68.22742462158203,1112200
3234,xxl-lm-d4-gpt-091621,_pick_the_most_correct_option,accuracy (Rank),ai2_arc_ARC_Challenge,65.21739196777344,1112200
3235,xxl-lm-d4-gpt-091621,_qa_options,accuracy (Rank),ai2_arc_ARC_Challenge,69.89966583251953,1112200
3236,xxl-lm-d4-all-091621,_heres_a_problem,accuracy (Rank),ai2_arc_ARC_Challenge,66.88963317871094,1112000
3237,xxl-lm-d4-all-091621,_i_am_hesitating,accuracy (Rank),ai2_arc_ARC_Challenge,68.22742462158203,1112000
3238,xxl-lm-d4-all-091621,_multiple_choice,accuracy (Rank),ai2_arc_ARC_Challenge,67.55852508544922,1112000
3239,xxl-lm-d4-all-091621,_pick_the_most_correct_option,accuracy (Rank),ai2_arc_ARC_Challenge,64.88294219970703,1112000
3240,xxl-lm-d4-all-091621,_qa_options,accuracy (Rank),ai2_arc_ARC_Challenge,67.55852508544922,1112000
3241,xxl-lm-d4-og-091621,_heres_a_problem,accuracy (Rank),ai2_arc_ARC_Challenge,59.53177261352539,1112000
3242,xxl-lm-d4-og-091621,_i_am_hesitating,accuracy (Rank),ai2_arc_ARC_Challenge,58.862876892089844,1112000
3243,xxl-lm-d4-og-091621,_multiple_choice,accuracy (Rank),ai2_arc_ARC_Challenge,57.85953140258789,1112000
3244,xxl-lm-d4-og-091621,_pick_the_most_correct_option,accuracy (Rank),ai2_arc_ARC_Challenge,57.85953140258789,1112000
3245,xxl-lm-d4-og-091621,_qa_options,accuracy (Rank),ai2_arc_ARC_Challenge,58.52842712402344,1112000
3246,xxl-lm-d4-all-og-091621,_heres_a_problem,accuracy (Rank),ai2_arc_ARC_Challenge,58.862876892089844,1112000
3247,xxl-lm-d4-all-og-091621,_i_am_hesitating,accuracy (Rank),ai2_arc_ARC_Challenge,57.190635681152344,1112000
3248,xxl-lm-d4-all-og-091621,_multiple_choice,accuracy (Rank),ai2_arc_ARC_Challenge,57.85953140258789,1112000
3249,xxl-lm-d4-all-og-091621,_pick_the_most_correct_option,accuracy (Rank),ai2_arc_ARC_Challenge,59.19732284545898,1112000
3250,xxl-lm-d4-all-og-091621,_qa_options,accuracy (Rank),ai2_arc_ARC_Challenge,58.1939811706543,1112000
3251,xxl-lm-d4-091621,_heres_a_problem,accuracy (Rank),ai2_arc_ARC_Challenge,22.40802764892578,1100000
3252,xxl-lm-d4-091621,_i_am_hesitating,accuracy (Rank),ai2_arc_ARC_Challenge,26.42140388488769,1100000
3253,xxl-lm-d4-091621,_multiple_choice,accuracy (Rank),ai2_arc_ARC_Challenge,26.7558536529541,1100000
3254,xxl-lm-d4-091621,_pick_the_most_correct_option,accuracy (Rank),ai2_arc_ARC_Challenge,21.07023429870605,1100000
3255,xxl-lm-d4-091621,_qa_options,accuracy (Rank),ai2_arc_ARC_Challenge,31.103679656982425,1100000
3256,xl-lm-d4-091621,_heres_a_problem,accuracy (Rank),ai2_arc_ARC_Challenge,39.464881896972656,1112000
3257,xl-lm-d4-091621,_i_am_hesitating,accuracy (Rank),ai2_arc_ARC_Challenge,41.137123107910156,1112000
3258,xl-lm-d4-091621,_multiple_choice,accuracy (Rank),ai2_arc_ARC_Challenge,33.110366821289055,1112000
3259,xl-lm-d4-091621,_pick_the_most_correct_option,accuracy (Rank),ai2_arc_ARC_Challenge,39.13043594360352,1112000
3260,xl-lm-d4-091621,_qa_options,accuracy (Rank),ai2_arc_ARC_Challenge,37.12374496459961,1112000
3326,xxl-lm-d4-091621-512,_heres_a_problem,accuracy (Rank),ai2_arc_ARC_Easy,74.03508758544922,1112200
3327,xxl-lm-d4-091621-512,_i_am_hesitating,accuracy (Rank),ai2_arc_ARC_Easy,76.31578826904297,1112200
3328,xxl-lm-d4-091621-512,_multiple_choice,accuracy (Rank),ai2_arc_ARC_Easy,75.08772277832031,1112200
3329,xxl-lm-d4-091621-512,_pick_the_most_correct_option,accuracy (Rank),ai2_arc_ARC_Easy,74.3859634399414,1112200
3330,xxl-lm-d4-091621-512,_qa_options,accuracy (Rank),ai2_arc_ARC_Easy,78.24561309814453,1112200
3331,xxl-lm-d4-gpt-091621,_heres_a_problem,accuracy (Rank),ai2_arc_ARC_Easy,79.8245620727539,1112200
3332,xxl-lm-d4-gpt-091621,_i_am_hesitating,accuracy (Rank),ai2_arc_ARC_Easy,80.52631378173828,1112200
3333,xxl-lm-d4-gpt-091621,_multiple_choice,accuracy (Rank),ai2_arc_ARC_Easy,81.40351104736328,1112200
3334,xxl-lm-d4-gpt-091621,_pick_the_most_correct_option,accuracy (Rank),ai2_arc_ARC_Easy,79.8245620727539,1112200
3335,xxl-lm-d4-gpt-091621,_qa_options,accuracy (Rank),ai2_arc_ARC_Easy,81.0526351928711,1112200
3336,xxl-lm-d4-all-091621,_heres_a_problem,accuracy (Rank),ai2_arc_ARC_Easy,79.8245620727539,1112000
3337,xxl-lm-d4-all-091621,_i_am_hesitating,accuracy (Rank),ai2_arc_ARC_Easy,81.40351104736328,1112000
3338,xxl-lm-d4-all-091621,_multiple_choice,accuracy (Rank),ai2_arc_ARC_Easy,81.92982482910156,1112000
3339,xxl-lm-d4-all-091621,_pick_the_most_correct_option,accuracy (Rank),ai2_arc_ARC_Easy,80.70175170898438,1112000
3340,xxl-lm-d4-all-091621,_qa_options,accuracy (Rank),ai2_arc_ARC_Easy,83.33333587646484,1112000
3341,xxl-lm-d4-og-091621,_heres_a_problem,accuracy (Rank),ai2_arc_ARC_Easy,76.66666412353516,1112000
3342,xxl-lm-d4-og-091621,_i_am_hesitating,accuracy (Rank),ai2_arc_ARC_Easy,75.08772277832031,1112000
3343,xxl-lm-d4-og-091621,_multiple_choice,accuracy (Rank),ai2_arc_ARC_Easy,73.68421173095703,1112000
3344,xxl-lm-d4-og-091621,_pick_the_most_correct_option,accuracy (Rank),ai2_arc_ARC_Easy,77.89473724365234,1112000
3345,xxl-lm-d4-og-091621,_qa_options,accuracy (Rank),ai2_arc_ARC_Easy,75.78947448730469,1112000
3346,xxl-lm-d4-all-og-091621,_heres_a_problem,accuracy (Rank),ai2_arc_ARC_Easy,74.7368392944336,1112000
3347,xxl-lm-d4-all-og-091621,_i_am_hesitating,accuracy (Rank),ai2_arc_ARC_Easy,77.89473724365234,1112000
3348,xxl-lm-d4-all-og-091621,_multiple_choice,accuracy (Rank),ai2_arc_ARC_Easy,77.89473724365234,1112000
3349,xxl-lm-d4-all-og-091621,_pick_the_most_correct_option,accuracy (Rank),ai2_arc_ARC_Easy,76.14035034179688,1112000
3350,xxl-lm-d4-all-og-091621,_qa_options,accuracy (Rank),ai2_arc_ARC_Easy,80.0,1112000
3351,xxl-lm-d4-091621,_heres_a_problem,accuracy (Rank),ai2_arc_ARC_Easy,26.140350341796875,1100000
3352,xxl-lm-d4-091621,_i_am_hesitating,accuracy (Rank),ai2_arc_ARC_Easy,45.96491241455078,1100000
3353,xxl-lm-d4-091621,_multiple_choice,accuracy (Rank),ai2_arc_ARC_Easy,40.0,1100000
3354,xxl-lm-d4-091621,_pick_the_most_correct_option,accuracy (Rank),ai2_arc_ARC_Easy,25.96491241455078,1100000
3355,xxl-lm-d4-091621,_qa_options,accuracy (Rank),ai2_arc_ARC_Easy,45.96491241455078,1100000
3356,xl-lm-d4-091621,_heres_a_problem,accuracy (Rank),ai2_arc_ARC_Easy,60.0,1112000
3357,xl-lm-d4-091621,_i_am_hesitating,accuracy (Rank),ai2_arc_ARC_Easy,59.12280654907226,1112000
3358,xl-lm-d4-091621,_multiple_choice,accuracy (Rank),ai2_arc_ARC_Easy,47.1929817199707,1112000
3359,xl-lm-d4-091621,_pick_the_most_correct_option,accuracy (Rank),ai2_arc_ARC_Easy,61.05263137817383,1112000
3360,xl-lm-d4-091621,_qa_options,accuracy (Rank),ai2_arc_ARC_Easy,54.91228103637695,1112000
3520,xxl-lm-d4-091621-512,_Can_you_figure_out_,accuracy (Rank),super_glue_record,19.3700008392334,1112200
3521,xxl-lm-d4-091621-512,_GPT_3_style_continuation_choices_,accuracy (Rank),super_glue_record,59.75,1112200
3522,xxl-lm-d4-091621-512,_GPT_3_style_summary_only_continuation_choices_,accuracy (Rank),super_glue_record,59.43000030517578,1112200
3523,xxl-lm-d4-091621-512,_GPT_3_style_with_labels_continuation_choices_,accuracy (Rank),super_glue_record,59.09000015258789,1112200
3524,xxl-lm-d4-091621-512,_GPT_3_style_with_labels_without_hyphens_continuation_choices_,accuracy (Rank),super_glue_record,56.93999862670898,1112200
3525,xxl-lm-d4-091621-512,_GPT_3_style_without_hyphens_continuation_choices_,accuracy (Rank),super_glue_record,57.59000015258789,1112200
3526,xxl-lm-d4-091621-512,_In_the_question_above_the_placeholder_stands_for,accuracy (Rank),super_glue_record,,1112200
3527,xxl-lm-d4-091621-512,_New_highlight_continuation_choices_,accuracy (Rank),super_glue_record,59.6500015258789,1112200
3528,xxl-lm-d4-091621-512,_News_article_continuation_choices_,accuracy (Rank),super_glue_record,60.06000137329102,1112200
3529,xxl-lm-d4-091621-512,_Summary_first_continuation_choices_,accuracy (Rank),super_glue_record,57.7400016784668,1112200
3530,xxl-lm-d4-091621-512,_What_could_the_placeholder_be_,accuracy (Rank),super_glue_record,,1112200
3531,xxl-lm-d4-091621-512,_Which_one_is_the_placeholder_,accuracy (Rank),super_glue_record,,1112200
3532,xxl-lm-d4-091621-512,_choose_between,accuracy (Rank),super_glue_record,,1112200
3533,xxl-lm-d4-091621-512,_corrupted,accuracy (Rank),super_glue_record,,1112200
3534,xxl-lm-d4-091621-512,_exercise,accuracy (Rank),super_glue_record,,1112200
3535,xxl-lm-d4-091621-512,_pick_one_option,accuracy (Rank),super_glue_record,,1112200
3536,xxl-lm-d4-091621-512,_the_placeholder_refers_to_,accuracy (Rank),super_glue_record,,1112200
3537,xxl-lm-d4-091621-512,_trying_to_decide,accuracy (Rank),super_glue_record,,1112200
3538,xxl-lm-d4-gpt-091621,_Can_you_figure_out_,accuracy (Rank),super_glue_record,21.8700008392334,1112200
3539,xxl-lm-d4-gpt-091621,_In_the_question_above_the_placeholder_stands_for,accuracy (Rank),super_glue_record,33.509998321533196,1112200
3540,xxl-lm-d4-gpt-091621,_What_could_the_placeholder_be_,accuracy (Rank),super_glue_record,17.309999465942386,1112200
3541,xxl-lm-d4-gpt-091621,_Which_one_is_the_placeholder_,accuracy (Rank),super_glue_record,19.770000457763672,1112200
3542,xxl-lm-d4-gpt-091621,_choose_between,accuracy (Rank),super_glue_record,24.75,1112200
3543,xxl-lm-d4-gpt-091621,_corrupted,accuracy (Rank),super_glue_record,,1112200
3544,xxl-lm-d4-gpt-091621,_exercise,accuracy (Rank),super_glue_record,27.020000457763672,1112200
3545,xxl-lm-d4-gpt-091621,_pick_one_option,accuracy (Rank),super_glue_record,,1112200
3546,xxl-lm-d4-gpt-091621,_the_placeholder_refers_to_,accuracy (Rank),super_glue_record,18.239999771118164,1112200
3547,xxl-lm-d4-gpt-091621,_trying_to_decide,accuracy (Rank),super_glue_record,24.670000076293945,1112200
3548,xxl-lm-d4-all-091621,_Can_you_figure_out_,accuracy (Rank),super_glue_record,67.48000335693361,1112000
3549,xxl-lm-d4-all-091621,_In_the_question_above_the_placeholder_stands_for,accuracy (Rank),super_glue_record,66.37999725341797,1112000
3550,xxl-lm-d4-all-091621,_What_could_the_placeholder_be_,accuracy (Rank),super_glue_record,66.69000244140625,1112000
3551,xxl-lm-d4-all-091621,_Which_one_is_the_placeholder_,accuracy (Rank),super_glue_record,67.31999969482422,1112000
3552,xxl-lm-d4-all-091621,_choose_between,accuracy (Rank),super_glue_record,66.97000122070311,1112000
3553,xxl-lm-d4-all-091621,_corrupted,accuracy (Rank),super_glue_record,66.33000183105469,1112000
3554,xxl-lm-d4-all-091621,_exercise,accuracy (Rank),super_glue_record,66.98000335693361,1112000
3555,xxl-lm-d4-all-091621,_pick_one_option,accuracy (Rank),super_glue_record,66.66999816894531,1112000
3556,xxl-lm-d4-all-091621,_the_placeholder_refers_to_,accuracy (Rank),super_glue_record,66.63999938964844,1112000
3557,xxl-lm-d4-all-091621,_trying_to_decide,accuracy (Rank),super_glue_record,,1112000
3558,xxl-lm-d4-og-091621,_Can_you_figure_out_,accuracy (Rank),super_glue_record,18.809999465942386,1112000
3559,xxl-lm-d4-og-091621,_In_the_question_above_the_placeholder_stands_for,accuracy (Rank),super_glue_record,25.54999923706055,1112000
3560,xxl-lm-d4-og-091621,_What_could_the_placeholder_be_,accuracy (Rank),super_glue_record,,1112000
3561,xxl-lm-d4-og-091621,_Which_one_is_the_placeholder_,accuracy (Rank),super_glue_record,13.520000457763672,1112000
3562,xxl-lm-d4-og-091621,_choose_between,accuracy (Rank),super_glue_record,21.1200008392334,1112000
3563,xxl-lm-d4-og-091621,_corrupted,accuracy (Rank),super_glue_record,20.790000915527344,1112000
3564,xxl-lm-d4-og-091621,_exercise,accuracy (Rank),super_glue_record,28.63999938964844,1112000
3565,xxl-lm-d4-og-091621,_pick_one_option,accuracy (Rank),super_glue_record,14.210000038146973,1112000
3566,xxl-lm-d4-og-091621,_the_placeholder_refers_to_,accuracy (Rank),super_glue_record,17.489999771118164,1112000
3567,xxl-lm-d4-og-091621,_trying_to_decide,accuracy (Rank),super_glue_record,18.76000022888184,1112000
3568,xxl-lm-d4-091621,_Can_you_figure_out_,accuracy (Rank),super_glue_record,,1100000
3569,xxl-lm-d4-091621,_In_the_question_above_the_placeholder_stands_for,accuracy (Rank),super_glue_record,,1100000
3570,xxl-lm-d4-091621,_What_could_the_placeholder_be_,accuracy (Rank),super_glue_record,,1100000
3571,xxl-lm-d4-091621,_Which_one_is_the_placeholder_,accuracy (Rank),super_glue_record,,1100000
3572,xxl-lm-d4-091621,_choose_between,accuracy (Rank),super_glue_record,,1100000
3573,xxl-lm-d4-091621,_corrupted,accuracy (Rank),super_glue_record,,1100000
3574,xxl-lm-d4-091621,_exercise,accuracy (Rank),super_glue_record,,1100000
3575,xxl-lm-d4-091621,_pick_one_option,accuracy (Rank),super_glue_record,,1100000
3576,xxl-lm-d4-091621,_the_placeholder_refers_to_,accuracy (Rank),super_glue_record,,1100000
3577,xxl-lm-d4-091621,_trying_to_decide,accuracy (Rank),super_glue_record,,1100000
3578,xl-lm-d4-091621,_Can_you_figure_out_,accuracy (Rank),super_glue_record,19.15999984741211,1112000
3579,xl-lm-d4-091621,_In_the_question_above_the_placeholder_stands_for,accuracy (Rank),super_glue_record,22.540000915527344,1112000
3580,xl-lm-d4-091621,_What_could_the_placeholder_be_,accuracy (Rank),super_glue_record,16.239999771118164,1112000
3581,xl-lm-d4-091621,_Which_one_is_the_placeholder_,accuracy (Rank),super_glue_record,,1112000
3582,xl-lm-d4-091621,_choose_between,accuracy (Rank),super_glue_record,20.31999969482422,1112000
3583,xl-lm-d4-091621,_corrupted,accuracy (Rank),super_glue_record,22.709999084472656,1112000
3584,xl-lm-d4-091621,_exercise,accuracy (Rank),super_glue_record,23.729999542236328,1112000
3585,xl-lm-d4-091621,_pick_one_option,accuracy (Rank),super_glue_record,16.649999618530273,1112000
3586,xl-lm-d4-091621,_the_placeholder_refers_to_,accuracy (Rank),super_glue_record,,1112000
3587,xl-lm-d4-091621,_trying_to_decide,accuracy (Rank),super_glue_record,19.0,1112000
3904,xxl-lm-d4-091621-512,_choices,accuracy (Rank),openbookqa_main,59.4000015258789,1112200
3905,xxl-lm-d4-091621-512,_choose_an_answer_with_options,accuracy (Rank),openbookqa_main,60.599998474121094,1112200
3906,xxl-lm-d4-091621-512,_only_options,accuracy (Rank),openbookqa_main,52.599998474121094,1112200
3907,xxl-lm-d4-091621-512,_pick_answer_with_options,accuracy (Rank),openbookqa_main,60.599998474121094,1112200
3908,xxl-lm-d4-091621-512,_pick_using_id,accuracy (Rank),openbookqa_main,58.599998474121094,1112200
3909,xxl-lm-d4-091621-512,_which_correct,accuracy (Rank),openbookqa_main,60.20000076293945,1112200
3910,xxl-lm-d4-091621-512,_which_correct_inverse,accuracy (Rank),openbookqa_main,61.79999923706055,1112200
3911,xxl-lm-d4-gpt-091621,_choices,accuracy (Rank),openbookqa_main,71.4000015258789,1112200
3912,xxl-lm-d4-gpt-091621,_choose_an_answer_with_options,accuracy (Rank),openbookqa_main,73.80000305175781,1112200
3913,xxl-lm-d4-gpt-091621,_only_options,accuracy (Rank),openbookqa_main,67.80000305175781,1112200
3914,xxl-lm-d4-gpt-091621,_pick_answer_with_options,accuracy (Rank),openbookqa_main,72.5999984741211,1112200
3915,xxl-lm-d4-gpt-091621,_pick_using_id,accuracy (Rank),openbookqa_main,70.4000015258789,1112200
3916,xxl-lm-d4-gpt-091621,_which_correct,accuracy (Rank),openbookqa_main,73.5999984741211,1112200
3917,xxl-lm-d4-gpt-091621,_which_correct_inverse,accuracy (Rank),openbookqa_main,75.5999984741211,1112200
3918,xxl-lm-d4-all-091621,_choices,accuracy (Rank),openbookqa_main,72.19999694824219,1112000
3919,xxl-lm-d4-all-091621,_choose_an_answer_with_options,accuracy (Rank),openbookqa_main,72.19999694824219,1112000
3920,xxl-lm-d4-all-091621,_only_options,accuracy (Rank),openbookqa_main,69.19999694824219,1112000
3921,xxl-lm-d4-all-091621,_pick_answer_with_options,accuracy (Rank),openbookqa_main,73.0,1112000
3922,xxl-lm-d4-all-091621,_pick_using_id,accuracy (Rank),openbookqa_main,71.4000015258789,1112000
3923,xxl-lm-d4-all-091621,_which_correct,accuracy (Rank),openbookqa_main,73.19999694824219,1112000
3924,xxl-lm-d4-all-091621,_which_correct_inverse,accuracy (Rank),openbookqa_main,76.0,1112000
3925,xxl-lm-d4-og-091621,_choices,accuracy (Rank),openbookqa_main,55.4000015258789,1112000
3926,xxl-lm-d4-og-091621,_choose_an_answer_with_options,accuracy (Rank),openbookqa_main,58.20000076293945,1112000
3927,xxl-lm-d4-og-091621,_only_options,accuracy (Rank),openbookqa_main,48.0,1112000
3928,xxl-lm-d4-og-091621,_pick_answer_with_options,accuracy (Rank),openbookqa_main,58.20000076293945,1112000
3929,xxl-lm-d4-og-091621,_pick_using_id,accuracy (Rank),openbookqa_main,55.20000076293945,1112000
3930,xxl-lm-d4-og-091621,_which_correct,accuracy (Rank),openbookqa_main,55.20000076293945,1112000
3931,xxl-lm-d4-og-091621,_which_correct_inverse,accuracy (Rank),openbookqa_main,52.599998474121094,1112000
3932,xxl-lm-d4-all-og-091621,_choices,accuracy (Rank),openbookqa_main,61.0,1112000
3933,xxl-lm-d4-all-og-091621,_choose_an_answer_with_options,accuracy (Rank),openbookqa_main,62.79999923706055,1112000
3934,xxl-lm-d4-all-og-091621,_only_options,accuracy (Rank),openbookqa_main,56.20000076293945,1112000
3935,xxl-lm-d4-all-og-091621,_pick_answer_with_options,accuracy (Rank),openbookqa_main,62.79999923706055,1112000
3936,xxl-lm-d4-all-og-091621,_pick_using_id,accuracy (Rank),openbookqa_main,58.79999923706055,1112000
3937,xxl-lm-d4-all-og-091621,_which_correct,accuracy (Rank),openbookqa_main,62.79999923706055,1112000
3938,xxl-lm-d4-all-og-091621,_which_correct_inverse,accuracy (Rank),openbookqa_main,60.79999923706055,1112000
3939,xxl-lm-d4-091621,_choices,accuracy (Rank),openbookqa_main,27.399999618530273,1100000
3940,xxl-lm-d4-091621,_choose_an_answer_with_options,accuracy (Rank),openbookqa_main,32.200000762939446,1100000
3941,xxl-lm-d4-091621,_only_options,accuracy (Rank),openbookqa_main,32.59999847412109,1100000
3942,xxl-lm-d4-091621,_pick_answer_with_options,accuracy (Rank),openbookqa_main,32.0,1100000
3943,xxl-lm-d4-091621,_pick_using_id,accuracy (Rank),openbookqa_main,25.0,1100000
3944,xxl-lm-d4-091621,_which_correct,accuracy (Rank),openbookqa_main,27.20000076293945,1100000
3945,xxl-lm-d4-091621,_which_correct_inverse,accuracy (Rank),openbookqa_main,29.0,1100000
3946,xl-lm-d4-091621,_choices,accuracy (Rank),openbookqa_main,43.599998474121094,1112000
3947,xl-lm-d4-091621,_choose_an_answer_with_options,accuracy (Rank),openbookqa_main,42.599998474121094,1112000
3948,xl-lm-d4-091621,_only_options,accuracy (Rank),openbookqa_main,41.0,1112000
3949,xl-lm-d4-091621,_pick_answer_with_options,accuracy (Rank),openbookqa_main,44.20000076293945,1112000
3950,xl-lm-d4-091621,_pick_using_id,accuracy (Rank),openbookqa_main,44.79999923706055,1112000
3951,xl-lm-d4-091621,_which_correct,accuracy (Rank),openbookqa_main,43.599998474121094,1112000
3952,xl-lm-d4-091621,_which_correct_inverse,accuracy (Rank),openbookqa_main,40.0,1112000
4074,xxl-lm-d4-091621-512,_Read_the_article_and_answer_the_question_no_option_,accuracy (Rank),race_high,,1112200
4075,xxl-lm-d4-091621-512,_Select_the_best_answer,accuracy (Rank),race_high,69.92176055908203,1112200
4076,xxl-lm-d4-091621-512,_Select_the_best_answer_generate_span_,accuracy (Rank),race_high,,1112200
4077,xxl-lm-d4-091621-512,_Select_the_best_answer_no_instructions_,accuracy (Rank),race_high,68.44393157958984,1112200
4078,xxl-lm-d4-091621-512,_Taking_a_test,accuracy (Rank),race_high,69.83483123779297,1112200
4079,xxl-lm-d4-gpt-091621,_Read_the_article_and_answer_the_question_no_option_,accuracy (Rank),race_high,51.26050567626953,1112200
4080,xxl-lm-d4-gpt-091621,_Select_the_best_answer,accuracy (Rank),race_high,81.68647003173828,1112200
4081,xxl-lm-d4-gpt-091621,_Select_the_best_answer_generate_span_,accuracy (Rank),race_high,78.9046630859375,1112200
4082,xxl-lm-d4-gpt-091621,_Select_the_best_answer_no_instructions_,accuracy (Rank),race_high,79.74500274658203,1112200
4083,xxl-lm-d4-gpt-091621,_Taking_a_test,accuracy (Rank),race_high,81.54158020019531,1112200
4084,xxl-lm-d4-all-091621,_Read_the_article_and_answer_the_question_no_option_,accuracy (Rank),race_high,51.23152542114258,1112000
4085,xxl-lm-d4-all-091621,_Select_the_best_answer,accuracy (Rank),race_high,81.19385528564453,1112000
4086,xxl-lm-d4-all-091621,_Select_the_best_answer_generate_span_,accuracy (Rank),race_high,79.42625427246094,1112000
4087,xxl-lm-d4-all-091621,_Select_the_best_answer_no_instructions_,accuracy (Rank),race_high,79.57113647460938,1112000
4088,xxl-lm-d4-all-091621,_Taking_a_test,accuracy (Rank),race_high,81.19385528564453,1112000
4089,xxl-lm-d4-og-091621,_Read_the_article_and_answer_the_question_no_option_,accuracy (Rank),race_high,46.07360076904297,1112000
4090,xxl-lm-d4-og-091621,_Select_the_best_answer,accuracy (Rank),race_high,72.18197631835938,1112000
4091,xxl-lm-d4-og-091621,_Select_the_best_answer_generate_span_,accuracy (Rank),race_high,63.34395980834961,1112000
4092,xxl-lm-d4-og-091621,_Select_the_best_answer_no_instructions_,accuracy (Rank),race_high,69.08142852783203,1112000
4093,xxl-lm-d4-og-091621,_Taking_a_test,accuracy (Rank),race_high,72.26890563964844,1112000
4094,xxl-lm-d4-all-og-091621,_Read_the_article_and_answer_the_question_no_option_,accuracy (Rank),race_high,45.58098983764648,1112000
4095,xxl-lm-d4-all-og-091621,_Select_the_best_answer,accuracy (Rank),race_high,71.42857360839844,1112000
4096,xxl-lm-d4-all-og-091621,_Select_the_best_answer_generate_span_,accuracy (Rank),race_high,66.53144073486328,1112000
4097,xxl-lm-d4-all-og-091621,_Select_the_best_answer_no_instructions_,accuracy (Rank),race_high,68.64676666259766,1112000
4098,xxl-lm-d4-all-og-091621,_Taking_a_test,accuracy (Rank),race_high,71.34163665771484,1112000
4099,xxl-lm-d4-091621,_Read_the_article_and_answer_the_question_no_option_,accuracy (Rank),race_high,36.6270637512207,1100000
4100,xxl-lm-d4-091621,_Select_the_best_answer,accuracy (Rank),race_high,22.283395767211914,1100000
4101,xxl-lm-d4-091621,_Select_the_best_answer_generate_span_,accuracy (Rank),race_high,27.38336753845215,1100000
4102,xxl-lm-d4-091621,_Select_the_best_answer_no_instructions_,accuracy (Rank),race_high,22.13850975036621,1100000
4103,xxl-lm-d4-091621,_Taking_a_test,accuracy (Rank),race_high,22.486236572265625,1100000
4104,xl-lm-d4-091621,_Read_the_article_and_answer_the_question_no_option_,accuracy (Rank),race_high,41.66908264160156,1112000
4105,xl-lm-d4-091621,_Select_the_best_answer,accuracy (Rank),race_high,58.79455184936523,1112000
4106,xl-lm-d4-091621,_Select_the_best_answer_generate_span_,accuracy (Rank),race_high,52.76731491088867,1112000
4107,xl-lm-d4-091621,_Select_the_best_answer_no_instructions_,accuracy (Rank),race_high,57.34569549560547,1112000
4108,xl-lm-d4-091621,_Taking_a_test,accuracy (Rank),race_high,58.70762252807617,1112000
4174,xxl-lm-d4-091621-512,_Read_the_article_and_answer_the_question_no_option_,accuracy (Rank),race_middle,,1112200
4175,xxl-lm-d4-091621-512,_Select_the_best_answer,accuracy (Rank),race_middle,76.46239471435547,1112200
4176,xxl-lm-d4-091621-512,_Select_the_best_answer_generate_span_,accuracy (Rank),race_middle,,1112200
4177,xxl-lm-d4-091621-512,_Select_the_best_answer_no_instructions_,accuracy (Rank),race_middle,74.37326049804688,1112200
4178,xxl-lm-d4-091621-512,_Taking_a_test,accuracy (Rank),race_middle,76.11420440673828,1112200
4179,xxl-lm-d4-gpt-091621,_Read_the_article_and_answer_the_question_no_option_,accuracy (Rank),race_middle,66.57381439208984,1112200
4180,xxl-lm-d4-gpt-091621,_Select_the_best_answer,accuracy (Rank),race_middle,86.83843994140625,1112200
4181,xxl-lm-d4-gpt-091621,_Select_the_best_answer_generate_span_,accuracy (Rank),race_middle,85.0278549194336,1112200
4182,xxl-lm-d4-gpt-091621,_Select_the_best_answer_no_instructions_,accuracy (Rank),race_middle,85.65459442138672,1112200
4183,xxl-lm-d4-gpt-091621,_Taking_a_test,accuracy (Rank),race_middle,86.9080810546875,1112200
4184,xxl-lm-d4-all-091621,_Read_the_article_and_answer_the_question_no_option_,accuracy (Rank),race_middle,67.33983612060547,1112000
4185,xxl-lm-d4-all-091621,_Select_the_best_answer,accuracy (Rank),race_middle,86.3509750366211,1112000
4186,xxl-lm-d4-all-091621,_Select_the_best_answer_generate_span_,accuracy (Rank),race_middle,85.37604522705078,1112000
4187,xxl-lm-d4-all-091621,_Select_the_best_answer_no_instructions_,accuracy (Rank),race_middle,84.74930572509766,1112000
4188,xxl-lm-d4-all-091621,_Taking_a_test,accuracy (Rank),race_middle,86.07242584228516,1112000
4189,xxl-lm-d4-og-091621,_Read_the_article_and_answer_the_question_no_option_,accuracy (Rank),race_middle,60.86351013183594,1112000
4190,xxl-lm-d4-og-091621,_Select_the_best_answer,accuracy (Rank),race_middle,78.4122543334961,1112000
4191,xxl-lm-d4-og-091621,_Select_the_best_answer_generate_span_,accuracy (Rank),race_middle,74.37326049804688,1112000
4192,xxl-lm-d4-og-091621,_Select_the_best_answer_no_instructions_,accuracy (Rank),race_middle,74.51253509521484,1112000
4193,xxl-lm-d4-og-091621,_Taking_a_test,accuracy (Rank),race_middle,77.78551483154297,1112000
4194,xxl-lm-d4-all-og-091621,_Read_the_article_and_answer_the_question_no_option_,accuracy (Rank),race_middle,61.14206314086914,1112000
4195,xxl-lm-d4-all-og-091621,_Select_the_best_answer,accuracy (Rank),race_middle,77.99443054199219,1112000
4196,xxl-lm-d4-all-og-091621,_Select_the_best_answer_generate_span_,accuracy (Rank),race_middle,75.90528869628906,1112000
4197,xxl-lm-d4-all-og-091621,_Select_the_best_answer_no_instructions_,accuracy (Rank),race_middle,75.69638061523438,1112000
4198,xxl-lm-d4-all-og-091621,_Taking_a_test,accuracy (Rank),race_middle,77.78551483154297,1112000
4199,xxl-lm-d4-091621,_Read_the_article_and_answer_the_question_no_option_,accuracy (Rank),race_middle,48.60724258422852,1100000
4200,xxl-lm-d4-091621,_Select_the_best_answer,accuracy (Rank),race_middle,21.657381057739254,1100000
4201,xxl-lm-d4-091621,_Select_the_best_answer_generate_span_,accuracy (Rank),race_middle,35.09749221801758,1100000
4202,xxl-lm-d4-091621,_Select_the_best_answer_no_instructions_,accuracy (Rank),race_middle,22.84122657775879,1100000
4203,xxl-lm-d4-091621,_Taking_a_test,accuracy (Rank),race_middle,21.93593406677246,1100000
4204,xl-lm-d4-091621,_Read_the_article_and_answer_the_question_no_option_,accuracy (Rank),race_middle,56.89414978027344,1112000
4205,xl-lm-d4-091621,_Select_the_best_answer,accuracy (Rank),race_middle,65.66852569580078,1112000
4206,xl-lm-d4-091621,_Select_the_best_answer_generate_span_,accuracy (Rank),race_middle,64.69359588623047,1112000
4207,xl-lm-d4-091621,_Select_the_best_answer_no_instructions_,accuracy (Rank),race_middle,62.74373245239258,1112000
4208,xl-lm-d4-091621,_Taking_a_test,accuracy (Rank),race_middle,65.18106079101561,1112000
4274,xxl-lm-d4-091621-512,_Check_if_a_random_answer_is_valid_or_not,accuracy (Rank),social_i_qa,75.2814712524414,1112200
4275,xxl-lm-d4-091621-512,_Generate_answer,accuracy (Rank),social_i_qa,55.01535415649414,1112200
4276,xxl-lm-d4-091621-512,_I_was_wondering,accuracy (Rank),social_i_qa,54.60593795776367,1112200
4277,xxl-lm-d4-091621-512,_Show_choices_and_generate_answer,accuracy (Rank),social_i_qa,71.80142974853516,1112200
4278,xxl-lm-d4-091621-512,_Show_choices_and_generate_index,accuracy (Rank),social_i_qa,71.85260772705078,1112200
4279,xxl-lm-d4-gpt-091621,_Check_if_a_random_answer_is_valid_or_not,accuracy (Rank),social_i_qa,76.04913330078125,1112200
4280,xxl-lm-d4-gpt-091621,_Generate_answer,accuracy (Rank),social_i_qa,54.8106460571289,1112200
4281,xxl-lm-d4-gpt-091621,_I_was_wondering,accuracy (Rank),social_i_qa,54.50358200073242,1112200
4282,xxl-lm-d4-gpt-091621,_Show_choices_and_generate_answer,accuracy (Rank),social_i_qa,72.00614166259766,1112200
4283,xxl-lm-d4-gpt-091621,_Show_choices_and_generate_index,accuracy (Rank),social_i_qa,73.28556823730469,1112200
4284,xxl-lm-d4-all-091621,_Check_if_a_random_answer_is_valid_or_not,accuracy (Rank),social_i_qa,74.46263885498047,1112000
4285,xxl-lm-d4-all-091621,_Generate_answer,accuracy (Rank),social_i_qa,54.75946807861328,1112000
4286,xxl-lm-d4-all-091621,_I_was_wondering,accuracy (Rank),social_i_qa,54.35005187988281,1112000
4287,xxl-lm-d4-all-091621,_Show_choices_and_generate_answer,accuracy (Rank),social_i_qa,71.85260772705078,1112000
4288,xxl-lm-d4-all-091621,_Show_choices_and_generate_index,accuracy (Rank),social_i_qa,73.0296859741211,1112000
4289,xxl-lm-d4-og-091621,_Check_if_a_random_answer_is_valid_or_not,accuracy (Rank),social_i_qa,75.02558898925781,1112000
4290,xxl-lm-d4-og-091621,_Generate_answer,accuracy (Rank),social_i_qa,46.059364318847656,1112000
4291,xxl-lm-d4-og-091621,_I_was_wondering,accuracy (Rank),social_i_qa,43.39815902709961,1112000
4292,xxl-lm-d4-og-091621,_Show_choices_and_generate_answer,accuracy (Rank),social_i_qa,60.696006774902344,1112000
4293,xxl-lm-d4-og-091621,_Show_choices_and_generate_index,accuracy (Rank),social_i_qa,69.60082244873047,1112000
4294,xxl-lm-d4-all-og-091621,_Check_if_a_random_answer_is_valid_or_not,accuracy (Rank),social_i_qa,75.07676696777344,1112000
4295,xxl-lm-d4-all-og-091621,_Generate_answer,accuracy (Rank),social_i_qa,54.24769592285156,1112000
4296,xxl-lm-d4-all-og-091621,_I_was_wondering,accuracy (Rank),social_i_qa,53.9918098449707,1112000
4297,xxl-lm-d4-all-og-091621,_Show_choices_and_generate_answer,accuracy (Rank),social_i_qa,72.569091796875,1112000
4298,xxl-lm-d4-all-og-091621,_Show_choices_and_generate_index,accuracy (Rank),social_i_qa,73.54145050048828,1112000
4299,xxl-lm-d4-091621,_Check_if_a_random_answer_is_valid_or_not,accuracy (Rank),social_i_qa,62.53838348388672,1100000
4300,xxl-lm-d4-091621,_Generate_answer,accuracy (Rank),social_i_qa,39.76458358764648,1100000
4301,xxl-lm-d4-091621,_I_was_wondering,accuracy (Rank),social_i_qa,38.53633499145508,1100000
4302,xxl-lm-d4-091621,_Show_choices_and_generate_answer,accuracy (Rank),social_i_qa,36.94984817504883,1100000
4303,xxl-lm-d4-091621,_Show_choices_and_generate_index,accuracy (Rank),social_i_qa,33.265098571777344,1100000
4304,xl-lm-d4-091621,_Check_if_a_random_answer_is_valid_or_not,accuracy (Rank),social_i_qa,69.39611053466797,1112000
4305,xl-lm-d4-091621,_Generate_answer,accuracy (Rank),social_i_qa,47.6970329284668,1112000
4306,xl-lm-d4-091621,_I_was_wondering,accuracy (Rank),social_i_qa,47.90174102783203,1112000
4307,xl-lm-d4-091621,_Show_choices_and_generate_answer,accuracy (Rank),social_i_qa,52.7635612487793,1112000
4308,xl-lm-d4-091621,_Show_choices_and_generate_index,accuracy (Rank),social_i_qa,53.377685546875,1112000
4509,xxl-lm-d4-091621-512,_GPT_3_Style,accuracy (Rank),super_glue_boolq,73.76146697998047,1112200
4510,xxl-lm-d4-091621-512,_I_wonder_,accuracy (Rank),super_glue_boolq,67.73699951171875,1112200
4511,xxl-lm-d4-091621-512,_after_reading,accuracy (Rank),super_glue_boolq,76.36085510253906,1112200
4512,xxl-lm-d4-091621-512,_based_on_the_following_passage,accuracy (Rank),super_glue_boolq,69.48012542724611,1112200
4513,xxl-lm-d4-091621-512,_based_on_the_previous_passage,accuracy (Rank),super_glue_boolq,72.84403991699219,1112200
4514,xxl-lm-d4-091621-512,_could_you_tell_me_,accuracy (Rank),super_glue_boolq,69.51070404052734,1112200
4515,xxl-lm-d4-091621-512,_exam,accuracy (Rank),super_glue_boolq,77.06421661376953,1112200
4516,xxl-lm-d4-091621-512,_exercise,accuracy (Rank),super_glue_boolq,73.60856628417969,1112200
4517,xxl-lm-d4-091621-512,_valid_binary,accuracy (Rank),super_glue_boolq,76.20795440673828,1112200
4518,xxl-lm-d4-091621-512,_yes_no_question,accuracy (Rank),super_glue_boolq,77.15596008300781,1112200
4519,xxl-lm-d4-gpt-091621,_GPT_3_Style,accuracy (Rank),super_glue_boolq,77.92048645019531,1112200
4520,xxl-lm-d4-gpt-091621,_I_wonder_,accuracy (Rank),super_glue_boolq,73.45565795898438,1112200
4521,xxl-lm-d4-gpt-091621,_after_reading,accuracy (Rank),super_glue_boolq,79.05198669433594,1112200
4522,xxl-lm-d4-gpt-091621,_based_on_the_following_passage,accuracy (Rank),super_glue_boolq,74.80122375488281,1112200
4523,xxl-lm-d4-gpt-091621,_based_on_the_previous_passage,accuracy (Rank),super_glue_boolq,78.53211212158203,1112200
4524,xxl-lm-d4-gpt-091621,_could_you_tell_me_,accuracy (Rank),super_glue_boolq,75.44342803955078,1112200
4525,xxl-lm-d4-gpt-091621,_exam,accuracy (Rank),super_glue_boolq,78.96024322509766,1112200
4526,xxl-lm-d4-gpt-091621,_exercise,accuracy (Rank),super_glue_boolq,76.60550689697266,1112200
4527,xxl-lm-d4-gpt-091621,_valid_binary,accuracy (Rank),super_glue_boolq,78.10397338867188,1112200
4528,xxl-lm-d4-gpt-091621,_yes_no_question,accuracy (Rank),super_glue_boolq,76.1773681640625,1112200
4529,xxl-lm-d4-all-091621,_GPT_3_Style,accuracy (Rank),super_glue_boolq,87.33944702148438,1112000
4530,xxl-lm-d4-all-091621,_I_wonder_,accuracy (Rank),super_glue_boolq,86.72782897949219,1112000
4531,xxl-lm-d4-all-091621,_after_reading,accuracy (Rank),super_glue_boolq,87.15596008300781,1112000
4532,xxl-lm-d4-all-091621,_based_on_the_following_passage,accuracy (Rank),super_glue_boolq,86.91131591796875,1112000
4533,xxl-lm-d4-all-091621,_based_on_the_previous_passage,accuracy (Rank),super_glue_boolq,87.21712493896484,1112000
4534,xxl-lm-d4-all-091621,_could_you_tell_me_,accuracy (Rank),super_glue_boolq,87.15596008300781,1112000
4535,xxl-lm-d4-all-091621,_exam,accuracy (Rank),super_glue_boolq,87.06421661376953,1112000
4536,xxl-lm-d4-all-091621,_exercise,accuracy (Rank),super_glue_boolq,87.33944702148438,1112000
4537,xxl-lm-d4-all-091621,_valid_binary,accuracy (Rank),super_glue_boolq,86.39143371582031,1112000
4538,xxl-lm-d4-all-091621,_yes_no_question,accuracy (Rank),super_glue_boolq,86.75840759277344,1112000
4539,xxl-lm-d4-og-091621,_GPT_3_Style,accuracy (Rank),super_glue_boolq,71.65137481689453,1112000
4540,xxl-lm-d4-og-091621,_I_wonder_,accuracy (Rank),super_glue_boolq,67.645263671875,1112000
4541,xxl-lm-d4-og-091621,_after_reading,accuracy (Rank),super_glue_boolq,62.782875061035156,1112000
4542,xxl-lm-d4-og-091621,_based_on_the_following_passage,accuracy (Rank),super_glue_boolq,69.75534820556639,1112000
4543,xxl-lm-d4-og-091621,_based_on_the_previous_passage,accuracy (Rank),super_glue_boolq,71.59021759033203,1112000
4544,xxl-lm-d4-og-091621,_could_you_tell_me_,accuracy (Rank),super_glue_boolq,69.54128265380861,1112000
4545,xxl-lm-d4-og-091621,_exam,accuracy (Rank),super_glue_boolq,77.09480285644531,1112000
4546,xxl-lm-d4-og-091621,_exercise,accuracy (Rank),super_glue_boolq,62.62997055053711,1112000
4547,xxl-lm-d4-og-091621,_valid_binary,accuracy (Rank),super_glue_boolq,63.02752304077149,1112000
4548,xxl-lm-d4-og-091621,_yes_no_question,accuracy (Rank),super_glue_boolq,76.60550689697266,1112000
4549,xxl-lm-d4-all-og-091621,_GPT_3_Style,accuracy (Rank),super_glue_boolq,72.20183563232422,1112000
4550,xxl-lm-d4-all-og-091621,_I_wonder_,accuracy (Rank),super_glue_boolq,67.55352020263672,1112000
4551,xxl-lm-d4-all-og-091621,_after_reading,accuracy (Rank),super_glue_boolq,67.82874298095703,1112000
4552,xxl-lm-d4-all-og-091621,_based_on_the_following_passage,accuracy (Rank),super_glue_boolq,71.03975677490234,1112000
4553,xxl-lm-d4-all-og-091621,_based_on_the_previous_passage,accuracy (Rank),super_glue_boolq,71.59021759033203,1112000
4554,xxl-lm-d4-all-og-091621,_could_you_tell_me_,accuracy (Rank),super_glue_boolq,69.84709167480469,1112000
4555,xxl-lm-d4-all-og-091621,_exam,accuracy (Rank),super_glue_boolq,74.43424987792969,1112000
4556,xxl-lm-d4-all-og-091621,_exercise,accuracy (Rank),super_glue_boolq,66.02446746826172,1112000
4557,xxl-lm-d4-all-og-091621,_valid_binary,accuracy (Rank),super_glue_boolq,67.82874298095703,1112000
4558,xxl-lm-d4-all-og-091621,_yes_no_question,accuracy (Rank),super_glue_boolq,73.30274963378906,1112000
4559,xxl-lm-d4-091621,_GPT_3_Style,accuracy (Rank),super_glue_boolq,45.9938850402832,1100000
4560,xxl-lm-d4-091621,_I_wonder_,accuracy (Rank),super_glue_boolq,44.22018432617188,1100000
4561,xxl-lm-d4-091621,_after_reading,accuracy (Rank),super_glue_boolq,58.960243225097656,1100000
4562,xxl-lm-d4-091621,_based_on_the_following_passage,accuracy (Rank),super_glue_boolq,38.929664611816406,1100000
4563,xxl-lm-d4-091621,_based_on_the_previous_passage,accuracy (Rank),super_glue_boolq,44.342506408691406,1100000
4564,xxl-lm-d4-091621,_could_you_tell_me_,accuracy (Rank),super_glue_boolq,44.58715438842773,1100000
4565,xxl-lm-d4-091621,_exam,accuracy (Rank),super_glue_boolq,40.58103942871094,1100000
4566,xxl-lm-d4-091621,_exercise,accuracy (Rank),super_glue_boolq,58.960243225097656,1100000
4567,xxl-lm-d4-091621,_valid_binary,accuracy (Rank),super_glue_boolq,58.62385177612305,1100000
4568,xxl-lm-d4-091621,_yes_no_question,accuracy (Rank),super_glue_boolq,47.85932540893555,1100000
4569,xl-lm-d4-091621,_GPT_3_Style,accuracy (Rank),super_glue_boolq,60.06116104125977,1112000
4570,xl-lm-d4-091621,_I_wonder_,accuracy (Rank),super_glue_boolq,59.3577995300293,1112000
4571,xl-lm-d4-091621,_after_reading,accuracy (Rank),super_glue_boolq,50.36697387695313,1112000
4572,xl-lm-d4-091621,_based_on_the_following_passage,accuracy (Rank),super_glue_boolq,59.17431259155274,1112000
4573,xl-lm-d4-091621,_based_on_the_previous_passage,accuracy (Rank),super_glue_boolq,59.8776741027832,1112000
4574,xl-lm-d4-091621,_could_you_tell_me_,accuracy (Rank),super_glue_boolq,60.97859191894531,1112000
4575,xl-lm-d4-091621,_exam,accuracy (Rank),super_glue_boolq,59.78593444824219,1112000
4576,xl-lm-d4-091621,_exercise,accuracy (Rank),super_glue_boolq,55.74923706054688,1112000
4577,xl-lm-d4-091621,_valid_binary,accuracy (Rank),super_glue_boolq,54.70948028564453,1112000
4578,xl-lm-d4-091621,_yes_no_question,accuracy (Rank),super_glue_boolq,59.38837814331055,1112000
4861,xxl-lm-d4-091621-512,_C1_or_C2_premise_so_because_,accuracy (Rank),super_glue_copa,82.0,1112200
4862,xxl-lm-d4-091621-512,__As_a_result_C1_or_C2_,accuracy (Rank),super_glue_copa,87.5,1112200
4863,xxl-lm-d4-091621-512,__What_could_happen_next_C1_or_C2_,accuracy (Rank),super_glue_copa,89.58333587646484,1112200
4864,xxl-lm-d4-091621-512,__which_may_be_caused_by,accuracy (Rank),super_glue_copa,84.61538696289062,1112200
4865,xxl-lm-d4-091621-512,__why_C1_or_C2,accuracy (Rank),super_glue_copa,86.53845977783203,1112200
4866,xxl-lm-d4-091621-512,_best_option,accuracy (Rank),super_glue_copa,88.0,1112200
4867,xxl-lm-d4-091621-512,_cause_effect,accuracy (Rank),super_glue_copa,93.0,1112200
4868,xxl-lm-d4-091621-512,_choose,accuracy (Rank),super_glue_copa,96.0,1112200
4869,xxl-lm-d4-091621-512,_exercise,accuracy (Rank),super_glue_copa,92.0,1112200
4870,xxl-lm-d4-091621-512,_i_am_hesitating,accuracy (Rank),super_glue_copa,94.0,1112200
4871,xxl-lm-d4-091621-512,_more_likely,accuracy (Rank),super_glue_copa,93.0,1112200
4872,xxl-lm-d4-091621-512,_plausible_alternatives,accuracy (Rank),super_glue_copa,94.0,1112200
4873,xxl-lm-d4-gpt-091621,_C1_or_C2_premise_so_because_,accuracy (Rank),super_glue_copa,86.0,1112200
4874,xxl-lm-d4-gpt-091621,__As_a_result_C1_or_C2_,accuracy (Rank),super_glue_copa,87.5,1112200
4875,xxl-lm-d4-gpt-091621,__What_could_happen_next_C1_or_C2_,accuracy (Rank),super_glue_copa,93.75,1112200
4876,xxl-lm-d4-gpt-091621,__which_may_be_caused_by,accuracy (Rank),super_glue_copa,92.30769348144531,1112200
4877,xxl-lm-d4-gpt-091621,__why_C1_or_C2,accuracy (Rank),super_glue_copa,92.30769348144531,1112200
4878,xxl-lm-d4-gpt-091621,_best_option,accuracy (Rank),super_glue_copa,88.0,1112200
4879,xxl-lm-d4-gpt-091621,_cause_effect,accuracy (Rank),super_glue_copa,95.0,1112200
4880,xxl-lm-d4-gpt-091621,_choose,accuracy (Rank),super_glue_copa,94.0,1112200
4881,xxl-lm-d4-gpt-091621,_exercise,accuracy (Rank),super_glue_copa,94.0,1112200
4882,xxl-lm-d4-gpt-091621,_i_am_hesitating,accuracy (Rank),super_glue_copa,95.0,1112200
4883,xxl-lm-d4-gpt-091621,_more_likely,accuracy (Rank),super_glue_copa,95.0,1112200
4884,xxl-lm-d4-gpt-091621,_plausible_alternatives,accuracy (Rank),super_glue_copa,94.0,1112200
4885,xxl-lm-d4-all-091621,_C1_or_C2_premise_so_because_,accuracy (Rank),super_glue_copa,93.0,1112000
4886,xxl-lm-d4-all-091621,__As_a_result_C1_or_C2_,accuracy (Rank),super_glue_copa,91.66666412353516,1112000
4887,xxl-lm-d4-all-091621,__What_could_happen_next_C1_or_C2_,accuracy (Rank),super_glue_copa,93.75,1112000
4888,xxl-lm-d4-all-091621,__which_may_be_caused_by,accuracy (Rank),super_glue_copa,90.38461303710938,1112000
4889,xxl-lm-d4-all-091621,__why_C1_or_C2,accuracy (Rank),super_glue_copa,,1112000
4890,xxl-lm-d4-all-091621,_best_option,accuracy (Rank),super_glue_copa,90.0,1112000
4891,xxl-lm-d4-all-091621,_cause_effect,accuracy (Rank),super_glue_copa,95.0,1112000
4892,xxl-lm-d4-all-091621,_choose,accuracy (Rank),super_glue_copa,96.0,1112000
4893,xxl-lm-d4-all-091621,_exercise,accuracy (Rank),super_glue_copa,97.0,1112000
4894,xxl-lm-d4-all-091621,_i_am_hesitating,accuracy (Rank),super_glue_copa,96.0,1112000
4895,xxl-lm-d4-all-091621,_more_likely,accuracy (Rank),super_glue_copa,95.0,1112000
4896,xxl-lm-d4-all-091621,_plausible_alternatives,accuracy (Rank),super_glue_copa,93.0,1112000
4897,xxl-lm-d4-og-091621,_C1_or_C2_premise_so_because_,accuracy (Rank),super_glue_copa,83.0,1112000
4898,xxl-lm-d4-og-091621,__As_a_result_C1_or_C2_,accuracy (Rank),super_glue_copa,85.41666412353516,1112000
4899,xxl-lm-d4-og-091621,__What_could_happen_next_C1_or_C2_,accuracy (Rank),super_glue_copa,87.5,1112000
4900,xxl-lm-d4-og-091621,__which_may_be_caused_by,accuracy (Rank),super_glue_copa,86.53845977783203,1112000
4901,xxl-lm-d4-og-091621,__why_C1_or_C2,accuracy (Rank),super_glue_copa,80.76923370361328,1112000
4902,xxl-lm-d4-og-091621,_best_option,accuracy (Rank),super_glue_copa,85.0,1112000
4903,xxl-lm-d4-og-091621,_cause_effect,accuracy (Rank),super_glue_copa,90.0,1112000
4904,xxl-lm-d4-og-091621,_choose,accuracy (Rank),super_glue_copa,94.0,1112000
4905,xxl-lm-d4-og-091621,_exercise,accuracy (Rank),super_glue_copa,,1112000
4906,xxl-lm-d4-og-091621,_i_am_hesitating,accuracy (Rank),super_glue_copa,90.0,1112000
4907,xxl-lm-d4-og-091621,_more_likely,accuracy (Rank),super_glue_copa,91.0,1112000
4908,xxl-lm-d4-og-091621,_plausible_alternatives,accuracy (Rank),super_glue_copa,91.0,1112000
4909,xxl-lm-d4-all-og-091621,_C1_or_C2_premise_so_because_,accuracy (Rank),super_glue_copa,84.0,1112000
4910,xxl-lm-d4-all-og-091621,__As_a_result_C1_or_C2_,accuracy (Rank),super_glue_copa,95.83333587646484,1112000
4911,xxl-lm-d4-all-og-091621,__What_could_happen_next_C1_or_C2_,accuracy (Rank),super_glue_copa,87.5,1112000
4912,xxl-lm-d4-all-og-091621,__which_may_be_caused_by,accuracy (Rank),super_glue_copa,90.38461303710938,1112000
4913,xxl-lm-d4-all-og-091621,__why_C1_or_C2,accuracy (Rank),super_glue_copa,86.53845977783203,1112000
4914,xxl-lm-d4-all-og-091621,_best_option,accuracy (Rank),super_glue_copa,88.0,1112000
4915,xxl-lm-d4-all-og-091621,_cause_effect,accuracy (Rank),super_glue_copa,93.0,1112000
4916,xxl-lm-d4-all-og-091621,_choose,accuracy (Rank),super_glue_copa,95.0,1112000
4917,xxl-lm-d4-all-og-091621,_exercise,accuracy (Rank),super_glue_copa,93.0,1112000
4918,xxl-lm-d4-all-og-091621,_i_am_hesitating,accuracy (Rank),super_glue_copa,93.0,1112000
4919,xxl-lm-d4-all-og-091621,_more_likely,accuracy (Rank),super_glue_copa,90.0,1112000
4920,xxl-lm-d4-all-og-091621,_plausible_alternatives,accuracy (Rank),super_glue_copa,94.0,1112000
4921,xxl-lm-d4-091621,_C1_or_C2_premise_so_because_,accuracy (Rank),super_glue_copa,59.0,1100000
4922,xxl-lm-d4-091621,__As_a_result_C1_or_C2_,accuracy (Rank),super_glue_copa,60.41666793823242,1100000
4923,xxl-lm-d4-091621,__What_could_happen_next_C1_or_C2_,accuracy (Rank),super_glue_copa,62.5,1100000
4924,xxl-lm-d4-091621,__which_may_be_caused_by,accuracy (Rank),super_glue_copa,53.846153259277344,1100000
4925,xxl-lm-d4-091621,__why_C1_or_C2,accuracy (Rank),super_glue_copa,51.92307662963867,1100000
4926,xxl-lm-d4-091621,_best_option,accuracy (Rank),super_glue_copa,58.0,1100000
4927,xxl-lm-d4-091621,_cause_effect,accuracy (Rank),super_glue_copa,45.0,1100000
4928,xxl-lm-d4-091621,_choose,accuracy (Rank),super_glue_copa,57.0,1100000
4929,xxl-lm-d4-091621,_exercise,accuracy (Rank),super_glue_copa,52.0,1100000
4930,xxl-lm-d4-091621,_i_am_hesitating,accuracy (Rank),super_glue_copa,55.0,1100000
4931,xxl-lm-d4-091621,_more_likely,accuracy (Rank),super_glue_copa,49.0,1100000
4932,xxl-lm-d4-091621,_plausible_alternatives,accuracy (Rank),super_glue_copa,,1100000
4933,xl-lm-d4-091621,_C1_or_C2_premise_so_because_,accuracy (Rank),super_glue_copa,61.0,1112000
4934,xl-lm-d4-091621,__As_a_result_C1_or_C2_,accuracy (Rank),super_glue_copa,62.5,1112000
4935,xl-lm-d4-091621,__What_could_happen_next_C1_or_C2_,accuracy (Rank),super_glue_copa,72.91666412353516,1112000
4936,xl-lm-d4-091621,__which_may_be_caused_by,accuracy (Rank),super_glue_copa,57.69230651855469,1112000
4937,xl-lm-d4-091621,__why_C1_or_C2,accuracy (Rank),super_glue_copa,76.92308044433594,1112000
4938,xl-lm-d4-091621,_best_option,accuracy (Rank),super_glue_copa,70.0,1112000
4939,xl-lm-d4-091621,_cause_effect,accuracy (Rank),super_glue_copa,,1112000
4940,xl-lm-d4-091621,_choose,accuracy (Rank),super_glue_copa,80.0,1112000
4941,xl-lm-d4-091621,_exercise,accuracy (Rank),super_glue_copa,80.0,1112000
4942,xl-lm-d4-091621,_i_am_hesitating,accuracy (Rank),super_glue_copa,,1112000
4943,xl-lm-d4-091621,_more_likely,accuracy (Rank),super_glue_copa,79.0,1112000
4944,xl-lm-d4-091621,_plausible_alternatives,accuracy (Rank),super_glue_copa,84.0,1112000
5185,xxl-lm-d4-091621-512,_I_was_going_to_say_,accuracy (Rank),super_glue_multirc,68.44059753417969,1112200
5186,xxl-lm-d4-091621-512,_Would_it_be_good_to_answer_,accuracy (Rank),super_glue_multirc,72.75164794921875,1112200
5187,xxl-lm-d4-091621-512,_confirm,accuracy (Rank),super_glue_multirc,78.87789154052734,1112200
5188,xxl-lm-d4-091621-512,_correct,accuracy (Rank),super_glue_multirc,75.55693054199219,1112200
5189,xxl-lm-d4-091621-512,_decide_valid,accuracy (Rank),super_glue_multirc,79.51732635498047,1112200
5190,xxl-lm-d4-091621-512,_found_this_answer,accuracy (Rank),super_glue_multirc,75.39191436767578,1112200
5191,xxl-lm-d4-091621-512,_grading,accuracy (Rank),super_glue_multirc,76.42326354980469,1112200
5192,xxl-lm-d4-091621-512,_is_a_correct_answer_,accuracy (Rank),super_glue_multirc,78.81600952148438,1112200
5193,xxl-lm-d4-091621-512,_is_the_correct_answer_,accuracy (Rank),super_glue_multirc,70.81270599365234,1112200
5194,xxl-lm-d4-091621-512,_paragraph_question_is_it_,accuracy (Rank),super_glue_multirc,69.26567840576172,1112200
5195,xxl-lm-d4-gpt-091621,_I_was_going_to_say_,accuracy (Rank),super_glue_multirc,63.63448715209961,1112200
5196,xxl-lm-d4-gpt-091621,_Would_it_be_good_to_answer_,accuracy (Rank),super_glue_multirc,65.34653472900389,1112200
5197,xxl-lm-d4-gpt-091621,_confirm,accuracy (Rank),super_glue_multirc,72.3184814453125,1112200
5198,xxl-lm-d4-gpt-091621,_correct,accuracy (Rank),super_glue_multirc,65.07838439941406,1112200
5199,xxl-lm-d4-gpt-091621,_decide_valid,accuracy (Rank),super_glue_multirc,72.40099334716797,1112200
5200,xxl-lm-d4-gpt-091621,_found_this_answer,accuracy (Rank),super_glue_multirc,59.96287155151367,1112200
5201,xxl-lm-d4-gpt-091621,_grading,accuracy (Rank),super_glue_multirc,60.086631774902344,1112200
5202,xxl-lm-d4-gpt-091621,_is_a_correct_answer_,accuracy (Rank),super_glue_multirc,67.34735870361328,1112200
5203,xxl-lm-d4-gpt-091621,_is_the_correct_answer_,accuracy (Rank),super_glue_multirc,61.05610656738281,1112200
5204,xxl-lm-d4-gpt-091621,_paragraph_question_is_it_,accuracy (Rank),super_glue_multirc,69.92574310302734,1112200
5205,xxl-lm-d4-all-091621,_I_was_going_to_say_,accuracy (Rank),super_glue_multirc,86.17987060546875,1112000
5206,xxl-lm-d4-all-091621,_Would_it_be_good_to_answer_,accuracy (Rank),super_glue_multirc,86.81930541992188,1112000
5207,xxl-lm-d4-all-091621,_confirm,accuracy (Rank),super_glue_multirc,87.16996765136719,1112000
5208,xxl-lm-d4-all-091621,_correct,accuracy (Rank),super_glue_multirc,84.6328353881836,1112000
5209,xxl-lm-d4-all-091621,_decide_valid,accuracy (Rank),super_glue_multirc,85.97359466552734,1112000
5210,xxl-lm-d4-all-091621,_found_this_answer,accuracy (Rank),super_glue_multirc,87.70626831054688,1112000
5211,xxl-lm-d4-all-091621,_grading,accuracy (Rank),super_glue_multirc,87.5206298828125,1112000
5212,xxl-lm-d4-all-091621,_is_a_correct_answer_,accuracy (Rank),super_glue_multirc,87.6650161743164,1112000
5213,xxl-lm-d4-all-091621,_is_the_correct_answer_,accuracy (Rank),super_glue_multirc,87.60313415527344,1112000
5214,xxl-lm-d4-all-091621,_paragraph_question_is_it_,accuracy (Rank),super_glue_multirc,87.23184967041016,1112000
5215,xxl-lm-d4-og-091621,_I_was_going_to_say_,accuracy (Rank),super_glue_multirc,63.03630447387695,1112000
5216,xxl-lm-d4-og-091621,_Would_it_be_good_to_answer_,accuracy (Rank),super_glue_multirc,64.99587249755861,1112000
5217,xxl-lm-d4-og-091621,_confirm,accuracy (Rank),super_glue_multirc,73.67987060546875,1112000
5218,xxl-lm-d4-og-091621,_correct,accuracy (Rank),super_glue_multirc,68.75,1112000
5219,xxl-lm-d4-og-091621,_decide_valid,accuracy (Rank),super_glue_multirc,75.28878021240234,1112000
5220,xxl-lm-d4-og-091621,_found_this_answer,accuracy (Rank),super_glue_multirc,71.30775451660156,1112000
5221,xxl-lm-d4-og-091621,_grading,accuracy (Rank),super_glue_multirc,69.59571075439453,1112000
5222,xxl-lm-d4-og-091621,_is_a_correct_answer_,accuracy (Rank),super_glue_multirc,73.80362701416016,1112000
5223,xxl-lm-d4-og-091621,_is_the_correct_answer_,accuracy (Rank),super_glue_multirc,68.70874786376953,1112000
5224,xxl-lm-d4-og-091621,_paragraph_question_is_it_,accuracy (Rank),super_glue_multirc,66.089111328125,1112000
5225,xxl-lm-d4-all-og-091621,_I_was_going_to_say_,accuracy (Rank),super_glue_multirc,65.03713226318361,1112000
5226,xxl-lm-d4-all-og-091621,_Would_it_be_good_to_answer_,accuracy (Rank),super_glue_multirc,68.95626831054689,1112000
5227,xxl-lm-d4-all-og-091621,_confirm,accuracy (Rank),super_glue_multirc,74.15428924560547,1112000
5228,xxl-lm-d4-all-og-091621,_correct,accuracy (Rank),super_glue_multirc,72.21534729003906,1112000
5229,xxl-lm-d4-all-og-091621,_decide_valid,accuracy (Rank),super_glue_multirc,75.37128448486328,1112000
5230,xxl-lm-d4-all-og-091621,_found_this_answer,accuracy (Rank),super_glue_multirc,70.07012939453125,1112000
5231,xxl-lm-d4-all-og-091621,_grading,accuracy (Rank),super_glue_multirc,70.83333587646484,1112000
5232,xxl-lm-d4-all-og-091621,_is_a_correct_answer_,accuracy (Rank),super_glue_multirc,74.89686584472656,1112000
5233,xxl-lm-d4-all-og-091621,_is_the_correct_answer_,accuracy (Rank),super_glue_multirc,69.80197906494139,1112000
5234,xxl-lm-d4-all-og-091621,_paragraph_question_is_it_,accuracy (Rank),super_glue_multirc,68.37871551513672,1112000
5235,xxl-lm-d4-091621,_I_was_going_to_say_,accuracy (Rank),super_glue_multirc,56.22937393188477,1100000
5236,xxl-lm-d4-091621,_Would_it_be_good_to_answer_,accuracy (Rank),super_glue_multirc,57.71452331542969,1100000
5237,xxl-lm-d4-091621,_confirm,accuracy (Rank),super_glue_multirc,58.0445556640625,1100000
5238,xxl-lm-d4-091621,_correct,accuracy (Rank),super_glue_multirc,56.84818649291992,1100000
5239,xxl-lm-d4-091621,_decide_valid,accuracy (Rank),super_glue_multirc,57.01320266723633,1100000
5240,xxl-lm-d4-091621,_found_this_answer,accuracy (Rank),super_glue_multirc,57.28135299682617,1100000
5241,xxl-lm-d4-091621,_grading,accuracy (Rank),super_glue_multirc,57.90016555786133,1100000
5242,xxl-lm-d4-091621,_is_a_correct_answer_,accuracy (Rank),super_glue_multirc,57.79703140258789,1100000
5243,xxl-lm-d4-091621,_is_the_correct_answer_,accuracy (Rank),super_glue_multirc,57.48762512207031,1100000
5244,xxl-lm-d4-091621,_paragraph_question_is_it_,accuracy (Rank),super_glue_multirc,57.8589096069336,1100000
5245,xl-lm-d4-091621,_I_was_going_to_say_,accuracy (Rank),super_glue_multirc,63.61386108398438,1112000
5246,xl-lm-d4-091621,_Would_it_be_good_to_answer_,accuracy (Rank),super_glue_multirc,65.51155090332031,1112000
5247,xl-lm-d4-091621,_confirm,accuracy (Rank),super_glue_multirc,66.35726165771484,1112000
5248,xl-lm-d4-091621,_correct,accuracy (Rank),super_glue_multirc,61.36551284790039,1112000
5249,xl-lm-d4-091621,_decide_valid,accuracy (Rank),super_glue_multirc,65.40841674804689,1112000
5250,xl-lm-d4-091621,_found_this_answer,accuracy (Rank),super_glue_multirc,64.19142150878906,1112000
5251,xl-lm-d4-091621,_grading,accuracy (Rank),super_glue_multirc,65.03713226318361,1112000
5252,xl-lm-d4-091621,_is_a_correct_answer_,accuracy (Rank),super_glue_multirc,65.1815185546875,1112000
5253,xl-lm-d4-091621,_is_the_correct_answer_,accuracy (Rank),super_glue_multirc,66.089111328125,1112000
5254,xl-lm-d4-091621,_paragraph_question_is_it_,accuracy (Rank),super_glue_multirc,66.50164794921875,1112000
5507,xxl-lm-d4-091621-512,_asked_my_friend,accuracy (Rank),mc_taco,69.15146636962889,1112200
5508,xxl-lm-d4-091621-512,_asked_my_friend_doubt,accuracy (Rank),mc_taco,31.905895233154297,1112200
5509,xxl-lm-d4-091621-512,_believable,accuracy (Rank),mc_taco,70.28813171386719,1112200
5510,xxl-lm-d4-091621-512,_formal_description,accuracy (Rank),mc_taco,71.76844024658203,1112200
5511,xxl-lm-d4-091621-512,_observe_check_plausible_yes_no,accuracy (Rank),mc_taco,69.89161682128906,1112200
5512,xxl-lm-d4-091621-512,_plausible_negated,accuracy (Rank),mc_taco,66.27015686035156,1112200
5513,xxl-lm-d4-091621-512,_plausible_true_false,accuracy (Rank),mc_taco,68.14697265625,1112200
5514,xxl-lm-d4-gpt-091621,_asked_my_friend,accuracy (Rank),mc_taco,68.93999481201172,1112200
5515,xxl-lm-d4-gpt-091621,_asked_my_friend_doubt,accuracy (Rank),mc_taco,32.30240631103516,1112200
5516,xxl-lm-d4-gpt-091621,_believable,accuracy (Rank),mc_taco,69.62728118896484,1112200
5517,xxl-lm-d4-gpt-091621,_formal_description,accuracy (Rank),mc_taco,70.34099578857422,1112200
5518,xxl-lm-d4-gpt-091621,_observe_check_plausible_yes_no,accuracy (Rank),mc_taco,70.71107482910156,1112200
5519,xxl-lm-d4-gpt-091621,_plausible_negated,accuracy (Rank),mc_taco,63.7060546875,1112200
5520,xxl-lm-d4-gpt-091621,_plausible_true_false,accuracy (Rank),mc_taco,72.98440551757812,1112200
5521,xxl-lm-d4-all-091621,_asked_my_friend,accuracy (Rank),mc_taco,72.1913833618164,1112000
5522,xxl-lm-d4-all-091621,_asked_my_friend_doubt,accuracy (Rank),mc_taco,31.720855712890625,1112000
5523,xxl-lm-d4-all-091621,_believable,accuracy (Rank),mc_taco,75.99788665771484,1112000
5524,xxl-lm-d4-all-091621,_formal_description,accuracy (Rank),mc_taco,76.92308044433594,1112000
5525,xxl-lm-d4-all-091621,_observe_check_plausible_yes_no,accuracy (Rank),mc_taco,74.30610656738281,1112000
5526,xxl-lm-d4-all-091621,_plausible_negated,accuracy (Rank),mc_taco,60.87760925292969,1112000
5527,xxl-lm-d4-all-091621,_plausible_true_false,accuracy (Rank),mc_taco,76.20935821533203,1112000
5528,xxl-lm-d4-og-091621,_asked_my_friend,accuracy (Rank),mc_taco,68.83425903320311,1112000
5529,xxl-lm-d4-og-091621,_asked_my_friend_doubt,accuracy (Rank),mc_taco,32.461009979248054,1112000
5530,xxl-lm-d4-og-091621,_believable,accuracy (Rank),mc_taco,71.68913269042969,1112000
5531,xxl-lm-d4-og-091621,_formal_description,accuracy (Rank),mc_taco,72.64076232910156,1112000
5532,xxl-lm-d4-og-091621,_observe_check_plausible_yes_no,accuracy (Rank),mc_taco,70.02378845214844,1112000
5533,xxl-lm-d4-og-091621,_plausible_negated,accuracy (Rank),mc_taco,44.62067031860352,1112000
5534,xxl-lm-d4-og-091621,_plausible_true_false,accuracy (Rank),mc_taco,33.14829635620117,1112000
5535,xxl-lm-d4-all-og-091621,_asked_my_friend,accuracy (Rank),mc_taco,68.38488006591797,1112000
5536,xxl-lm-d4-all-og-091621,_asked_my_friend_doubt,accuracy (Rank),mc_taco,32.434574127197266,1112000
5537,xxl-lm-d4-all-og-091621,_believable,accuracy (Rank),mc_taco,70.65821075439453,1112000
5538,xxl-lm-d4-all-og-091621,_formal_description,accuracy (Rank),mc_taco,71.10758972167969,1112000
5539,xxl-lm-d4-all-og-091621,_observe_check_plausible_yes_no,accuracy (Rank),mc_taco,69.49510955810547,1112000
5540,xxl-lm-d4-all-og-091621,_plausible_negated,accuracy (Rank),mc_taco,50.859107971191406,1112000
5541,xxl-lm-d4-all-og-091621,_plausible_true_false,accuracy (Rank),mc_taco,69.94448852539061,1112000
5542,xxl-lm-d4-091621,_asked_my_friend,accuracy (Rank),mc_taco,53.79328536987305,1100000
5543,xxl-lm-d4-091621,_asked_my_friend_doubt,accuracy (Rank),mc_taco,42.6116828918457,1100000
5544,xxl-lm-d4-091621,_believable,accuracy (Rank),mc_taco,63.7589225769043,1100000
5545,xxl-lm-d4-091621,_formal_description,accuracy (Rank),mc_taco,61.7763671875,1100000
5546,xxl-lm-d4-091621,_observe_check_plausible_yes_no,accuracy (Rank),mc_taco,66.34945678710939,1100000
5547,xxl-lm-d4-091621,_plausible_negated,accuracy (Rank),mc_taco,34.840072631835945,1100000
5548,xxl-lm-d4-091621,_plausible_true_false,accuracy (Rank),mc_taco,37.50991439819336,1100000
5549,xl-lm-d4-091621,_asked_my_friend,accuracy (Rank),mc_taco,66.79883575439453,1112000
5550,xl-lm-d4-091621,_asked_my_friend_doubt,accuracy (Rank),mc_taco,32.619613647460945,1112000
5551,xl-lm-d4-091621,_believable,accuracy (Rank),mc_taco,68.51705169677734,1112000
5552,xl-lm-d4-091621,_formal_description,accuracy (Rank),mc_taco,67.82976531982422,1112000
5553,xl-lm-d4-091621,_observe_check_plausible_yes_no,accuracy (Rank),mc_taco,67.64472961425781,1112000
5554,xl-lm-d4-091621,_plausible_negated,accuracy (Rank),mc_taco,66.64023590087889,1112000
5555,xl-lm-d4-091621,_plausible_true_false,accuracy (Rank),mc_taco,68.09410858154297,1112000
5733,xxl-lm-d4-091621-512,_choose_the_most_appropriate_solution,accuracy (Rank),piqa,68.00870513916016,1112200
5734,xxl-lm-d4-091621-512,_finish_sentence_with_correct_choice,accuracy (Rank),piqa,77.25788879394531,1112200
5735,xxl-lm-d4-091621-512,_pick_correct_choice_index,accuracy (Rank),piqa,67.68226623535156,1112200
5736,xxl-lm-d4-091621-512,_pick_correct_choice_with_choice_given_before_goal,accuracy (Rank),piqa,72.74211120605469,1112200
5737,xxl-lm-d4-091621-512,_what_is_the_correct_ending,accuracy (Rank),piqa,76.76822662353516,1112200
5738,xxl-lm-d4-gpt-091621,_choose_the_most_appropriate_solution,accuracy (Rank),piqa,84.43960571289062,1112200
5739,xxl-lm-d4-gpt-091621,_finish_sentence_with_correct_choice,accuracy (Rank),piqa,85.5821533203125,1112200
5740,xxl-lm-d4-gpt-091621,_pick_correct_choice_index,accuracy (Rank),piqa,83.84113311767578,1112200
5741,xxl-lm-d4-gpt-091621,_pick_correct_choice_with_choice_given_before_goal,accuracy (Rank),piqa,85.63655853271484,1112200
5742,xxl-lm-d4-gpt-091621,_what_is_the_correct_ending,accuracy (Rank),piqa,85.5821533203125,1112200
5743,xxl-lm-d4-all-091621,_choose_the_most_appropriate_solution,accuracy (Rank),piqa,84.33079528808594,1112000
5744,xxl-lm-d4-all-091621,_finish_sentence_with_correct_choice,accuracy (Rank),piqa,85.5821533203125,1112000
5745,xxl-lm-d4-all-091621,_pick_correct_choice_index,accuracy (Rank),piqa,83.73231506347656,1112000
5746,xxl-lm-d4-all-091621,_pick_correct_choice_with_choice_given_before_goal,accuracy (Rank),piqa,85.14689636230469,1112000
5747,xxl-lm-d4-all-091621,_what_is_the_correct_ending,accuracy (Rank),piqa,86.28944396972656,1112000
5748,xxl-lm-d4-og-091621,_choose_the_most_appropriate_solution,accuracy (Rank),piqa,73.721435546875,1112000
5749,xxl-lm-d4-og-091621,_finish_sentence_with_correct_choice,accuracy (Rank),piqa,74.42872619628906,1112000
5750,xxl-lm-d4-og-091621,_pick_correct_choice_index,accuracy (Rank),piqa,74.53754425048828,1112000
5751,xxl-lm-d4-og-091621,_pick_correct_choice_with_choice_given_before_goal,accuracy (Rank),piqa,64.14581298828125,1112000
5752,xxl-lm-d4-og-091621,_what_is_the_correct_ending,accuracy (Rank),piqa,72.52448272705078,1112000
5753,xxl-lm-d4-all-og-091621,_choose_the_most_appropriate_solution,accuracy (Rank),piqa,67.08378601074219,1112000
5754,xxl-lm-d4-all-og-091621,_finish_sentence_with_correct_choice,accuracy (Rank),piqa,78.67247009277344,1112000
5755,xxl-lm-d4-all-og-091621,_pick_correct_choice_index,accuracy (Rank),piqa,75.40805053710938,1112000
5756,xxl-lm-d4-all-og-091621,_pick_correct_choice_with_choice_given_before_goal,accuracy (Rank),piqa,70.02175903320311,1112000
5757,xxl-lm-d4-all-og-091621,_what_is_the_correct_ending,accuracy (Rank),piqa,78.12840270996094,1112000
5758,xxl-lm-d4-091621,_choose_the_most_appropriate_solution,accuracy (Rank),piqa,49.945594787597656,1100000
5759,xxl-lm-d4-091621,_finish_sentence_with_correct_choice,accuracy (Rank),piqa,57.07290649414063,1100000
5760,xxl-lm-d4-091621,_pick_correct_choice_index,accuracy (Rank),piqa,50.43525695800781,1100000
5761,xxl-lm-d4-091621,_pick_correct_choice_with_choice_given_before_goal,accuracy (Rank),piqa,54.67899703979492,1100000
5762,xxl-lm-d4-091621,_what_is_the_correct_ending,accuracy (Rank),piqa,57.50815963745117,1100000
5763,xl-lm-d4-091621,_choose_the_most_appropriate_solution,accuracy (Rank),piqa,49.510337829589844,1112000
5764,xl-lm-d4-091621,_finish_sentence_with_correct_choice,accuracy (Rank),piqa,67.57344818115234,1112000
5765,xl-lm-d4-091621,_pick_correct_choice_index,accuracy (Rank),piqa,50.3808479309082,1112000
5766,xl-lm-d4-091621,_pick_correct_choice_with_choice_given_before_goal,accuracy (Rank),piqa,62.40478897094727,1112000
5767,xl-lm-d4-091621,_what_is_the_correct_ending,accuracy (Rank),piqa,66.53971862792969,1112000
5909,xxl-lm-d4-091621-512,_Answer_Given_options,accuracy (Rank),story_cloze_2016,94.92250061035156,1112200
5910,xxl-lm-d4-091621-512,_Choose_Story_Ending,accuracy (Rank),story_cloze_2016,94.70870971679688,1112200
5911,xxl-lm-d4-091621-512,_Movie_What_Happens_Next,accuracy (Rank),story_cloze_2016,83.00373840332031,1112200
5912,xxl-lm-d4-091621-512,_Novel_Correct_Ending,accuracy (Rank),story_cloze_2016,94.7621612548828,1112200
5913,xxl-lm-d4-091621-512,_Story_Continuation_and_Options,accuracy (Rank),story_cloze_2016,94.60181427001952,1112200
5914,xxl-lm-d4-gpt-091621,_Answer_Given_options,accuracy (Rank),story_cloze_2016,97.11384582519531,1112200
5915,xxl-lm-d4-gpt-091621,_Choose_Story_Ending,accuracy (Rank),story_cloze_2016,97.48797607421876,1112200
5916,xxl-lm-d4-gpt-091621,_Movie_What_Happens_Next,accuracy (Rank),story_cloze_2016,92.9449462890625,1112200
5917,xxl-lm-d4-gpt-091621,_Novel_Correct_Ending,accuracy (Rank),story_cloze_2016,97.16728973388672,1112200
5918,xxl-lm-d4-gpt-091621,_Story_Continuation_and_Options,accuracy (Rank),story_cloze_2016,97.4345245361328,1112200
5919,xxl-lm-d4-all-091621,_Answer_Given_options,accuracy (Rank),story_cloze_2016,97.32762908935548,1112000
5920,xxl-lm-d4-all-091621,_Choose_Story_Ending,accuracy (Rank),story_cloze_2016,97.80865478515624,1112000
5921,xxl-lm-d4-all-091621,_Movie_What_Happens_Next,accuracy (Rank),story_cloze_2016,92.6777114868164,1112000
5922,xxl-lm-d4-all-091621,_Novel_Correct_Ending,accuracy (Rank),story_cloze_2016,97.06039428710938,1112000
5923,xxl-lm-d4-all-091621,_Story_Continuation_and_Options,accuracy (Rank),story_cloze_2016,97.5948715209961,1112000
5924,xxl-lm-d4-og-091621,_Answer_Given_options,accuracy (Rank),story_cloze_2016,92.19668579101562,1112000
5925,xxl-lm-d4-og-091621,_Choose_Story_Ending,accuracy (Rank),story_cloze_2016,93.10529327392578,1112000
5926,xxl-lm-d4-og-091621,_Movie_What_Happens_Next,accuracy (Rank),story_cloze_2016,76.32282257080078,1112000
5927,xxl-lm-d4-og-091621,_Novel_Correct_Ending,accuracy (Rank),story_cloze_2016,93.21218872070312,1112000
5928,xxl-lm-d4-og-091621,_Story_Continuation_and_Options,accuracy (Rank),story_cloze_2016,92.99839782714844,1112000
5929,xxl-lm-d4-all-og-091621,_Answer_Given_options,accuracy (Rank),story_cloze_2016,95.88455200195312,1112000
5930,xxl-lm-d4-all-og-091621,_Choose_Story_Ending,accuracy (Rank),story_cloze_2016,95.88455200195312,1112000
5931,xxl-lm-d4-all-og-091621,_Movie_What_Happens_Next,accuracy (Rank),story_cloze_2016,92.9449462890625,1112000
5932,xxl-lm-d4-all-og-091621,_Novel_Correct_Ending,accuracy (Rank),story_cloze_2016,96.15178680419922,1112000
5933,xxl-lm-d4-all-og-091621,_Story_Continuation_and_Options,accuracy (Rank),story_cloze_2016,96.3655776977539,1112000
5934,xxl-lm-d4-091621,_Answer_Given_options,accuracy (Rank),story_cloze_2016,47.56814575195313,1100000
5935,xxl-lm-d4-091621,_Choose_Story_Ending,accuracy (Rank),story_cloze_2016,48.85088348388672,1100000
5936,xxl-lm-d4-091621,_Movie_What_Happens_Next,accuracy (Rank),story_cloze_2016,45.64403915405274,1100000
5937,xxl-lm-d4-091621,_Novel_Correct_Ending,accuracy (Rank),story_cloze_2016,49.70603942871094,1100000
5938,xxl-lm-d4-091621,_Story_Continuation_and_Options,accuracy (Rank),story_cloze_2016,49.01122283935547,1100000
5939,xl-lm-d4-091621,_Answer_Given_options,accuracy (Rank),story_cloze_2016,86.47782135009766,1112000
5940,xl-lm-d4-091621,_Choose_Story_Ending,accuracy (Rank),story_cloze_2016,86.9053955078125,1112000
5941,xl-lm-d4-091621,_Movie_What_Happens_Next,accuracy (Rank),story_cloze_2016,78.08658599853516,1112000
5942,xl-lm-d4-091621,_Novel_Correct_Ending,accuracy (Rank),story_cloze_2016,85.08818817138672,1112000
5943,xl-lm-d4-091621,_Story_Continuation_and_Options,accuracy (Rank),story_cloze_2016,83.59165954589844,1112000
6043,xxl-lm-d4-091621-512,_Predict_ending_with_hint,accuracy (Rank),hellaswag,33.330013275146484,1112200
6044,xxl-lm-d4-091621-512,_Randomized_prompts_template,accuracy (Rank),hellaswag,34.056961059570305,1112200
6045,xxl-lm-d4-091621-512,_complete_first_then,accuracy (Rank),hellaswag,32.971519470214844,1112200
6046,xxl-lm-d4-091621-512,_if_begins_how_continues,accuracy (Rank),hellaswag,33.977294921875,1112200
6047,xxl-lm-d4-gpt-091621,_Predict_ending_with_hint,accuracy (Rank),hellaswag,86.3373794555664,1112200
6048,xxl-lm-d4-gpt-091621,_Randomized_prompts_template,accuracy (Rank),hellaswag,84.83370208740234,1112200
6049,xxl-lm-d4-gpt-091621,_complete_first_then,accuracy (Rank),hellaswag,85.24198150634766,1112200
6050,xxl-lm-d4-gpt-091621,_if_begins_how_continues,accuracy (Rank),hellaswag,88.09998321533203,1112200
6051,xxl-lm-d4-all-091621,_Predict_ending_with_hint,accuracy (Rank),hellaswag,86.4469223022461,1112000
6052,xxl-lm-d4-all-091621,_Randomized_prompts_template,accuracy (Rank),hellaswag,84.84365844726562,1112000
6053,xxl-lm-d4-all-091621,_complete_first_then,accuracy (Rank),hellaswag,84.82373809814453,1112000
6054,xxl-lm-d4-all-091621,_if_begins_how_continues,accuracy (Rank),hellaswag,88.31906127929688,1112000
6055,xxl-lm-d4-og-091621,_Predict_ending_with_hint,accuracy (Rank),hellaswag,33.30014038085937,1112000
6056,xxl-lm-d4-og-091621,_Randomized_prompts_template,accuracy (Rank),hellaswag,33.230430603027344,1112000
6057,xxl-lm-d4-og-091621,_complete_first_then,accuracy (Rank),hellaswag,33.439552307128906,1112000
6058,xxl-lm-d4-og-091621,_if_begins_how_continues,accuracy (Rank),hellaswag,31.19896507263184,1112000
6059,xxl-lm-d4-all-og-091621,_Predict_ending_with_hint,accuracy (Rank),hellaswag,35.7896842956543,1112000
6060,xxl-lm-d4-all-og-091621,_Randomized_prompts_template,accuracy (Rank),hellaswag,35.082653045654304,1112000
6061,xxl-lm-d4-all-og-091621,_complete_first_then,accuracy (Rank),hellaswag,34.614620208740234,1112000
6062,xxl-lm-d4-all-og-091621,_if_begins_how_continues,accuracy (Rank),hellaswag,35.31169128417969,1112000
6063,xxl-lm-d4-091621,_Predict_ending_with_hint,accuracy (Rank),hellaswag,27.85301780700684,1100000
6064,xxl-lm-d4-091621,_Randomized_prompts_template,accuracy (Rank),hellaswag,27.803226470947266,1100000
6065,xxl-lm-d4-091621,_complete_first_then,accuracy (Rank),hellaswag,27.65385437011719,1100000
6066,xxl-lm-d4-091621,_if_begins_how_continues,accuracy (Rank),hellaswag,24.676359176635746,1100000
6067,xl-lm-d4-091621,_Predict_ending_with_hint,accuracy (Rank),hellaswag,27.73351860046387,1112000
6068,xl-lm-d4-091621,_Randomized_prompts_template,accuracy (Rank),hellaswag,27.285400390625,1112000
6069,xl-lm-d4-091621,_complete_first_then,accuracy (Rank),hellaswag,28.46046638488769,1112000
6070,xl-lm-d4-091621,_if_begins_how_continues,accuracy (Rank),hellaswag,25.66221809387207,1112000
6399,xxl-lm-d4-091621-512,_GPT_3_prompt,accuracy (Rank),super_glue_wic,57.83699035644531,1112200
6400,xxl-lm-d4-091621-512,_GPT_3_prompt_with_label,accuracy (Rank),super_glue_wic,54.85893249511719,1112200
6401,xxl-lm-d4-091621-512,_affirmation_true_or_false,accuracy (Rank),super_glue_wic,53.29153442382813,1112200
6402,xxl-lm-d4-091621-512,_grammar_homework,accuracy (Rank),super_glue_wic,54.54545593261719,1112200
6403,xxl-lm-d4-091621-512,_polysemous,accuracy (Rank),super_glue_wic,57.99372863769531,1112200
6404,xxl-lm-d4-091621-512,_question_context,accuracy (Rank),super_glue_wic,56.42633056640625,1112200
6405,xxl-lm-d4-091621-512,_question_context_meaning,accuracy (Rank),super_glue_wic,57.21002960205078,1112200
6406,xxl-lm-d4-091621-512,_question_context_meaning_with_label,accuracy (Rank),super_glue_wic,,1112200
6407,xxl-lm-d4-091621-512,_same_sense,accuracy (Rank),super_glue_wic,58.463951110839844,1112200
6408,xxl-lm-d4-091621-512,_similar_sense,accuracy (Rank),super_glue_wic,58.620689392089844,1112200
6409,xxl-lm-d4-gpt-091621,_GPT_3_prompt,accuracy (Rank),super_glue_wic,62.5391845703125,1112200
6410,xxl-lm-d4-gpt-091621,_GPT_3_prompt_with_label,accuracy (Rank),super_glue_wic,57.52350997924805,1112200
6411,xxl-lm-d4-gpt-091621,_affirmation_true_or_false,accuracy (Rank),super_glue_wic,49.37303924560547,1112200
6412,xxl-lm-d4-gpt-091621,_grammar_homework,accuracy (Rank),super_glue_wic,55.48589324951172,1112200
6413,xxl-lm-d4-gpt-091621,_polysemous,accuracy (Rank),super_glue_wic,50.94043731689453,1112200
6414,xxl-lm-d4-gpt-091621,_question_context,accuracy (Rank),super_glue_wic,55.48589324951172,1112200
6415,xxl-lm-d4-gpt-091621,_question_context_meaning,accuracy (Rank),super_glue_wic,54.075233459472656,1112200
6416,xxl-lm-d4-gpt-091621,_question_context_meaning_with_label,accuracy (Rank),super_glue_wic,51.0971794128418,1112200
6417,xxl-lm-d4-gpt-091621,_same_sense,accuracy (Rank),super_glue_wic,55.64263153076172,1112200
6418,xxl-lm-d4-gpt-091621,_similar_sense,accuracy (Rank),super_glue_wic,57.99372863769531,1112200
6419,xxl-lm-d4-all-091621,_GPT_3_prompt,accuracy (Rank),super_glue_wic,70.21943664550781,1112000
6420,xxl-lm-d4-all-091621,_GPT_3_prompt_with_label,accuracy (Rank),super_glue_wic,68.96551513671875,1112000
6421,xxl-lm-d4-all-091621,_affirmation_true_or_false,accuracy (Rank),super_glue_wic,65.67398071289061,1112000
6422,xxl-lm-d4-all-091621,_grammar_homework,accuracy (Rank),super_glue_wic,72.10031127929688,1112000
6423,xxl-lm-d4-all-091621,_polysemous,accuracy (Rank),super_glue_wic,69.74921417236328,1112000
6424,xxl-lm-d4-all-091621,_question_context,accuracy (Rank),super_glue_wic,70.21943664550781,1112000
6425,xxl-lm-d4-all-091621,_question_context_meaning,accuracy (Rank),super_glue_wic,72.5705337524414,1112000
6426,xxl-lm-d4-all-091621,_question_context_meaning_with_label,accuracy (Rank),super_glue_wic,72.25704956054688,1112000
6427,xxl-lm-d4-all-091621,_same_sense,accuracy (Rank),super_glue_wic,68.65203857421875,1112000
6428,xxl-lm-d4-all-091621,_similar_sense,accuracy (Rank),super_glue_wic,69.74921417236328,1112000
6429,xxl-lm-d4-og-091621,_GPT_3_prompt,accuracy (Rank),super_glue_wic,58.620689392089844,1112000
6430,xxl-lm-d4-og-091621,_GPT_3_prompt_with_label,accuracy (Rank),super_glue_wic,58.620689392089844,1112000
6431,xxl-lm-d4-og-091621,_affirmation_true_or_false,accuracy (Rank),super_glue_wic,50.0,1112000
6432,xxl-lm-d4-og-091621,_grammar_homework,accuracy (Rank),super_glue_wic,52.5078353881836,1112000
6433,xxl-lm-d4-og-091621,_polysemous,accuracy (Rank),super_glue_wic,56.26959228515625,1112000
6434,xxl-lm-d4-og-091621,_question_context,accuracy (Rank),super_glue_wic,52.97805786132813,1112000
6435,xxl-lm-d4-og-091621,_question_context_meaning,accuracy (Rank),super_glue_wic,54.23197555541992,1112000
6436,xxl-lm-d4-og-091621,_question_context_meaning_with_label,accuracy (Rank),super_glue_wic,55.48589324951172,1112000
6437,xxl-lm-d4-og-091621,_same_sense,accuracy (Rank),super_glue_wic,57.21002960205078,1112000
6438,xxl-lm-d4-og-091621,_similar_sense,accuracy (Rank),super_glue_wic,54.38871383666992,1112000
6439,xxl-lm-d4-all-og-091621,_GPT_3_prompt,accuracy (Rank),super_glue_wic,59.56112670898438,1112000
6440,xxl-lm-d4-all-og-091621,_GPT_3_prompt_with_label,accuracy (Rank),super_glue_wic,57.36677169799805,1112000
6441,xxl-lm-d4-all-og-091621,_affirmation_true_or_false,accuracy (Rank),super_glue_wic,54.85893249511719,1112000
6442,xxl-lm-d4-all-og-091621,_grammar_homework,accuracy (Rank),super_glue_wic,53.13479614257813,1112000
6443,xxl-lm-d4-all-og-091621,_polysemous,accuracy (Rank),super_glue_wic,55.79937362670898,1112000
6444,xxl-lm-d4-all-og-091621,_question_context,accuracy (Rank),super_glue_wic,55.01567459106445,1112000
6445,xxl-lm-d4-all-og-091621,_question_context_meaning,accuracy (Rank),super_glue_wic,53.44827651977539,1112000
6446,xxl-lm-d4-all-og-091621,_question_context_meaning_with_label,accuracy (Rank),super_glue_wic,52.66457748413086,1112000
6447,xxl-lm-d4-all-og-091621,_same_sense,accuracy (Rank),super_glue_wic,55.48589324951172,1112000
6448,xxl-lm-d4-all-og-091621,_similar_sense,accuracy (Rank),super_glue_wic,52.66457748413086,1112000
6449,xxl-lm-d4-091621,_GPT_3_prompt,accuracy (Rank),super_glue_wic,50.0,1100000
6450,xxl-lm-d4-091621,_GPT_3_prompt_with_label,accuracy (Rank),super_glue_wic,50.62696075439453,1100000
6451,xxl-lm-d4-091621,_affirmation_true_or_false,accuracy (Rank),super_glue_wic,49.21630096435547,1100000
6452,xxl-lm-d4-091621,_grammar_homework,accuracy (Rank),super_glue_wic,50.31348037719727,1100000
6453,xxl-lm-d4-091621,_polysemous,accuracy (Rank),super_glue_wic,50.78369903564453,1100000
6454,xxl-lm-d4-091621,_question_context,accuracy (Rank),super_glue_wic,50.15673828125,1100000
6455,xxl-lm-d4-091621,_question_context_meaning,accuracy (Rank),super_glue_wic,49.84326171875,1100000
6456,xxl-lm-d4-091621,_question_context_meaning_with_label,accuracy (Rank),super_glue_wic,50.15673828125,1100000
6457,xxl-lm-d4-091621,_same_sense,accuracy (Rank),super_glue_wic,50.94043731689453,1100000
6458,xxl-lm-d4-091621,_similar_sense,accuracy (Rank),super_glue_wic,50.94043731689453,1100000
6459,xl-lm-d4-091621,_GPT_3_prompt,accuracy (Rank),super_glue_wic,51.72413635253906,1112000
6460,xl-lm-d4-091621,_GPT_3_prompt_with_label,accuracy (Rank),super_glue_wic,50.47021865844727,1112000
6461,xl-lm-d4-091621,_affirmation_true_or_false,accuracy (Rank),super_glue_wic,49.68651962280274,1112000
6462,xl-lm-d4-091621,_grammar_homework,accuracy (Rank),super_glue_wic,49.84326171875,1112000
6463,xl-lm-d4-091621,_polysemous,accuracy (Rank),super_glue_wic,50.0,1112000
6464,xl-lm-d4-091621,_question_context,accuracy (Rank),super_glue_wic,51.88087844848633,1112000
6465,xl-lm-d4-091621,_question_context_meaning,accuracy (Rank),super_glue_wic,50.62696075439453,1112000
6466,xl-lm-d4-091621,_question_context_meaning_with_label,accuracy (Rank),super_glue_wic,50.31348037719727,1112000
6467,xl-lm-d4-091621,_same_sense,accuracy (Rank),super_glue_wic,49.84326171875,1112000
6468,xl-lm-d4-091621,_similar_sense,accuracy (Rank),super_glue_wic,52.5078353881836,1112000
